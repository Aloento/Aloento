{"posts":[{"title":"Basics of Computer Science","text":"我是真没搞明白这老师在干什么所以我按着她的板书，自己搓了一遍她写的那个字，就跟狗爬的一样 Algorithmic problems, modellingtheory of computation, modelling tools, examples What is it good for Create efficient algorithms Programming language research Efficient compiler design and construction 我们为什么要研究算法？ 构建高效算法 编程语言研究 高效编译器设计和构建 Branches of ToCAutomata theory is the study of abstract computational devices formal framework for designing and analyzing computing devices we will discuss Turing Machines. 自动机理论 是对抽象计算机的研究 用于设计和分析计算机的形式框架 我们将讨论图灵机 Computability Theory defines whether a problem is “solvable” by any abstract machines some problems are computable, some are not (e.g. travelling salesman problem) 可计算性理论 定义了一个问题是否可以被任何抽象机器解决 有些问题是可计算的，有些不是（例如旅行推销员问题） Complexity Theory studying the cost of solving problems cost = resources (e.g. time, memory) running time of algorithms varies with inputs and usually grows with the site of inputs we will discuss how to measure complexity 复杂度理论 研究解决问题的成本 成本 = 资源（例如时间，内存） 算法的运行时间随着输入而变化，通常随着输入的增大而增长 我们将讨论如何衡量复杂度 ModllingProblem -&gt; (Model) -&gt; Mathematica Frame -&gt; (Algorithm) -&gt; Solution 问题 -&gt; (模型) -&gt; 数学框架 -&gt; (算法) -&gt; 解决方案 Tools of modelling sets function number systems, coding graphs 集合 函数 数制，编码 图 Graph definitionG=(V,E) where V is finite and not empty set, V = edges, E = vertices G=(V,E) 其中 V 是有限且非空的集合，V = 边，E = 顶点 Graph Representations drawing edge and vertex list adjacency matrix 图形表示法 绘图 边和顶点的列表 邻接矩阵 Examples of graph modelsComplicated intersection traffic lights Translates to graph coloring problem and maximal independent set problem too King Arthur and the knights of the Round TableNoblemen and Noble MaidensTuring Machinesdefinition, construction, properties, transition functions What is a Turing Machine TMS are abstract models for real computers having an infinite memory(in the form of a tape) and a reading head has finite number of internal states has distinguished starting and final states (termination: accept / reject) has transition functions (Tt) (graphs) 图灵机是对真实计算机的抽象模型，它具有无限内存（以磁带的形式）和读写头 具有有限数量的内部状态 具有特殊的起始和终止状态（终止：接受/拒绝） 具有转换函数（Tt）（图） TM accepts the initial content of the tape if it terminates in an acceptingstate. Otherwise TM rejects it. TM terminates, if there is no rule with watching conditionsfor certain state and input symbols. TM is ND (non-deterministic), if such a state and set of input symbolsexist, for which there are multiple rules defined.(= from the same set of starting state and input symbols the TM has multiple outcomes) 如果图灵机终止于接受状态，则它接受磁带的初始内容。否则拒绝。 如果没有匹配的规则，则图灵机终止。 如果存在某个状态和输入符号集，对于该状态和输入符号集，有多个规则，则图灵机是非确定性的（ND）。（=从同一组起始状态和输入符号集，图灵机具有多个结果） NDTM accepts the initial content of the tape if there isa sequence of transition functions that accepts it. Thesis: For All NDTM Exsist equivalent DTM 对于所有的非确定性图灵机，都存在等价的确定性图灵机 Defining a Turing Machine defining the number of tapes &amp; head defining the tape alphabets defining the net of state, initial and terminating states,accepting and rejection terminal states From an already existing machine it is possible to head the followings: number of heads set of states constructed from the states mentioned in the TFS Universal TM: TM, which can simulate All other TM Church - Turing thesis:A function (problem) can be effectively solved &lt;=&gt; it is computable with a TM The same problems can be solved by a TM and modern computers Complexity of algorithmsmeasuring complexity, complexity classes 算法会消耗时间和内存，复杂度就是衡量消耗的指标 时间复杂度时间复杂度主要是循环导致的，我们不必把它想得太复杂下面列出的时间复杂度越来越大，执行的效率越来越低 常数阶 O(1)12let i = 1;i = i + 1; 说白了就是没有循环，即便它有几百万行 对数阶 O(logN)1234let i = 1;while (i &lt; n) { i = i * 2;} 我们可以看到，每次循环都会把 i 乘 2设循环 x 次后，i 大于 n则 2^x &gt; n，即 x &gt; log2(n) 线性阶 O(N)123for (let i = 0; i &lt; n; i++) { console.log(i);} 这个就更好理解了，循环 n 次它的前进速度明显就没有之前乘 2 的那个快了 线性对数阶 O(NlogN)12345for (let i = 1; i &lt; n; i = i * 2) { for (let j = 0; j &lt; n; j++) { console.log(j); }} 名字看的很奇怪，但实际上把 O(logN) 的代码，再循环 N 次那它的时间复杂度就是 n * logn 了 当然你也可以把 O(N) 的代码，再循环 logN 次就像上面的例子一样 平方阶 O(N^2)12345for (let i = 0; i &lt; m; i++) { for (let j = 0; j &lt; n; j++) { console.log(j); }} n * n 不就是 n^2 吗把 O(N) 的代码，再循环 N 次比之前那个还好理解 当然也可以是 m * n那时间复杂度就是 O(MN) 了 其他的还有 K 次方阶 O(N^k) 指数阶 O(2^N)一般是递归算法 O(3^N) etc. 计算T(n) 算法的执行次数T(n) = O(f(n)) 嵌套循环由内向外分析，并相乘 1234567// O(n)for (let i = 0; i &lt; n; i++) { // O(n) for (let j = 0; j &lt; n; j++) { console.log(j); // O(1) }} 时间复杂度为 O(n * n * 1) = O(n^2) 顺序执行你可以把它们的时间复杂度相加在不要求精度的情况下可以直接等于其中最大的时间复杂度 1234567891011// O(n)for (let i = 0; i &lt; n; i++) { console.log(i);}// O(n^2)for (let i = 0; i &lt; n; i++) { for (let j = 0; j &lt; n; j++) { console.log(j); }} 时间复杂度为 O(n + n^2) 或者不要求精度 O(n^2) 条件分支时间复杂度等于所有分支中最大的时间复杂度说人话就是：最麻烦的那个情况 123456789if (n &gt; 10) { // O(n) for (let i = 0; i &lt; n; i++) { console.log(i); }} else { // O(1) console.log(n);} 时间复杂度为 O(n) 空间复杂度很显然，时间复杂度并没有真正计算算法实际的执行时间那么空间复杂度一样也不是真正的占用空间 O(1)12let i = 1;i = i + 1; 代码中的变量所分配的空间，都不随数据量的变化而变化所以空间复杂度为 O(1) O(N)1234let arr = [];for (let i = 0; i &lt; n; i++) { arr.push(i);} 看到数组就表明，空间是随着 n 增大而增大的所以空间复杂度为 O(N) 计算所以说的简单一点 如果 n 增大，程序占用的空间不变，则空间复杂度为 O(1) 如果 n 增大，程序占用的空间成线性增长，那么空间复杂度就是 O(N) 如果 n 增大，程序占用的空间成平方增长，那么空间复杂度就是 O(N^2) 以此类推当然也有 O(N + M), O(logN)等 Sorting algorithms and their complexityselection sort, bubble sort, insertion sort and optimization, their analysis, theorem about maximum complexity case runtime steps 我们按时间复杂度区分，并介绍十大常用的排序算法由于这门课并不教怎么写代码，所以我们只需要了解它是怎么工作的就行了 学计算机不学写代码，行吧，当数学课上 O(N)它们都是非比较算法，不适合大量或大范围数据 计数排序Counting Sort每个桶只存储单一键值O(N + K) 对于给定的输入，统计每个元素出现的次数，然后依次把元素输出 桶排序Bucket Sort 每个桶存储一定范围的数值它需要调用其他的排序算法来完成排序所以它的实际时间复杂度受到其使用的排序算法的影响O(N * K) 基本思路是，把数据分到有限数量的桶里，然后对每个桶内部的数据进行排序最后将各个桶内的数据依次取出，得到结果 让我们看一个例子假设我们有 20 个数据，要分成 5 个桶 12345678910111213141516171819202122232425262728293031323334353637383940function bucketSort(arr: number[], bucketSize: number) { // 创建大小为 bucketSize 的桶数组 const bucket: number[][] = []; // 初始化桶数组 for (let i = 0; i &lt; bucketSize; i++) { bucket[i] = []; } // 获取数组中的最大值和最小值 const max = Math.max(...arr); // 194 const min = Math.min(...arr); // 13 // 计算桶的范围 // (194 - 13 + 1) / 5 = 36.4 const range = (max - min + 1) / bucketSize; // 将数据放入对应的桶中 for (let i = 0; i &lt; arr.length; i++) { // 计算数据应该放入的桶的索引 // 比如 63：floor(63 - 13) / 36.4) = 1 const index = Math.floor((arr[i] - min) / range); bucket[index].push(arr[i]); } // 使用其他算法，对桶内的数据进行排序 for (let i = 0; i &lt; bucketSize; i++) { bucket[i].sort((a, b) =&gt; a - b); } // 将桶内排好序的数据依次取出，得到有序序列 const result: number[] = []; for (let i = 0; i &lt; bucketSize; i++) { for (let j = 0; j &lt; bucketSize; j++) { result.push(bucket[i][j]); } } return result;} 基数排序Radix Sort根据键值的每位数字来分配桶O(d(n+r))，其中 d 是基数，n 是要排序的数据个数，r 是每个关键字的基数 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零然后，从最低位开始，依次进行一次排序这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列 O(NlogN)希尔排序Shell Sort，也称递减增量排序是插入排序的一种更高效的改进版本，它会优先比较距离较远的元素 先将整个序列，分割成若干个子序列，分别进行插入排序待整个序列基本有序时，再对整体进行插入排序 我们有 [7, 6, 9, 3, 1, 5, 2, 4] 需要排序首先我们确定增量为 4，每次缩小一半 所以我们有 4 个子序列 1234[7, 1];[6, 5];[9, 2];[3, 4]; 分别排序它们 1234[1, 7];[5, 6];[2, 9];[3, 4]; 得到 1[1, 5, 2, 3, 7, 6, 9, 4]; 然后缩小增量为 2，再次分割 12[1, 2, 7, 9];[5, 3, 6, 4]; 排序得到 1[1, 2, 3, 4, 5, 6, 7, 9]; 归并排序Merge Sort，是一种分治算法将两个或两个以上的有序表合并成一个新的有序表 把长度为 n 的序列分成两个长度为 n/2 的子序列 对这两个子序列分别采用归并排序（递归） 将两个排序好的子序列合并成一个最终的排序序列 快速排序Quick Sort应该算是在冒泡排序基础上的递归分治法 随便选择一个元素 将比这个元素小的放在左边，比这个元素大的放在右边 对左右两边的元素重复第二步，直到各区间只有一个元素 堆排序Heap Sort 构建一个大顶堆，此时，整个序列的最大值就是堆顶的根节点 将其与末尾元素进行交换，此时末尾就为最大值 然后将剩余的 n-1 个元素重新构建成一个堆，这样会得到 n 个元素的次小值 如此反复执行，便能得到一个有序序列了 O(N^2)冒泡排序Bubble Sort比较相邻的元素，如果第一个比第二个大，就交换他们两个，一直向上冒泡 选择排序Selection Sort也就是每次找到最小的元素，放到前面，重复 优化可以在找到最小元素时记录下它的位置，并在最后交换元素的时候使用该位置。这样可以避免每次都将最小元素与已排序序列的最后一个元素交换，减少了不必要的操作 例如，对于序列[5, 3, 8, 1, 9]，优化的过程如下： 第一次遍历，找到最小元素 1，然后将 1 与 5 交换[1, 3, 8, 5, 9] 第三次遍历，在剩下的序列 [5, 8, 9] 中找到最小的元素 5，然后将 5 与 8 交换[1, 3, 5, 8, 9] 插入排序Insertion Sort像打扑克时整理手牌一样，将每张牌插入到合适的位置 Basic graph algorithmsgraph searches (BFS, DFS, Dijsktra), tree traversals, longest path problems 深度优先搜索 广度优先搜索 遍历前序遍历：根结点 —&gt; 左子树 —&gt; 右子树是从最上层往下走 中序遍历：左子树 —&gt; 根结点 —&gt; 右子树是从最左边往右走 后序遍历：左子树 —&gt; 右子树 —&gt; 根结点是从最下层往上走 层次遍历：只需按层遍历即可 Dijsktra123456789 5A ----- B| || |4 6| || |C ----- D 5 首先，我们将 A 设为原点，并初始化每个顶点到原点的距离为无穷大 1234567891011121314/** * 每个顶点到原点的距离 */let dist: Record&lt;string, number&gt; = { A: 0, B: Infinity, C: Infinity, D: Infinity,};/** * 获取两个顶点之间的权重 */declare function weight(node1: string, node2: string): number; 接下来，我们要不断迭代更新每个顶点到原点的最短距离，直到所有顶点的最短距离，都被更新为最终值。 在每次迭代中，我们首先找到所有未被更新的顶点中，距离原点最近的顶点，然后更新它到原点的最短距离，并根据新的距离，更新其他顶点，到原点的距离。 从 A 向外扩散 1234dist.B = Math.min(dist.B, dist.A + weight(&quot;A&quot;, &quot;B&quot;)) = Math.min(Infinity, 0 + 5) = 5; 1234dist.C = Math.min(dist.C, dist.A + weight(&quot;A&quot;, &quot;C&quot;)) = Math.min(Infinity, 0 + 4) = 4; 从 B 向外扩散 1234dist.D = Math.min(dist.D, dist.B + weight(&quot;B&quot;, &quot;D&quot;)) = Math.min(Infinity, 5 + 6) = 11; 从 C 向外扩散 1dist.D = Math.min(dist.D, dist.C + weight(&quot;C&quot;, &quot;D&quot;)) = Math.min(11, 4 + 5) = 9; 得到结果 123456dist = { A: 0, B: 5, C: 4, D: 9,}; 所以，从 A 到 D 的最短距离为 9 Graph diagnosticsGraph diagnostic problems are graph problems that can be answered with Y/N. Connectivity A graph G is connected, if for any two nodes there exists a walk between them. 连通性是指图中任意两个顶点之间是否存在一条路径，使得两个顶点可以互相到达。如果一个图中的任意两个顶点都可以互相到达，那么这个图就被称为连通图。 要判断一个图是否连通，可以使用搜索算法，如广度优先搜索或深度优先搜索。搜索时，从图中的任意一个顶点开始，并尝试访问该顶点的所有邻接点。如果能够访问到图中所有的顶点，那么这个图就是连通图。 Absolute winner绝对赢家指的是一个结点，它在一个博弈论游戏中总是能够获胜。这意味着，不论对手采取什么策略，该结点都有某种优势，使它能够获胜。例如，如果一个结点具有更多的邻居，那么它就可能是一个绝对赢家，因为它可以通过与其他结点交换信息来获得更多的有利条件。 绝对赢家与相对赢家有所不同。相对赢家指的是在某些情况下，某个结点比其他结点更有优势，从而使它有可能获胜。但是，如果对手采取了特定的策略，那么这个结点可能就不再是赢家了。而绝对赢家则不存在这种情况，它总是能够获能，不管对手采取什么策略。 Complete node, logical formulas完全节点是指，这个节点与其他任何节点都至少存在一条边 至于 logical formulas，指的是 FDNF disjunctive normal form它与 DNF 不同点似乎是每个出现的变量都会出现在每个子句中 Graph coloringVertex顶点着色的规则是，任意两个相邻的顶点不能有相同的颜色。并且我们使用尽可能少的颜色来着色。 我们从图中的一个顶点开始，为它分配一种颜色。然后，我们按照顶点的顺序遍历图中的其他顶点，为每个顶点分配一种与相邻顶点不同的颜色 Brooks theorem描述了图的着色数与图中最大度数的关系，提供了图着色数的一个上界 如果一个无向图 G 满足以下条件，那么它可以用 Δ(G) 或更少的颜色染色： G 是一个连通图（即它不包含任何脱离的部分） G 不包含任何奇环（即它不包含任何长度为奇数的环） Δ(G) 指的是图 G 中最大的度数。 Degree度数指的是一个顶点与其相邻顶点之间的边的数量度数可以用来衡量一个顶点与其他顶点的连通性。通常情况下，一个顶点的度数越大，它与其他顶点的连通性就越强 Four color theorem如果一个平面图 G 不包含任何环，那么它可以用不超过 4 种颜色染色，使得相邻的两个区域拥有不同的颜色。 Subgraph在原图中选择一些节点和边，并从原图中删除其他的节点和边。这样得到的图就是原图的一个子图。如果一个节点的度数为 2，那么我们可以删除该节点，并将它与其他两个节点之间的两条边”合并”成一条边。 Edge给图中的边分配颜色，使得图中相邻的边拥有不同的颜色 Chromatic index 是图的最小着色度，指需要多少种不同的颜色 Vising theorem 指 对于任意一个无向图，它的染色度（chromatic number）不会超过其度数（degree）的上限 Bipartite graphs 是一种二分图，它由两个部分组成，每个部分内部的点互不相邻，而两个部分之间的点才会相互相邻。 Planar graphs 则是一种平面图，它是指图中任意两条边都不会相交，也就是说，图中的边可以在平面上放置而不会交叉。 Scheduling problems 例如，在一个工厂生产线上，有许多不同的机器和工人，他们需要按照特定的顺序来完成各种任务。为了让生产流程顺利进行，我们可以使用 edge coloring 算法来给每个任务分配一种颜色，并确保相邻的任务颜色不同。这样，工人和机器就可以按照颜色顺序来执行任务，从而保证生产流程的顺利进行。 Packing and CoveringGeneralizationGeneral, “everyday” problems, which have suboptimal solutions: Put in objects into one container!Some pairs are incompatible, those cannot be put into the container together.Question: how to put the maximal number of objects into the container? n people at a meeting.Find the largest subgroup of them, in which everybody knows everybody! Trucker delivering goods with no going backQuestion: how can they deliver the maximum number of goods? Big piece of leather, cutting out small shapes.Question: how to cut out the largest amount of smaller shapes? Common property of these problems: representable with a graph similarly.Is there any connection between their solutions? Let’s look at the problems solutions, starting with the “easiest”: 一般来说，“日常” 问题，它们有着次优解： 把物品放入一个容器中有些物品是不兼容的，它们不能放在同一个容器中问题：如何把最多的物品放入容器中？ n 个人在会议中找到其中最大的一个子集，其中每个人都认识 卡车司机送货，不允许回头 大块皮革，切割成小块。问题：如何切割出最多的小块？ 这些问题的共同特点：它们可以用图来表示 Disjoint Interval Search Trucker delivering goods with no going backQuestion: how can they deliver the maximum number of goods? Disjoint Interval Search (DIS)This problem is also called interval packing. 绎演丁真，鉴定为史 如果一个卡车司机要把货物送到多个不同的地方，而且一旦离开一个地方就不能再回去，那么他应该怎样才能把尽可能多的货物送到目的地呢？ 我寻思着这问题应该用 TSP 来解才对总之先看看什么是 DIS DIS 是一种用于处理区间数据的算法。区间数据是指一组由起始和结束点表示的区间，例如：[1, 5]、[10, 15] 等。它能够快速检索出与给定的区间不相交的区间。 将区间数据存储在能够快速查找和插入的数据结构中，例如红黑树、平衡树或 B 树 查找与给定区间不相交的区间检查区间数据中的每一个区间，并判断它们是否与给定区间不相交如果一个区间与给定区间不相交，则将其加入结果集。 返回结果集 Cliquen people at a meeting.Find the largest subgroup of them, in which everybody knows everybody! Can we find three people like that?Can we find four people like that?Can we find five people like that? Why not?Clique search 衣掩丁真，鉴定为衣驼使 这是一个分团问题Clique search 是一种用于寻找图中的完全子图（即“clique”）的算法完全子图是指一个子图中所有节点都相互连通算法需要枚举所有可能的完全子图，并确定哪些子图满足给定的条件 Maximal Independent SetPut in objects into one container!Some pairs are incompatible, those cannot be put into the container together.Question: how to put the maximal number of objects into the container? Edges code incompatibility.We are searching for independent node subsets.Maximal Independent Set (MIS) We found a maximal empty subgraph. Connection with the previous problem?If we create the complimenting graph from this (where we had an edge, now we don’t have one, and vice versa), and consider the same chosen nodes, then that is a clique. So we can convert this problem into the previous one: MIS → Clique search These problems are basically the same, only their representation is different. In this sense, even problem no.3 is the same as no.1 and no.2. Converting problem no. 3 to the present form: Intervals are going to turn into vertices of a graph.If two intervals are incompatible, we draw an edge between the corresponding nodes. We converted DIS into MIS. Maximal Independent Set 是指一个图中没有一个节点与其他节点相邻，并且该集合不能再增加任何节点而保持这种性质的节点集合 一个独立集（也称为稳定集）是一个图中一些两两不相邻的顶点所形成的集合，如果两个点没有公共边，那么这两个点可以被放到一个独立集中 对于三个点组成的完全图而言，每个点自身是一个独立集（且是最大独立集）对四个点构成的四边形图而言，对角的两个点组成一个独立集（且是最大独立集） 如果往图 G 的独立集 S 中添加任一个顶点都会使独立性丧失（亦即造成某两点间有边），那么称 S 是极大独立集。 如果 S 是图中所有独立集之中基数最大的，那么称 S 是最大独立集，且将该基数称为 G 的独立数，记为 α(G)。一般来讲，图 G 中可能存在多个极大独立集和最大独立集。 根据定义，最大独立集一定是极大独立集，但反之未必。 CutBig piece of leather, cutting out small shapes.Question: how to cut out the largest amount of smaller shapes? 大块的皮革，切出小的形状。问：如何切出最多的小形状？ We can rotate the sample, but we still have to fit into the big piece of leather. 我们可以旋转样本，但我们仍然要贴合大块皮革。 This is the most difficult problem out of the four, because the main “philosophical” difference between them is that the first three were obvious finite problems (finite number of people, objects, intervals), whereas this problem cannot produce obvious finite number of nodes. 这是四个问题中最困难的一个，因为它们之间的主要“哲学”区别在于前三个是显然的有限问题（人数、物品数、区间数都是有限的），而这个问题不能产生显然的有限节点数。 So we make a grid on the big leather, place a node on the shape, and say that the shape can only be cut out of that node fits on one of the grid points. 因此，我们在大皮革上做一个网格，在形状上放一个节点，并说形状只能在该节点适合网格点之一时被切出来。 The grid points create a finite set. But since we can still rotate the shape around the grid point, our choices are infinite again. Solution: we only consider a few angles. So now we can only cut out the shape if the node is ou a grid point, and the line on the sample can only parallel to one of our predefined angle lines. 网格点创建了一个有限集。但是，由于我们仍然可以围绕网格点旋转形状，所以我们的选择又是无限的。解决方案：我们只考虑几个角度。因此，现在我们只能在节点在网格点上并且样本上的线只能与我们预定义的角度线平行时切出形状。 So to make an infinite problem finite we need to add restrictions. 因此，要使无限问题变为有限，我们需要增加限制。 We can code the placement with the number of the grid point and the number of the angle.Eg: (5; 6) and (14; 6). 我们可以用网格点的编号和角度的编号来编码放置位置。例如：（5；6）和（14；6）。 However, these two overlap, so they cannot be cut out together. This incompatibility can be represented in a graph by adding an edge between these two number pains. 然而，这两个重叠了，因此它们不能一起切出来。这种不兼容可以通过在这两个数字之间添加一条边来表示在图中。 This way we can create a graph, and the maximum number of cutouts on the leather is reduced to finding the maximal number of independent nodes in the corresponding graph. 这样我们就可以创建一个图，皮革上的最大切割次数就被减少到在相应图中找到最大的独立节点数。 What is the problem with this method?The restrictions can cause a result with less cutouts, than if we could freely place the shape. 这种方法有什么问题？限制可能导致切割次数比我们可以自由放置形状时少的结果。 Solution: let’s use a denser grid and consider none rotational angles! 解决方案：让我们使用更密集的网格并考虑非旋转角度！ Problem with the solution: as we have more gridpoints and angles, the graph becomes larger, so finding the MI5 is more complicated. 解决方案的问题：随着我们有更多的网格点和角度，图变得更大，因此找到 MI5 变得更复杂。 So this method is a digitalization, which has a resolution. The bigger the resolution is, the closer to the optimal solution we are. 因此，这种方法是一种数字化，它具有分辨率。分辨率越大，我们越接近最优解。 总结Ater examining these four problems, we have a general framework: 在经过对这四个问题的检查后，我们得出了一个总体框架： Given is a graph. Find the maximal number of nodes such that those are never connected to each other. &lt;=&gt; We want to find the maximal independent set of nodes. → MIS problem. 给定一张图。找到一个节点的最大数量，这些节点从不相互连接。&lt;=&gt;我们想找到节点的最大独立集合。→MIS 问题。 This can be solved in exponential time. 这可以在指数时间内解决。 The trivial algorithm for finding MIS: 找到 MIS 的简单算法： We want to find MIS of { 1, 2, 3, 4, 5, 6 }. We try to find an independent subset of size 2. Start with 41,2}. Is this independent? No! So try { 1, 3 }. This is good! But then can we find an independent subset of nite 3? We need to check all site 3 subsets. 我们想找到 {1,2,3,4,5,6} 的 MIS。我们试图找到大小为 2 的独立子集。从 {1,2} 开始。这是独立的吗？不是！所以尝试 {1,3}。这很好！但是然后我们能找到大小为 3 的独立子集吗？我们需要检查所有大小为 3 的子集。 In the worst case we need to investigate all subsets of { 1, 2, 3, 4, 5, 6 } 在最坏的情况下，我们需要调查 {1,2,3,4,5,6} 的所有子集 Theorem: If |x| = n, then |p(x)| = 2^n. (p(x) = { y | y &lt;= x } -&gt; power set = set of all subsets) In our example n = 6, so we have 2^6 = 64 subsets. How to code subsets? { 1, 2, 3, 4, 5, 6 } 1 0 1 0 0 0 1 1 0 0 0 1 -&gt; this will code { 1; 3 }-&gt; this will code { 1; 2; 6 } Since it is a one-to-one correspondence between subsets and outshines,then |p(x)| = |{ binary string of length 8 }| 因为子集和出现之间是一一对应的，所以 |p(x)| = |{长度为 8 的二进制字符串}| because a choice codes 1 On 0 = yes or no 因为选择编码 1 On 0 = yes or no In terms of our MIS - finding problem: if we count checking a binary string for independence, then this trivial algorithm has an exponential runtime, exactly 2^n. 就我们的 MIS 查找问题而言：如果我们算出检查一个二进制字符串是否独立的次数，那么这个简单算法的运行时间是指数级别的，精确地说是 2^n。 A more refined algorithm for the same problem:Find a method, where we only check already independent sets. 同一问题的一种更优秀的算法：找到一种方法，只检查已经独立的集合。 Example: The independent set is called S.We always ask the nodes whether they are an element of S. → “yes” branches and “no” branches. Next question is based on already existing elements. 独立集合称为 S。我们总是问节点是否是 S 的元素。→“是”和“否”分支。下一个问题是基于已存在的元素。 This is a labelled and rooted binary thee.Can be done faster, if we are only considering paths that have a chance to have enough nodes on them.“if it’s not there, don’t even look” 这是一棵带标签和根的二叉树。如果我们只考虑可能有足够节点的路径，可以更快地完成。“如果它不在那里，甚至都不用看”。 Interval packing, dominating setsA little help for the next algorithm: the Pidgeon-hole principle. 下一算法的一点帮助：鸽巢原理。 Question: when the pigeons go to their pigeon-holes, what can we state for sure?Whichever houses they choose, there is going to be at least one hole with two pigeons in it. 问题：当鸽子去它们的鸽巢时，我们能肯定什么？无论它们选择哪所房子，至少会有一个洞有两只鸽子。 So the pigeon-hole principle says that if there are more pigeons than houses, then there will be at least one hole with at least two pigeons in it. 因此，鸽巢原理说，如果有比房子更多的鸽子，那么至少会有一个洞至少有两只鸽子。 If this weren’t true, and all houses tould contain one pigeon at worst, then there would be only as many pigeons as houses. Whereas we had more pigeons. 如果这不是真的，并且所有的房子里最多只有一只鸽子，那么只会有和房子一样多的鸽子。但我们有更多的鸽子。 If we use our previous example 3, we can apply the pigeon-hole principle to the problem: 如果我们用之前的例子 3，我们可以将鸽巢原理应用于问题： The algorithm: choose closest destination, if starting point is still ahead=&gt; maximal number of =&gt; independent intervals =&gt; Interval packing algorithm 算法：如果起点仍然在前面，则选择最近的目的地=&gt;最大数量的=&gt;独立区间=&gt;区间打包算法 If we only consider the destinations as pink dots, then we can choose any interval, there will always be a pink dot on it - at least one dot.=&gt; the set of pink dots is a dominating set. 如果我们只考虑目的地作为粉红色点，那么我们可以选择任何区间，它上面总会有一个粉点——至少有一个点。=&gt;粉点集是一个支配集。 A set X is a dominating set, if for every you find at least one element of the set on that interval. 一个集合 X 是支配集，如果对于每个区间都能找到集合中的至少一个元素。 Femina: X is a dominating set, 4 is an independent set of intervals.Then |x| &gt;= |y|. X 是支配集，4 是区间的独立集。 The chosen intervals corresponding to the transportation is an independent set with three intervals. There are also three pink dots as the dominant set. So based on the lemma, there can be no more independent intervals. 选择的区间对应于运输是具有三个区间的独立集。还有三个粉红色的点作为支配集。因此，根据引理，不能有更多的独立区间。 Proof: Indirectly. New statement: |x|birds &lt; |y|houses. Let’s have one more independent interval. But according to the pigeon-hole principle, there is at least one pint dominating dot on every interval. In order to dominate the all intervals, we would need at 1 different pink dots. 让我们再来一个独立区间。但根据鸽巢原理，每个区间都至少有一个主要点。为了控制所有区间，我们需要至少 1 个不同的粉点。 =&gt; There must be at least two intervals with the same pink dot,but then they’re not independent. =&gt; 必须有至少两个区间有相同的粉点，但这样它们就不是独立的了。 Even though there is no general quick (polynomial) solution forfinding MIS, the Interval pairing algorithm is fast. How fast? 尽管没有求解 MIS 的通用快速（多项式）解决方案，但 Interval pairing 算法是快速的。它有多快？ We shone all starting and destination point somehow - e.g. by numbers.So we only have to order them, and find the “smallest” endpoint first. 我们用某种方式给所有起点和终点标号——例如，用数字。所以我们只需要按顺序排序，找到“最小”的终点。 ~n steps needed to find the closest destinationwe need to repeat it at worst a times =&gt; polynomial algorithm 找到最近目的地需要 ~n 步最坏情况下，我们需要重复 a 次，所以这是一个多项式算法 How can it be that MI5 can’t be solved quickly, but this algorithm has quadratic runtime?! 为什么 MI5 无法快速解决，但这个算法的运行时间是二次的呢？ The intervals are represented as nodes and overlaps as edges in the graph.So did we just solve MI5 in quadratic time?! 区间在图中表示为节点，重叠部分表示为边。所以我们刚刚在二次时间内解决了 MI5 吗？ No! Because not all graphs can be processed by this method. (Not all graphs with a nodes occur this way.) so we only solved MI5 for a subset of graphs having a nodes. 不是的！因为并不是所有图都可以用这种方法处理。（不是所有带有 n 个节点的图都是这样出现的。）所以我们只为一个带有 n 个节点的图子集解决了 MI5。 So for a subset of cases we have a solution, but not for the general case.(e.g. 5th degree polynomials) 所以对于一个子集的情况，我们有一个解决方案，但不是通用情况。（例如，五次多项式） 区间打包，用于找到最多可以放在一个容器内的不相交区间的最大数量。是指把一系列区间尽可能多地放到一个集合中，使得它们都不重叠。 支配集指在一张图中，存在一组节点，每个节点都与它相邻的节点相连，或者至少有一个节点在该组中。其中的元素可以覆盖整个集合，即每个元素都与至少一个其他元素有交集。 Suboptimal algorithms次优算法 what is the basic problem?→ polynomial algorithms are “quick”→ exponential algorithms are “very slow” 基本问题是什么？→ 多项式算法“快”→ 指数算法“非常慢” There is a set of problems for which there is no quick algorithm. 有一类问题没有快速算法。 Their runtime is proportionate to f(a) =2^n. To put this in perspective, there are no more than 2^350 atoms in the whole universe. 它们的运行时间与 f(a) = 2^n 成比例。为了更好地理解这一点，整个宇宙中没有超过 2^350 种原子。 Therefore we can just use this disadvantage to our advantage by using these kind of problems for coding protocols, as decoding them would tale over a million years. 因此，我们可以利用这个缺点，通过使用这类问题来编写编码协议，因为解码它们需要超过一百万年。 Good example for this is finding a Hamiltonian cycle in a graph. Creating is easy, but then we can obfuscate it. 寻找图中的汉密尔顿回路是一个很好的例子。创建容易，但是我们可以混淆它。 Problem is, that there are a lot of real-life situations that can only be converted into these kinds of problems, where the solution is exponential, or even worse. 问题是，有很多现实生活中的情况只能转换为这类问题，其解是指数级的，甚至更糟。 Good example is the traveling agent problem. This is understood on weighed graphs, and the point is to touch all the nodes with a minimal sum of edge weights. (Hamiltonian path problem). 一个很好的例子是旅行代理问题。这在加权图上是可以理解的，其目的是以最小的边权和触摸所有节点。（汉密尔顿路径问题） In this case we can imagine a package delivery service, in which case we need the shortest possible combination / permutation of the packages in order to make the least amount of kilometers. Though, this is a hard problem, meaning, there exists not a quick algorithm for this. 在这种情况下，我们可以想象一个包裹配送服务，在这种情况下，我们需要包裹的最短可能组合/排列，以便减少尽可能多的公里数。尽管这是一个难题，即不存在一个快速的算法来解决这个问题。 =&gt; suboptimal algorithms-&gt; We don’t want to (= can’t) find the best solution, but something that is pretty close this best solution. =&gt; 次优算法-&gt; 我们不想（也不能）找到最优解，而是找到一个非常接近最优解的解决方案。 So in case of the traveling agent, we don’t want to find the optimal route, but we want a route such that it is sure that it uses at more Klia as many kilometers as the optimal one. It would be a 2-optimal algorithm. 所以在旅行代理的情况下，我们不想找到最优路线，而是想找到一条路线，使得它确保它使用的公里数至少与最优路线相同。这将是一个 2-optimal 算法。 So the suboptimality of algorithms has nothing to do with running time. 因此，算法的次优性与运行时间无关。 In the traveling agent situation a 3-optimal algorithm would find a solution that is at most three times worse than the optimal one, meaning, it would find a permutation of the target adnesses such that if the driver follows that order, than at most three times as many kilometers are used as in case of the optimal solution. 在旅行代理的情况下，3-optimal 算法将找到一个至多比最优解差三倍的解决方案，这意味着它会找到目标地址的一个排列，如果司机遵循这种顺序，那么至多会使用三倍于最优解情况下的公里数。 An algorithm is called k-optimal (k ≥ 1) if its output is at most b-times worse than the best output would be. 如果其输出最多比最佳输出差 b 倍，则称该算法为 k-optimal（k ≥ 1）。 Bin packing problem Objects with volumes:V1, V2, V3 … Vn. Vi &lt;= (i = 1, …, n) Problem: use the least amount of containers to store all objects. 问题：使用最少的容器来存储所有物品。 (The sum of the volumes of objects in one container can’t exceed volume of the container.) （一个容器中物品的总体积不能超过容器的体积。） This is a hard problem. But there exists a 2-optimal algorithm for that. 这是一个难题。但是存在一个 2-optimal 算法。 First Fit Algorithm: Choose the first container in which the object fits. (This is greedy.) 首次适应算法：选择第一个容器，其中的物品适合。（这是贪婪的。） 降序首次适应算法First Fit Decreasing 将物品按照价值从大到小排序 找到一个能放下物品的背包，放入物品 重复 2，直到所有物品都放入 简而言之，FFD 按照大小降序排列项目，然后放入第一合适的背包 Algebraic algorithmsDivisibility, Euclidean algorithmFaster multiplication and division of large numbers","link":"/Algorithm/Basics-of-Computer-Science/"},{"title":"DAA Midterm Exam","text":"The Midterm Exam for Design and Analysis of Algorithms直接一套连招被送走，我真的是命苦 Gale-Shapley Boys b1 g2 g4 g3 g1 g5 b2 g3 g2 g1 g5 g4 b3 g2 g1 g3 g5 g4 b4 g4 g3 g5 g1 g2 b5 g2 g4 g3 g1 g5 Girl g1 b2 b5 b1 b3 b4 g2 b2 b3 b1 b4 b5 g3 b4 b2 b5 b1 b3 g4 b3 b1 b5 b2 b4 g5 b5 b3 b4 b1 b2 Solution Day g1 g2 g3 g4 g5 1 - b1, b3, b5 b2 b4 - 2 - b3 b2 b4, b1, b5 - 3 - b3 b2, b4, b5 b1 - 4 b5 b3, b2 b4 b1 - 5 b5, b3 b2 b4 b1 - 6,7 b5 b2 b4 b1 b3 (g1, b5), (g2, b2), (g3, b4), (g4, b1), (g5, b3) Stable MarriageIf it is true, give a short explanation. Otherwise, give a counterexample. ExistenceIn every instance of the Stable Marriage Problem, there is a suitable matching containing a pair $(b, g)$ such that $b$ is ranked first on the preference list of $g$ and $g$ is ranked first on the preference list of $b$. SolutionFalse, consider the following case: Boys b1 g1 g2 b2 g1 g2 Girl g1 b2 b1 g2 b1 b2 (b1, g2), (b2, g1) is the only stable matching. b2 and g1 are both first on each other’s preference list.But we cannot find a pair where b1 and b2 are each other’s first preference.So it’s not true for every instance. BelongingConsider an instance of the Stable Marriage Problem in which there exists a boy $b$ and a girl $g$ such that $b$ is ranked first on the preference list of $g$ and $g$ is ranked first on the preference list of $b$. Then every stable marriage $M$ for this instance, the pair $(b, g)$ belongs to $M$. SolutionTrue. If $b$ and $g$ rank each other first, then any pairing where they are not matched would be unstable. Because if either $b$ or $g$ where matched with someone else, they would both prefer to be matched with each other, leading to an unstable pairing. So, in any stable pairing $M$, $b$ and $g$ must be matched. Master Method$T(n) = 4T(n/2) + n$$a = 4, b = 2, f(n) = n, n^{\\log_{b} a} = n^2$ $T(n) = 6T(n/3) + n^2$$a = 6, b = 3, f(n) = n^2, n^{\\log_{b} a} = n^{\\log_{3} 6} \\approx n^{1.63} &lt; n^2$ $af(n/b) = 6(n/3)^2 = \\frac{2}{3}n^2$ $c = \\frac{2}{3} &lt; 1$ $T(n) = n^2$ $T(n) = 8T(n/2) + n^3$$a = 8, b = 2, f(n) = n^3, n^{\\log_{b} a} = n^3 = f(n)$ $T(n) = n^3 \\log n$ Significant InversionRecall the problem of finding the number of inversions: we are given a sequence of n numbers $a_1, a_2, \\cdots, a_n$, which we assume are all distinct, and we define an inversion to be a pair $i &lt; j$ such that $a_i &gt; a_j$. We motivated the problem of counting inversions as a good measure of how different two orderings are. However, one might feel that this measure is too sensitive. Let’s call a pair a significant inversion if $i &lt; j$ and $a_i &gt; 2a_j$. Give an $O(n \\log n)$ divide and conquer algorithm to count the number of significant inversions in a sequence of n pairwise distinct numbers $a_1, a_2, \\cdots, a_n$. Solution123456789101112131415161718192021222324function mergeAndCount(left: number[], right: number[]): [number[], number] { let i = 0, j = 0, inversions = 0; const sorted: number[] = []; while (i &lt; left.length &amp;&amp; j &lt; right.length) { if (left[i] &lt;= 2 * right[j]) { sorted.push(left[i]); i++; } else { // Since left[i] &gt; 2 * right[j], all remaining elements in left are also inversions. inversions += left.length - i; sorted.push(right[j]); j++; } } // Append any remaining elements (no further inversions can be found here) while (i &lt; left.length) sorted.push(left[i++]); while (j &lt; right.length) sorted.push(right[j++]); return [sorted, inversions];} Largest Contiguous SumGive a $O(n \\log n)$ time divide and conquer algorithm to find a contiguous subarray within a one-dimensional array $A[1 : n]$ of real numbers which has the largest sum, i.e., find indices $1 \\leq i \\leq j \\leq n$ such that$$ A[i] + A[i+1] + \\cdots + A[j] $$is as large as possible. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162function findMaxCrossingSubarray( A: number[], low: number, mid: number, high: number): [number, number, number] { let leftSum = -Infinity; let sum = 0; let maxLeft = mid; for (let i = mid; i &gt;= low; i--) { sum += A[i]; if (sum &gt; leftSum) { leftSum = sum; maxLeft = i; } } let rightSum = -Infinity; sum = 0; let maxRight = mid; for (let j = mid + 1; j &lt;= high; j++) { sum += A[j]; if (sum &gt; rightSum) { rightSum = sum; maxRight = j; } } return [maxLeft, maxRight, leftSum + rightSum];}function findMaximumSubarray( A: number[], low: number, high: number): [number, number, number] { if (high === low) { return [low, high, A[low]]; // Base case: only one element } else { const mid = Math.floor((low + high) / 2); const [leftLow, leftHigh, leftSum] = findMaximumSubarray(A, low, mid); const [rightLow, rightHigh, rightSum] = findMaximumSubarray( A, mid + 1, high ); const [crossLow, crossHigh, crossSum] = findMaxCrossingSubarray( A, low, mid, high ); if (leftSum &gt;= rightSum &amp;&amp; leftSum &gt;= crossSum) { return [leftLow, leftHigh, leftSum]; } else if (rightSum &gt;= leftSum &amp;&amp; rightSum &gt;= crossSum) { return [rightLow, rightHigh, rightSum]; } else { return [crossLow, crossHigh, crossSum]; } }}","link":"/Algorithm/DAA-Midterm-Exam/"},{"title":"DAA Midterm Revision","text":"重修此课喜提 60 元账单 Gale-Shapley算法在 $(n - 1)^2 + 1$ 天内结束 习题 1 Girl g1 b3 b5 b2 b1 b4 g2 b5 b2 b1 b4 b3 g3 b4 b3 b5 b1 b2 g4 b1 b2 b3 b4 b5 g5 b2 b3 b4 b1 b5 Boys b1 g3 g2 g5 g1 g4 b2 g1 g2 g5 g3 g4 b3 g4 g3 g2 g1 g5 b4 g1 g3 g4 g2 g5 b5 g1 g2 g4 g5 g3 解题方法复习 习题 2有 n 名男演员和 n 名女演员，其中，有 k 名高个男演员和 k 名金发女演员。每位男演员都更喜欢金发女演员，每位女演员都更喜欢高个男演员。请证明，在稳定匹配中，高个男演员会匹配金发女演员，矮个男演员会匹配非金发女演员。 题解 假设有稳定匹配 (b_矮个, g_金发)，由于男女数量相同，必定有 (b_高个, g_黑发)。但根据规则，高个更喜欢金发，所以 (b_高个, g_金发) 是 rogue copule，与稳定匹配矛盾。 习题 3证明如果所有女生的偏好列表都相同，那么只存在唯一的稳定匹配。 假设有两组稳定匹配，A / B，有 (g, b)_A 和 (g, b')_B。由于所有女生的偏好列表相同，所以匹配完全由男生的偏好列表决定。若要让 g 能够与 b' 匹配，则必定所有女生都更喜欢 b' 而不是 b，这就导致在 A 中产生了 (g, b') 的 rogue couple，与 A 的稳定性矛盾。 习题 4证明不存在任何一种匹配（无论是否稳定），使得所有男生都比使用 Gale-Shapley 算法时的匹配结果更好。 设有匹配，使得所有男生都获得了比 GS 更好的结果，这意味着每个男生都与他匹配列表中更高的女孩匹配了，所以至少有一个男生与在 GS 算法中拒绝过他的女生匹配。但根据 GS 的规则，算法结束时每个男生都无法与他偏好列表中更高位的女生配对，因为她一定在某个时刻拒绝了他，并跟她更喜欢的男生匹配。所以如果一定要让一个男生获得更好的匹配，那么必定要拆散已经存在的匹配，这就导致另一个男生无法得到他更喜欢的女生。 习题 5在每个稳定婚姻问题的实例中，是否必定存在一个合适的匹配，其中包含一对 $(b, g)$，使得 $ b $ 在 $ g $ 的偏好列表中排名第一，且 $ g $ 在 $ b $ 的偏好列表中排名第一？ 并不，考虑以下情况 (12 21 21 12) B_1 -&gt; (G_1, G_2)，B_2 -&gt; (G_2, G_1) 和G_1 -&gt; (B_2, B_1)，G_2 -&gt; (B_1, B_2)。 有稳定匹配 (B_1, G_1)，(B_2, G_2) 和 (B_1, G_2)，(B_2, G_1)。它们均不同时是双方的第一选择。 习题 6考虑一个稳定婚姻问题的实例，其中存在一名男生 $ b $ 和一名女生 $ g $，使得 $ b $ 在 $ g $ 的偏好列表中排名第一，且 $ g $ 在 $ b $ 的偏好列表中排名第一。那么，在该实例的任何稳定匹配 $ M $ 中，配对 $ (b, g) $ 是否都属于 $ M $？ 是的。设存在 M'，有稳定匹配 (b, g')，那么一定存在 (b', g)。但由于 g 与 b 都相互最喜欢，则导致 (b, g)是 rogue couple，与稳定性矛盾。 算法实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129function validateInput( boysPreferences: string[][], girlsPreferences: string[][]): void { const n = boysPreferences.length; if (n !== girlsPreferences.length) { throw new Error(&quot;男孩和女孩的数量必须相等。&quot;); } const boys = new Set&lt;string&gt;(); const girls = new Set&lt;string&gt;(); for (let i = 0; i &lt; n; i++) { boys.add(`b${i + 1}`); girls.add(`g${i + 1}`); } for (let i = 0; i &lt; n; i++) { const boyPref = boysPreferences[i]; if (boyPref.length !== n) { throw new Error(`男孩 b${i + 1} 的偏好列表长度必须等于总数。`); } const boyPrefSet = new Set(boyPref); if ( boyPrefSet.size !== n || !Array.from(boyPrefSet).every((g) =&gt; girls.has(g)) ) { throw new Error(`男孩 b${i + 1} 的偏好列表不完整或包含重复。`); } const girlPref = girlsPreferences[i]; if (girlPref.length !== n) { throw new Error(`女孩 g${i + 1} 的偏好列表长度必须等于总数。`); } const girlPrefSet = new Set(girlPref); if ( girlPrefSet.size !== n || !Array.from(girlPrefSet).every((b) =&gt; boys.has(b)) ) { throw new Error(`女孩 g${i + 1} 的偏好列表不完整或包含重复。`); } }}function getIndex(id: string): number { return parseInt(id.substring(1)) - 1;}function findStableMatching( boysPreferences: string[][], girlsPreferences: string[][]): Map&lt;string, string&gt; { validateInput(boysPreferences, girlsPreferences); const n = boysPreferences.length; const boyToGirl = new Map&lt;string, string&gt;(); const girlToBoy = new Map&lt;string, string&gt;(); const freeBoys: string[] = []; for (let i = 0; i &lt; n; i++) { freeBoys.push(`b${i + 1}`); } // 预处理女孩的偏好排名 const girlRankings = new Map&lt;string, Map&lt;string, number&gt;&gt;(); for (let i = 0; i &lt; n; i++) { const girl = `g${i + 1}`; const ranking = new Map&lt;string, number&gt;(); for (let j = 0; j &lt; girlsPreferences[i].length; j++) { const boy = girlsPreferences[i][j]; ranking.set(boy, j); } girlRankings.set(girl, ranking); } while (freeBoys.length &gt; 0) { const boy = freeBoys.shift()!; const preferences = boysPreferences[getIndex(boy)]; for (const girl of preferences) { if (!girlToBoy.has(girl)) { // 女孩未匹配 boyToGirl.set(boy, girl); girlToBoy.set(girl, boy); break; } else { const currentBoy = girlToBoy.get(girl)!; const ranking = girlRankings.get(girl)!; const currentRank = ranking.get(currentBoy)!; const newRank = ranking.get(boy)!; if (newRank &lt; currentRank) { // 女孩更喜欢当前男孩 boyToGirl.delete(currentBoy); girlToBoy.delete(girl); boyToGirl.set(boy, girl); girlToBoy.set(girl, boy); freeBoys.push(currentBoy); break; } } } } return boyToGirl;}const boysPreferences: string[][] = [ [&quot;g2&quot;, &quot;g4&quot;, &quot;g3&quot;, &quot;g1&quot;, &quot;g5&quot;], // b1 的偏好 [&quot;g3&quot;, &quot;g2&quot;, &quot;g1&quot;, &quot;g5&quot;, &quot;g4&quot;], // b2 的偏好 [&quot;g2&quot;, &quot;g1&quot;, &quot;g3&quot;, &quot;g5&quot;, &quot;g4&quot;], // b3 的偏好 [&quot;g4&quot;, &quot;g3&quot;, &quot;g5&quot;, &quot;g1&quot;, &quot;g2&quot;], // b4 的偏好 [&quot;g2&quot;, &quot;g4&quot;, &quot;g3&quot;, &quot;g1&quot;, &quot;g5&quot;], // b5 的偏好];const girlsPreferences: string[][] = [ [&quot;b2&quot;, &quot;b5&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;b4&quot;], // g1 的偏好 [&quot;b2&quot;, &quot;b3&quot;, &quot;b1&quot;, &quot;b4&quot;, &quot;b5&quot;], // g2 的偏好 [&quot;b4&quot;, &quot;b2&quot;, &quot;b5&quot;, &quot;b1&quot;, &quot;b3&quot;], // g3 的偏好 [&quot;b3&quot;, &quot;b1&quot;, &quot;b5&quot;, &quot;b2&quot;, &quot;b4&quot;], // g4 的偏好 [&quot;b5&quot;, &quot;b3&quot;, &quot;b4&quot;, &quot;b1&quot;, &quot;b2&quot;], // g5 的偏好];// 调用稳定匹配算法const stableMatching = findStableMatching(boysPreferences, girlsPreferences);// 输出匹配结果console.log(&quot;稳定匹配结果：&quot;);for (const [boy, girl] of stableMatching.entries()) { console.log(`${boy} ↔ ${girl}`);} Master Method复习 $T(n) = 2T(n/2) + n^3$ $T(n) = T(9n/10) + n$ $T(n) = 16T(n/4) + n^2$ $T(n) = 7T(n/3) + n^2$ $T(n) = 7T(n/2) + n^2$ $T(n) = 2T(n/4) + \\sqrt{n}$ 递归主导：$n^{\\log_b a}$ 平衡：$n^{\\log_b a} \\log n$ 分治主导：$f(n)$ when $af(\\frac{n}{b}) \\leq cf(n)$ where $c &lt; 1, n \\rightarrow \\infty$ Divide and Conquer题解 习题 1我们给定一个正整数数组 → $ A[1:n] $ 找到满足 $ 1 \\leq i \\leq j \\leq n $ 的索引，使得 $ A[j] - A[i] $ 最大。 朴素算法：枚举所有可能的 $ (i, j) $ 组合，并计算 $ A[j] - A[i] $，然后选择其中的最大值→ 该算法的时间复杂度为 $ O(n^2) $ 改进方法： 使用 分治法 得到 $ O(n \\log n) $ 时间复杂度的算法 进一步优化该算法，使其达到 $ O(n) $ 时间复杂度 将数组递归的平分为两份 递归找出左数组的最大差值 递归找出右数组的最大差值 找出左数组的最小值 找出右数组的最大值 计算右减左（跨中间点）的差值 返回三者中的最大值对应的两个索引 习题 2我们给定一个整数数组（可能包含负数） → $ A[1:n] $ 找到满足 $ 1 \\leq i \\leq j \\leq n $ 的索引，使得 子数组和 $ A[i] + A[i+1] + \\dots + A[j] $ 最大。 朴素算法：枚举所有可能的 $ (i, j) $ 组合，计算 子数组和 $ A[i] + A[i+1] + \\dots + A[j] $，然后选择其中的最大值→ 时间复杂度为 $ O(n^3) $ 优化方法： 使用 分治法 得到 $ O(n \\log n) $ 时间复杂度的算法 进一步优化该算法，使其达到 $ O(n) $ 时间复杂度 将数组递归的平分为两份 递归找出左侧数组的最大前缀和，最大后缀和，总和 递归找出右侧数组的最大前缀和，最大后缀和，总和 计算跨越最大合：左最大后缀和 + 右最大前缀和 三者的最大值为左右合并数组的最大子数组和 返回最大值对应的两个索引 合并数组的最大前缀和：左最大前缀 比 左总和 + 右最大前缀合并数组的最大后缀和：右最大后缀 比 右总和 + 左最大后缀前缀合：从第一个元素向后累加，[1], [1, 2], [1, 2, 3]后缀合：从最后一个元素向前累加，[3], [2, 3], [1, 2, 3] 习题 3我们给定一个包含任意对象的数组 $ A[1:n] $。如果某个对象 $ x $ 在 $ A[1:n] $ 中出现的次数 多于 $ n/2 $ 次，则称其为 多数元素（majority element）。 当 $ n = 10 $ 时，至少需要出现 6 次 才能成为多数元素 当 $ n = 17 $ 时，至少需要出现 9 次 才能成为多数元素 当 $ n = 1 $ 时，唯一的元素即为多数元素 显然，在 $ A[1:n] $ 中最多只能存在 一个 多数元素。 任务：设计 D&amp;C 算法，判断 $ A[1:n] $ 是否包含多数元素。 将数组递归的平分为两份 找出左侧数组出现次数最多的元素 找出右侧数组出现次数最多的元素 如果左右两侧的多数元素相同，则返回该元素 否则，计算两个元素在整个数组中出现的次数，返回出现次数较多的元素 确保返回的元素在整个数组中出现的次数大于 $ n/2 $，否则返回 null 习题 4我们给定一个长度为 $ n $ 的数列 $ a_1, a_2, \\dots, a_n $，假设所有数都互不相同。我们定义一个 逆序对 为满足 $ i &lt; j $ 且 $ a_i &gt; a_j $ 的一对索引 $ (i, j) $。 我们最初将 逆序对计数 作为衡量两个排列之间差异程度的一个指标。然而，有人可能会认为这个度量过于敏感。因此，我们引入一个新的概念，称为 “显著逆序对”，即当满足： $$i &lt; j \\quad \\text{且} \\quad a_i &gt; 2a_j$$ 的索引对 $ (i, j) $ 被称为 显著逆序对。 任务：设计一个 $ O(n \\log n) $ 的 分治算法 来计算一个序列 $ a_1, a_2, \\dots, a_n $ 中的显著逆序对的数量。 将数组递归的平分为两份 递归找出左侧数组的显著逆序对数量（左侧元素除以右侧元素大于 2） 递归找出右侧数组的显著逆序对数量 嵌套遍历左右数组，找出跨越中间点的显著逆序对数量 此时可以使用排序算法加速 习题 5最近点对问题（Closest pair of points in the plane） 我们有一个 平面点集：$\\mathcal{P} = { p_1, p_2, \\dots, p_n }$ 我们的目标是找到 距离最小的两点对。 朴素解法： 枚举所有点对，计算其距离，并找到最小距离。 该方法的时间复杂度为： $O(n^2)$ 将集合平均分为两份 递归找出左侧集合中最近的两点对 递归找出右侧集合中最近的两点对 嵌套遍历左右集合，找出跨越中间点的最近两点对 找出三者中的最小距离 可以对 x 和 y 坐标分别排序，以加速查找 习题 6有一个 n 节点的平衡完全二叉树，每个节点都有一个实数值且不重复。若节点 v 的值严格小于与其直接相连的所有节点的值，则节点 v 被称为 局部最小值。请设计一个 $O(\\log n)$ 的算法来找到这个局部最小值。 选择中间节点 m 如果 m 是局部最小值，则返回 m 否则，如果 m 的左侧节点更小，则递归左侧 否则，递归右侧 题目并没有说明要找到全部局部最小值，所以不必遍历左右两侧子叶 如果需要找到全部局部最小值，可以使用以下方法： 选择中间节点 m 如果 m 是局部最小值，则跳过其左右子叶，直接进入子叶节点的下一层继续递归 否则，分别递归左右两侧 但这样的时间复杂度为 $O(n)$","link":"/Algorithm/DAA-Midterm-Revision/"},{"title":"ITDS Midterm","text":"学不动了 DS &amp; MLWhat are the main differences between DS and ML, and how do their goals and functionalities differ even though they are closely linked? DS 和 ML 之间的主要区别是什么？尽管两者密切相关，但它们的目标和功能有何不同？ DS 是涵盖数据处理、分析、可视化的广泛领域，目的是从数据中提取信息。ML 是 DS 的子领域，专注算法和模型，使计算机能基于数据学习并作出预测。DS 注重数据处理流程，而 ML 专注于算法模型。 LifecycleEnumerate the steps involved in the DS lifecycle. Highlight the key tasks and considerations at each stage? 列举 DS 周期中涉及的步骤。在每个阶段突出关键任务和考虑因素是什么？ 需求：明确目标 数据采集：公共，私有，第三方 数据处理：清洗，整理 数据分析：统计，可视化 建模：使用 ML 部署：持续监控，优化 HammingConsider two objects represented by binary strings:A = 110010, B = 101011.Define and calculate the Hamming distance between A and B.Can we use the Hamming distance if A and B have different lengths and why? 考虑由二进制字符串表示的两个对象：A = 110010，B = 101011。定义并计算 A 和 B 之间的汉明距离。如果 A 和 B 长度不同，我们可以使用汉明距离吗？为什么？ 汉明指两个等长字符串对应位置上不同字符的数量。 12A = 110010;B = 101011; 观察得到有三个位不同，所以汉明距离为 3。如果 A 和 B 长度不同，汉明距离无法计算，无法确保每个位置都有对应的字符进行比较。 MetricUnder which conditions is a distance measure a metric?Demonstrate that the Hamming distance is a metric.Provide explanations and calculations to support each part of the proof. 在什么条件下，一个距离测量是一个度量？证明汉明距离是一个度量。提供解释和计算来支持证明的每个部分。 Non-Negative：$d(x, y) \\geq 0$ Symmetry：$d(x, y) = d(y, x)$ Identity：$d(x, y) = 0 \\Leftrightarrow x = y$ Triangle Inequality：$d(x, y) + d(y, z) \\geq d(x, z)$ 汉明距离是非负的，最小为 0 基于位置的比较导致顺序无关 如果距离为 0 ，则两个字符串相同 设有 A B C 等长字符串。若 A 和 C 在 x 位置上相同，则 $d(A, C)_x = 0$。若 A 和 B and/or B 和 C 在 x 位置上不同，最多会使 $d(A, C)$ 增加 1。但 $d(A, B) + d(B, C)$ 至少为 1，因此满足三角不等式。 K-MeansWhat are the hyper-parameters of K-means clustering and how do we set them? K-means 聚类的超参数有哪些，我们应该如何设置它们？ Cluster Number $k$：聚类数量，使用 Elbow Method 或 Silhouette Score Initial Centroids：初始质心，使用随机选择或 KMeans++ Maximum Iterations：最大迭代次数，一般为 300 Convergence Tolerance：收敛容差，当质心变化小于阈值时停止迭代，一般为 $10^{-4}$ AgglomerativeIn hierarchical agglomerative clustering, how would you determine the optimal number of clusters without relying on pre-defined stopping criteria? 在层次聚类中，如何在不依赖预定义停止条件的情况下确定最优的聚类数量？ 一般使用 Dendrogram 来帮助确定最优聚类数量。 生成树状图 寻找最大的 Merge Distance 增量 在这个点 Cut 树状图 切割点以上的分支数量即为最优数 DBSCANIf you set a large value for $\\epsilon$ in DBSCAN, what would be the potential consequences on the clustering results? 如果在 DBSCAN 中设置一个较大的 $\\epsilon$ 值，这对聚类结果可能有什么影响？ $\\epsilon$ 表示 Eps-neighborhood，即邻域半径 导致本应分开的不同簇被合并 噪声点可能被错误地分配到簇中 边界结构 Blurred Overfitting RegressionDiscuss the difference between simple linear regression and multiple linear regression. 讨论简单线性回归和多元线性回归之间的区别。 简单线性只涉及一个 feature，多元线性涉及多个 feature。都是使误差平方和最小化，但多元线性可以更全面地分析多个因素对结果变量的综合影响 GradientDescribe the process by which gradient descent is employed to refine the parameters of a linear regression model. 描述梯度下降如何被用来优化线性回归模型参数的过程。 线性回归模型参数随机初始化 通常使用 MSE 计算 Loss 为 Loss 的每个参数计算 partial derivative 将参数减去 学习率 * gradient 重复 2-4 直到收敛 RegularizationHow does regularization help overcome the challenges associated with using polynomial regression models?Particularly in mitigating overfitting and controlling model complexity? 正则化如何帮助克服使用多项式回归模型所面临的挑战？特别是在减少过拟合和控制模型复杂度方面？ Overfitting：向 Loss 增加额外的 Penalty，通常是 L1 或 L2，使得模型不能 fit 小波动 Complexity：惩罚大的 coefficient，削弱其影响，降低复杂度，提高 generalization ability","link":"/Data-Science/ITDS-Midterm/"},{"title":"ITDS-简介","text":"我又重生了，这一次我要拿回属于我的一切 什么是 DS它的目标是：从数据中提取有用的信息 我们将 机器学习的算法应用于各种数据，以训练 AI 来完成通常需要人类进行的任务这些 AI 会产生一些见解，以供用户将其转化为业务价值 关系 DS 与 ML 密切相关 DS 研究如何从原始数据中提取信息 ML 是 DS 的一种技术，使机器能够自动从过去的数据中学习 AI 使用指导思想，即让机器模仿人类的思维方式 DL 是 ML 的子集，它使用多层神经网络计算 数据科学家：分析数据，寻找模式，训练模型 数据工程师：收集，储存，处理，提供数据给科学家 生命周期让我们来看看 DS 的生命周期 商业需求 Business Requirement 数据采集 Data Acquisition 数据处理 Data Preprocessing 数据分析 Data Exploration 建模，使用 ML Modeling 部署和优化模型 Deployment and Optimization 数据挖掘步骤 明确目标 Learn about the application 确定挖掘任务 Identify data mining tasks 数据准备 Collect data 数据清洗预处理 Clean and preprocess the data 数据转换与提取 Transform data or select valuable subsets 选择数据挖掘算法 Choose a data mining algorithm 数据挖掘 Data mining 评估、可视化和解释结果 Evaluate, visualize, and interpret results 应用结果 Use results for profit or other goals 数据我们称数据表的 Columns 为 Features，Rows 为 Samples / Examples / Instances 数据的类型： Categorical分类特征来自无序集合，如 City.{Viena, Paris} Numerical数值特征来自有序集合，如 Age.{0, 1, 2, 3, …} 我们偏向于把 Categorical 转化为 Numerical 例如 Age City 20 Viena 30 Paris 转化为 Age City_Viena City_Paris 20 1 0 30 0 1 这样我们就可以将 instance 表达为空间中的一个点，如 (20, 1, 0) 我们可以使用 one hot 编码实现这种转化 随后我们可以： 把所有数据映射到空间中，称之为 Feature Space 使用 Euclidean Distance 来计算两个点之间的距离 用来查找相似内容… 质量ML 算法需要干净的数据 原始数据有可能： NoiseModicitation of original values Outliers (异常 / 离群)与大部分数据有截然不同的特征 Missing Values Duplicates如同一个人使用不同 ID 数据缺失可能是由于 未收集（拒绝回答），或不适用（未成年人的收入）导致的可以使用以下方法处理： 删除 估计 Estimation 忽略 对于数据量，一般是越多越好，有一个流行的说法是 十倍于特征数量，但是要保证质量","link":"/Data-Science/ITDS-%E7%AE%80%E4%BB%8B/"},{"title":"ITDS-聚类","text":"Hierarchical，Similarity，DBSCAN 层次聚类 Agglomerative每次合并最近的两个点，直到合并成 k 个类 Divisive从一个包含所有数据点的类开始进行分裂，直到分裂成 k 个类 每次操作都只对一个聚类进行，聚类结果会形成一种嵌套关系，每个节点代表一个聚类，上层节点是由下层节点合并产生的，我们可以使用 dendrogram 树状图 来表示这种嵌套关系。它不需要预设聚类数量，通过在合适的层次切割树状图，就可以得到任意数量的聚类。 凝聚式算法： 计算 Proximity Matrix邻近矩阵衡量各个数据点之间的距离 将每个数据点看作一个聚类 合并最近的两个聚类 更新邻近矩阵 重复 3-4 直到只剩下 k 个聚类 相似度需要明确聚类间的相似性，以此判断哪些聚类应该合并或保持分离。计算两个簇之间的距离有不同的方法： Single Linkage (MIN)计算两个簇之间最小距离，即最近两个点之间的距离。在簇之间形成链状连接，适用于发现非球形簇。 Complete Linkage (MAX)计算两个簇之间的最大距离，即最远两个点之间的距离。能创建更紧密，类似球形的簇，并减少噪声的影响。 Average Linkage计算两个簇之间所有点的平均距离，是 Single 和 Complete 的折中方案，对噪声敏感度底，偏向形成球形聚类。 Centroid Linkage计算两个簇之间质心（如几何中心）的距离。这种方法计算简单，处理复杂形状聚类时可能效果不佳。 Ward’s Method此方法选择 合并两个簇后，簇内平方和的增加量最小 的一对。这种方法对噪声敏感度低，适用于球形簇结构。 问题 层次聚类计算复杂度高，时间复杂度为 O(n^3)，空间复杂度为 O(n^2) 合并决策不可逆 无目标函数，无法直接优化 处理多种形状的簇效果不佳 DBSCANDensity-Based Spatial Clustering of Applications with Noise 是一种基于密度的聚类算法，能够识别形状不规则的簇，并检测噪声点，不需要预设聚类数量。 它主要依赖两个参数： Eps：邻域半径，用于确定一个点的邻域范围，也就是多远才算是邻居 MinPts：邻域内最少点数，也就是在一个区域类至少需要多少个点，才能算作一个簇 根据这两个参数，DBSCAN 将数据点分为三类： 核心点：在 Eps 范围内至少包含 MinPts 个点（包括自身） 边界点：不是核心点，但在某个核心点的 Eps 范围内 噪声点：既不是核心点也不是边界点 选择 Eps 和 MinPts对于簇中的点，它们的第 k 近邻的距离应该相似，如第 2 与第 3 近邻的距离相差不大。我们可以通过 k-distance graph 来选择合适的 Eps 和 MinPts。 计算所有点到第 k 近邻的距离 对距离进行排序，画出随 k 变化的距离图 找到出现突然增长的点 这个点的横坐标就是 Eps，纵坐标就是 MinPts Density Connectivity Density Edge: 如果 p 和 q 都是核心点，且它们的距离小于等于 Eps，则能够在它们之间构建一条密度边，它的存在意味着两个核心点所在区域数据点密集，具备归为同一簇的条件，它用于构建核心点网络。 Density Connected: 如果某个点 p 可以通过一系列的密度边连接到另一个核心点 q，则 p 和 q 是密度相连的，它们可能不能直接相连，但是可以通过多个核心点传递连接。它是判断点是否属于同一簇的关键条件。 密度连接使 DBSCAN 能够形成任意形状的簇。 缺点 计算复杂度高 它假设所有簇的密度相近，对密度差异较大的数据集效果不佳 对参数敏感，需要调参","link":"/Data-Science/ITDS-%E8%81%9A%E7%B1%BB/"},{"title":"ITDS-聚类分析","text":"Distance, Clustering，K-Means 距离与相似度基础设 $d$ 是距离函数，$s$ 是相似度函数，那么 $s = 1 - d$。 距离 $d$ 的值是度量（Metric），度量满足以下条件： 非负性：Non-negativity $d(x, y) \\geq 0$ 同一性：Coincidence $d(x, y) = 0 \\iff x = y$ 对称性：Symmetry $d(x, y) = d(y, x)$ 三角不等式：Triangle Inequality $d(x, y) + d(y, z) \\geq d(x, z)$ 三角不等式假设我们有多个聚类中心，目标是找到某个数据点到最近的中心点。一般情况下，我们需要计算所有的距离，但利用三角不等式可以减少计算： 我们想检查 $c_2$ 是否比 $c_1$ 更接近 x，即 $$d(x, c_2) &lt; d(x, c_1)$$ 根据三角不等式 $$d(x, c_2) \\geq d(c_1, c_2) - d(x, c_1)$$ 我们可以知道 $d(x, c_2)$ 最小就是 $d(c_1, c_2) - d(x, c_1)$。现在我们要求这个最小值都比 $d(x, c_1)$ 大，这样我们就可以跳过计算： $$d(c_1, c_2) - d(x, c_1) \\geq d(x, c_1)$$ 则 $$d(c_1, c_2) \\geq 2d(x, c_1)$$ 所以如果 $c_2$ 满足上述条件，则可以跳过计算 $d(x, c_2)$，它不可能比 $c_1$ 更近。 常见的距离度量 欧几里得距离（Euclidean Distance） $$d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$ 这是最常见的距离计算方法，适用于数值型数据 曼哈顿距离（Manhattan Distance） $$d(x, y) = \\sum_{i=1}^{n} |x_i - y_i|$$ 也称为 L1 距离，适用于网格状数据，如城市街道距离 切比雪夫距离（Chebyshev Distance） $$d(x, y) = \\max |x_i - y_i|$$ 适用于棋盘距离，如国际象棋中的马步 闵可夫斯基距离（Minkowski Distance） $$d(x, y) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{1/p}$$ 当 $p = 1$ 时，是曼哈顿距离；当 $p = 2$ 时，是欧几里得距离，$p \\to \\infty$ 时，是切比雪夫距离 Curse of Dimensionality （维度诅咒），随着维度的增加，数据点之间的距离变得越来越远，这会导致距离度量失效。因此在高维数据中，需要谨慎选择距离度量。 汉明距离Hamming 距离用于计算两个二进制字符串之间的差异： 1234x = 1011101y = 1001001-----------差异位数 = 2 = Hamming Distance 在字符串中的应用Hamming 距离适用于 等长 的二进制数据或字符串，例如： 1234x = &quot;karolin&quot;y = &quot;kathrin&quot;-----------差异位数 = 3 = Hamming Distance 在集合中的应用假设有两个集合 有 1000 个项目，其中 995 个相同 有 5 个项目，均不相同 这两个集合的汉明距离都是 10，这表明汉明距离不适用于衡量集合的相似性。 10 的原因是因为不同的物品在两个集合中需要独立表示 Jaccard 相似度Jaccard Similarity 用于计算两个集合之间的相似性： $$s(x, y) = \\frac{|x \\cap y|}{|x \\cup y|}$$ 其中： $|x \\cap y|$ 是两个集合的交集（共同元素） $|x \\cup y|$ 是两个集合的并集（所有元素） 995 个相同的集合：$s = \\frac{995}{1000} = 0.995$ 5 个不同的集合：$s = \\frac{0}{5} = 0$ 编辑距离将一个字符串转换为另一个字符串所需的最小操作数： 插入（Insertion） 删除（Deletion） 替换（Substitution） Levenshtein 距离 12x = &quot;kitten&quot;y = &quot;sitting&quot; kitten -&gt; sitten (substitute k for s) sitten -&gt; sittin (substitute e for i) sittin -&gt; sitting (insert g at the end) 编辑距离是 3。 聚类分析Clustring Analysis 是用于发现数据集中自然分组的技术，目的是识别数据中的模式或结构，将相似的数据归为一类。使同一组内对象相似度高，不同组间对象相似度低。 聚类并不只是通过可视化数据来观察，实际上大多数有价值的数据都是高维的，无法通过肉眼观察来发现模式，所以我们需要依靠自动化算法来寻找自然分组。 聚类的类型 Hard：每个数据点只能属于一个类别 Partitional：将数据集分为 k 个不相交的子集 Hierarchical：将数据集分层次地组织为树形结构，为凝聚式（Agglomerative）和分裂式（Divisive）两种 Fuzzy：每个数据点可以属于多个类别 聚类的质量一个理想的聚类，应该使簇内数据点的距离尽可能小，簇间数据点的距离尽可能大。为了量化聚类质量，我们可以使用以下指标： S：计算同一簇内数据点的平均距离 D：计算不同簇间数据点的平均距离 D/S：越大越好 例如： $$A_1, B_1, C_2, D_1, E_2, F_1, G_2, H_1$$ S = [(AB + AD + AF + AH + BD + BF + BH + DF + DH + FH) + (CE + CG + EG)] / 13 = 44 / 13 = 3.38 D = [AC + AE + AG + BC + BE + BG + DC + DE + DG + FC + FE + FG + HC + HE + HG] / 15 = 40 / 15 = 2.67 D/S = 2.67 / 3.38 = 0.79 聚类通常不存在绝对正确的结果 不同的算法可能会产生不同的结果 数据分布呈球形时，K-Means 效果最好 数据分布不规则时，DBSCAN 效果最好 D/S 在很多情况下效果不佳，它无法区分不同聚类结构的差异 K-Means是一种常用的无监督学习算法，能够自动将数据分为 K 个簇。 你需要手动指定 K 的值，即数据分成多少个类别 随机初始化 K 个中心点 计算每个数据点到所有 K 个中心点的距离 将数据点分配到距离最近的中心点 计算每个簇所有数据点的平均值 将平均值作为新的中心点 重复 3-6 步骤，直到中心点变化很小或达到最大迭代次数 Convergence：K-Means 一定会在有限次迭代后收敛 将数据点分配到最近的中心点：$O(n \\cdot k)$ 更新中心点：$O(n)$ Elbow Method常用的选择 K 值的方法是肘部法则： 运行 K-Means，计算 总平方误差 (Sum of Squared Error, SSE) 画出 SSE 随着 K 值的变化图 找到拐点，即 SSE 开始下降的速度变慢的点 拐点的值就是最佳的 K 值 问题 不同的初始中心点可能导致不同的结果 K 值需要手动指定 对异常值敏感 适用于球形数据，无法处理复杂形状的数据","link":"/Data-Science/ITDS-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"},{"title":"MSSQL 练习题","text":"最近因为学校的原因，不得不学习 MS SQL 相关内容遂记录一些练习题 首先我们 1234DROP DATABASE IF EXISTS Learn;CREATE DATABASE Learn;USE Learn; Check创建一个 Student 表，有 ID, Name, Semester, City 字段。写一个 SQL，只允许插入第三学期的学生。这意味着用户不能插入第一、第二或第四学期的学生。 Create one Student table where is ID, Name, Semester, City colums.Find the solution that we can insert just the 3rd semester students.This mean that the user connot inser Student who are in 1, 2, or 4th semester. 12345678DROP TABLE IF EXISTS Student;CREATE TABLE Student ( ID INT PRIMARY KEY IDENTITY(1, 1), Semester TINYINT CHECK(Semester = 3) NOT NULL, NAME TEXT NOT NULL, City TEXT NOT NULL,); 去重创建一个方法，对同一 record 进行过滤，并只返回一次。例如，如果我们有 3 个价格为 450 的比萨饼，如果我们 Select，那么结果将是只有 1 个比萨，而不是 3 个比萨。 Create one method, what filtering the same record and give back just once.For example, if we have 3 pizza with 450 price, if we take a Select,then results will be just 1 pizza, not 3 pizza. 1234567891011121314151617181920DROP TABLE IF EXISTS Food;CREATE TABLE Food ( ID INT PRIMARY KEY IDENTITY(1, 1), Name VARCHAR(50) NOT NULL, Price DECIMAL CHECK(Price &gt;= 0) NOT NULL,);INSERT INTO Food Values ('Pizza', 450), ('Pizza', 450), ('Pizza', 450);-- Type 1SELECT MIN(Id), Min(Name), Min(Price) FROM Food GROUP BY Name;-- Type 2SELECT DISTINCT Name, Price FROM Food; 函数创建一个阻止 18 岁以下用户的 function。 Create one function what block the user who are younger as 18 years old. 1234567DROP TABLE IF EXISTS TUser;CREATE TABLE TUser ( ID INT PRIMARY KEY IDENTITY(1, 1), Name VARCHAR(50) UNIQUE NOT NULL, Age TINYINT CHECK(Age &gt;= 0),); 123456789101112131415CREATE OR ALTER FUNCTION IsAdult(@Name VARCHAR(50))RETURNS BITASBEGIN IF EXISTS( SELECT * FROM TUser WHERE Name = @Name And Age &gt;= 18 ) RETURN 1 RETURN 0END 12345INSERT INTO TUser Values('Some', 18)DECLARE @ret BITEXEC @ret = IsAdult 'Some'SELECT @ret 层次化索引 Create one hierarchy index. 12345678910DROP TABLE IF EXISTS HIndex;CREATE TABLE HIndex ( IdPath HIERARCHYID PRIMARY KEY, Sth TEXT)INSERT INTO HIndex VALUES ('/1/', 'Something'), ('/1/1/', 'Somebody') Trigger创建一个触发器，如果产品数量在 10 个以下，则更新价格（+20%）。 Create one trigger what is update the price(+20%)if the products quantity is under 10 pirces. 123456789101112DROP TABLE IF EXISTS Product;CREATE TABLE Product( Id INT PRIMARY KEY IDENTITY, Name VARCHAR(50), Price MONEY, Quantity INT CHECK(Quantity &gt;= 0));INSERT INTO Product VALUES ('Pizza', 1000, 15), ('Bun', 100, 12); 1234567CREATE OR ALTER TRIGGER IncreasePriceOn Product FOR UPDATE ASBEGIN UPDATE Product SET Price = Price * 1.2 WHERE Quantity &lt; 10END; 12UPDATE ProductSET Quantity = 8; 复合主键不是很能理解他到底在说什么，但是答案是复合主键相关 How can we kill the nested loops operator?How can we kill the double I/O problems? 1234567DROP TABLE IF EXISTS Composite;CREATE TABLE Composite( Id INT NOT NULL, Comp INT NOT NULL, CONSTRAINT PK_Composite_Id_Comp PRIMARY KEY (Id, Comp)); 脏读 Create one select what is dirty read. 1234567891011DROP TABLE IF EXISTS Bank;CREATE TABLE Bank( Id INT PRIMARY KEY IDENTITY(1, 1), AccountNum VARCHAR(50), Name VARCHAR(50), Balance MONEY)INSERT INTO Bank VALUES ('SomeAccountNum', 'SomeName', '80'); 123456789BEGIN TRAN; UPDATE Bank SET Balance = Balance - 45 WHERE AccountNum = 'SomeAccountNum'; WAITFOR DELAY '00:00:10';ROLLBACK TRAN;SELECT * FROM BankWHERE AccountNum = 'SomeAccountNum'; 123456-- Dirty ReadSET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;BEGIN TRAN; SELECT * FROM Bank WHERE AccountNum = 'SomeAccountNum';COMMIT TRAN; 或者 12Select Count(*)FROM Bank WITH (NOLOCK) While两个产品。咖啡是 245，披萨是 475。(硬币：20，10，5）如果我们想买这些产品，请计算需要多少硬币。 You have 2 products. The coffee is 245, the pizza is 475. (Coins: 20, 10, 5)Please count how many coins need it if we would like to buy this products. 12345678910111213141516171819202122232425262728293031CREATE OR ALTER PROCEDURE CountCoins(@Price INT)ASBEGINDECLARE @C20 INT, @C10 INT, @C5 INT;SET @C20 = 0;SET @C10 = 0;SET @C5 = 0; WHILE @Price &gt;= 20 SET @Price = @Price - 20 SET @C20 = @C20 + 1 WHILE @Price &gt;= 10 SET @Price = @Price - 10 SET @C10 = @C10 + 1 WHILE @Price &gt;= 5 SET @Price = @Price - 5 SET @C5 = @C5 + 1 PRINT 'It can be paid with ' + TRIM(CAST(@C20 as VARCHAR(50))) + ' 20Coin, ' + TRIM(CAST(@C10 as VARCHAR(50))) + ' 10Coin, ' + TRIM(CAST(@C10 as VARCHAR(50))) + ' 5Coin.'END 聚集索引 Create two cluster index on your table, on the same table but different columns. 123456789DROP TABLE IF EXISTS TTest;CREATE TABLE TTest( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));CREATE CLUSTERED INDEX IX_TTest_Col1 ON TTest (Col1, Col2); XML导出表到 XML。 Create XML code from your table. 12345678910111213DROP TABLE IF EXISTS TXML;CREATE TABLE TXML( Col1 INT PRIMARY KEY IDENTITY, Col2 VARCHAR(10), Col3 VARCHAR(50));INSERT INTO TXML VALUES ('Some', 'Thing'), ('Body', 'Any');SELECT * FROM TXML FOR XML AUTO; 事务用事务填充表。 Create one table with 900 records. 123456789101112131415161718DROP TABLE IF EXISTS Fill;CREATE TABLE Fill( Id INT PRIMARY KEY IDENTITY, Increse INT);BEGIN TRANDECLARE @index INTSET @index = 0WHILE @index &lt; 900BEGIN INSERT INTO Fill VALUES (@index) SET @index = @index + 1ENDCOMMIT TRAN 用户账户创建新用户并授予其权限。 Create a new account, which log in via system administrator with data reader persmission. 123CREATE LOGIN [DGYY] WITH PASSWORD=N'123', DEFAULT_DATABASE=[master]ALTER SERVER ROLE [sysadmin] ADD MEMBER [DGYY]ALTER ROLE [db_datareader] ADD MEMBER [DGYY] UNION合并多个 SELECT 语句的结果集 How can we use the data of set? 123SELECT NULL FROM SomeTableUNIONSELECT NULL FROM OtherTable; CASE WHEN用 CASE 写一个判断 Create one new table for cars(Id, type, color). After this,select one car from the table and compare this car color onthe next logical statement the car is Black (True, False) Or White. 1234567891011121314151617181920DROP TABLE IF EXISTS Car;CREATE TABLE Car( Id INT PRIMARY KEY IDENTITY, Type VARCHAR(50), Color VARCHAR(50));INSERT INTO Car VALUES ('Audi', 'Black'), ('BMW', 'Red'), ('Suzuki', 'Grey'), ('Aston', 'White');SELECT TOP(1) CASE WHEN Car.Color = 'White' Then 'White' WHEN Car.Color = 'Black' THEN 'True' ELSE 'False' ENDFROM Car OFFSET How can we use the data offset? 123456789101112131415161718192021DROP TABLE IF EXISTS Offset;CREATE TABLE Offset( Id INT PRIMARY KEY IDENTITY, Sth INT);DECLARE @index INTSET @index = 0WHILE @index &lt; 5BEGIN INSERT INTO Offset VALUES(RAND() * 10) SET @index = @index + 1ENDSELECT *FROM OffsetORDER BY IdOFFSET 2 ROWSFETCH NEXT 3 ROWS ONLY; BETWEEN12ALTER TABLE TableNameADD CONSTRAINT CK_Between CHECK (LEN(ColomnName) BETWEEN 1 AND 10) THROW Create one trigger what give for us an error messageif we cannot insert data in the table. 123456789CREATE TRIGGER ErrorTrigger-- 类似 BEFOREON TTest INSTEAD OF INSERT ASBEGIN IF 1 = 1 THROW 60000, 'Error Message!', 1 ;END 表变量12345678910111213DECLARE @TTest TABLE( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));INSERT INTO @TTest VALUES (1, 2, 'Some'), (3, 4, 'Thing');SELECT * FROM @TTest;DROP TABLE @TTest; 临时表12345678910111213CREATE TABLE #TTest( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));INSERT INTO #TTest VALUES (5, 6, 'Body'), (7, 8, 'Any');SELECT * FROM #TTest;DROP TABLE #TTest;","link":"/Database/MSSQL/MSSQL-%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"title":"Master Method","text":"本文是 Design and Analysis of Algorithms 的一部分 本节课一上来就给我搞了一个新概念让我措手不及，完全听不懂 前置知识在学习可以手搓魔法阵的大师方法之前，我们需要一些前置知识 时间复杂度在 很久之前 我就写过关于时间复杂度的内容 我们做复杂度分析的时候，考虑的因变量只有问题规模，而不是具体输入无论哪种记法，默认是取最坏情况来分析 大 O 与 渐进分析用 大 O 表示的复杂度，就叫渐进复杂度我们常说的分析复杂度，其实就是分析渐进复杂度 它忽略了复杂度的常数倍差别，更关心 “算法所需要的资源，随问题规模增长而增长的速度” 且 O 表达的是低阶于，即算法的复杂度不会超过这个值比如，对于一个 O(1) 的算法，你要说它是 O(n) 也没错，只不过你的上限不够紧致 所以，$O$ 是上限，$\\Omega$ 是下限，$\\Theta$ 是上下限相同（即确定就在这一阶） 递归分治算法一个典型的例子就是 Merge Sort 让我们来快速复习一下： 把序列一分为二 分别对两个子序列进行归并排序 合并两个有序序列 Master Method如果我们想快速计算归并，或者存在递归的分治算法的时间复杂度，我们可以使用主定理 定义有递归关系式 $$ T(n) = aT(\\frac{n}{b}) + f(n), 其中 a \\geq 1, b &gt; 1$$ n 是问题规模，a 是递归子问题数量，b 是问题规模的缩小比例$\\frac{n}{b}$ 是子问题规模，$f(n)$ 为递归以外的操作（如分治） 那么我们存在三种情况 1. 递归主导存在常数 $\\epsilon &gt; 0$，使得 $$ f(n) = O(n^{\\log_b(a) - \\epsilon}) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)}) $$ 2. 一样耗时存在常数 $\\epsilon \\geq 0$，使得 $$ f(n) = \\Theta(n^{\\log_b(a)} \\log^\\epsilon n) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)} \\log^{1+\\epsilon} n) $$ 另可写为$$ f(n) = \\Theta(n^{\\log_b(a)}) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)} \\log n) $$ 3. 分治主导存在常数 $\\epsilon &gt; 0$，使得 $$ f(n) = \\Omega(n^{\\log_b(a) + \\epsilon}) $$ 且存在常数 $c &lt; 1， n \\to \\infty$ 时，有 $$ af(\\frac{n}{b}) \\leq cf(n) $$ 则 $$ T(n) = \\Theta(f(n)) $$ 理解汗流浃背了吧 以 $T(n) = 2T(\\frac{n}{2}) + n$ 为例 12345678 f(n) / \\ f(n/b) f(n/b) / \\ / \\f(n/b^2) f(n/b^2) f(n/b^2) f(n/b^2) / \\ / \\ / \\ / \\ ......（很多次递归以后）Θ(1) Θ(1) ... Θ(1) Θ(1) Θ(1) Θ(1) ... 递归树被分为两个部分：$f(n)$ 与 $\\Theta(1)$ 本质它其实在对比这两个部分的时间复杂度： 是 $\\sum f(n)$ 耗时，还是 $\\sum \\Theta(1)$ 耗时 所以我们可以将其描述为 $$ T(n) = g \\cdot f(n) + k \\cdot \\Theta(1)$$ 由于 $g$ 增长较慢，所以我们可以认为 g 是常数，则有 $$ g \\cdot f(n) \\to O (f(n)) $$ 所以问题来了，$k$ 是多少 推导我们可以发现这个树每一层分叉都是 $a$ 每次问题规模缩小为 $\\frac{n}{b}$，且 $n = b^{\\log_b (n)}$所以这棵树的高度是 $\\log_b n$这样我们就有 $a^{\\log_b (n)}$ 个叶子节点 所以，有 $\\sum \\Theta(1) = \\Theta(a^{\\log_b (n)})$使用换底公式，$\\Theta(n^{\\log_b (a)})$ 眼熟吗？ 将 $k$ 代入，得到 $T(n) = g \\cdot f(n) + n^{\\log_b (a)}$ 对比接下来我们就只需要对比 $f(n)$ 与 $n^{\\log_b (a)}$ 到底谁随着 n 增长的速度更快了 1. $\\sum \\Theta(1) &gt;$$k$ 的增长大于 $f(n)$ 的增长表示最终处理问题的最小任务占主导 则 $T(n) = \\Theta(n^{\\log_b (a)})$引入 $\\epsilon$，仅为了说明增长速度快 2. $=$表示最小子任务与分割任务的时间复杂度一样此时 $f(n) = \\Theta(n^{\\log_b (a)})$因此需要把两个的时间复杂度都算上有 $T(n) = \\Theta(n^{\\log_b (a)} \\log n)$ 3. $\\sum f(n) &gt;$分治过程占主导，为什么有额外要求呢？ $$c &lt; 1, af(\\frac{n}{b}) \\leq cf(n), n \\to \\infty$$ 因为不可以让子问题的耗时增长速率大于其本身，但其实是在限制 $g$ 限制 $g$我们前文提到，$g$ 被限制速率不可超过 $O(f(n))$，所以认为 $g$ 是常数这在 1 / 2 情况中默认不可能超过 $k$，而 3 中我们需要额外限制 $g$ 的计算让我们把 $f(n)$ 加起来 $$\\sum_{j=0}^{\\log_b (n) - 1} a^j f(\\frac{n}{b^j})$$ 随后我们用变形的 等比数列求和公式 得到 $$\\sum_{i=0}^{k} r^i = \\frac{r^{k+1} - 1}{r - 1}$$ 递归树有 $\\log_b (n)$ 层，去掉最后一层是 $k = \\log_b (n) - 1$，变形公式正好抵消 1 我们发现第三条的规定，就是在限制 $r$ 足够小 细节我也看不明白，希望大佬指点 例题让我们来画点魔法阵 情况一$T(n) = 9T(\\frac{n}{3}) + n$ $a = 9, b = 3, f(n) = n$ $T(n) = n^{\\log_{3} (9)} = n^2 &gt; f(n)$ 情况二$T(n) = T(\\frac{2n}{3}) + 1$ $a = 1, b = \\frac{3}{2}, f(n) = 1$ $n^{\\log_b (a)} = n^{\\log_{\\frac{3}{2}} (1)} = n^0 = 1 = f(n)$ $T(n) = 1 \\times \\log n = \\log n$ 情况三$T(n) = 3T(\\frac{n}{4}) + n \\log n$ $a = 3, b = 4, f(n) = n \\log n, n \\to \\infty$ $n^{\\log_4 (3)} = n^{0.792} &lt; n &lt; n \\log n$ 由此判定为情况三，则 $af(\\frac{n}{b}) = 3 \\frac{n}{4} \\log \\frac{n}{4} &lt; \\frac{3}{4} n \\log n = cf(n)$ 取 $c = \\frac{3}{4}$ 即可 $T(n) = n \\log n$ 不适用$T(n) = 2T(\\frac{n}{2}) + n \\log n$ $a = 2, b = 2, f(n) = n \\log n, n \\to \\infty$ $n^{\\log_2 (2)} = n &lt; f(n)$ 由此判定为情况三，我们尝试验证 $af(\\frac{n}{b}) \\leq cf(n)$ $af(\\frac{n}{b}) = 2 \\frac{n}{2} \\log \\frac{n}{2} = n \\log \\frac{n}{2} = n \\log n - n = n(\\log n - 1) \\leq c \\times n \\log n = cf(n)$ 则等价于 $\\log n - 1 \\leq c \\log n$ 我们尝试求解 $\\log n - 1 \\geq c \\log n$ 重写为 $(1 - c) \\log n \\geq 1 \\to \\log n \\geq \\frac{1}{1 - c} $ 得到 $n \\geq 2^{\\frac{1}{1 - c}}$ 这说明对于任何 $c &lt; 1$，都存在一个 $n \\geq 2^{\\frac{-1}{c - 1}}$，使得 $af(\\frac{n}{b}) \\geq cf(n)$ 所以存在一个 $n$ 的界限，超过后 $g$ 的增长速度将超过 $k$ 的增长速度 导致不能使用主定理 注：根据对数法则，$\\log \\frac{n}{2} = \\log n - \\log 2$由于本题讨论计算机领域，默认以二为底，有 $\\log = \\log_2$则 $\\log 2 = 1$，所以 $\\log \\frac{n}{2} = \\log n - 1$ 习题1.$T(n) = 7 T(\\frac{n}{2}) + n^2$ $a = 7, b = 2, f(n) = n^2$ $T(n) = n^{\\log_{2} (7)} = n^{2.8\\dots} &gt; f(n)$ 2.$T(n) = 7 T(\\frac{n}{3}) + n^2$ $a = 7, b = 3, f(n) = n^2$ $n^{\\log_{3} (7)} = n^{1.77\\dots} &lt; f(n)$ $af(\\frac{n}{b}) = 7 (\\frac{n}{3})^2 = \\frac{7}{9} n^2 = cf(n)$ $c = \\frac{7}{9} &lt; 1$ $T(n) = n^2$ 3.$T(n) = 16 T(\\frac{n}{4}) + n^2$ $a = 16, b = 4, f(n) = n^2$ $n^{\\log_{4} (16)} = n^2 = f(n)$ $T(n) = n^2 \\log n$","link":"/Algorithm/Master-Method/"},{"title":"Matplotlib 入门","text":"本文是 Introduction to Data Science 的一部分 你们就照着文档念吧，谁照着念能念的过你们啊，活爹 快速开始实际上这玩意就是一个 Python 版的 Matlab 绘图库对于有 Matlab 经验的人来说基本就是换个地方写一样的东西 接下来的每一个代码块都默认附加在上一个代码块的后面 导入12345678# 启用 Jupyter 嵌入绘制的魔术命令%matplotlib inlineimport matplotlib as mpl# 真要用的也就只有 pltimport matplotlib.pyplot as plt# 怎么能少了数据源呢import numpy as np 其中，inline 会嵌入静态图片，notebook 会嵌入交互式图片 尝试1234567# 生成数据x = np.linspace(0, 10, 200)# 绘制图形plt.plot(x, np.sin(x))plt.plot(x, np.cos(x))# 显示图形plt.show() 保存12345678# 生成一个空白图形并将其赋给 fig 对象fig = plt.figure()# 绘制实线plt.plot(x, np.sin(x), '-')# 保存矢量图fig.savefig('my_figure.svg')# 查看所有支持的格式fig.canvas.get_supported_filetypes() 两种绘图方式MATLAB 风格对于一般的绘图来说，这种方式更加直观简单 12345678910# 创建一个图形plt.figure()# 创建一个子图plt.subplot(2, 1, 1)# 绘制第一个子图plt.plot(x, np.sin(x))# 创建第二个子图plt.subplot(2, 1, 2)# 绘制第二个子图plt.plot(x, np.cos(x)) 创建子图：subplot(rows: 子图行数, columns: 子图列数, subplot_number: 子图序号) 绘制图形：plot(x: x 轴数据, y: y 轴数据, …) 面向对象风格对于复杂的绘图来说，这种方式更加灵活 123456# 创建一个图像网格fig, ax = plt.subplots(2)# 绘制第一个子图ax[0].plot(x, np.sin(x))# 绘制第二个子图ax[1].plot(x, np.cos(x)) subplots 会返回一个包含所有子图的数组 基本图形线图1234# 使用 rangeplt.plot(range(1, 10))# 使用 numpyplt.plot(range(10, 1, -1), np.arange(1, 10)) plot(y: y 轴数据, …)x 会自动使用 0 到 len(y) - 1 的整数 使用 OOP12345678910# 创建图像fig = plt.figure()# 创建坐标轴ax = plt.axes()# 创建等长数据序列x = np.linspace(0, 5, 20)# 绘制 sinax.plot(x, np.sin(x))# 绘制 cosax.plot(x, np.cos(x)) linspace(start: 起始值, stop: 结束值, num: 生成的数据个数)该函数会返回一个包含 num 个元素的等差数列 多次调用 plot 会在同一张图上绘制多个图形 plot123456789101112plot( x: x 轴数据, y: y 轴数据, linestyle: 线条风格, linewidth: 线宽, color: 颜色, marker: 为线图添加散点，指定点的形状, markersize: 点大小, markeredgecolor: 点边框颜色, label: 图例标签, alpha: 透明度) 颜色plot 会自动循环使用颜色，但是也可以手动指定 12345678910# 短颜色编码（rgbcmyk）plt.plot(x, 2*x+1, color = &quot;g&quot;)# 灰度，从0到1plt.plot(x, 2*x+2, color = &quot;0.6&quot;)# HEXplt.plot(x, 2*x+3, color = &quot;#FFEE22&quot;)# RGB元组，从0到1plt.plot(x, 2*x+4, color = (0.8, 0.7, 0.1))# CSS 颜色名plt.plot(x, 2*x+5, color = &quot;chartreuse&quot;) 线条风格plot(…, linestyle: 线条风格) 使用名称12345678# 实线plt.plot(x, 2*x, linestyle = &quot;solid&quot;)# 虚线plt.plot(x, 2*x+1, linestyle = &quot;dashed&quot;)# 点线plt.plot(x, 2*x+2, linestyle = &quot;dotted&quot;)# 点划线plt.plot(x, 2*x+3, linestyle = &quot;dashdot&quot;) 使用符号12345678# 实线plt.plot(x, 2*x, linestyle = &quot;-&quot;)# 虚线plt.plot(x, 2*x+1, linestyle = &quot;--&quot;)# 点线plt.plot(x, 2*x+2, linestyle = &quot;:&quot;)# 点划线plt.plot(x, 2*x+3, linestyle = &quot;-.&quot;) 我们还可以把颜色和线条风格合并在一起 1234# 绿色虚线plt.plot(x, 2*x, &quot;g--&quot;)# 蓝色点线plt.plot(x, 2*x+1, &quot;:b&quot;) 图例虽然 plot 提供了 label 参数，但需要 legend() 才能显示 12345678910111213141516171819202122232425262728293031323334x = range(0, 10)y = np.cos(x)# 蓝线plt.plot( x, y, linestyle = '-.', linewidth = 1, color = 'blue', marker = 'o', markersize = 10, markeredgecolor = 'r', label = 'Cos', alpha = 0.5)y2 = np.sin(x)# 红线plt.plot( x, y2, linestyle = '--', linewidth = 1, color = 'red', marker = 'x', markersize = 10, markeredgecolor = 'b', label = 'Sin', alpha = 0.5)plt.legend() 标题标签123456x = np.linspace(0, 10, 200)plt.plot(np.sin(x))plt.title('Sine Curve')plt.xlabel('Radian')plt.ylabel('Magnitude') 范围123456plt.plot(np.sin(x))# X 设置在 50 到 175plt.xlim(50, 175)# Y 设置在 -0.5 到 1plt.ylim(-0.5, 1) 如果将参数反转，可以实现坐标轴的翻转 123456plt.plot(np.sin(x))# X 设置在 175 到 50plt.xlim(175, 50)# Y 设置在 1 到 -0.5plt.ylim(1, -0.5) axis我们还可以通过 axis: [xmin, xmax, ymin, ymax] 函数一次性设置 12345plt.plot(np.sin(x))# X 设置在 175 到 50# Y 设置在 -0.5 到 1plt.axis([175, 50, -0.5, 1]) 它还支持自动调整 axis('tight') 会自动调整到数据的最小范围 axis('equal') 会使 x 和 y 与屏幕宽高比一致 axis('scaled') 会使 x 和 y 的单位长度相等，不会调整到数据的最小范围 axis('square') 会使 x 和 y 的单位长度相等，并且调整到数据的最小范围 axis('off') 会关闭坐标轴 可以使用 plt.axis? 查看更多信息 散点图今天做 quiz 的时候居然在一个非常简单的问题上选错了，不能再摆了 散点图在观察数据分布的时候非常有用 123x = range(1, 11)# 传入 &quot;o&quot; 以便绘制散点图plt.plot(x, x, &quot;o&quot;) 还可以使用 scatter 函数，其提供了更多可以自定义的特性 1plt.scatter(x, x) 形状Matplotlib 支持很多点的形状 12345678910# 随机数生成器rand = np.random.RandomState(42)# 绘制随机点for marker in ['o', '.', ',', 'x', '+', 'v', '^', '&lt;', '&gt;', 's', 'd']: plt.plot(rand.rand(5), rand.rand(5), marker, label = &quot;marker = '{}'&quot;.format(marker))plt.legend()# 避免图例与数据重叠plt.xlim(0, 1.8) 透明度点太多会重叠，不便于观察 12345x = rand.rand(200)y = rand.rand(200)# 绘制散点图plt.scatter(x, y, alpha = 0.5) 颜色与大小12345678910x = rand.rand(100)y = rand.rand(100)colors = rand.rand(100)sizes = 1000 * rand.rand(100)# 绘制散点图plt.scatter(x, y, c = colors, s = sizes, alpha = 0.5)# 添加颜色条plt.colorbar() 条形图PPT 专用图形 1234x = range(1, 6)y = [1, 4, 6, 8, 4]plt.bar(x, y) 还可以是水平的 1plt.barh(x, y) 分组123456789101112131415161718192021222324member = ['A', 'B', 'C', 'D']jan = [30, 40, 50, 60]feb = [35, 45, 55, 65]mar = [40, 50, 60, 70]# 设置每个柱状图的宽度width = 0.2# 绘制柱状图plt.bar(range(4), jan, width = width, label = 'Jan')plt.bar(np.arange(4) + width, feb, width = width, label = 'Feb')plt.bar(np.arange(4) + width * 2, mar, width = width, label = 'Mar')# 添加图例plt.legend()# 设置刻度plt.xticks(np.arange(4) + width, member)# 设置 y 轴标签plt.ylabel('Revenue')# 显示网格plt.grid()# 显示图形plt.show() 堆叠1234567891011121314151617# 绘制堆叠柱状图plt.bar(np.arange(4), jan, label = 'Jan')plt.bar(np.arange(4), feb, bottom = jan, label = 'Feb')plt.bar(np.arange(4), mar, bottom = np.array(jan) + np.array(feb), label = 'Mar')# 添加图例plt.legend()# 设置刻度plt.xticks(np.arange(4), member)# 设置 y 轴标签plt.ylabel('Revenue')# 显示网格plt.grid()# 显示图形plt.show() bottom 让数据在上一个数据的基础上偏移np.array 便于元素级别（向量化）运算 直方图123456789x1 = np.random.normal(0, 0.4, 1000)x2 = np.random.normal(-3, 1, 1000)x3 = np.random.normal(2, 2, 1000)kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=40)plt.hist(x1, **kwargs)plt.hist(x2, **kwargs)plt.hist(x3, **kwargs) 参数1234567891011121314151617plt.hist( x: 数据, bins: 柱数, range: 上下边界, density: 频数转换成频率, weights: 每个数据的权重, cumulative: 计算累计频数或频率, bottom: 基准线, histtype: 柱状图类型 _bar_ / barstacked / step / stepfilled, align: 边界对齐方式 left / _mid_ / right, orientation: 方向 _vertical_ / horizontal, rwidth: 柱宽, log: 是否对 y 轴取对数, color: 颜色, label: 图例标签, stacked: 有多个数据时是否堆叠 默认水平) 二维数据二维直方图在两个维度进行切分，来查看数据的分布 12345x = np.random.randn(1000)y = np.random.randn(1000)plt.hist2d(x, y, bins=30, cmap='Blues')plt.colorbar() 饼图","link":"/Program/Python/Matplotlib-%E5%85%A5%E9%97%A8/"},{"title":"Morgan Stanley 的面试题","text":"TMD，跟资本拼了 卷入资本的大潮踩在浪尖上的就是巅峰踩不上的就卷到大海里走上人生巅峰了属于是 摩根士丹利在我们学校招聘，提供了一些公开的习题，我也来做做看 JavaFilter12345678910111213import hava.util.stream.Stream;class Main { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of( &quot;Morgan&quot;, &quot;Stanley&quot;, &quot;Investment&quot;, &quot;Managment&quot; ); stream.filter( str -&gt; &quot;AEIOU&quot;.indexOf(Character.toUpperCase(str.charAt(0))) != -1) .forEach(System.out::println); }} OOP12345678910111213141516171819202122232425262728abstract class Animal { public void sound() { System.out.println(&quot;sound &quot;); }}class Dog extends Animal { public void sound() { super.sound(); }}class SleepingDog extends Dog { public void sound() { System.out.println(&quot;silence &quot;); }}class Main { public static void main(String[] args) { Animal rex = new Dog(); Animal spike = new SleepingDog(); rex.sound(); System.out.println(&quot;of &quot;); spike.sound(); }} Recursive1234567891011121314151617181920212223242526272829public class Main extends Thread { public static int result = 1; private int n; Main(int x) { n = x; } public void fac() { if (n &lt;= 1) { result *= 1; return; } result *= n; Main thread = new Main(n - 1); thread.start(); } public void run() { fac(); } public static void main(String[] args) throws InterruptedException { Main thread = new Main(5); thread.fac(); System.out.println(result); }} Concept You can define static functions outside classes. There are 4 different access modifiers in Java. A Java class can extend multiple classes. A Java interface can extend multiple interfaces. Type Size byte 1 bit boolean 1 bit char 2 bit int 4 bit double 8 bit PythonSyntax [] * 42 [_ for _ in range(66) if not _] [[i for i in range(2)] if i is 1] ['Why?' for why in ['Yes', 'Indeed', 'Sure']] For12345678for i in range(1, 3): if not i % 3: print(&quot;Found: &quot;, i, end=', ') break else: passelse: print(&quot;Invalid&quot;, end=', ') Equality123str1 = &quot;equality in Python&quot;.upper()str2 = &quot;EQUALITY IN PYTHON&quot;print(str1 == str2, str1.__eq__(str2), str1 is str2) OOP123456789101112class A: def a(self): return 'a' def b(self): return 'b'd = dir(A())for fun in d: if not fun.startswith('__'): result = getattr(A(), fun)() print(result, end='') Numpy123import numpy as npa = np.array([[1, 2], [3, 4]])print(int(np.linalg.det(a))) C++SizeHow many bits in a C++ byte? 4 / 8 / 8+ / depends on system FlushWhich of the following will flush the output buffer? std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; '\\n'; std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; std::flush; printf(&quot;Please flush!&quot;); Pointer123int arr[3] = {1, 2, 3};int *p = arr;std::cout &lt;&lt; *p++ &lt;&lt; &quot; &quot; &lt;&lt; * p &lt;&lt; std::endl; Virtual The member function to call is resolved at compile time based on the type of the pointer or reference to the object. The member function to call is resolved at runtime time based on the type of the pointer or reference to the the object. The member function to call is resolved at runtime time based on the type of object(not the pointer or reference to the object), by checking the v-table realted to the object instance. The member function to call is resolved at runtime time based on the type of object(not the pointer or reference to the object), by checking the v-table associated with the object class.","link":"/Program/Morgan-Stanley-%E7%9A%84%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"NLP-Alignments","text":"对齐 AI alignment in generalAI系统的 对齐 是确保其操作符合 人类（用户、操作员等）的预期目标和偏好 一般的伦理原则 （ethical） 基于机器学习的AI系统的行为受到其开发者的多种方式影响。最重要的是，他们选择/开发了 用于训练数据驱动模型的数据集 如果模型使用强化学习进行训练，则是奖励函数（reward） 一般来说，在训练期间通过使用的参数优化方法（例如梯度下降）最小化或最大化的损失或目标函数 不对齐（misalignment 缺乏对齐）的实例有时分为两种（不一定容易区分）的类型： 外部不对齐：开发者指定的系统目标或奖励与预期的人类目标之间的偏差 内部不对齐：显式指定的训练目标与系统实际追求的目标（所谓的涌现目标 emergent）之间的偏差 指令跟随大型语言模型中的涌现少样本能力Emergent few-shot abilities 正如GPT-3所展示的那样，使用标准MLE目标训练的LLM在许多任务上表现出显著的 0-shot、1-shot和少样本性能： 在许多情况下，MLE训练的LLM只需要一个包含任务简单描述的提示，并且可选地提供几个示例即可表现良好： 据报道，MLE训练的GPT-3在没有任务特定微调的情况下，在以下任务上表现良好： 翻译 问答 阅读理解 SAT风格的类比 检测句子之间的逻辑关系 简单算术 单词拼写和操作（如字谜、单词反转等） 根据给定的标题和风格写诗 指令跟随模型这些观察自然引出了基于LLM的通用 指令跟随助手 的想法，这些助手可以根据描述执行广泛的、开放式的任务。 从这种预期用途的角度来看，对这种模型的期望包括： 有帮助的：它应该真正尝试执行所描述的任务 诚实的：它应该提供准确的信息，包括在适当情况下表达不确定性 无害的：它不应该具有攻击性、歧视性，也不应该推荐或帮助危险或不道德的行为 指令跟随中的不对齐关于这些人类目标和期望（它们应该作为 有帮助的助手）来说，GPT-3类的LLM在以下情况下训练 （主要）在未经筛选的网络抓取数据上 使用基于标准MLE的语言建模目标 将会 不对齐：根据收到的提示，它们 可以轻易生成 有害的（危险的、歧视性的等）内容 产生听起来合理但不真实、误导性的陈述（“幻觉” hallucinations） 可能无法（尝试）真正执行所描述的任务 关于仅使用MLE训练的LLM正确执行任务的重要类型的不对齐是对小的和（对用户来说）看似无关紧要的 提示差异 过于 敏感。在任务描述、示例选择和示例顺序上的微小变化被报告为导致了巨大的性能差异。 一个说明性示例：实验提示模板对 他们发现左边的0-shot模板在GPT-3版本上比右边的1-shot甚至10-shot实例表现更好。（在WMT’14 Fr-En数据集上的BLEU得分为1-shot的18.0，10-shot的24.1，但0-shot提示的26.5。） 对齐与不对齐是相对使用案例的MLE训练的语言模型仍然可以（并且确实）与其他合法的使用案例 良好对齐，例如，用于 OCR 或 语音识别 的语言建模，其中任务只是评估在某种上下文中由人类产生的一段文本或语音的概率。 与指令跟随的对齐监督微调提高指令执行的低和/或不一致性能的最明显方法是创建一个包含大量不同任务的 监督数据集，其中包含 $$(\\mathrm{task \\space instruction}, \\mathrm{correct \\space response})$$ 对，并在其上对MLE预训练的LLM进行 微调。 给定一个好的指令数据集，监督微调本身不需要特殊技术，例如，对于一个transformer-decoder类型的语言模型 $(\\mathrm{instruction}, \\mathrm{response})$ 对被转换为单个序列，中间有一个固定的分隔符（例如，Flan在它们之间使用一个“特殊的EOS标记”） 训练损失是通常的 交叉熵损失（使用教师强制），它可以包括指令中标记的损失，但可能权重较低 指令数据集更严峻的挑战是创建高质量的指令数据集 （instruction）。创建数据点的主要策略是 手动创建：正确的响应由人工注释者编写，指令要么从用户与LLM的交互中收集，要么也是手动创建 数据整合：使用手动创建的模板将现有的监督NLP任务数据集转换为自然语言的 $(\\mathrm{instruction}, \\mathrm{response})$ 对 基于LLM的合成生成：响应由LLM生成（但可能由人类过滤），而指令要么 从用户提示中收集 也由LLM基于手动创建的种子提示生成 数据整合：Flan从2020年开始，发布了几个指令微调数据集，其中基于大量NLP任务数据集的Flan具有高度影响力： Flan为每个数据集使用10个手动创建的转换模板来转换数据点： 合成生成像 Self-Instruct [S-I] 这样的激进合成(Synthetic)生成方法使用 一个小的手动创建的初始池 种子任务指令（S-I 使用 175 个）和具体示例（S-I 每个任务使用 1 个示例） 随机抽取池中的内容来 提示 LLM 生成更多的指令和示例 生成的新指令和示例使用启发式规则进行 过滤，高质量的内容被添加到池中。采样、生成、过滤和池扩展步骤可以 递归重复，直到达到所需的数据集大小。 即使生成器模型是一个普通的 MLE 训练的 LLM，Self-Instruct 风格的合成生成数据集在指令微调中也可以非常有用。报告显示，在 SuperNatural Instructions 数据集上使用 ROUGE-L 评分测量性能， 普通 GPT-3 在自生成的 Self-Instruct 数据集上微调后性能提高了 33% 它非常接近 InstructGPT 的性能（39.9 对 40.8%） 由于其多样性，它们也可以作为手动创建的指令数据集的有用补充。 基于人类反馈的强化学习也许最有影响力的方法是 OpenAI 对 GPT-3 微调的方法： 起点是一个 MLE 预训练的 GPT-3 和一个 监督数据集，该数据集包含指令提示（从 API 调用中收集）和 手动创建的首选输出示例 预训练模型在此数据集上进行 MLE 微调 微调模型和标注者的监督信号用于训练一个回归 奖励模型，该模型为提示-响应对分配标量奖励 最后，使用奖励模型提供的信号，通过 强化学习 进一步微调模型 将文本生成视为强化学习问题 状态 是要继续的标记序列——可能只包含一个 $\\langle start \\rangle$ 标记 动作 是从词汇表中添加一个新标记到序列中，因此 $|\\textrm{Actions}|=|\\textrm{Vocabulary}|$ 状态转换 是 确定性 的（添加一个标记确定性地产生扩展序列） 策略 基本上是“预测下一个”类型的语言模型，通常是随机的，因为通常有几种替代的续集 奖励 通常是稀疏的，即基于整个完成的序列 奖励模型 奖励模型（RM）的起点是一个相对较小的（6B）MLE预训练的GPT版本，该版本也在监督数据集上进行了指令微调 初始奖励模型只是这个语言模型，将其解嵌层替换为回归头 奖励模型在一个手动创建的质量比较数据集上进行训练，该数据集包含监督数据集中提示的替代模型输出对（由MLE微调的大型GPT-3生成） 奖励模型在 $(x, y_{better}, y_{worse})$ 三元组上的损失，其中 $x$ 是从提示数据集中采样的指令，$y_{better}, y_{worse}$ 是两个排序的替代模型输出，是 $$-\\log(\\sigma(RM_{\\Theta}(x, y_{better})-RM_{\\Theta}(x, y_{worse})))$$ 引导模型为给定的指令提示提供更高的奖励给“更好”的输出。 强化学习训练最后一步是使用奖励模型通过 强化学习 进一步微调语言模型 使用的算法通常是 近端策略优化（Proximal Policy Optimization PPO），这是一种策略梯度变体，通过将更新剪辑到一定范围来避免进行过大的策略更改 强化学习训练的目标是 最大化 奖励模型对（指令，模型响应）对的预期奖励，但也要 最小化（缩放版本的）策略预测的条件分布与用于初始化的指令语言模型之间的 KL散度 直接偏好优化（Direct Preference Optimization DPO）RLHF需要训练一个单独的奖励模型和一个人类反馈循环，这两者都很昂贵。 直接偏好优化 将RL优化问题转化为监督（机器学习）任务。 重新参数化RL优化问题，以__策略__而不是奖励模型$RM$为基础 为策略 $\\pi_\\theta$ 制定最大似然目标 在原始用户判断上通过监督学习优化策略 DPO… 表现类似于PPO，有时甚至更好 需要的计算量比PPO少5-8倍，内存需求减半 对采样温度不太敏感 助手聊天机器人作为对话系统的指令微调语言模型近年来，指令数据集生成和微调方法的成功导致了一系列指令微调的大型语言模型的发展：Google的FLAN、OpenAI的InstructGPT、Stanford的Alpaca等。 作为对话系统，这些模型支持的对话具有以下特点： 用户发起 由正好 两轮 组成 其 目标 是 执行描述的任务 与传统的任务导向系统相比，没有预定义的领域和任务列表，范围是真正 开放的 Assistant chatbots指令微调模型最明显的限制是它们不支持 多轮对话，而对齐的大型语言模型的下一个开发周期的主要目标是消除这一限制。 主要解决方案是保持用于指令微调的框架： 从一个 MLE预训练的大型语言模型 开始 收集一个$D$ 条件文本生成数据集，包含$(x, y)$输入-输出对 在$D$上对预训练的大型语言模型进行 微调，使用监督训练和可选的基于RLHF的训练（后者需要额外的数据和奖励模型的训练） 主要区别在于，条件文本生成的输入不是单个指令，而是一个复杂的 助手对话上下文的表示，包括其 历史： 表示对话历史最简单的表示当然是完整的 $$[u_1, s_1, u_2, \\dots, s_{N-1}, u_N]$$ 从开始到结束交替出现的用户和系统话语列表，但在非常长的对话情况下，这可能会超过模型的最大输入大小，因此通常会被 截断。 更复杂的解决方案不仅仅是简单地删除对话的早期部分，而是用某种压缩表示来替换它，例如 摘要。 挑战尽管取得了不可否认的进展，当前基于LLM的开放域辅助聊天机器人仍然可能 提供不准确或误导的信息（“幻觉”） 产生__冒犯或危险__的输出 未能真正尝试执行任务 因此，在 诚实、无害 和 有帮助 方面的进一步对齐仍然是一个活跃的研究领域。","link":"/AI/NLP/NLP-Alignments/"},{"title":"NLP-Classification-SequenceTagging","text":"分类和序列标注 文本分类文本分类任务文本分类任务是从给定的 $C={c_1,\\dots,c_n}$ 类别/分类标签集中为 $d$ 文本/文档 分配适当的标签。 代表性的例子包括 情感分析：根据文档表达的情感进行分类。标签集示例： { positive, negative, ambigous } { admiration, amusement, annoyance, approval, …, sadness, surprise } 垃圾邮件检测：SPAM，二分类决定消息是否为未经请求的邮件 作者身份检测：从指定的作者集中确定谁写了文本 作者特征检测：作者是男性还是女性，他们的年龄等 主题/话题检测：文档属于预定义列表中的哪个 主题/话题，例如，在国会图书馆分类系统中 { 医学, 农业, 科学, 美术, … } 体裁检测：Genre，确定文本的体裁，例如，从集合 { 科幻, 冒险, 爱情故事, 悬疑, 历史, 西部 } 中分配标签 方法 手工设计的基于规则的系统：例如，使用精心设计的与类别正相关或负相关的词列表。 这些系统可以达到良好的性能，但需要大量的手工工作，并且难以维护和适应。 机器学习方法：在包含标记文档的监督数据集上学习的模型：${\\langle d_i, c_i \\rangle}_{i\\in {1, \\dots, N}}$ 方法范围从线性机器学习方法如逻辑回归（logistic regression）到深度神经网络。 词袋表示法Bag of words 许多基于机器学习的分类方法需要将输入表示为固定长度的数值向量。对于长度不一的文本，一个常见的方法是使用词袋表示法： 使用词汇表 $V={w_1,\\dots,w_N}$ 对输入文本进行分词 并将它们表示为 $|V|=N$ 维的词频向量，即，对于一个文档 $d$，$BOW_V(d)=\\langle c_{1,d}, \\dots, c_{N,d}\\rangle$，其中每个 $c_{i,d}$ 是 $w_i$ 在 $d$ 中的出现次数 一个简单的例子： 词袋表示法的改进基本的 BOW 表示法可以通过几种方式进行改进，可能最重要的三种是： 从 BOW 向量中省略stopword（非信息词）的计数。什么算作停用词取决于任务和领域，但通常会考虑（某些）功能词，例如限定词作为停用词 向 BOW 表示中添加一些词序列计数，例如，bigram或三元组计数 根据词的信息量对词进行加权：最广泛使用的方法是根据词频和逆文档频率（term frequency-inverse document frequency）进行加权 TF-IDF 方案TF-IDF 加权方案的基本假设是，出现在大部分训练文档中的词不如只出现在少数文档中的词信息量大。因此，TF-IDF 向量相应地通过文档频率来折扣 word counts（term frequencies）。一个简单但广泛使用的变体： $$TF{\\text -}IDF(d)=\\langle tf_{1,d}\\cdot idf_1, \\dots, tf_{N,d}\\cdot idf_N\\rangle$$ 其中 $tf_{i,d}$ 只是 $w_i$ 在 $d$ 中的出现次数，而 $$idf_i = \\log\\frac{\\mathrm{\\# of \\space all \\space documents}}{\\mathrm{\\# of \\space documents \\space containing} \\space w_i }$$ 二进制词袋表示法词袋表示法的一种有趣的简化是仅指示单词的存在或不存在： $$BOW_{bin}(d)=\\mathop{\\mathrm{sign}}(BOW(d))$$ 其中 $\\mathop{\\mathrm{sign}}$ 函数的应用是逐元素的，即， $$BOW_{bin}(d)=\\langle \\mathop{\\mathrm{sign}}(c_{1,d}), \\dots, \\mathop{\\mathrm{sign}}(c_{N,d})\\rangle$$ 事实证明，在许多情况下，这些更简单且占用内存更少的表示法可以代替正常的 BOW 向量使用，而不会有明显的性能差异。 朴素贝叶斯与词袋表示法Naive Bayes classifier with BOW 在其最简单的形式中，朴素贝叶斯（NB）分类器是一种生成模型，建模 $\\mathbf{x}$ 观测特征向量和它们的 $c$ 类别标签的联合分布为 $$P(\\mathbf{x}, c) = P(c)\\prod_{i=1}^D P(x_i \\space \\vert \\space c)$$ 该模型被称为“朴素”，因为它基于条件独立假设（conditionalindependence assumption），即在给定类别标签的情况下，所有观测特征彼此独立。 NB 模型可以通过指定以下内容来精确描述： 类别标签的分类分布 $P(c)$，以及 每个 $x_i$ 观测特征和 $c_j$ 标签的 $P(x_i \\space \\vert \\space c_j)$ 分布 $P(c)$ 始终是一个分类（伯努利或“多项”）分布，而 $P(x_i \\space \\vert \\space c_j)$ 分布的选择取决于 $x_i$ 的类型；对于连续的 $x_i$，它可以是任何连续分布，高斯分布是一个常见的选择。 NB 模型可以通过将 NB 假设应用于单个标记来适应文本分类：假设每个标记是根据分类条件分布 $P(w \\space | \\space c)$ 独立选择的。如果 $\\mathbf{x}$ 是一个词袋向量，$c$ 是一个类别标签，这意味着 $$P(\\mathbf{x}, c) = P(c) \\prod_{i=1}^{|V|}P(w_i \\space \\vert \\space c)^{x_i}$$ 为了数值稳定性，对两边取对数： $$\\log P(\\mathbf{x}, c) = \\log P(c) + \\sum_{i=1}^{|V|}x_i \\log P(w_i \\space \\vert \\space c)$$ 这意味着，给定一个 $\\mathbf{x}$ 词袋向量和一个向量 $$\\theta_c=\\langle \\log P(w_1 \\space \\vert \\space c),\\dots,\\log P(w_{|V|} \\space \\vert \\space c) \\rangle$$ 表示类别 $c$ 的条件对数概率， $$\\log P(\\mathbf{x}, c) = \\log P(c) + \\theta_c \\cdot \\mathbf{x}$$ 即 $(\\mathbf{x}, c)$ 的对数概率对于每个 $c_i$ 是一个简单的线性函数。对于一个文档 $d$，预测最可能的类别也非常简单： $$\\hat c = \\mathop{\\mathrm{argmax}}_{c\\in C}(\\log P(c) + \\theta_{c} \\cdot BOW(d))$$ 模型参数的最大似然估计可以基于简单的计数： $$P(c) \\approx \\frac{\\# \\mathrm{of} \\space c \\space \\mathrm{documents}}{ \\# \\mathrm{of \\space all \\space documents }}$$ $$P(w \\space | \\space c) \\approx \\frac{\\# w \\space \\mathrm{occurrences \\space in} \\space c \\space \\mathrm{documents}}{\\# of \\space \\mathrm{words \\space in} \\space c \\space \\mathrm{documents}}$$ 由于我们基本上在处理每个类别的（unigram）语言模型，数据稀疏性再次带来了问题。 最极端的情况是，如果一个词 $w\\in V$ 在任何 $c$ 类别的文档中都没有出现，那么基于语料库的最大似然估计 $P(w \\space | \\space c)=0$，因此，对于任何包含 $w$ 的非零计数的 $\\mathbf{x}$ 词袋向量的文档， $$P(\\mathbf{x}, c) = P(c) \\prod_{i=1}^{|V|}P(w_i \\space \\vert \\space c)^{x_i}=0$$ 无论它们包含任何其他词。 解决方案是使用适当的平滑方法，例如，加一平滑。 朴素贝叶斯的局限性尽管基于 BOW 的 NB 模型相对简单，可以用于估计和预测，并且表现尚可，但也存在一些缺点： NB 条件独立假设相当不现实，并且在基本 BOW 模型中会导致误导性的概率预测 NB 假设使得使用 $N$-gram 基于 BOW 的特征向量比使用 unigram 更加值得怀疑 对于判别任务使用完整的生成模型通常会带来一些性能损失 判别线性方法在经典学习算法领域中，最重要的替代方法是使用 BOW 向量的判别方法之一： 感知器变体 perceptron variant 逻辑回归 支持向量机（SVM）， 基于决策树的集成方法，如随机森林或梯度提升树 这些模型不假设条件独立，并且在使用改进的（例如基于 $N$-gram 的）BOW 表示作为输入时没有问题。 有些出乎意料的是，在某些应用中，在朴素贝叶斯文本分类器中使用重叠(overlapping)的 $N$-gram 实际上对性能有益处，例如，character $N$-gram 经常用于语言识别的 NB 模型中。 序列标注序列标注任务通常是将给定有限标签集 $T$ 中的一个标签分配给可变长度输入序列的每个元素。在 NLP 中，输入序列通常是 $\\langle w_1,\\dots,w_n \\rangle$ 的标记序列。因此，序列标注任务也被称为 标记分类。 在传统的 NLP 流水线中，有些任务是明确的序列标注任务，例如词性标注（POS-tagging）和形态标注（morphological tagging）。其他任务，如名词短语分块（NP-chunking）、命名实体识别（NER）或关键词识别，可以通过简单的技巧转化为序列标注任务。 IOB 标注Inside-Outside-Beginning 这些任务表面上是跨度查找和跨度标注任务：目标是找到属于某些类别的标记跨度。 例如，在（最小）名词短语（NP）分块的情况下： IOB 技巧是将 跨度识别/标注 （span identification） 任务重新表述为序列标注任务。如果有 $T_1,\\dots,T_N$ 个要识别的跨度类型，那么我们引入三种类型的标记级别标签： 对于所有跨度类型的 $B$（开始）标签：$BT_1,\\dots,BT_N$ 表示给定类型的跨度的第一个标记 对于所有跨度类型的 $I$（内部）标签：$IT_1,\\dots,IT_N$ 表示一个标记在跨度内（作为第二个或更晚的元素），最后 对于不属于任何要找到的跨度类型的标记，使用唯一的 $O$ 标签 使用这些标签，跨度识别任务变成了序列标注任务。 除了 IOB（BIO）之外，还有其他方案，最流行的是 BIOES，它引入了 $ET_i$ 结束标签，以及用于单标记跨度的 $ST_i$ 标签。 序列标注的挑战序列标注的主要挑战是元素标签与其他元素的特征（包括它们的标签）之间的复杂相互依赖性：在大多数 NLP 标注任务中，标签是 强烈依赖上下文 的。 另一个重要问题是特征工程：哪些序列元素的特征与标注相关？如果要正确处理词汇表外的单词，那么至少有些特征可能应该基于单词的表面形式，例如其大写、后缀等。 序列标注的监督方法这些方法假设有一个监督数据集 $$D={\\langle \\mathbf{x_1},\\mathbf{y_1} \\rangle,\\dots, \\langle \\mathbf{x_N},\\mathbf{y_N} \\rangle}$$ 其中每对 $\\langle \\mathbf{x}_i, \\mathbf{y}_i \\rangle$ 包含一个要标注的序列 $\\langle x_1^i,\\dots,x_{n_i}^i\\rangle$ 和对应的正确标签序列 $\\langle y_1^i,\\dots,y_{n_i}^i\\rangle$。 我们将讨论的方法都是概率方法（probabilistic）：它们要么建模 $P(\\mathbf{X}, \\mathbf{Y})$ 联合分布（generative model），要么建模 $P(\\mathbf{Y} \\space | \\space \\mathbf{X})$ 条件分布（判别模型，discriminative model）。 隐马尔可夫模型(Hidden Markov models) HMMs 是基于假设可观察序列 $\\mathbf{x}$ 的元素实际上依赖于位置上对应的隐藏序列 $\\mathbf{y}$ 的元素的 $P(\\mathbf{X}, \\mathbf{Y})$ 分布的生成模型，而这些隐藏元素又根据马尔可夫模型分布。条件独立假设共同遵循以下图形模型： 由于关于 $Y$ 的马尔可夫模型假设，有一个 $A$ 矩阵指定所有标签的转移概率，因此对于任何适当的 $k, i, j$， $$P(Y_k=y_j \\space | \\space Y_{k-1}=y_i) = a_{i j}$$ HMMs 还假设 $P(X \\space | \\space Y)$ 发射概率与位置无关：因此也有一个 $B$ 矩阵，对于任何 $k, i, j$， $$P(X_k= x_j \\space | \\space Y_{k}= y_i) = b_{i j}$$ 假设最终有一个包含每个可能 $y_i$ 标签的起始概率的 $\\Pi$ 向量： $$P(Y_1 = y_i) = \\pi_i,$$ 具体的 $\\langle \\mathbf{x}, \\mathbf{y} \\rangle =\\langle \\langle x_{l_1},\\dots,x_{l_n} \\rangle, \\langle y_{m_1},\\dots,y_{m_n} \\rangle \\rangle$ 对的概率可以计算为 $$P(\\mathbf{x}, \\mathbf{y}) = \\pi_{m_1} b_{m_1 l_1} \\prod_{i=2}^na_{m_{i-1} m_i}b_{m_i l_i}.$$ $A, B$ 和 $\\Pi$ 中概率的最大似然估计 (MLE) 可以通过简单计数来计算。如果训练数据集包含 $N$ 个序列，那么 $$ \\begin{equation} \\begin{gathered} \\pi_i = \\frac{C(\\mathrm{first~~element~~is~~} y_i)}{N}\\\\ \\nonumber a_{ij} = \\frac{C(\\langle y_i,y_j\\rangle)}{\\sum_kC(\\langle y_i,y_k\\rangle)}\\\\ \\nonumber b_{ij} = \\frac{C(y_i \\mathrm{~~emits~~} x_j)}{C(y_i)} \\nonumber \\end{gathered} \\end{equation} $$ 与其他基于计数的 MLE 方法类似，在数据稀疏（sparse）的情况下可能需要平滑处理。 维特比算法Viterbi algorithm 给定一个训练好的 HMM 及其 $\\pi, A, B$ 参数，以及一个长度为 $n$ 的输入序列 $\\mathbf{x}$，我们希望确定最可能的对应标签序列 $\\mathbf{y}$，即找到 $$\\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^n} P(\\mathbf{y} | \\mathbf{x}, \\Pi, A, B)$$ 这等价于 $$\\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^n} P(\\mathbf{x}, \\mathbf{y} | \\Pi, A, B)$$ 穷举搜索是不可行的，因为有 $|Y|^n$ 种可能的标签序列。 动机：最小和算法我们如何根据如下图所示的图表找到 A 和 B 之间的最低成本路径？ 与时间复杂度可能是 A 和 B 之间最短路径长度的指数级的暴力（brute）解决方案不同，我们可以使用一个简单的 消息传递 方法。 从 A 开始，每个节点 接收来自其前驱节点（predecessors）的关于它们从 A 的最小和距离的消息 基于这些消息，计算自己的最小和距离和入边，并 将其最小和距离发送给所有后继节点 最终，消息到达 B，B 能够计算出 A-B 的最小和距离，并且可以重建 A 和 B 之间的最小和路径。 Min-Sum 算法可以适应解决我们的问题，因为它可以在不进行任何显著更改的情况下用于最大化节点之间路径上的乘积（max-product），并且 HMM 的 transition/emission 概率具有所需的有向无环图结构： The Viterbi algorithm更正式地说，HMM 的 conditional independence assumptions 有以下结果：如果我们知道，对于所有 $y_i\\in Y$，值 $$ \\mathbf{y}^{n-1}_i = \\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^{n-1}~\\wedge~\\mathbf{y}[n-1] = y_i} P(\\mathbf{x}[1:n-1], \\mathbf{y} ~|~ \\Pi, A, B) $$ （即以 $y_i$ 结尾的最可能的 $n-1$ 长度标签序列），那么最可能的 $\\mathbf{y}$ 可以通过仅比较 $|Y|^2$ 个延续来计算： $$ \\mathbf{y} = \\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in \\{\\langle \\mathbf{y}_i^{n-1},~y \\rangle ~|~ i \\in 1\\dots |Y|~\\wedge~ y \\in Y\\}} P(\\mathbf{x}, \\mathbf{y} ~|~ \\Pi, A, B) $$ 这就提出了以下算法： 算法通常通过逐步填充一个 $|Y| \\times \\mathrm{length}(\\mathbf{x})$ 表来实现。在前向传递中，它 计算 $y_i^t$ 的概率，并 维护到最可能的 $\\mathbf{y}^{t-1}$ 的反向引用 在后向传递中，选择最可能的 $y_i^n$ 并通过跟随反向引用恢复 $\\mathbf{y}$。 维特比是一种 动态规划 算法，与穷举搜索形成鲜明对比，其时间复杂度为 $\\mathcal O(\\mathrm{length}(\\mathbf{x})|Y|^2)$ 跟踪部分 $\\mathbf{y}_i^t$ 序列元素及其概率的表仅占用 $\\mathcal{O}(\\mathrm{length}(\\mathbf{x})|Y|)$ 空间。 直接计算要比较的概率需要乘以非常接近于零的数字，因此通常使用对数概率的和来进行计算。 注意：正如我们所见，维特比算法也被称为 最小和 或 最大积 算法的应用。 判别序列标注方法Discriminative methods 与朴素贝叶斯序列分类器类似，HMM 是生成模型，建模输入和标签的概率，这在我们的设置中是不必要的。我们可以通过“反转”输入和标签之间的箭头并对 $\\mathbf{X}$ 进行条件化来构建类似结构但判别的模型： 最大熵马尔可夫模型Maximum entropy Markov models (MEMMs) 根据前面的图形模型假设， $$ P(\\mathbf{Y}~|~\\mathbf{X}) = P(Y_1~|~ \\mathbf{X})\\prod_{m=2}^n P(Y_m|Y_{m-1}, \\mathbf{X}) $$ MEMMs 通过使 $Y_m$ 仅在当前观测 $O_m$ 上条件依赖来形式化这个通用模型： $$ P(\\mathbf{Y}~|~\\mathbf{X}) = P(Y_1~|~O_1)\\prod_{m=2}^n P(Y_m|Y_{m-1},O_m) $$ 那么 $Y_m$ 如何依赖于 $\\mathbf{X}$ 呢？诀窍在于如何定义 $O_m$。 特征函数$Y_{m-1},O_m$ 对被定义为 $\\mathbf{f}(y_k,\\mathbf{x}, m)$，其中 $f(\\cdot)$ 是一个基于 $Y_{m-1}=y_k$ 和 $x$ 在 $m$ 处生成 feature vector 的函数。 在 NLP 中，我们仅在要标注元素周围的上下文窗口内对local features进行条件化。由语言学家设计的一些用于词性标注的示例特征： 上下文窗口中 $x_m$ 周围的元素，例如 $\\langle x_{m-1}, x_{m}, x_{m+1} \\rangle$ 上下文窗口元素的后缀（固定长度） 上下文窗口元素的前缀（固定长度） 上下文窗口元素的大小写信息 前一个元素的词性标注 $y_k$ MEMMs个别的 $P(Y_m|Y_{m-1},X_m)$ 概率类似于使用 softmax 函数的multinomial logistic regression进行建模： $$ P(Y_m = y_i|Y_{m-1}=y_k,\\mathbf{x})=\\frac{\\exp (\\mathbf{w}_i \\cdot \\mathbf{f}(y_k, \\mathbf{x}, m))}{\\sum_{j=1}^{|Y|}\\exp (\\mathbf{w}_j \\cdot \\mathbf{f}(y_k, \\mathbf{x}, m))} $$ 其中每个 $\\mathbf{w}_i$ 是 $y_i\\in Y$ 标签的权重向量。 MEMM 这个名称来源于在 NLP 中，多项逻辑回归更常被称为maximum entropy。 标签偏置尽管 MEMMs 比 HMMs 更灵活（例如，标签可以依赖于上下文的其他特征而不仅仅是前一个标签），但它们也有重要的局限性。 也许最重要的是标签概率是局部归一化的：$\\sum_{y\\in Y}P(y~|y_{m-1}, \\mathbf{x}, m)=1$，无论模型对上下文有多“熟悉”，因此模型无法表达对给定上下文中的标签的一般低置信度。 这导致了所谓的Label bias问题：模型无法轻易从在低置信度情况下做出的过去标注错误中恢复。 示例一个词性标注器将句子 “cat sat” 标注为 ARTICLE VERB，因为 标注器无法从 &lt;S&gt; 处 cat 的偏斜后验分布（skewed posterior distribution）中恢复，使用局部归一化（图1）。 未归一化的 $\\mathbf{w}_i \\cdot \\mathbf{f}(\\cdot)$ 观测值（图2）显示 标注器对”cat“ 开始一个句子没有信心 全局 NOUN VERB 具有更高的分数（对数和沿边缘相加） 条件随机场线性链条件随机场（Linear chain Conditional Random Fields）是判别模型，旨在避免标签偏置。它们假设以下 undirected 结构： 根据这些假设， $$P(\\mathbf{Y}~|~\\mathbf{X}) = \\frac{1}{Z(\\mathbf{X})}\\prod_{m=1}^{n-1} \\phi_{m}(Y_m, Y_{m+1}, \\mathbf{X})$$ 与 MEMMs 有些类似，$\\phi_m(\\cdot)$ 势函数 （potential）通过特征函数和相应的权重向量线性建模。它们基本上是 softmax 的分子： $$\\phi_m(y_m, y_{m+1},\\mathbf{x})={\\exp (\\mathbf{w} \\cdot \\mathbf{f}(y_m,y_{m+1}, \\mathbf{x}, m))}$$ 关键区别在于归一化是全局的： $$P(\\mathbf{y}~|~\\mathbf{x}) = \\frac{\\exp(\\sum_{m=1}^{n-1}\\mathbf{w}\\cdot\\mathbf{f}(y_m,y_{m+1}, \\mathbf{x}, m))} {\\sum_{\\mathbf{y}'\\in Y^n}\\exp(\\sum_{m=1}^{n-1}\\mathbf{w}\\cdot\\mathbf{f}(y'_m,y'_{m+1}, \\mathbf{x}, m))}$$ 优化和推理MEMMs 和线性链 CRFs 都可以使用标准的凸优化技术进行优化，例如梯度下降，并且在训练模型后，可以使用维特比算法的变体有效地找到给定输入的最可能标签序列。","link":"/AI/NLP/NLP-Classification-SequenceTagging/"},{"title":"NLP-Contrastive","text":"对比表征学习 自监督学习主要目标自监督学习（Self-supervised learning）旨在从数据本身获取监督。 “从一切中预测一切。”Yann Lecun 数据是部分已知，部分未知的。利用数据的潜在结构（例如语言建模中的顺序性）。 为什么不是强化学习？试错法无效。 优势自监督学习： 降低标注的成本和复杂性 增加系统的额外泛化 generalization 能力 使得可以利用数据的内部结构 能够重建控制输入集的潜在 latent 变量 基于能量的建模基于能量的建模（Energy-based modeling）是大多数 SSL 方法的统一原则。 EBM 解决了 $L_2$ 类损失的“平均问题”。 想象一个有多个可行输出的情况（例如 Skipgram 模型中的相邻词） 损失将对这些单个输出的“平均值”最小化 我们希望损失函数对每一个可行解都接近最小 能量函数能量函数 $F(x, y)$ 在 $x \\in X$ 输入空间和 $y \\in Y$ 输出空间上设计来解决这个问题，其中低能量意味着可行解。 这种模型的推理可以通过：$\\hat{y} = argmin_y F(x, y)$ 需要注意的是，多个 $\\hat{y}$ 可能是可行的！ 能量函数 $F(x, y)$ 衡量 $x$ 和 $y$ 之间的兼容性。 作为概率模型的 EBM使用 Gibbs-Boltzmann 分布，生成（联合“分布”）EBM 可以转换为判别概率模型： $P(y|x) = \\frac{e^{-\\beta F(x, y)}}{\\int_{\\acute{y}} e^{-\\beta F(x, \\acute{y})}}$ 这里 $\\beta$ 是一个正常数，$\\acute{y} \\in Y$。 多模态 EBM 架构EBM 对于创建联合 Multimodal 表示非常有用。 潜 Latent 变量可以用于生成过程（例如扩散 diffusion）。$z$ 是一个独立的“解释 explanatory”变量。可以通过对 $y$ 和 $z$ 的联合最小化进行推理。 EBM 的学习方法主要目标：为可行的 $x$-$y$ 对获取低能量，同时为不兼容的对保持高能量。 对比方法 为每个兼容对（即数据集的正元素）降低 $F(x, y)$ 为每个其他可能的组合（即负示例）提高 $F(x, y’)$ 主要目标：为可行的 $x$-$y$ 对获取低能量，同时为不兼容的对保持高能量。 正则化方法 确保低能量区域的范围有限或最小化 正则化、量化、聚类等 主要目标：为可行的 $x$-$y$ 对获取低能量，同时为不兼容的对保持高能量。 对比学习及其变体学习方法对比学习通常包括以下主要步骤： 选择一个 $q$ 查询并从正样本分布 $k^+\\sim p^+(.|q)$ 和负样本分布 $k^-\\sim p^-(.|q)$ 中采样 应用模型变换，将 $\\mathcal{X} \\rightarrow \\mathcal{R}^N$ ，其中 $N$ 是结果嵌入维度，$x \\in \\mathcal{X} | x = (q, k)$ 使用基于能量或概率的方法对正负样本对进行评分 参数更新 评分函数评分函数是损失计算的核心，由所需嵌入空间的属性决定。它们是简单的函数，例如： L1 或 L2 距离 点积 双线性模型 $S(q, k) = qAk$ 基于距离和概率的损失函数建立在这些度量之上。 基于距离的损失函数对 Pair 损失$\\mathcal{L}_{pair} = \\begin{cases} ||q-k^+||_2^2\\ max(0, m-||q-k^-||_2^2) \\end{cases}$ 其中 $m$ 是围绕 x 的预定义边距。这最小化了正样本的距离，并尝试将负样本的距离推到边距之外。 三元组 Triplet 损失$\\mathcal{L}_{triplet} = max(0, ||q-k^+||_2^2 - ||q-k^-||_2^2 + m)$这种方法强制正样本和负样本之间的相对距离。 基于 Softmax 的概率损失函数动机：正确分类pairs。作为使用评分函数 $S(.,.)$ 的分类问题，我们可以将其表述为： $p(k^+|q) = \\frac{exp(S(q, k^+))}{\\sum_k exp(S(q, k))}$ 引入负采样到过程中，我们可以避免计算所有 $k$ 的分母。相反，我们将计算重新表述为一个二元问题。 噪声对比估计Noise Contrastive Estimation，如果我们从均匀分布中更频繁地采样负例 $M$ 次，则对对是正例 (C=1) 的概率为：$p(C=1|q,k) = \\frac{p(k^+|q)}{p(k^+|q)+m\\cdot p(k^-|q)}$ 因此，二元分类损失是（使用负对数似然）对所有可能对的： $$ \\begin{align*}\\begin{split} \\mathcal{L}*{bin\\_NCE} = - \\mathbb{E}*{p^+}[logp(C=1|q,k)] \\\\ - \\mathbb{E}_{p^-}[log(1-p(C=1|q,k))] \\end{split}\\end{align*} $$ 其中 $p^-(.|q)$ 是噪声（负样本）分布，$p^+(.,.)$ 是正分布。 InfoNCE我们可以构建一个包含多个负例和一个正例的集合 $K = {k^+, k^-_1, k^-2, …, k^-{M}}$，而不是二元分类。然后修改后的任务是确定哪个元素是正例。这导致了一个类似 softmax 的度量，称为 InfoNCE： $$ \\mathcal{L}_{InfoNCE} = -log\\frac{exp(S(q, k^+))}{\\sum_{i=0}^{M+1}exp(S(q, k[i]))} $$ $$ \\mathcal{L}_{InfoNCE} = - S(q, k^+) + log\\sum_{i=0}^{M+1}e^{S(q, k[i])} $$ 为什么它有效？使用 InfoNCE 类损失函数训练模型 $f$ 反转（解码）数据生成的未知生成过程 $g$。因此，我们数据背后的潜在分布被重建并变得可访问。 采样示例数据生成过程可以包括广泛的自监督过程，例如： 邻域信息（空间或时间） 掩蔽 各种增强（视觉或音频噪声等） 添加标签监督通过结合标签信息（添加经典监督）也可以进行数据生成。在这种情况下，正常的 InfoNCE 方程将发生变化，因为存在多个正样本。这导致了 InfoNCE 项的总和。在对数内和对数外有两个变体。 $$ \\mathcal{L}^{sup}_{in} = \\sum\\limits_{q \\in J}-log\\left(\\frac{1}{|P(q)|}\\sum\\limits_{k^p\\in P(q)}\\frac{exp(S(q, k^p))}{\\sum\\limits_{i\\in I}exp(S(q, k[i]))}\\right) $$ 其中 $J$ 是批处理元素的集合，$q$ 是选定的查询元素，$I$ 是不包括 $q$ 的批处理元素集合，$P(q)$ 是与 $q$ 具有相同标签的元素集合。 $$ \\mathcal{L}^{sup}_{out} = \\sum\\limits_{q \\in J}\\frac{-1}{|P(q)|}log\\sum\\limits_{k^p\\in P(q)}\\frac{exp(S(q, k^p))}{\\sum\\limits_{i\\in I}exp(S(q, k[i]))} $$ 其中 $J$ 是批处理元素的集合，$q$ 是选定的查询元素，$I$ 是不包括 $q$ 的批处理元素集合，$P(q)$ 是与 $q$ 具有相同标签的元素集合。 不变性和等变性特征在标准对比学习中，正样本对具有所需的不变性。$S(q, k)$ 应该很高。当 $q=k$ 时，标准相似性度量最能产生这种行为。这种行为将抵消两个原始输入 $x_q$ 和 $x_k$ 之间的某些差异的影响。 令 $T(\\cdot)$ 变换表示这种差异，$f(\\cdot)$ 表示我们用 CL 训练的函数（或网络）。在不变的最优情况下： $x_k = T(x_q) \\rightarrow k = q$ 在某些情况下，我们希望在嵌入空间中保留这种变换。这意味着我们需要在嵌入空间中与输入空间中相同或相似的变换（$\\acute{T}(\\cdot)$）。 $x_k = T(x_q) \\rightarrow k = \\acute{T}(q)$ NLP 中的对比方法Word2Vec 作为对比学习 将 skipgram 重新表述为多编码器联合嵌入类型的自监督问题。 我们使用噪声对比估计损失（Noise Contrastive Estimation）而不是 Softmax。 正样本对最大化相似性（根据 EBM 建模最小化能量）。 负样本对最小化相似性（根据 EBM 建模最大化能量）。 BERT 下一句预测 文本嵌入模型预训练和微调的语言模型可用于生成文本的语义嵌入。 这在一般语言语义方面是有利的 在领域相关的嵌入或多任务嵌入的情况下，对比微调附加的自监督任务非常有用。这些任务可能包括： 检索，重新排序（根据查询查找/排序文档） 聚类（在嵌入空间中创建聚类） 文本分类 摘要 去重 对比多模态方法CLIP对比语言-图像预训练 问题：视觉分类器受限于有限的监督标签集 解决方案：使用自然语言描述视觉特征，尝试实现零样本/少样本学习 数据：来自网络爬虫的（图像，文本）对（甚至是文件名），包括 Instagram、基于 Wikipedia 的图像文本、YFCC100M 和 MS-COCO。开源的大规模数据集包括 Laion5B CLIP 结构图像嵌入 ($E_I$) ResNet 或 ViT $[n \\times d_I]$ 文本嵌入 ($E_T$) Transformer LM $[n \\times d_T]$ 线性投影 ($W_I$, $W_T$) $[d_I \\times d_E]$, $[d_T \\times d_E]$ 分类的温度参数 $t$（类似于 softmax 温度） 相似性的标签 $L$ 通常是单位矩阵 $[n \\times n]$ 按列（文本）或按行（图像）的交叉熵损失 $CE_{col | row}$ $S_{scaled} = \\frac{E_I \\cdot W_I}{||E_I \\cdot W_I||_{L2}} \\cdot \\left(\\frac{E_T \\cdot W_T}{||E_T \\cdot W_T||_{L2}}\\right)^T \\cdot exp(t)$ $[n \\times n]$ $loss = 0.5 CE_{col}(S_{scaled}, L) + 0.5 CE_{row}(S_{scaled}, L)$ CLIP 编码器细节 修改的全局池化：注意力池化 交叉注意力，其中图像特征是 K，V，Q 由一个学习的常量向量（或一组向量）定义。 ViT（视觉 Transformer）：使用图像的小块（矩形部分）作为标记的 Transformer。 文本编码器是一个 GPT-2 风格的模型。 CLIP 训练 CLIP 零样本推理 CLIP 可以根据相应的文本定义对图像进行分类。 选择通过找到最相似的类别定义来完成。 其他用例包括： 自定义分类器的基础模型 迁移学习的基础模型（性能优于以前的 ImageNet 模型） 图像检索（搜索引擎） 图像生成的条件向量 多模态语义 ImageBindCLIP 展示了通过在一个表示空间中结合多种模态可以产生额外的泛化能力。ImageBind 更进一步，将 $7$ 种模态结合在一个嵌入空间中。 自发 Emergent 对齐再次使用 InfoNCE，我们可以构建 $(\\mathcal{I}, \\mathcal{M}_1)$ 和 $(\\mathcal{I}, \\mathcal{M}_2)$ 的对齐。观察到这种对齐是传递的，并导致部分 $(\\mathcal{M}_1, \\mathcal{M}_2)$ 对齐。编码器现在从预训练模型（例如：CLIP）初始化。 ImageBind 结果多模态对比嵌入在没有自然存在的多模态信号（例如：文本到音频）的情况下，表现优于监督模态转换器。 ImageBind 的用例示例包括： 跨模态检索 嵌入空间算术 跨模态解码器再利用 跨模态检索 嵌入空间算术 跨模态解码器再利用 解码方法如何反转联合嵌入？ 迭代方法 前缀解码器 零样本解码器 对比描述器（Contrastive Captioners CoCa） 扩散过程（Diffusion） 我们的示例主要集中在视觉-语言模态对（主要是描述），但这些方法也可以适用于其他模态对。 迭代解码器最简单的解决方案，不涉及训练。 该方法依赖于语言模型。在生成过程中，中间文本输出被迭代地编码到联合 CLIP 空间，其中与编码图像表示最相似的被选中。然后基于这些生成新的候选描述（或续写）。 问题： 不准确（没有适当的指导） 效率低（随词汇量/描述长度扩展） 前缀解码器前缀解码器使用经典的 seq2seq 解码方法。通过结合 CLIP 和 LM（通常是 GPT），所需的数据量减少。 一个小的映射网络足以使 CLIP 图像嵌入空间和 LM 兼容。微调 LM 通常会带来轻微的性能提升。 我们可以想象映射器是一个小的 MLP 或 Transformer，从输入图像 $x^i$ 生成 $[p_1^i, …, p_k^i] = MAP(CLIP(x^i))$ 前缀。 前缀解码器中的映射为什么需要映射？ 对比损失不能确保正文本-图像对嵌入的精确匹配 领域相关的描述可能需要在嵌入空间中稍微不同的对齐/结构 前缀解码器的训练模型在带有描述的图像上进行微调。使用以下损失函数： $L = - \\sum_{i=1}^N\\sum_{j=1}^M log p_\\theta(c_j^i | p_1^i, …, p_k^i, c_1^i, …, c_{j-1}^i)$ 其中 $c_1^i, …, c_{j-1}^i$ 是之前的描述标记，$\\theta$ 表示可训练参数。 零样本解码器虽然前缀解码器有效且性能可接受，但它们仍然需要依赖于领域的（图像，标题）训练数据。 最流行的解决方案使用仅文本前缀微调解码器，并使用不同的技巧来替换 CLIP 空间映射： 基于先前编码文本嵌入的非训练投影 噪声注入以训练一个鲁棒的解码器 DeCap CapDec 对比描述器（CoCa）与前缀解码器相关的性能和效率问题： 当我们有交叉注意力时，我们还需要前缀吗？ 为什么不在对比训练阶段并行训练解码器，从而设计一个具有解码能力的原始模型？ 编码器应该是迁移学习的 CoCa 架构 CoCa 训练 从单模态预训练模型初始化模型 更改视觉头（不同的注意力池化用于标题生成和对比学习） 拆分文本，省略前半部分的交叉注意力 同时进行对比和重建（标题生成）训练 如果词汇表正好是可能类别的集合，则图像仅数据集也可以用于重建任务。 CoCa 推理对比描述器模型可以通过进一步微调或以零样本方式使用其构建块的任意组合。CoCa 不仅限于视觉-语言模态。 总结自监督学习（SSL）是一种强大且成本高效的训练方法，可以捕捉给定数据集的潜在分布。广泛使用的神经网络形式是通过对比学习（由 InfoNCE 类损失定义）。 对比方法生成多模态的联合嵌入，通过跨模态对齐创建强大的语义表示。这些方法对于检索和零样本分类任务非常有用。解码器（例如：描述器）也可以构建来执行逆任务。","link":"/AI/NLP/NLP-Contrastive/"},{"title":"NLP-DatasetsBenchmarks","text":"数据集，基准测试，引导 介绍众所周知，LLM 需要庞大的文本语料库进行（预）训练。实际上，我们使用几种类型的数据集来训练和/或评估 LLM： 预训练语料库 微调数据集 指令微调数据集 基准测试 在本讲座中，我们将详细讨论这些类型，并了解每种类型的最流行示例。 预训练LLM（顾名思义）总是通过某种形式的语言建模目标进行训练： 因果（自回归）语言建模 掩码语言建模（MLM） 等等 这种类型的预训练只能在庞大的文本语料库上进行（取决于模型大小）。LLM 需要比 人类儿童/年轻人 遇到的文本数据多得多。另一方面， LLM 没有多感官输入（有些在某种程度上有） 我们之前看到一次性标签会减慢收敛速度 预训练语料库大小 来源预训练语料库通常来自多种来源的混合： 网络文本 书籍和娱乐 学术存储库 程序代码 对话数据 杂项 the Pile 的组成：一个 800GB 的英语语料库用于 LLM 预训练。它由 22 个数据集创建，组成如下： 网络文本通常是任何预训练语料库中最大的组成部分。 优点： 易于获取，通常以网络抓取格式存在 数据量大 缺点： 质量参差不齐，通常低于其他来源 即使是好的页面也包含非内容元素（例如广告） 文本重复 偏见、有害、极端内容 AI 生成/自动翻译的内容 网络文本语料库Corpora Common Crawl (CC): 一个免费的、开放的网络抓取数据存储库，以 WARC 格式提供 大约每月一次新的抓取 数据量达到 PB 级；2023 年 9/10 月的抓取数据为 100TB 构成了大多数用于预训练的网络文本语料库的基础 Web ARChive 格式 EnglishC4: 从 2019 年 4 月的 CC 转储创建；750GB 用于预训练 T5 过滤包含不良词汇的文档（减少 $3\\times$） WebText: GPT-2 的预训练语料库 800 万文档，40GB 从“策划”的文档中创建：Reddit 上至少有 3 个 karma 的外部链接 不包括 Wikipedia，以避免 GPT-2 的测试集与训练集重叠 专有 OpenWebText: WebText 的开源重新实现 MultilingualOSCAR: 一个巨大的多语言语料库，由单个每月 CC 抓取创建 Ungoliant 数据管道 标记数量： 英语：3770 亿 匈牙利语：46 亿 约鲁巴语：1 千 ROOTS: 一个 1.6TB 的语料库 由 BigScience 编译 国际研究人员合作 Hugging Face 支持 用于预训练 BLOOM ROOTS 中的语言ROOTS 的语言分布。此外，与其他语料库（例如 OSCAR）相比，英语被高度下采样。 mC4: C4 的多语言版本 (Hugging Face HUB) 基于整个 CC 语料库（截至 2021 年），因此有足够的数据用于中等规模的语言，如匈牙利语（390 亿标记） 并未真正清理过，因此标记数量有些乐观 llm-datasets 数据集和脚本的 GitHub 仓库 包含 Common Crawl 以外的语料库 如何预处理 Common Crawl基于 Common Crawl 创建特定语言的网络文本语料库看似简单，但实际上是一个多步骤的过程，存在许多陷阱。这里我们回顾一下 cc_corpus 所采取的步骤，这是用于创建 Webcorpus 2 的管道。 要求：下载所有（多个）每月转储，因为只有英语在一个转储中有足够的标记。 下载索引 CC 索引是按域名而不是按语言划分的 例如，对于匈牙利语，我们下载 .hu 顶级域名 根据 OSCAR 统计，包含许多匈牙利语页面的其他域名 在每月索引转储之间去重 URL 下载数据 CC 不应被 DDoS WARC 文件需要大量空间 去除样板 去除网页的非内容部分（导航、广告、图片、表格等） 我们使用 jusText 和自定义代码去除 JS / cookie 警告 需要处理各种文件类型（HTML、RSS、文本等） 过滤 语言过滤 基于质量的过滤： 文档长度 还可以使用例如样板比例、某些 HTML 标签的长度等 去重 文档级去重以保持文本完整性 MinHash–LSH 设置 需要大量内存，否则会非常慢 可选：按域名去重频繁段落（基于内容的样板去除） 硬件设置： 在单个服务器上运行；多服务器通信正在进行中 所有类似映射的步骤都是高度并行的，以充分利用 多核/CPU 服务器 一台具有 768GB 内存的服务器用于去重 特殊网络文本数据集Wikipedia: 非常优质的编辑资源，大多真实 大小取决于语言，例如英语是匈牙利语的 10 倍 预处理并不简单，因为标记格式： wikiextractor 尝试解决这个问题 zim_to_corpus 从 Kiwix 的预处理 .zim 存档中提取文本 Stack Overflow, Reddit: 策划的数据集（points / karma） 可用于问答、编程等 编辑文本编辑文本是高质量文本的重要来源。不幸的是，与网络文本相比，数量上要难得多。 编辑文本通常有两种格式： 数字原生：从一开始就为数字消费准备的文本。通常可以直接使用，但 可能需要去除样板：表格、图形、页眉/页脚 编码问题确实会发生，尤其是 PDF 扫描：原本在纸上的数字化文档。版面分析 和 光学字符识别 (OCR) 的质量可能从可接受到非常糟糕不等。 编辑文本 / Prose自 BERT 以来，常规散文（如书籍）一直是 LLM 训练方案的一部分。文本的水平因体裁而异，导致训练语料库多样化。 BookCorpus 一个由 7,185 本自出版书籍创建的 985M 字语料库 用于训练 GPT 和 BERT，但后来被撤回，不公开提供 BookCorpus2 (the Pile)：BookCorpus 的扩展，大约 17k 本书 已出版书籍语料库： Books1-2 (GPT-3)：67B 标记 Books3，Project Gutenberg (the Pile)：分别约 187k 和 27k 本书 匈牙利电子图书馆 (MEK)：32,830 本书，800M 标记 OpenSubtitles： 从电影和电视字幕创建了 1689 个双语文本 可以从中提取大约 300M 字的语料库 语料库主要由对话组成 书籍等是预训练语料库的重要且非常有用的部分。然而，它们并非完全安全： 可能存在有问题的内容（色情、有害等） 在模型中使用它们可能导致 版权侵犯 编辑文本 / Professional通常是非常高质量的专业文本，具有自己的术语。 学术存储库： 非常高水平的文本 许多表格、图形等，打断文本流 通常需要大学访问权限（和爬虫）来下载论文 议会记录： 国家 / 欧盟 / 等等 有些可能提供 REST API，有些需要爬取 法律、裁决、法规等 新闻： 大量且重要的来源，但也可能有偏见和有害内容 极端重复 通常在付费墙后面 私人数据： 公司规则和公司内部通信 知识等 杂项数据对话 对于聊天机器人非常重要 对于通用对话：电影、书籍等 最重要的来源：互联网论坛、实际客户服务互动 编程 来自 CVS 服务（GitHub、SourceForge 等）的开源项目 版权和许可证违规是一个可能带来法律后果的问题 指令指令获取我们在前一讲中讨论了指令微调数据集的编译方式： 手动 / 众包努力 从用户收集数据 将 NLP 任务转换为指令 自我指令 我们已经看到 FLAN 如何将 NLP 任务转换为指令，但我们跳过了第一类。 Manual Instructions手动创建指令数据集需要众包（crowdsourcing）。两个例子： Databricks 的 Dolly： 包含 15,000 对提示/响应对 由 5,000 多名 Databricks 员工创建 ShareGPT： 用户分享他们与 ChatGPT 的对话 质量非常好，但由于 OpenAI 的许可证存在问题 被用于训练 Vicuna LAION 的 Open-Assistant 由志愿者编译 英语和西班牙语代表性很好，但其他语言代表性不足 Self-instruct两个自我指令数据集的例子： Alpaca： 使用 OpenAI 的 text-davinci-003 创建的最著名的自我指令数据集 页面包含有关如何使用 GPT3 进行指令生成的良好建议 由于 GPT3 许可证，不能用于商业目的 WizardLM： 使用 Evol-Instruct 从 Alpaca 创建 微调微调数据集已经证明，具有分类器头的 LLM 可以在 NLP 数据集上进行微调，以达到最先进的结果。这包括 传统的 NLP 任务（NP 分块、NER、依存解析等） NLU 任务（问答、自然语言推理等） 各种分类数据集（情感分析、主题分类等）这些通常在树库上进行训练 微调数据集具有训练-开发-测试拆分，因此它们也作为基准数据集。 传统数据集 任务 英语 命名实体识别 CONLL 2003 其他数据集 NP 分块 CONLL 2003 依存关系 Universal Dependencies 解析 Penn TreeBank 其他资源 可以在 NLP-progress page 上跟踪 NLP 任务的进展 有各种 NLP 数据集列表： Awesome NLP / Datasets nlp-datasets Awesome Hungarian NLP / Datasets NLU 数据集这些数据集包括传统 NLP 可以（和不能）解决的任务，但 LLM 可以。因此，这些数据集是 LLM 的便捷基准。 GLUE： 一个包含 9 个任务的 NLU 基准（句子相似性、释义、QA 等） 测试集不共享；在线排行榜 SuperGLUE： 8 个精心策划的任务（开放、困难、宽松许可等） SQuAD2.0： 由众包工人编译 10 万个问题加上 5 万个对抗性、无法回答的问题 MMLU： 一个仅用于测试的基准，包含 57 个主题中的 15,687 个选择题 对抗性基准测试问题：基准测试被越来越好的模型“快速”清除。我们能否创建更难的基准，使其持续时间更长？ 模型脆弱性：证据表明 自然语言推理（NLI）数据集由于（注释者）偏见而表现出虚假的统计模式 模型实际上学习了这些模式，而不是推理 因此，它们是脆弱的，可以被非专家注释者打破 想法：人类与模型循环启用训练（HAMLET）。 对抗性 NLI对抗性 NLI (Adversarial) 通过在注释者和模型之间引入“军备竞赛”编译而成。 这导致 一个良好的训练集，可以很好地转移到其他 NLI 基准 一个非常难的训练集 测试工具LLM 测试越来越多地通过 测试工具 自动化： Google 的 BIG-bench EleutherAI 的 lm-evaluation-harness 两者都包含 200 多个任务，并提供 新任务的轻松集成； 使用所有任务评估模型。 可重复的测试使得竞争成为可能，例如 Open LLM Leaderboard。 Bootstrapping什么是引导？引导 是一种使用现有资源创建新资源的方法。 在我们的例子中，我们将使用现有的预训练模型来创建新的数据集以训练新模型。我们通常使用现有的最大、性能最好的模型。在 2023 年底，这些模型是私有的 GPT-4 和开源的 LLaMa2-70B。 引导是： 成本效益高 快速 易于实施 能够生成高复杂度数据 有风险（许可证问题、质量问题） 使用现有模型生成数据“自我”指令在这里，我们使用现有模型为我们自己的模型生成数据。在这种情况下，另一个模型是教师，我们的模型是学生。 重要区别：与蒸馏相反，我们不使用教师在向量级别的预测，而是使用教师在数据集中的标记级别输出。这样就不需要直接访问教师模型。 斯坦福 Alpaca 声称，这种方式的指令微调具有成本效益且快速。它可以在几百美元内完成。 零样本链式思维可靠的链式思维（chain-of-thought）提示需要一些示例才能工作。通过使用 CoT 提示，我们可以为给定主题生成大量的 CoT 完成数据集。 WizardLM 通过使用 Evol-Instruct 逐步演变给定任务的指令，采用了一种更抽象的指令生成方法。这样生成的指令将覆盖任务空间的更广范围，并具有更复杂的提示。 我们提示我们的 LLM 生成指令的修改版本，然后使用这些版本生成数据集。这些修改步骤可以链接在一起。 Evol-Instruct任务演变的示例（对于基本任务“1+1=？”）： 深化：在什么情况下 1+1 不等于 2？ 增加推理：如果 x^3 + 2x + 3 = 7，x 的值是多少？ 具体化：如果你有一个苹果，有人给你另一个香蕉，你有多少水果？ 添加约束：如何在哥德巴赫猜想中证明 1 + 1 = 2？ 复杂输入：1/(sqrt(2) + 4^2) = ？ 广度演变（变异）：真空中光速是多少？ 增加演变推理（上述）：光在真空中比声音快多少倍？ 演变步骤 移除演变当以下情况发生时，消除中间结果： 演变后的指令相比原始指令没有提供任何信息增益。使用 ChatGPT 来做出这个决定 演变后的指令使得 LLM 难以生成响应。如果生成的响应包含“对不起”且长度相对较短（即少于 80 个单词），通常表明 LLM 难以响应演变后的指令 LLM 生成的响应仅包含标点符号和停用词 演变后的指令明显复制了一些来自演变提示的词语，例如“给定提示”、“重写提示”、“#重写提示#”等 EvolInstruct 的效果EvolInstruct 微调能够提高高复杂度任务的性能，如下图所示。 OrcaEvolInstruct 在指令生成方面引入了多样性。与此相反，Orca 深入研究了响应生成方面，特别是推理和解释生成。在原始论文中，他们为 LLM 定义了各种系统提示，以指导响应生成风格。 一些示例包括： 你是一个 AI 助手。提供详细的答案，使用户不需要在外部搜索来理解答案 你应该描述任务并解释你的答案。在回答选择题时，首先输出正确答案。然后解释为什么其他答案是错误的。想象你在回答一个五岁孩子的问题 解释调优的优势小模型通过解释调优可以轻松解决困难和专业任务。 小模型通过解释调优可以轻松解决困难和专业任务。 模型评估评估复杂模型很难，因为没有明确的方法来评估开放域性能。常见的方法包括人工和 LLM 评审。 人工评审昂贵且缓慢，但可以通过众包来加速和稳定这一过程，例如 Chatbot Arena。Chatbot Arena 是一个评估聊天机器人的平台，用户可以与多个机器人聊天并表示他们的偏好。 LLM 评审更快且更便宜，但偏见更大。利用方法包括：两个答案的成对比较、单个答案评分（分数分配）、参考引导评分（分数分配）。 模型偏见根据 LLM 的评审，评审员倾向于第一个答案以及较长的答案。值得使用对称评估。“重命名”提示表明某些模型（如 Claude-v1）也对名称（如助手 A、助手 B 等）存在偏见。 评审员 提示 一致性 偏向第一个 偏向第二个 错误 Claude-v1 默认 23.8% 75.0% 0.0% 1.2% Claude-v1 重命名 56.2% 11.2% 28.7% 3.8% GPT-3.5 默认 46.2% 50.0% 1.2% 2.5% GPT-3.5 重命名 51.2% 38.8% 6.2% 3.8% GPT-4 默认 65.0% 30.0% 5.0% 0.0% GPT-4 重命名 66.2% 28.7% 5.0% 0.0%","link":"/AI/NLP/NLP-DatasetsBenchmarks/"},{"title":"NLP-DeepSTT","text":"端到端 STT HMM-ANN 混合模型神经网络可以在基于 HMM 的语音转文本 (STT) 模型中代替传统的发射模型。该模型的训练分为两个步骤： 在数据集上训练一个传统的 HMM-GMM 模型 训练一个神经网络分类器，根据可观察的声学特征预测 HMM-GMM 模型的隐藏状态。训练数据集是 HMM-GMM 模型在训练数据上生成的隐藏状态-声学对齐 用于这些神经发射模型的架构从简单的 MLP 到复杂的基于深度学习的模型，例如 LSTM。 训练好的神经分类器输出 $P(hidden | acoustic)$ 概率，但对于 Viterbi 解码，使用的是发射概率 $$P( acoustic | hidden) = \\frac{P(hidden | acoustic) P(acoustic)}{P(hidden)}$$ 幸运的是，对于解码，只需计算缩放后的 $$ \\frac{P(hidden | acoustic)}{P(hidden)} \\propto P( acoustic | hidden)$$ 值，因为 $acoustic$ 是固定的，并且 $P(hidden)$ 值可以从对齐数据中的隐藏状态频率估计出来。 端到端 DL-based ASR 系统Deep Speech (Baidu, 2014) 这种类型的第一个重要模型是 Baidu 的 Deep Speech，它与传统的基于 HMM 的 ASR 解决方案相比，引入了根本性的变化： 声学模型是一个端到端训练的 DNN 音素级表示被完全消除：系统仅根据书面转录进行训练，没有任何语音信息 DNN 的输入仅由音频信号的频谱表示组成（没有 MFCC 等） 系统的输出不是单词，而是输入的字符级转录 网络使用 CTC（连接时序分类）损失进行训练，并使用 CTC 解码生成最终输出 这个出乎意料的简单架构仅包含 5 个隐藏层，其中只有一个是简单的（双向，但不是 LSTM）RNN。输入是一个窗口，在每个时间步包含帧的移动窗口的频谱。 即使没有专用语言模型，性能也可以接受，但完整系统使用了一个 N-gram LM 尽管 Deep Speech 在当时改进了最先进的技术（Switchboard 语料库上的 WER 从 18.4% 降至 16%），并且使用了一个出乎意料的简单和干净的架构 它是在比通常用于基于 HMM 的训练的数据集大得多的数据集上训练的：虽然 200 小时长的数据集被认为对基于 HMM 的系统来说已经足够，但 Deep Speech 的最大模型是在“9600 名说话者的 5000 小时朗读语音”上训练的。 连接时序分类损失HMM 基于 ASR 模型的最大似然估计 (MLE) 要么基于 一个完全对齐和注释的语料库，其中隐藏状态是已知的，在这种情况下，估计可以基于频率，或者使用 前向后向算法，这是 EM 算法在 HMM 上的应用 对于 Deep Speech 类模型，应使用哪种类型的损失，这些模型 为每个语音时间步预测一个字符，并且 关键是，真实值是由正常书写的单词组成的转录字符序列？ 这个问题非常普遍，它出现在许多序列分类应用中，其中真实值是未对齐的，例如在 OCR、视频帧的动作分类以及 STT 中： 在真实转录 $\\mathbf y$ 和一系列时间步长字符分布输出 $\\mathbf X$（两者的长度通常不同）的上下文中，我们希望计算 基于计算 $P(\\mathbf y | \\mathbf X)$ 的训练损失，以可微分的方式进行 MLE 基于 GD 的参数优化 通过高效计算 $${\\mathbf{y}^*}=\\underset{\\mathbf y}{\\operatorname{argmax}} ~ P(\\mathbf y | \\mathbf X)$$ 进行推理。 主要思想是通过找到所有可以与 $\\mathbf y$ 对齐的单个 $\\mathbf x_y$ 序列并根据 $\\mathbf X$ 中的分布累加它们的预测概率来计算 $P(\\mathbf y | \\mathbf X)$： $$ P(\\mathbf y | \\mathbf X)= \\sum_{\\mathbf x_y}P(\\mathbf x_y | \\mathbf X) $$ 复杂性： 可能有一些时间步长在最终预期输出方面没有适当的分类，例如输入中的静音 有时字符重复不能简单地折叠，例如在 hello 的情况下 这些问题通过在输出词汇表中引入“空白” $\\epsilon$ 标签/字符来处理。 在固定时间步长序列上的可能 $\\mathbf x$ 字符组合的数量当然是序列长度 $T$ 的指数，并且可以对齐的 $\\mathbf y$ 序列的数量也可能非常大，因此重要的是高效地计算 $\\sum_{\\mathbf x_y}P(\\mathbf x_y | \\mathbf X)$。 幸运的是，与 HMM 的 Viterbi 算法类似，有一个快速的动态规划算法可以在 $\\mathcal O(T)$ 时间内计算总和。 还有线性时间复杂度的解码算法，即计算最可能的最终输出序列 $\\underset{\\mathbf y}{\\operatorname{argmax}} ~ P(\\mathbf y | \\mathbf X)$。 WhisperWhisper 是一个基于 transformer 编码器-解码器的模型，训练用于执行各种语音处理任务，包括： 多语言语音识别 语音翻译（任何语言到英语） 口语语言识别 语音活动检测 创新不在于架构，而在于扩大模型规模并在大量异构、弱监督数据上训练，以处理大量语音任务。 值得注意的细节： 预处理的音频由 80 通道 Log-Mel 频谱图表示，窗口为 25 毫秒，步幅为 10 毫秒 transformer 编码器的“音频标记化”由两个 3 宽的 1D 卷积滤波器组成，第二个使用步幅为 2 模型执行的任务由任务指示符特殊标记表示 任务特定表示 训练 该模型在 680000 小时的（弱标记）数据上训练，包括 117000 小时的非英语语言和 125000 小时的英语语音翻译 数据集经过筛选，仅包含人工生成的数据 模型大小从 39M 到 1550M 参数不等 解码器的输入包含随机选择的数据点的前一段转录 结果Whisper 的 ASR 性能与最先进的商业 ASR 系统竞争，并且优于所有开源系统。它的表现也非常接近人类专业人员。","link":"/AI/NLP/NLP-DeepSTT/"},{"title":"NLP-DependencyParsing","text":"依赖关系解析 依存解析任务句法解析（复习）Syntactic theories 旨在描述 “支配单词如何组合成短语、形成良构单词序列的规则或原则。” 在这种情况下，最重要的“良构序列”是句子：给定语言的句法理论的核心目标是找到 characterize/delineate 该语言良构句子的结构规则或原则。 如果一个句子具有满足所讨论理论的句法约束的结构描述或句法解析，那么它就是良构的。句法上的良构性并不保证连贯性或有意义。引用乔姆斯基的著名例子： Colorless green ideas sleep furiously. 在句法上是良构的但无意义，而 Furiously sleep ideas green colorless. 甚至不是良构的。 依存语法（复习）Dependency grammars 将单词之间的依存关系视为基本关系。 具体标准因理论而异，但通常在一个句子中，如果一个 $d$ 单词依赖于一个 $h$ 单词（等价地，$h$ 支配 $d$），则 $d$ 修饰 $h$ 的意义，使其更具体，例如 eats $\\Rightarrow$ eats bread, eats slowly 等 并且它们之间存在不对称的可省略关系：可以从句子中省略 $d$ 而保留 $h$，反之则不行 依存语法对一个良构句子中的依存关系施加了重要的全局约束，例如， 恰好有一个独立的单词（句子的根）。 所有其他单词直接依赖于一个单词。 由于这些约束的结果，句子的直接依存图是一个树。 大多数依存语法使用typed direct dependencies：存在有限的直接依存类型列表，并对它们何时可以成立施加特定约束。 投射性依存解析树的一个重要（但并非总是满足）要求是projectivity： 如果一个 $w$ 单词直接依赖于 $h$，并且一个 $w’$ 单词在句子的词序中位于它们之间，那么这个 $w’$ 的支配词要么是 $w$，要么是 $h$，或者是位于它们之间的另一个单词。 更不正式地说，投射性条件表明依存关系是嵌套的，单词之间不能有交叉依存关系。 依存语法的优势依存语法已成为 NLP 中使用的主要句法理论，因为 依存树在许多方面比短语结构解析树更简单的结构（例如，每个单词只有一个节点）； 依存图提供的句子谓词-论元分析是事件或框架导向语义分析的一个很好的起点。 Universal Dependencies (UD) 框架已被创建，以促进不同语言之间的一致 annotation。 语义表示的可用性比较事件语义方面 依存解析给定一个句法理论（syntactic theory），解析任务是为输入句子分配满足该理论 constraints/conditions 的句法结构。对于依存语法，这意味着分配一个依存结构： 识别句子中单词之间的直接依存关系 以这样的方式使它们共同构成一个满足所有理论约束的依存树 在现代 NLP 实践中，解析任务所依据的依存语法通常是隐式指定的，使用所谓的树库，即由带有解析树注释的句子组成的数据集。 这使得解析成为一个结构化的监督学习任务：给定一个由大量 $\\langle \\mathrm{sentence}, \\mathrm{parse} \\space \\mathrm{tree} \\rangle$ 对组成的训练集，学习预测未见句子的解析树。 性能指标对于依存语法解析器，最常用的评估指标是 UAS：Unlabeled Attachment Score（无标签依存准确率）正确依附于正确支配词的单词百分比 LAS：Labeled Attachment Score（有标签依存准确率）正确依附于正确支配词并具有正确依存标签的单词百分比 解析算法像大多数序列标注方法一样，依存解析算法使用将预测任务分解为结构元素的单个决策的策略。在这种情况下， 单个决策是关于单词之间的个体依存关系 主要问题是确保这些单个决策能形成一个连贯的依存树 依存解析器通常使用 transition-based，或 graph-based的方法 基于转换的解析该算法基于一个解析过程的形式模型，该模型从左到右移动要解析的句子，并在每一步选择以下操作之一： 将当前单词分配为某个先前看到的单词的中心词（head） 将某个先前看到的单词分配为当前单词的中心词 或者推迟对当前单词的任何处理，将其添加到存储中以供以后处理 该过程的形式模型由以下组件组成： 一个缓冲区，其中包含未处理的输入标记 一个堆栈，包含当前操作的标记并存储推迟的元素 一个依存图，用于为输入句子构建 模型配置在过程的每一步，模型处于某种配置中： 初始配置解析过程从特殊的初始配置开始，其中 缓冲区包含输入的所有单词 堆栈包含依存图的单个根节点 并且依存图是空的（不包含任何依存边） 解析过程在每一步，都会执行一个允许的配置操作（配置转换）。允许的操作有所不同；在所谓的 arc standard 方法中使用了一组非常简单的操作： 带标签 $l$ 的左弧：将边 $s_2\\xleftarrow{l} s_1$ 添加到图中并移除 $s_2$（$s_2$ 不能是根元素） 带标签 $l$ 的右弧：将边 $s_2\\xrightarrow{l} s_1$ 添加到图中并移除 $s_1$（$s_1$ 不能是根元素） 移位：从缓冲区中移除第一个单词 $w_1$ 并将其放在堆栈顶部 当达到一个无法执行任何操作的配置时，过程结束。 该过程保证在有限步数后结束，在此配置中，缓冲区为空，并且创建的依存图是整个输入的良构依存树： 它会结束，因为在每一步中我们都会减少依存图的 “collective token distance” $$ 2 \\cdot \\#(\\mathrm{缓冲区中的tokens}) + \\#(\\mathrm{堆栈中的tokens}) $$ 缓冲区必须为空，因为否则移位操作将可用，并且堆栈只能包含根元素，原因类似 每个输入标记在图中恰好有一个中心词 图中不能有circle 选择正确的操作解析器如何决定选择哪个操作？模型必须充当一个 可能配置的分类器：如果有 $n$ 个标签，那么将会有 $2n+1$ 个 actions/classes。 为了为这个分类器提供训练数据，依存树库注释必须转换为包含 $$ \\langle \\mathrm{parser~~configuration}, \\mathrm{correct~~action} \\rangle $$ 对的监督数据集，即，treebanks 必须转换为关于“parsing oracle”动作的数据集，解析神谕总是选择正确的操作。 将解析树“转换为神谕操作”给定正确的解析树，可以使用一个简单的算法重建oracle的配置和操作： （显然）从堆栈中仅包含根和包含完整输入的缓冲区开始 如果选择左弧操作会导致正确的边，则选择该操作并附上正确的标签 否则，如果选择右弧操作会（i）导致正确的边（ii）所有以 $s_1$ 为中心词的依存关系已经添加到依存图中，则选择该操作并附上正确的标签 否则选择移位操作 替代操作/转换集Arc-standard 并不是基于转换的解析器所使用的唯一转换系统 — 一个重要的替代方案是 arc-eager，它可以显著简化某些推导。Arc-eager 有以下操作： 右弧: 添加边 $s_1\\xrightarrow{l} w_1$ 并将 $w_1$ 移动到堆栈顶部 左弧: 添加边 $s_1\\xleftarrow{l} w_1$ 并从缓冲区中移除 $w_1$。前提条件：$s_1$ 尚未有中心词 Shift: 将 $w_1$ 移动到堆栈顶部 Reduce: 从堆栈中移除 $s_1$。前提条件：$s_1$ 已经有中心词 非投射性问题Arc-standard 和 arc-eager 转换只能生成投射树，但大多数树库包含相当数量的非投射句子： 非投射性：解决方案 使用可以创建（一定数量的）非投射边的转换系统 伪投射解析： 找到一个 $\\varphi$ 映射，将所有相关的（投射和非投射）树映射到投射树 对于训练，使用 $\\varphi$ 对训练集进行“投射化”，并在转换后的数据集上训练解析器 对于预测/推理，应用 $\\varphi^{-1}$ 到解析器的输出，以获得最终的（可能是非投射的）结果 分类器特征从配置中提取适当的特征对于性能至关重要。传统的（例如基于感知器的）解决方案使用复杂的、专家设计的特征模板，例如， 与其他领域一样，手动特征工程和数据稀疏性的问题导致了深度学习解决方案的发展，这些解决方案依赖于embeddings进行分类。Stanford 神经依存解析器是一个简单但具有代表性的例子： 架构所使用的模型架构是 NLP 中典型的分类架构： 在出现基于深度学习的解析器之前，主要使用线性模型（使用 weighted perceptron 或 SVM 作为学习算法），但也存在基于 k-NN 的解决方案 在深度学习中，在出现基于 transformer 的解决方案之前，CNN 和 LSTM 模型占主导地位，这些解决方案在很大程度上依赖于预训练的上下文嵌入，如 BERT 基于图的解析两种对解析树进行评分的对比方法： 基于转换的方法 将对依存图的评分问题转化为对一个稍微复杂的图构建过程步骤的评分 基于图的解析器，相反，直接对图本身进行评分，并尝试找到得分最高的依存图： $$\\hat g =\\underset{g\\in G}{\\operatorname{argmax}}~S(g)$$ 一种简单但表现出色的方法是： 创建一个由所有可能的依存边组成的完全连接、有权重、有向图（如果有 $n$ 个标记和 $l$ 个标签，则有 $n(n-1)l$ 条边） 单独对边进行评分，然后 找到总得分最高的（方向正确的）树 假设是 $$S(g) = \\sum_{e\\in g} S(e)$$ 这种对图进行评分的方法称为edge-或arc-factored方法。 寻找得分最高的树显然，对所有可能的图进行暴力搜索是不可行的。幸运的是，有一些相对快速的算法可以找到得分最高的树（所谓的maximum spanning tree）。 一个常用的算法是 Chu-Liu-Edmonds 算法，其时间复杂度为 $\\mathcal O( n^3 l)$，其中 $n$ 是输入标记的数量，$l$ 是可能的标签数量。通过将边缘得分存储在一种特殊的数据结构中，即所谓的斐波那契堆，可以将其减少到 $\\mathcal O(n^2l)$。 边缘评分特征基于图的依存解析器是regressors：它们必须为输入标记之间的可能边缘生成得分。所使用的特征模板类似于基于转换的解析器： 依存词及其词缀（affixes）、词性（POS）等 中心词及其词缀、词性等 边缘标签 句子中中心词和依存词之间的关系，例如它们之间的距离 对于神经架构，节点和边缘标签的嵌入 Architectures与基于转换的情况类似，多年来已经开发了经典的机器学习和神经网络的基于图的解析器，性能最高的解析器使用自注意力层。 一些最近架构的一个重要方面是由 @dozat2016deep 的论文引入的，即它们对同一单词的中心词和依存词表示使用不同的嵌入集。 vs这两种方法之间存在重要的权衡。 时间复杂度: 解析 $n$ 个标记并有 $l$ 个可能的边缘标签的时间复杂度为 对于基于转换的解析器通常是 $\\mathcal O (n)$，而 基于图的解析器预先计算所有可能边缘的分数，因此它们从 $\\mathcal O(n^2 l)$ 操作开始，并且还要加上找到最大生成树的时间。即使我们将找到标签视为一个单独的任务，$\\mathcal O(n^2)$ 的复杂性也是不可避免的 非投射性: 如我们所见，非投射性是最广泛使用的转换系统的一个严重问题，需要特殊处理。基于图的方法没有这个问题。 性能: 基于转换的系统往往在处理长距离依存关系时存在问题，而基于图的模型没有这个性能问题。因此，依存解析器的排行榜通常由基于图的系统主导。","link":"/AI/NLP/NLP-DependencyParsing/"},{"title":"NLP-DialogSystems","text":"Chatbot 介绍对话系统 它们通过进行对话与用户交流 对话的形式可以是 口语 书面（文本） 混合：除了语音和/或文本对话外，还可以包含带有按钮的对话框等GUI元素 典型的环境包括 消息平台（例如，Slack和Facebook Messenger） 智能手机助手（Siri，Cortana等） 智能音箱（例如，Alexa） 汽车（例如，Google Android Auto） 对话系统的类型通常区分 任务导向 （task-oriented）和 开放域 （open domain）对话系统（后者也称为 聊天机器人）。 任务导向对话系统：目标是在预定义的任务集中完成一个或多个任务，例如，订购某物、打电话、转账、获取路线等 开放域对话系统： 目标是开放式和非结构化的扩展对话 没有预定的任务（或任务集）作为目标 在许多情况下，主要结果只是“娱乐” 可以作为主要任务导向系统的附加组件 另一种重要的分类是根据谁发起和控制对话。对话可以是 用户发起：例如，手机助手。对话通常非常简短，例如，用户问题和系统回答使用手机助手 系统控制：变体包括 系统发起并控制，例如通过警告或提醒用户某事 用户通过请求指示发起，从那里系统指示而无需用户的基本输入 用户通过请求服务发起，从那里系统通过提问帮助用户“填写问卷” 混合主动性：有几个回合，系统和用户都可以主动（initiative） — 这些通常是开放域对话系统 一般对话需求系统需要能够再现人类之间对话的重要特征，包括但不限于： 语境建立Grounding，通过说话者不断确认理解对方所说内容，建立一个不断演变的 共同语境（common ground）。 说话者 引入 新的信息 确认 添加的信息（通过手势或口头确认） 如果需要，请求澄清 邻接对Adjacency pairs，话语类型与响应期望相关联： 问题 $\\Rightarrow$ 答案 提议 $\\Rightarrow$ 接受 赞美 $\\Rightarrow$ 降低 等 question $\\Rightarrow$ answer proposal $\\Rightarrow$ acceptance compliment $\\Rightarrow$ downplayer etc. 语用推理Pragmatic inferences，我们通过假设话语（utterances）是 相关的 信息丰富的 真实的 清晰简洁的（或者至少说话者的目标是这样）来推断说话者的意思 开放域对话系统方法 基于规则 传统上，基于规则的“模式匹配和替换”类型系统被使用，著名的有 Eliza (1966)，模拟罗杰斯心理学家 PARRY (1971)，用于研究精神分裂症 基于语料库 更现代的替代方法当然是构建一个基于语料库（Corpus）的系统，该系统在包含大量对话的数据集上进行训练。 基于语料库的方法 检索（retrieval）响应：使用数据集中 与最后一轮最相似的发言 是与最后一轮最相似的发言的响应的发言 相似性可以是完全预训练的，或基于 训练/微调 的嵌入 生成响应：在数据集上训练一个生成模型，典型的架构包括： 基于RNN或Transformer的编码器-解码器 一个微调的“预测下一个”语言模型，例如GPT类架构。我们将在下一讲中讨论这种替代方法 任务导向对话系统Task-oriented dialog systems 框架大多数任务导向对话系统（TODs）基于（某种变体的）框架，即用户意图的结构化表示，包含可以用 值 填充的 slots。槽值可以是另一个框架。 基于框架的TOD系统会提出问题，帮助填充框架槽，直到填满当前目标任务所需的所有槽，然后执行任务。 早期基于框架的架构早期基于框架的任务导向对话系统（TODs）具有以下组件： 控制结构：一个生产规则系统，控制如何操作槽值以及根据实际状态和用户输入提出哪些问题 自然语言理解（NLU）：一个基于规则的NLP模块，确定话语的domain（一般主题）、意图（intent，具体目标）和槽 和 填充值 自然语言生成（NLG）模块：一个基于模板的系统，用于生成适当的系统问题给用户 可选的自动语音识别（ASR）模块，通常基于任务特定的词汇和 语法/语言 模型 Natural language generation Natural language understandingNLU 任务是确定每个用户话语的领域、意图和槽填充。例如，对于 Show me morning flights from Boston to San Francisco on Tuesday 我们希望得到如下分析： DOMAIN AIR-TRAVEL INTENT SHOW-FLIGHTS ORIGIN-CITY Boston ORIGIN-DATE Tuesday ORIGIN-TIME morning DEST-CITY San Francisco 对话状态系统现代、更复杂的基于框架的TODs方法的化身是 Dialog-state systems 架构。 与早期系统相比，主要区别在于 将 控制 分解为两个独立的模块： 对话状态跟踪器（也称为 belief state tracker），根据对话历史计算当前更新的对话状态（用户目标，即填充的槽值等） 对话策略，根据实际状态确定下一个系统动作 在所有模块中广泛使用 机器学习方法，而不是早期系统的基于规则的方法 基于语音的系统的完整架构： 实现NLU组件识别用户话语中的领域、意图和槽值/实体可以通过分类器和序列标注模型来实现： 对话状态跟踪基于NLU的（N-best）输出 和/或 对话历史，跟踪器确定发生的对话行为，以及当前（更新的）对话状态。这可以通过生成一组候选状态并对其进行评分来实现： 评分器可以基于像BERT这样的预训练编码器： 除了对完整的对话状态进行评分，还可以单独对（槽，值）对进行评分： NLU 如前两个示例中所示，现代对话状态跟踪器经常直接使用用户话语作为输入，而不需要在对话架构中独立的NLU组件 基于机器学习的NLU和对话状态跟踪模块的对话系统通常通过首先开发一个基于规则的系统来启动，并使用它来生成一个“银”标注的数据集（当然，验证数据集仍然是完全手动标注的。） 对话策略Dialog policy 决定系统接下来应该采取的行动，基于对话状态和可能的对话历史的其他元素。最重要的行动类型是 系统对话行为（例如，提问、确认请求等）、查询数据库 和外部 API 调用。 对话策略通常可以实现为一个分类器，因为通常有一个有限（且通常较小）的可能行动集合可供选择。策略模块可以实现为 基于规则 的系统 使用 监督学习 的机器学习模型 使用 强化学习 优化的机器学习模型（可能在监督预训练之后） NLG最后，当所需的行动是一种系统话语时，NLG 组件根据具体的行动、对话状态和（可选的）对话历史生成实际的句子。 NLG 任务通常分解为 话语规划：规划话语的内容（应提到哪些槽/值，可能还有它们的顺序和分组） 话语实现：实际生成计划内容的自然语言表达 简化生成任务和缓解数据稀疏性的一种广泛使用的策略是生成 去词化模板，其中包含槽值的占位符，然后用所需的槽值替换它们。 话语或其模板的生成可以实现为基于规则的系统或机器学习模型；最近的实现通常使用 序列到序列模型： 简化的架构和模型广泛使用的seq2seq模型用于实现独立的对话状态系统模块，以及在单独训练的模块之间的错误传播，导致了提出训练一个（基于预训练语言模型的）单一多任务seq2seq模型，SimpleTOD，同时用于 对话（信念）状态跟踪 对话策略 自然语言生成（NLG） 当然，类似SimpleTOD的方法仍然需要一个带有对话动作和对话状态标注的数据集进行训练，并且需要关于领域意图和 实体类型/槽 的通用信息。因此，为具体任务或任务训练的模型不能用于其他任务，除非重新训练。 一个有趣的研究领域是训练完全通用的任务导向对话模型，这些模型明确地以任务导向对话描述为条件，即所谓的 对话模式图 （dialog schema graphs）。 对话模式图 基于模式的任务导向对话数据集有几个基于模式的任务导向对话数据集可用，这些数据集除了包含注释对话外，还包含模式图： STAR 数据集包含 13 个领域中的 5,820 个任务导向对话，共 127,833 个话语 SGD Schema-Guided Dialog 数据集包含 20,000 个对话 SGD-X 数据集“通过为每个模式扩展 5 个众包变体来扩展 SGD 数据集，这些变体在语义上相似但风格上多样” 评估评估开放域对话系统基于某种类型的距离与预定义的正确行为的度量不起作用，因为在任何给定回合中正确响应的集合太大。相反，人类 参与者 （participants）或 观察者 （observers）根据各种质量方面评估系统产生的对话行为，例如： 对话有多 吸引人 话语是否 像人类 响应在上下文中是否 有意义 是否 流畅 是否避免 重复 评估任务导向对话系统一个核心指标是 绝对任务成功率：根据用户的意图，多少百分比的对话导致任务成功执行。 对于基于槽的系统，还可以测量 槽错误率：系统正确填充的槽的百分比。 除了这些与成功相关的指标外，用户评估中的 用户满意度 和 总体对话质量 也非常有用。（细粒度指标可以测量类似于开放域系统的方面。）","link":"/AI/NLP/NLP-DialogSystems/"},{"title":"NLP-EfficientAttention","text":"高效注意力 动机Transformer 非常强大，主要得益于 注意力机制，它避免了传统 seq2seq 模型中的瓶颈。然而，注意力机制也有其自身的成本。 回想一下在注意力层中，输入序列中的每个向量 $\\mathbf{I} = \\langle\\mathbf{i}_1, …, \\mathbf{i}_n\\rangle$ 都会与另一个序列中的每个向量 $\\mathbf{X} = \\langle\\mathbf{x}_1, …, \\mathbf{x}_m\\rangle$ 进行比较，通过计算（例如）相似度 $$s(\\mathbf{i}_i, \\mathbf{x}_j) = \\frac{\\mathbf{i}^\\intercal_i \\mathbf{x}_j}{\\sqrt{d}}$$ 大多数 Transformer 模型使用 全局注意力，其中（在自注意力层中）$\\mathbf{X}=\\mathbf{I}$。这意味着 $$\\mathbf{S} = \\frac{\\mathbf{Q^\\intercal}\\mathbf{K}}{\\sqrt{d}}$$ 矩阵的计算和存储复杂度将是二次的：$\\mathcal{O}(n^2)$。这限制了 Transformer 可以使用的 上下文 适合 GPU 内存的模型 大小 模型的 吞吐量，因此增加了其碳足迹 在下文中，我们将看到试图解决这些问题的技术。 稀疏 Sparse 注意力稠密 Dense 层中的稀疏性在 CIFAR-10 数据集上训练了一个 128 层的图像 Transformer，并观察到在许多层中，注意力模式是稀疏的： 因式分解自注意力注意力层可以通过 连接模式 （connectivity pattern） $S = {S_1, …, S_n}$ 来表征，其中 $S_i$ 是第 $i$ 个输出向量关注的输入索引集。对于常规自注意力，这是 $S_i = {j: j \\leq i}$。 Factorized 自注意力 有 $p$ 个独立的头，而不是常规注意力的 1 个头（或多头注意力的 $\\times p$） 对于第 $m$ 个头，$S_i = A^{(m)}_i \\subset {j: j \\leq i}$，是稠密注意力的一个 子集 这些是连续应用的：$A_i = A^{(1)}_i \\cdots A^{(p)}_i$ 如果 $|A^{(m)}_i| \\propto \\sqrt[p]{n}$，则因式分解自注意力的复杂度为 $\\mathcal{O}(n\\sqrt[p]{n})$。从现在起，假设 $p=2$。 因式分解 patterns如果 $A$ 可以连接所有输入和输出位置，则因式分解是 有效的。两个例子： 跨步 Strided 注意力 给定一个 步长 $l \\approx \\sqrt{n}$ $A^{(1)}_i = {i-l, i-l+1, …, i}$（前 $l$ 个位置） $A^{(2)}_i = {j: (i - j)\\mod l = 0}$（每 $l$ 个） 固定注意力 $A^{(1)}_i = {j: (\\lfloor j/l \\rfloor = \\lfloor i/l \\rfloor)}$（每个输出向量关注其块） $A^{(2)}_i = {j: j\\mod l \\in {l-c,l-c+1,…,l} }$（未来的输出关注块中的最后 $c$ 个项目） 固定注意力更适合文本，跨步注意力更适合图像。 两种稀疏注意力类型的示意图： 架构$p$ 个头可以通过三种方式集成（$W_p$ 是 FF）： 每层一个头： $\\textrm{attention}(X) = W_p \\cdot \\textrm{attend}(X, A^{(r\\mod p)})$ 合并头： $\\textrm{attention}(X) = W_p \\cdot \\textrm{attend}(X, \\bigcup^p_{m=1}A^m)$ 多头（$n_h$）注意力： $\\textrm{attention}(X) = W_p\\bigl(\\textrm{attend}(X, A)^{(i)}\\bigr)_{i \\in {1, …, n_h}}$ 通过这些变化，可以训练具有数百层和/或非常长上下文（文本为 12,160，音乐为 $2^{20}$）的 Transformer。 其他稀疏注意力变体多头注意力选项也适用于其他稀疏注意力模式： 全局注意力：一些全局 token 关注整个序列；（注意：这种稀疏全局注意力不同于密集全局注意力，因为只有少数 token 关注所有内容） 随机注意力：对于每个查询，计算一组 $r$ 个随机键，查询关注这些键 窗口注意力：仅关注固定半径内的局部邻居 Big BirdBig Bird 模型结合了所有这些线性注意力类型，以显著增加输入 token 的数量，而不会显著改变内存需求： 长序列长序列的外推RNN 可以在短序列上训练，但在推理期间可以在更长的序列上运行。Transformer 解码器可以像这样 extrapolate，但效果不佳： 位置方法测试了以下位置方法： 正弦位置嵌入：默认的 Transformer 嵌入。性能在增加 $5-10%$ 额外 token 后下降 旋转位置嵌入 (RoPE)：例如在 GPT-3 中使用。将Sinusoidal嵌入应用于每个注意力层中的 $\\mathcal{K}$ 和 $\\mathcal{Q}$（但不应用于 $\\mathcal{V}$ 和嵌入）。可以外推到 $+10-40%$ 的 token，但速度较慢 T5 偏置：一种相对位置方法，根据每层中键和值对之间的距离向 $\\mathcal{V}$ 添加一个 学习 偏置。嵌入未被修改。可以外推到 $+80-120%$，但速度非常慢 ALiBiALiBi (Attention with Linear Biases) 是一种简单的方法，它根据查询-键距离添加一个静态（非学习）偏置： $$ \\textrm{softmax}(\\mathbf{q}_i\\mathbf{K}^\\intercal + m\\cdot[-(i-1),…,-1,0]) $$ 对于 $n$ 个头，斜率形成一个几何序列，范围在 $\\bigl(1, \\frac{1}{2^8}\\bigr]$ 之间；例如，对于 8 个头，斜率为 $\\frac{1}{2^1}, …, \\frac{1}{2^8}$。 具有 ALiBi 的模型可以轻松地将其训练上下文（$L$）外推到 $2-10$ 倍，通常在 $2L$ 时表现最佳！ RoPE 的分析为什么 RoPE 的直接外推不起作用？ 虽然在 RoPE 中自注意力得分应该只取决于两个位置之间的相对距离，但在训练上下文 $L$ 之外（中间），它会变得任意大。 三角函数族是一个通用 approximator，可以拟合任意函数。由于我们只在 $[0, L]$ 范围内训练 RoPE，我们不知道函数在 $L$ 以上的表现。 位置插值位置插值（Position Interpolation，PI）通过将更长的上下文窗口 $L’$ 映射到 $L$ 来解决这个问题。 每个位置 $m’ \\in L’$ 被转换为 $m = m’\\frac{L}{L’}$ 然后对模型进行 1000 步的微调 结果实验表明 Llama 的 2k 上下文可以扩展到 32k； 针对 $L’=8k$ 微调的模型在原始 $L$ 范围内表现出最小的退化（$2%$）。 其他 实现类似策略的报告表明，即使没有微调，也可能实现 $2-4\\times$ 的扩展。 Flash 注意力理论与实践许多近似方法（例如稀疏注意力）设法减少了 FLOPs，但没有减少实际时间。这是因为忽略了内存访问速度（IO）。 常规注意力通过物化从 $Q, K, V \\in \\mathbb{R}^{N\\times d}$ 计算输出 $\\mathbf{O} \\in \\mathbb{R}^{N\\times d}$ $\\mathbf{S} = \\mathbf{QK}^\\intercal \\in \\mathbb{R}^{N\\times N}$ $\\mathbf{P} = \\textrm{softmax}(\\mathbf{S}) \\in \\mathbb{R}^{N\\times N}$ $\\mathbf{O} = \\mathbf{PV} \\in \\mathbb{R}^{N\\times d}$ 在 GPU 的高带宽内存（HBM）中。这是因为 这些是 PyTorch / TF 中的单独指令 这些矩阵在反向传播 backpropagation 中是必需的 GPU 层次结构主要问题是 与计算和 SRAM 相比，HBM 非常慢 softmax、dropout、norm 操作都是内存受限的，需要 $\\mathcal{O}(N^2)$ 的 HBM 访问 FlashAttention 通过优化内存访问解决了这些问题。 FlashAttention优化： $\\mathbf{S}$ 和 $\\mathbf{P}$ 使用平铺 tiling逐块计算 它们从未在 HBM 上物化，而是在反向传播时重新计算 单个块的所有操作在单个内核中同时执行 尽管重新计算会导致更多的指令（FLOPs），但 HBM 访问的总次数减少了 从 $\\Theta(Nd+N^2)$（标准注意力） 到 $\\Theta(N^2d^2M^{-1})$（FlashAttention） 其中 SRAM 大小 $M &gt; d^2$ “多次”。 FlashAttention 相对于标准注意力，实现了 $15%$（与 BERT 速度记录相比）到 $3\\times$（GPT-2）的加速 内存随 $N$ 线性扩展 允许更长的上下文（GPT-2 为 4k） 稀疏 FlashAttention 块稀疏注意力可以通过 FlashAttention 加速 更快（取决于稀疏性，$2-4\\times$），上下文可达 64k FlashAttention2 通过优化 GPU 线程之间的作业分配，再次实现 $2\\times$ 的加速","link":"/AI/NLP/NLP-EfficientAttention/"},{"title":"NLP-Inference","text":"推理，生成，水印 介绍随着语言模型变得越来越大，关于如何有效地使用它们、如何使它们的答案更加多样化（“创造性”），以及如何防止它们生成有害内容的问题也随之而来。我们将讨论以下主题： 标准LLM推理方法和参数 “边缘”和服务器推理 辅助推理和推测 引导文本生成 推理时模型“适应” 水印 标准LLM推理回顾：采样 贪婪解码：总是选择最可能的标记 $w_t = \\arg\\max_{w} P(w|w_{t-c}, \\ldots, w_{t-1})$ 随机采样：从分布 $P(w|w_{t-c}, \\ldots, w_{t-1})$ 中采样 束搜索：在每一步保留 $b$ 个最可能的序列 随机束搜索：从 $b$ 个最可能的序列中采样 概率分布Softmax 用于将模型的 logits 转换为概率分布。为了从最可能的标记中提取概率质量（从而使模型更加“创造性”和不那么重复），我们可以使用温度缩放： $$P(w|w_{t-c}, \\ldots, w_{t-1}) = \\frac{\\exp(\\textit{logits}(w) / T)}{\\sum_{w’} \\exp(\\textit{logits}(w’) / T)}$$ 其中 $T$ 是温度参数。 Top-k 采样计算整个词汇表的 softmax 是昂贵的，低评分的标记通常不有趣，因此在每一步几乎限制词汇表到前 $k$ 个标记是可行的。这称为 top-$k$ 采样。 Top-p 采样核采样，或 top-$p$ 采样，以不同的方式限制词汇表：它保留最可能标记的最小集合，其组合概率质量达到（并超过）阈值 $p$。 给定以下标记和概率集： 苹果 (0.3), 香蕉 (0.2), 樱桃 (0.15), 枣 (0.1), 接骨木 (0.1), 无花果 (0.1), 葡萄 (0.05) 一个 top-$p$ 采样，$p=0.6$ 将保留 苹果、香蕉 和 樱桃。 Logit 偏置我们还可以对模型的 logits 进行偏置，以偏向某些标记。这可以用来防止模型生成有害内容，或者使其生成更符合某种风格的内容。例如，意图分类将受益于对类别标签标记添加较大的正偏置，同时抑制其他标记的概率。 更复杂的情况包括“存在”和“频率”惩罚，其中前者对当前文本中出现的标记施加固定惩罚，而后者随着出现次数的增加逐步减少偏置。 应用的公式因实现而异，但惩罚通常使用指数形式。 Beam 大小，最佳 N束大小 $b$ 是束搜索的一个超参数。它是每一步保留的序列数量。较大的束大小将导致更多样化的输出，但也会显著减慢推理速度。束根据其累积概率对序列进行排序，并且可以在推理结束时选择最佳的 N 个序列。 更激进的方法包括完全重启，其中推理从头开始重复 N 次，并选择最佳序列。 高效和边缘推理CPU 推理在 CPU 上进行推理通常速度较慢且内存有限。为了克服这些限制，当前的边缘计算库将模型的权重量化为 4-bit 整数（从 32 位浮点数）。这显著提高了速度并减少了内存占用。 llama.cpp 是一个流行的在 $C^{++}$ 上运行的 LLM CPU 推理库（也有 Rust 变体）。它优化了使用基于 CPU 的高级向量操作。显著成就包括在桌面 CPU、树莓派模型、Apple Silicon、安卓手机上运行 7B GPT 模型，并且还支持桌面混合 CPU-GPU 推理。 最新版本使用 mmap 兼容的内存映射来按需从磁盘加载和卸载权重。 高效 GPU 推理使用 GPU 进行推理时，除了内存容量外，限制因素是内存带宽，因为逐个生成标记需要大量的内存访问操作。 为了克服这一点，可以进行缓存，我们将先前计算的键和值对保存在内存中，并在下一个标记生成时重用它们 这样，每个批次中的查询大小通常为 $1$，由于内存限制，批次大小通常较低（低于 GPU 中的处理单元数量）–&gt; 低 GPU 利用率 Flash 解码 将 $QK$ 乘积计算并行化到序列长度上，softmax 和输出在并行处理完成后计算 Flash 解码 vs 仅缓存关于两者区别的： Softmax 问题计算注意力分数中的 softmax 也可能成为瓶颈。LLM 通常使用“最大值”技巧来防止指数溢出（$\\exp{x_i}\\rightarrow\\exp{x_i - \\max{x}}$），但这包括一个最大值计算，这很难并行化。 Flashdecoding++ 使用了一个经验技巧。它使用基于 activation statistics 的 fixed global constant 来防止溢出，因此 softmax 的元素可以并行计算。如果方法遇到溢出，它将使用实际最大值重新计算 softmax，但这种情况的发生概率应小于 1%。 Flashdecoding++ 还通过双缓冲升级了通用矩阵乘法（General Matrix Multiplication，GEMM），以解决低批次大小下的内存延迟问题，并根据给定的 LLM 和批次大小启发式地选择最佳实现。 最大注意力值 处理并发请求给定一个集中式推理服务器，我们通常期望尽可能少的延迟并行处理大量请求。高性能推理包括两个阶段： 预填充：处理用户提示，计算并缓存 K 和 V。这可以在单次传递中完成，并且可能比生成的输出序列更长。这还包括生成第一个输出标记 解码：这是生成下一个标记并计算下一个 K 和 V 的迭代过程。这不能并行化，但可以重用缓存中的 K 和 V。我们只需要为每次传递计算一个 Q Flashdecoding++ 并发请求的问题 Monolithic KV 缓存：长序列的 KV 缓存可能导致内存碎片化，从而减慢推理速度并导致内存使用效率低下 短序列：短序列无法利用变压器的输入大小，因此传统上填充它们是一种解决方案，但在内存和计算方面是浪费的 不同的预填充和解码时间：我们可以估计给定请求的预填充时间，但解码时间难以预测。这可能导致处理队列中的阻塞和气泡效应 次优的 GPU 利用率：使用正确的批次与序列长度比率对于高效的 GPU 利用率至关重要。我们无法控制传入请求的长度 解决缓存问题缓存分页是一种高效的方法，受虚拟内存管理的启发，解决了各种缓存问题，例如内存碎片化、未知的解码长度、共享序列前缀。 Pages（小的固定大小内存块）用于存储 KV 缓存，以使逻辑上连续的序列存储在非连续的物理内存中。然后利用 PagedAttention，这是一种基于页面的间接部分注意力（可以以类似于 flashdecoding++ 的方式并行化）。vLLM 是一个实现此方法的框架。 内存问题 vLLM 虚拟化 逻辑 vs 物理内存 Solving cache problems这种方法允许动态内存分配和解码长度变化的释放，以及在序列之间共享缓存，并消除具有相同提示或束搜索输入的重复项。 共享前缀在聊天模型中非常常见（通常每个用户与相同的系统提示交互）。Hydragen 提出了进一步的优化，不仅用于缓存，还用于 QK 乘积计算。通过分别计算前缀和序列其余部分的 QK 乘积（可能在单独的传递中），节省了计算，并且前缀在 GPU 工作内存中从页面中读取一次。 Hydragen Piggybacking 和连续批处理可以将小的输入序列组合在一起，形成一个较长的序列，并使用掩码等方法在多个分区上计算注意力。这样，我们可以在一次传递中计算多个解码标记。这称为 continuous batching 或 piggybacking。 混合预填充和解码批处理也是可能的，其中一部分用于计算 KV 缓存，而另一部分用于生成标记。这对于消除解码期间的气泡效应非常有用（长序列处理必须完成后才能开始下一个任务，从而导致 GPU 利用率低下）。 Microbatching将长序列拆分为较小的部分并并行处理，同时将尽可能多的解码任务填充到连续批处理中（解码最大化微批处理）是解决不同序列长度引起的气泡问题的好方法。然而，不同请求的解码时间以及预填充和解码处理时间的总体差异可能会导致微批处理无法解决的气泡。 DeepSpeed-FastGen 还测量了最佳 GPU 吞吐量曲线，并使用此启发式方法找到适合给定 LLM、批处理大小和 GPU 的上下文长度。这通常只有几百个标记。 Sarathi 解决的气泡效应 GPU 利用率 混合预填充和解码每个任务还有不同的限制特征： 预填充是计算受限的 解码是内存受限且延迟关键的 对它们进行联合优化通常会导致干扰（你不能同时优化内存访问和计算）。解决方案：将它们解耦，通过另一个抽象层将逻辑预填充和解码请求映射到不同的物理资源（GPU）。 根据当前负载和预期的解码长度，将 GPU 分配给预填充或解码任务（像这样的解决方案开发了一个长度预测模型来实现这一点）。 解耦(Decoupled)预填充和解码 辅助推理和推测Assisted inference辅助推理或推测推理是一种方法，其中我们的大型自回归模型由一个较小的“草稿”或“助手”模型引导。其思路是自回归地运行助手模型并生成几个标记的序列，然后运行原始模型进行单步推理。这样，原始模型在单次传递中评估助手的整个“推测”（我们检查每个新添加标记的输出，而不仅仅是最后一个）。可能的结果是： 助手模型第一个标记错误 $\\rightarrow$ 原始模型将纠正该标记 助手模型某些标记正确 $\\rightarrow$ 原始模型接受这些标记并纠正第一个错误标记 助手模型所有标记正确 $\\rightarrow$ 原始模型接受整个序列并生成下一个标记 视频资源 预测多少个标记？ 给定 speculate 标记的数量 $\\gamma$ 助手模型在给定序列上的标记接受率 $\\beta$ 模型的一般预期接受率 $\\alpha = \\mathbb{E}[\\beta]$ 单次运行的成本系数 $\\frac{T_{\\text{assistant}}}{T_{\\text{original}}}$ 模型总是生成 $1$ 到 $\\gamma+1$ 个标记。平均接受的标记数量为 $\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha}$。生成一个标记的预期成本为 $(c\\gamma + 1)T_{\\text{original}}\\cdot\\frac{1-\\alpha}{1-\\alpha^{\\gamma+1}}$。总改进为 $\\frac{1-\\alpha^{\\gamma+1}}{(c\\gamma + 1)(1-\\alpha)}$。 在有足够内存进行预测且 $\\alpha &gt; c$ 的情况下，我们选择最大化改进的整数 $\\gamma$。 预测解码结果给定一个标准 LLM，例如 Chincilla(70B) 和一个 4B 的助手模型，使用 $\\gamma=3$ 且 $c=0.13$ 时，预期接受率约为 $\\alpha=0.7$。这种方式的改进约为 $1.82$（推理速度提高 1.82 倍）。 T5 模型也可以通过这种方法改进，例如在英语到德语翻译中，XXL (11B) 模型可以由小型 (60M) 模型辅助。这里的预期接受率约为 $\\alpha=0.75$，改进约为 $3.4$，使用 $\\gamma=7$。 采样通常会降低接受率，但改进仍然显著。 进一步方向 分块解码和验证：先前的研究表明，通过小规模的微调，可以为模型附加多个输出头，不仅预测下一个标记，还预测接下来的 $k$ 个标记。然后我们可以假设这些 $k$ 个标记是由助手模型生成的，并使用原始输出作为验证器。算法类似于上面描述的，但使用具有多个输出的单个模型 重用：辅助可以来自先前生成的标记，例如提示本身、缓存的历史记录、其他用户的会话等。然后由原始模型进行验证 分块解码头 重用标记 引导文本生成Logit 偏置值可以根据辅助评分函数动态设置。这可以用来引导模型生成更符合特定用例的文本，或限制模型的输出风格。 这还可以包括有限状态机，其中模型的输出词典根据机器的当前状态受到限制。如果我们根据例如给定的正则表达式构建 FSM，我们可以保证模型生成的文本与正则表达式一致。 基于 FSM 的引导 分类器引导分类器也是可行的引导工具，其中输出 logits 被偏向所需的类别，使用辅助分类器。这被证明在避免有害文本方面是有用的。对所有词汇元素进行此操作是不可行的，因此选择了一组得分最高的标记进行重新评分。 小型专家语言模型和专家+反专家对也可以用来输出一个 logit 分布，然后用于引导。在专家+反专家对的情况下，我们取两个模型 logits 的差值，并将其用作引导信号。 专家引导 推理时模型“适应”代理微调是一种有前途的方法，它利用专家和反专家模型，其中专家是一个小型微调模型，反专家是代理的原始未调版本。通过这种方式，可以进行指令微调和各种对齐方法（过滤有害响应等），以及提高模型在下游任务中的性能。代理微调在“沟通风格”类任务中表现出色，同时在事实性和连贯性方面也有所改善。 代理微调的突出特点是它是模型无关的（仅限于词汇表）、便携且可重用的、硬件高效的（无需对大型模型进行微调，这将非常昂贵），并且可组合的，因为可以同时使用多个专家和反专家。 Proxy-tuning 代理微调结果 水印为什么需要水印？随着大型语言模型（LLM）的性能不断提高，对模型输出的可追溯性和可检测性的需求也在增加。水印是一种在模型输出中嵌入独特模式的方法，其特点是： 对模型性能影响微乎其微（人类无法察觉） 验证简单且快速 无需了解模型参数即可验证 在相对较小的标记集上工作 不易移除（部分移除或修改仍可检测） 无需重新训练模型 硬性红名单策略红绿名单策略是一种简单的水印方法。在推理的每一步中，我们选择一组不允许生成的红名单标记（其余为绿名单标记）。这样，我们可以通过以下步骤在模型输出中嵌入独特模式： 取最后一个标记 $t-1$，并使用哈希函数生成随机种子 使用该种子生成随机数，将词汇表分为红绿两半 使用 LLM 的 logits 从绿名单中采样一个标记 检测硬性红名单水印一种基线检测方法是从以下事实出发：在不知道红名单标记的情况下，生成长度为 $T$ 的序列而不违反红名单的概率是 $\\left(\\frac{1}{2}\\right)^T$。即使是短序列，这个概率也非常低。 一种更复杂的方法是对以下零假设使用 z 检验：文本序列是在不知道红名单规则的情况下生成的。 假设绿名单标记的数量为 $G$，其期望值为 $0.5T$，方差为 $0.25T$，我们可以计算 z 分数为： $$z = 2(G-0.5T)/\\sqrt{T}$$ 如果 $z$ 超过给定阈值，我们就拒绝零假设。作者建议使用 $z&gt;4$ 作为拒绝标准，因为在这种情况下，误报率为 $3\\cdot10^{-5}$，并且我们可以检测到所有包含 $16$ 个或更多标记的水印。 考虑到对手的标记翻转会在最坏情况下导致 $t$ 和 $t+1$ 处的违规，因为哈希函数依赖于前一个标记。 这意味着对于 $T=1000$ 的标记，修改 $200$ 个标记最多会导致 $400$ 次违规，对于这种情况，$z$ 分数仍然约为 $6.3$。 通常，移除水印需要修改至少 $25%$ 的标记。 低熵序列从硬性水印的角度来看，Low entropy 序列（模型输出高度可预测的地方）是有问题的。 首先，人类也很有可能生成相同的序列（例如在 Barack 之后跟随 Obama）。对这些序列进行水印是适得其反的。 其次，硬性水印通常会破坏这些序列，因为高概率的标记可能会落入红名单。 软性水印解决低熵序列水印问题的一种方法是软性水印，其中绿名单标记仅相对于红名单标记获得小的（而不是完全的）优势。 我们在应用 softmax 之前在绿名单的 logits 上加上一个小的 $\\delta$。这样，当熵高时，绿名单标记获得相对较高的优势，但在熵低的情况下，即使是红名单中的单个最佳标记（$p\\sim1$）也不会有劣势。 作为另一种扩展，我们可以选择词汇表的一部分 $\\gamma$ 作为绿名单标记。这是一个通常保持在 $0.5$ 的超参数。 检测软性水印检测软性水印比检测硬性水印更困难。z 检验仍然适用： $$z = (G-\\gamma T)/\\sqrt{T\\gamma(1-\\gamma)}$$ 误报率仍然很低，但对于低熵序列，检测率会下降。 在给定标记生成时，最大偏离分布的最坏情况困惑度增加为 $(1+(e^\\delta-1)\\gamma)P_{\\text{original}}$（对于 $\\delta=2$ 和 $\\gamma=0.5$ 约为 $4$）。 软性水印侵蚀 erosion当 logit 分布集中在少数几个标记上时，水印较弱。 对于平均熵序列，水印在 $T=200$ 个标记中仍然有 $98.4%$ 的检测率，$\\gamma=0.5$ 和 $\\delta=2$。 对于低熵序列，检测率会下降。这种情况发生在重复的特定文本和记忆的序列中，模型基本上再现了它之前见过的完全相同的文本。 可以通过在 z 检验中仅包括 n-gram 的第一次出现，或使用更多的先前标记来计算哈希函数来解决重复文本的问题（因此红名单对于所有较短的 n-gram 不会相同）。 私有水印从检测器的决策中推断水印方法是可能的，通过提交 $|V|^h$ 个标记到检测器，其中 $h$ 是哈希函数中使用的标记数量。为了对抗解密，我们可以使用更大的 $h$，但这也会引入检测困难，因为翻转一个标记可能会影响接下来的 $h$ 个标记，并平均破坏 $0.5h$ 个标记。 使用更复杂的方法也是可行的，这些方法依赖于当前标记和前 $h$ 个标记中的一个，其中错误率降低到 $1/h$。 使用具有秘密密钥的加密哈希函数（如 AES 或 SHA3）也可以实现私有水印。这样，攻击者在不知道密钥的情况下无法检测到水印。","link":"/AI/NLP/NLP-Inference/"},{"title":"NLP-Introduction","text":"本章主要讲述了 NLP 的基本概念，和关键主题 接下来我将把 PPT 和整理过后的笔记穿插在一起成文 什么是自然语言处理？自然语言处理（NLP） 是一个跨学科领域，旨在使自然语言对计算机可访问。 自然语言 在此上下文中指的是人类用于交流的普通语言，如英语、中文、西班牙语等。 能够访问自然语言涵盖了广泛的能力，重要领域包括： 自然语言是普通人类使用的语言。C++ 就不是自然语言。海军陆战队使用的语言来传递操作代码，这是一种非自然语言。微分方程或其符号表示也可以被视为非自然语言。 交流：接受输入和生成自然语言输出的能力； 理解：能够访问和利用信息和情感内容； 语言协助：帮助人类在语言表达上的能力。 “理解”和“语义内容”这些概念仍然有些模糊，难以明确定义。我们已经在使用一些语言辅助工具，如 Grammarly 和 Google Translate，这些工具是 NLP 的实际应用。 相关领域计算语言学使用计算方法对语言进行科学研究。 也许是最接近 NLP 的领域，但重点不同：NLP 并不关心自然语言的理论见解，而只关注对计算语言处理有用的方法的设计和分析。 它通常不是直接实现理论思想，而是为 NLP 系统提供架构灵感。 NLP 是一种应用导向的构建，旨在实现实际功能，而计算语言学则是使用计算方法研究语言的理论学科。NLP 从计算语言学的理论中获得灵感，但通常不会直接实现这些理论。一个著名的例子是 Transformer 架构 人工智能 (AI)显然，NLP 目标与 AI 构建智能系统的目标有很大的重叠： 语言使用与成为智能所需的概念、表示和推理能力密切相关， 实际上，如果没有从自然语言输入中提取信息的能力，大规模知识获取也是不可能的。 上述特征使得 AI 子领域 知识表示 和 推理 对 NLP 尤为重要。 AI 是一个更广泛的概念，而 GPT、NLP 和 ML 都是 AI 的子领域或应用。人类与其他动物的主要区别在于人类使用抽象语言的能力。这种能力被认为是人类智能的一个关键特征。 机器学习现代 NLP 在很大程度上依赖于机器学习技术，事实上，近年来通用 ML 方法的语言学应用主导了该领域。 主要使用监督或半监督方法，但强化学习的使用也在增加。 文本是离散符号的序列，因此需要能够处理这种类型输入（以及生成时的输出）的 ML 模型。 强化学习在 NLP 中的应用变得非常重要文本基本上是离散符号的序列即使是非深度学习的统计模型也在 NLP 中广泛使用。虽然可以将其归结为普通的统计模型，但这些模型在机器学习中仍然很重要。逻辑回归不是深度学习方法。它不使用神经网络，而是依赖统计建模和优化。提到一个名为 Aliza 的聊天机器人，它被认为是第一个通过图灵测试的聊天机器人。Aliza 是一个基于规则的系统，而不是基于机器学习的系统。使用机器学习是因为手动编写成千上万的规则既繁琐又不够灵活。 语音处理语音信号的处理和生成传统上不被认为是 NLP 的一部分，NLP 主要关注文本，但显然与其密切相关： 语音转文本为 NLP 应用提供输入， NLP 应用为语音合成提供输入； 处理和合成语音都需要语言学知识，这对于 NLP 也很重要：尤其是语言建模在这两个领域中都起着核心作用。 应用应用示例 机器翻译， 文档检索：检索与用户查询匹配的自由文本文档， 问答系统，例如，智能手机助手回答问题的能力， 文本分类，例如检测电子邮件垃圾邮件， 聊天机器人，例如，用于购买火车票的聊天机器人， 拼写检查和语法检查， 自由文本输入的自动补全， 文档摘要， 从结构化数据生成文本（从股票交易新闻到错误消息）。 中心主题管道与端到端架构一种有影响力的 NLP 观点认为其核心任务是提供一个模块管道，该管道依次生成通用的语言分析，每个模块基于前一个模块的输出构建： 然后，专门的 NLP 应用程序作为这个通用管道元素之上的相对简单的附加组件构建。 相反的观点集中在构建 NLP 应用程序作为端到端机器学习模型，这些模型学习将原始输入转换为所需的输出，而无需专门的语言分析模块。 最先进的 NLP 应用程序通常介于这两个极端之间：它们使用一些通用的分析模块，例如用于分词或词干提取，并且还依赖于跳过某些传统管道步骤的机器学习模型来生成所需的输出。 流水线（或称为过滤器和管道）通常由不同的处理单元组成。每个处理单元的输入是前一个单元的输出，这种因果关系在流水线中保持不变。但是，NLP 中的流水线可能会出现循环（loops），这会导致一些架构问题。由于流水线方法的局限性（如递归处理问题），人们开始考虑端到端（end-to-end）架构。端到端架构直接从原始输入生成所需输出，中间没有任何分析器。有时，端到端模型中也会包含一些预处理或后处理的管道元素。端到端模型在某些情况下可能不够通用，无法适应所有任务。 迁移学习一个有趣且相对较新的发展是出现了在非常大的文本集合上进行无监督任务预训练的端到端神经模型，这些模型可以替代传统的处理管道： 可以通过在架构中添加一些非常浅层的层来构建专门的模型，同时保留预训练的权重，可能只需进行一些微调。 似乎传统管道的某些组件在这些模型中有神经类比：某些层似乎学习（更多）形态学，其他层则学习语义等。 基础模型（Foundation Models，FM）这些基础模型通常是端到端预训练的，并且大多数情况下是无监督或半监督的。通过迁移学习，可以对这些预训练模型进行微调，创建专门的模型。迁移学习包括改变一些权重、调整它们、添加新权重，甚至可能是组合权重层。神经网络中的神经激活可以视为一种软流水线元素。基础模型旨在自动化特征工程的过程，从而减少对人工特征工程的依赖。 学习与搜索我们将遇到的大量监督 NLP 任务可以表述为形式为 $$\\hat y = \\mathop{\\mathrm{argmax}}{y\\in Y(x)}\\Psi\\theta(x, y)$$ 的优化问题，其中 $x\\in X$ 和 $Y(x)$ 是任务的输入和潜在输出， $\\Psi_\\theta: X\\times Y \\rightarrow \\mathbb R$ 是一个评分函数或模型，它为输入-输出对 $\\langle x, y \\rangle$ 分配分数，并由向量 $\\theta$ 参数化， $\\hat y$ 是预测输出。 特征工程的目的是减少数据的维度。通过特征生成模型（即基础模型）来实现这一点。基础模型需要足够大才能发挥作用。小模型通常不被称为基础模型。基础模型生成的向量空间需要足够大。提到如果 P 等于 NP，那么模型可能不需要太大。 例如， $X$ 可以包含电影评论，$Y$ 可以包含情感标签 Positive、Negative 和 Neutral，$\\Psi_\\theta$ 可以是一个函数，为评论的可能情感标注分配概率。 同样，$X$ 可以是德语文本集，$Y$ 可以是其潜在的英语翻译，$\\Psi_\\theta$ 为候选翻译分配翻译质量分数。这种表述使得可以将问题分解为两个由两个不同模块解决的优化子问题： 学习：找到最优的 $\\theta$ 参数。这通常通过在一个大型监督数据集 ${\\langle x_i, y_i \\rangle}_{i=1}^N$ 上优化 $\\theta$ 来完成，使用数值优化方法。 搜索：为特定的 $x$ 找到得分最高的 $y$，即计算公式中的 $\\mathop{\\mathrm{argmax}}$ 的值。由于搜索空间 $Y(x)$ 通常很大，因为潜在的 $y$ 具有复杂的结构（例如，考虑解析树），这个问题经常需要组合优化。 目标是将问题形式化为一个优化问题，并寻找一个好的解决方案。通过最大化某个函数来实现这一点，这个过程称为推理。通过预测输出和实际测量值之间的差异来进行优化。目标是最大化这个误差的逆，这就是所谓的学习。是否有不使用梯度的学习算法，提到零阶优化算法作为一个例子。提到消除排序（elimination-based sorting）和消除搜索（elimination-based searching）作为学习算法的配对。这种方法与修剪神经网络（pruning neural networks）相关联。 语义视角：关系考虑以下话语 我叔叔买了一只猫。它可能是我见过的最讨厌的动物。 我们如何知道“动物”是指提到的那只猫？一个因素是我们知道猫是动物的一个子类别：它们通过 is_a 关系连接。 计算机需要某种形式的知识来理解语义。这种知识通常以关系的形式存在，例如“猫是动物”。 关系视角 关注表达的意义之间的这些语义/概念链接，它们共同构成语义网络： 词汇语义本体如WordNet和FrameNet试图枚举大量词义之间的语义关系。 关系信息通常以三元组的形式表示，包括源、目标和它们之间的谓词（关系）。通过关系数据库和语义网络来表示语义信息。如果你想使用已经形式化的本体论（如 WordNet），那么 WordNet 有一套封闭的关系集可以使用。过去的语言模型构建原则（如基于规则的翻译模型或对话系统）已经不再是主流。现代语言模型更注重表示底层信息，而不是依赖于预定义的规则。 语义视角：组合性关系视角将词义视为网络中的原子节点。相反，组合视角根据表达式的内部组成来分析其意义。 例如，分解 $$un\\vert bear \\vert able \\vert s$$ 使我们能够看到unbearables的意义是由其部分un与bear、able和s的意义组成的。 分解视角，即分析语言中不同符号的内部组成，这种方法关注语言的内部结构和组成部分。 组合性原则： 复杂表达式的意义由其组成表达式的意义和用于组合它们的规则决定。 该原则可以应用于比单词更大的语言单位：句子甚至段落等。 一种（传统的）方法是用逻辑公式表示意义，并将语法组合规则与语义/逻辑规则关联起来： 1234567891011John visits Julie (S)├── John (NP)└── visits Julie (VP) ├── visits (VT) └── Julie (NP)visits(john, julie)├── john└── λx.visits(x, julie) ├── λy.λx.visits(x, y) └── julie 如果你了解有限自动机，你会发现组合性原理在数学公式中也有类似的应用。如果能将一个句子转化为一阶逻辑（first order logic），那就是一种组合语义表示。即使有很好的表示方法来反映单词之间的联系，仍然存在一个问题：这些表示与文本内容之间的关系是什么。可以使用 GPT 模型生成摘要，然后将摘要表示为向量。 语义视角：分布式“bardiwac”是什么意思？ 他递给她一杯bardiwac。 牛肉菜肴是为了搭配bardiwacs而制作的。 饮料很美味：血红色的bardiwac以及清淡甜美的莱茵酒。 奈杰尔的脸因为喝了太多bardiwac而变红。 马尔贝克是较不知名的bardiwac葡萄之一。 我吃了面包、奶酪和这款极好的bardiwac。 $\\Rightarrow$ Bardiwac 是一种由葡萄制成的浓烈红色酒精饮料。 即使我们不知道“bardiwac”在语义网络中的位置，也不知道其部分的含义，但它出现的上下文提供了大量关于其含义的信息。 分布假设： “你将通过它所处的环境了解一个词。” “具有相似分布的语言项目具有相似的含义。” 分布式方法在实际应用中的一个重要优势是，它使得可以从大型但未标注的文本集合中自动学习单词的语义，而不需要专家知识和注释。 当然，这种方法也不是没有局限性： 对于罕见词汇存在问题；以及 学习相似性而不提供任何解释为什么这些分布是相似的。 由于缺乏分布式学习材料，这些罕见词语无法被模型有效地表示。提到“Bank”这个词，过去在语言模型中难以区分“河岸”（riverbank）和“金融机构”（monetary institution）的不同含义。如果模型只能访问分布数据而没有其他信息来源（如上下文或其他模态），那么它将无法正确理解罕见词语的含义。","link":"/AI/NLP/NLP-Introduction/"},{"title":"NLP-LexicalSemantics","text":"词汇语义学 介绍词义正如我们在第一讲中所见，根据 组合原则， 复杂表达式的意义由其组成表达式的意义和用于组合它们的规则决定。 尽管这一原则并非没有问题，它表明要了解较大文本单元（句子、段落等）的意义，有必要了解组成它们的 词的意义。 直观地说，几个词有不止一个含义，例如，mouse 在以下句子中有不同的含义： 一只 mouse 吃了奶酪。 和 用 mouse 点击关闭按钮。 mouse 可以表示 一种小型啮齿动物 或 一种电子指点设备。识别和描述这些词义或 词义 的任务是 词汇语义学。 词典中的词义一种描述词义的方法是通过传统的词典。例如，在线版的牛津高阶英汉双解词典 描述了这些词义，如下所示： 这些词义描述的显著特点是： 词义有精确的标识符：表面形式 mouse，词性标签 noun 和词义编号共同明确地标识了这些词义； 每个词义都有一个文本定义，虽然不是形式化的，但 使用相对较小的定义词汇 遵循某些惯例，例如，以一个更一般的词加上特征属性开始（小动物，小设备） 有几个例句，展示了该词义使用的典型模式。 关系语义学词汇关系词典可能包含有关词义之间的词汇关系的信息，特别是关于 同义关系：synonymy，两个词义是否（几乎）相同 反义关系：antonimy，两个词义是否彼此相反 其他重要的词汇关系包括分类关系（taxonomical）： 如果词义 $s_1$ 更具体，则 $s_1$ 是 $s_2$ 的下位词（hyponym），例如，$mouse_1$ 是 $animal_1$ 的下位词 相反，如果 $s_2$ 比 $s_1$ 更具体，则 $s_1$ 是 $s_2$ 的上位词（hypernym） 最后，部分-整体关系，即部分关系（meronymy）：例如，finger 是 hand 的部分关系。 总体而言，词义及其词汇关系构成了一个网络，其中 节点是同义词集，且 边是词汇关系。 由于下位词关系（也称为 is_a）是传递的，因此在网络中仅保留直接下位词边是有意义的，即仅当不存在节点 $s_3$ 使得 $s_1 \\xrightarrow{is_a} s_3$ 且 $s_3 \\xrightarrow{is_a} s_2$ 时，才有 $s_1 \\xrightarrow{is_a} s_2$ 边。 WordNet为了在 NLP 中可用，词汇语义信息必须作为具有明确查询 API 的计算资源可访问，并且从 1980 年代中期开始，许多项目开发了此类资源。 最重要的是WordNet 英语词汇数据库，它包含大量带有定义、示例和词汇关系的同义词集。在其成功之后，许多其他语言也开发了 WordNet，现在已有超过 200 个 WordNet 可用。 英语 WordNet 网络的一部分： 知识库作为词汇资源除了专门的词汇数据库外，知识库 也可以作为有用的词汇语义资源，因为它们包含有关 实体 和 概念 的信息，这些信息可以链接到词汇中的单词。重要的例子包括： 维基，最重要的是英文维基百科，这里各种类型的链接和引用在条目之间提供了关系信息 形式本体：这些以形式逻辑语言描述概念之间的关系 注意：词典编纂者区分词汇、概念和百科知识；后者不被认为是单词语义的一部分。 词义消歧为了使用这些词汇资源提供的词义信息，NLP 应用程序必须能够确定输入中使用的单词的意义，即执行 词义消歧 (word sense disambiguation)。WSD 任务的细节取决于它基于哪个词汇资源以及如何使用该资源。给定一个包含词义的资源， 监督 WSD 使用在标注了正确词义的训练数据上的机器学习方法；而 基于知识的 WSD 利用词汇资源中的信息，例如 WordNet 中的词汇关系和定义 潜在语义分析Latent Semantic Analysis 基于向量的词汇语义学我们迄今为止看到的词汇语义学方法具有某些特征，使得它难以实现大范围覆盖并适应新的语言或领域： 词汇数据库是由高素质专家手工组装的 高性能的词义消歧模块的开发通常需要大量专家标注的训练数据 这些问题导致了对替代方法的研究，这些方法以无监督的方式分配有用的词义表示，简单地从文本语料库中学习它们。 尽管曾尝试从文本语料库中学习语义网络，但第一个成功的无监督词汇语义方法是从文本语料库中学习词向量，即形式为 $$E: V \\rightarrow \\mathbb{R}^d$$ 的嵌入函数，它将 $V$ 词汇表中的每个词分配到 $d$ 维（$d\\in \\mathbb N$）向量。当然，并非任何这样的函数都可以：显而易见的要求是，学习到的向量必须传达关于它们所分配词的意义的有用信息。 确保这种联系的一种方法是利用分布假设（distributional hypothesis）： “通过一个词的同伴，你将了解这个词。” “具有相似分布的语言项目具有相似的意义。” 这表明，如果词向量反映了它们所分配词的分布，那么它们也将反映这些词的意义。 共现矩阵获取反映语料库中单词分布的词向量的最直接方法是考虑共现（Co-occurrence）矩阵。如果语料库中有 $D$ 个文档，$V$ 是语料库词汇表，那么 term-document 矩阵是 $|V|\\times D$ 维矩阵，其中每一行是一个词向量，其第 $i$ 个元素是该词在第 $i$ 个文档中的出现次数，而 词-词 矩阵是 $|V|\\times |V|$ 维矩阵，其中每一行是一个词向量，其第 $i$ 个元素是该词与第 $i$ 个其他词的共现次数。 直接使用这些向量的一个重要问题是它们的巨大维度和稀疏性。为了解决这个问题，潜在语义分析 方法应用降维矩阵分解方法，通常是截断奇异值分解（truncated singular value decomposition），以找到原始 $C$ 共现矩阵的低秩近似（low-rank approximation）。使用 SVD 的分解是 $$C \\approx USV^\\intercal$$ 其中 $U,V$ 是正交矩阵（orthonormal），$S$ 是对角矩阵（diagonal）。在截断 SVD 的情况下，$U$ 矩阵的行可以用作基于共现的原始词向量的低维近似表示。","link":"/AI/NLP/NLP-LexicalSemantics/"},{"title":"NLP-MixtureModels","text":"混合模型 介绍集成方法集成机器学习方法是一组使用多个估计器并结合其结果以生成最终输出的方法。常见的方法包括袋装法、提升法、堆叠法等。这些方法背后的思想是，多个估计器的组合比单个估计器更准确。 流行的集成方法包括随机森林和梯度提升等方法。 袋装法（Bootstrap Aggregating）使用训练数据的不同子集来训练多个模型，然后结合它们的结果 提升法（Boosting）顺序地使用多个模型，每个模型都被训练来纠正前一个模型的错误 堆叠法（Stacking）使用多个模型生成预测，然后使用另一个模型来结合前几个模型的预测 专家混合（Mixture of Experts）区分不同类型的输入，使用不同的模型来处理它们，然后结合所选模型的结果 专家混合（MoE）MoE 概述在1991年引入了专家混合（MoE）模型。该模型是混合模型的推广，其中输入用于选择用于生成输出的模型。该模型被训练来为每个输入选择最佳模型。 在原始论文中，该模型由多个前馈神经网络作为专家组成，还有一个决定每个专家被选择概率的门控网络。门控网络也是一个具有softmax激活的前馈神经网络。这里每个专家具有相同的输入，输出维度对于所有专家都是相同的，只是权重不同。 MoE 部件MoE 模型的主要部件包括： 数据集划分（每个专家的输入是什么） 专家（每个专家的架构是什么） 门控网络（如何加权专家输出） 聚合（如何结合加权输出） 路由（不使用权重为零/低的专家） 稀疏性（如何分离专家的知识） 在深度学习模型中，稀疏性和路由可以替代数据集划分。 现代 MoE 稀疏门控引入了一种噪声-Top-K 稀疏门控程序，其中输出是专家的门控和。在使用 $n$ 个专家 ($E(.)$) 和 $G_i(.)$ 门控网络的 $x$ 输入上，输出为： $$O(x)=\\sum\\limits_{i=1}^n G_i(x)E_i(x)$$ 这种架构使用以下方法代替基于 softmax 的门控程序： $$G(x)=Softmax(KeepTopK(H(x),k))$$ KeepTopK 让前 $k$ 个值的原始值通过，并将其余的值在 softmax 之前设置为 $-\\infty$。 这里，$H(x)$ 是一个噪声门控值： $$H_i(x) = (x\\cdot W_g)_i + z_i \\cdot Softplus((x\\cdot W_N)_i)$$ 其中 $z_i \\sim \\mathcal{N}(0,1)$ 是一个随机变量，$W_g$ 和 $W_N$ 是可调权重，softplus 是 ReLU 函数的平滑近似。 这确保了网络在每个输入时激活少量专家。问题是，如果一个专家被频繁激活，它会更频繁地被训练，因此表现会更好，从而会更频繁地被激活。这可能导致大多数输入只使用少量专家。 平衡专家利用率为了解决专家过度使用的问题，我们可以引入一个额外的重要性损失项。这个重要性损失试图最小化每个训练批次中专家重要性的变化。 $$I_{batch}(X) = \\sum\\limits_{x\\in X} G(x)$$ $I_{batch}(X)$ 是批次 $X$ 中输入的专家重要性之和的向量。损失与专家重要性变异（coefficient）系数成正比： $$\\mathcal{L}_{importance} = w_{importance} \\cdot CV(X)$$ 其中 $w_{importance}$ 是一个超参数， $$CV(X) = \\frac{\\sigma(I_{batch}(X))}{\\mu(I_{batch}(X))}$$ 是变异系数。 优化和负载均衡除了专家的均匀利用外，一些解决方案还为每个批次的负载不均衡定义了损失（负载是指分配给每个专家的输入数量）。均衡负载有利于模型的并行化。 由于大批次更有利于平衡，多GPU数据和模型并行性被使用。标准层和门控以数据并行方式复制，而专家是模型并行分片，在整个系统中每个专家子集只有一个副本。不同的子集存储在不同的GPU上，信息根据门控在GPU之间传递。 分层 MoE还引入了一种用于语言建模的分层 MoE 模型，其中第一个路由器/门控网络激活专家集，然后该专家集像传统的 MoE 块一样工作。 快速前馈层是具有对数复杂度树状门控程序的分层 MoE 块。该树中的每一层是一个 $[dim_{in}, dim_{node_{hidden}}, 1]$ 层维度的门控网络，具有 sigmoid 激活。输出表示输入应路由到哪个子节点。叶节点是正常的、更大的前馈专家。 参数效率 + MoE最近引入了许多使用 MoE 架构来改进适配器、前缀调优或 LoRA 的模型，以提供高效且性能优越的适应性。通常，这些 MoE 风格的适配器比密集对应物效果更好。 最近提交给 ICLR 2024 的一篇论文还引入了 MoE 层，其中每个专家都是一个 LoRA。这为使用新添加的专家扩展 MoE 模型并动态激活或停用专家提供了可能性。 为什么它们效果很好？ 仅文本 MoESwitch TransformerSwitch Transformer 基于稀疏 MoE 的思想，但不是将每个输入路由到单个专家，而是将输入拆分并独立地将每个 token 路由到单个专家。 为了指导负载平衡，在重要性和负载损失（它们融合在一起）之上，引入了专家容量（$tokens_{batch}/num_{experts}\\cdot capacity_factor$），这是每个专家可以处理的 token 数量的硬限制。如果发生溢出，本应路由到专家的 token 将不被处理（但其原始值通过残差连接传递）。 Switch Transformer 用 switch MoE 块替换 transformer 模块中的前馈层。Switch Transformer 相比传统的 MoE 和 T5 模型实现了最先进的结果。 作者还指出，特殊的权重初始化、32 位门控精度和 dropout（包括专家和其他部分）是有益的。Q、K、V 权重也可以被 MoE 模型替换，但在 16 位计算时观察到训练不稳定，详情请参阅相关文献。 在相同性能下，Switch Transformer 的训练速度比完整的 T5 模型快 2-3 倍。 UltraFastBERT介绍了 UltraFastBERT，它是使用快速前馈层实现的 BERT。将编码器逐点前馈层中的中间层替换为单神经元专家，并在 11 层二进制决策后使用 GELU 激活函数，据报道可以达到原始 BERT 性能的 96% 以上。 训练时间也显著减少，但推理时间呈指数级加快。作者报告在朴素 GPU 实现上加速了 80 倍，在 CPU 上加速了 250 倍。 多模态 MoEsBeiT在多模态网络中，选择输入数据的“子集”是显而易见的，因为可以根据输入模态选择专家。BeiT-3 以及之前的两个模型，在相同的掩码建模任务中处理图像和文本输入。该模型通过一组视觉、语言和视觉-语言组合专家进行增强。每个输入 token 都有相应的模态信息。根据模态信息从相应的池中为每个 token 选择一个专家。 该模型在发布时在检索任务、目标检测、分割和图像分类方面达到了顶级性能。 BeiT 架构 BeiT 用例","link":"/AI/NLP/NLP-MixtureModels/"},{"title":"NLP-NGram-LM","text":"基于 N-gram 的语言模型 语言模型什么是语言模型？回想一下，在形式语言理论中，语言 $\\mathcal L$ 只是某个字母表 $\\Sigma$ 的子集 $\\Sigma^*$。 相反，统计语言模型切换到语言生成的概率视图，并为来自词汇 $V$ 的任意序列 $\\langle w_1,\\dots, w_n\\rangle \\in V^*$ 分配一个概率 $$P(\\langle w_1,\\dots, w_n\\rangle)$$ 使得 $$\\sum_{\\mathbf{w}\\in V^*} P(\\mathbf{w}) = 1$$ 词汇表传统上，语言模型的词汇表由完整的单词组成，例如， $V$ = {the, be, to, of, $\\dots$} 但最近基于子词和字符的语言模型也被广泛使用，词汇表如{ _don’, t, _un, related, $\\dots$} 或 {a, b, c, d, e, f, $\\dots$} 本章讨论基于单词的语言建模技术 — 字符和子词级别建模技术将是第 9 和第 11 讲的主题。 为什么语言模型有用？概率语言模型对于大量的自然语言处理应用非常重要，其目标是生成合理的词序列作为输出，其中包括 拼写和语法检查 预测输入 语音转文字 聊天机器人 机器翻译 摘要生成 使用连续概率建模使用链式法则，令token序列 $\\mathbf{w} = \\langle w_1,\\dots, w_n\\rangle$ 的概率可以重写为 $$P(\\mathbf w)= P(w_1)\\cdot P(w_2 \\vert w_1 )\\dots \\cdot P(w_n\\vert w_1,\\dots, w_{n-1})$$ 也就是说，对于一个完整的语言模型，只需指定 对于任何 $w\\in V$ 单词，概率 $P(w)$ 表示它将是序列中的第一个单词，以及 对于任何 $w\\in V$ 和 $\\langle w_1,\\dots,w_n\\rangle$ 部分序列，单词 $w$ 的连续概率，即$$P(w ~\\vert ~ w_1,\\dots,w_n)$$ 起始和结束符号基于链式法则的序列概率公式 需要一个单独的、无条件的子句来表示起始概率，并且 没有解决在某个点结束序列的概率。 这两个问题都可以通过在词汇表中添加显式的 $\\langle start \\rangle$ 和 $\\langle end \\rangle$ 符号来解决，并假设语言的所有序列都以这些符号 开始/结束。通过这个技巧，起始/结束 概率可以重写为条件形式 $P(w \\vert \\langle start \\rangle)$ 和 $P(\\langle end \\rangle \\vert \\mathbf{w})$ 语言模型树结构使用 起始/结束 符号，语言模型分配的词序列及其连续概率可以排列成树结构： 文本生成使用语言模型，可以基于模型的生成概率分布生成新的文本。 在前一张幻灯片所示的树结构中，我们寻找权重（对数概率）之和较大的分支。穷举搜索是不可行的，众所周知的策略包括 贪婪搜索 集束（beam）搜索 随机集束搜索 一个简单的集束搜索示例，$K=5$： 评估语言模型的评估可以是 外在的: extrinsic，模型在拼写检查、语音转文字系统等组件中的表现如何，或者 内在的: intrinsic，分配的概率与测试语料库中的文本对应得有多好？ 最广泛使用的内在评估指标是语料库的 困惑度。语言模型 $\\mathcal M$ 在序列 $\\mathbf w = \\langle w_1,\\dots, w_n\\rangle$ 上的困惑度为 $$\\mathbf{PP}_{\\mathcal M}(\\mathbf w) = \\sqrt[n]{\\frac{1}{P_{\\mathcal M}(\\mathbf w)}}$$ 使用链式法则，困惑度可以重写为 $${\\sqrt[n]{\\frac{1}{P_{\\mathcal M}(w_1)}\\cdot \\frac{1}{P_{\\mathcal M}(w_2 \\vert w_1 )}\\dots\\cdot \\frac{1}{P_{\\mathcal M}(w_n\\vert w_1,\\dots, w_{n-1})}}}$$ 这正是语料库中所有单词条件概率倒数的几何平均值。 换句话说，困惑度衡量的是，对于语言模型来说，语料库中的单词（续词）平均而言有多“出乎意料”。 取困惑度的对数，通过一些简单的代数运算可以得到结果 $$-\\frac{1}{n} \\left(\\log P_{\\mathcal M}(w_1) + \\sum_{i=2}^n\\log P_{\\mathcal M}(w_i \\vert w_1,\\dots, w_{i-1})\\right)$$ 这就是每个单词的平均交叉熵和负对数似然。 一个简单的推论是：通过最小化平均交叉熵（cross-entropy）或最大化平均对数似然（log-likelihood），也可以最小化模型在训练数据上的困惑度（perplexity）。 基于 N-gram 的建模概率估计我们如何从文本语料库中估计所需的 $P(\\mathbf{w})$ 概率？我们可以尝试使用出现次数来获得最大似然估计： $$P(\\mathbf{w}) \\approx \\frac{C(\\mathbf{w})}{C(\\mathrm{all \\space texts \\space in \\space corpus})}$$ 但在任何现实的语料库中，大多数文本只出现一次，许多可能的文本根本没有出现。一个选项是切换到连续概率： $$P(w_{i} \\vert w_1,\\dots,w_{i-1})$$ 使用基于计数的估计，我们可以得到 $$P(w_{i} \\vert w_1,\\dots,w_{i-1}) \\approx \\frac{C(\\langle w_1,\\dots,w_{i} \\rangle)}{C(\\langle w_1,\\dots,w_{i-1} \\rangle)}$$ 但同样会遇到数据稀疏性问题。缓解这一问题的一种方法是使用 $$P(w_{i} \\vert w_1,\\dots,w_{i-1}) \\approx P(w_{i} \\vert w_{i-k},\\dots,w_{i-1})$$ 的近似，对于某个 $k$，假设续词概率（近似）由序列中前 $k$ 个 token 决定。 N-gram 语言模型使用这种近似，$\\langle w_1,\\dots,w_n \\rangle$ 序列的概率可以计算为 $$P(w_1) \\prod_{i=2}^k P(w_{i} \\vert w_{1},\\dots,w_{i-1}) \\prod_{i=k+1}^n P(w_{i} \\vert w_{i-k},\\dots,w_{i-1})$$ 其主要优点是 $$P(w_{i} \\vert w_{i-k},\\dots,w_{i-1}) \\approx\\frac{C(\\langle w_{i-k},\\dots,w_{i}\\rangle)}{C(\\langle w_{i-k},\\dots,w_{i-1} \\rangle)}$$ 的估计可以仅基于语料库中最长为 $k+1$ 的子序列计数，即所谓的 N-gram $(N=1, 2, 3,\\dots)$ 一元模型最简单的 $N$-gram 语言模型是*一元（Unigram）*模型，它为序列 $\\langle w_1,\\dots,w_n \\rangle$ 分配概率 $$P(w_1)\\cdot P(w_2)\\cdot \\dots \\cdot P(w_{n-1})\\cdot P(w_n)$$ 其中单词概率可以简单地估计为 $$P(w) \\approx \\frac{C(w)}{\\sum_{w’ \\in V}C(w’)}$$ 一元模型忽略了单词的顺序，最可能的序列只是完全由最频繁的单词组成的序列。 二元模型自然地，基于更长子序列的 $N$-gram 模型更加细致，甚至所谓的*二元（Bigram）*模型（$N=2$）计算序列概率简单为 $$P(\\langle w_1,\\dots,w_n \\rangle) = P(w_1)\\prod_{i=2}^n P(w_i \\vert w_{i-1})$$ 其中 $$P(w_2 \\vert w_1) \\approx \\frac{C(\\langle w_1,w_2\\rangle)}{C(w_1)}$$ 马尔可夫语言模型$N$-gram 模型实际上是用概率有限状态机（Markov）来建模语言，其中状态对应于 $N-1$-gram。 例如，在 $\\mathcal M$ 二元模型的情况下，状态对应于词汇表加上一个开始和结束状态，状态 $w_1$ 和 $w_2$ 之间的转移概率只是 $P(w_2 \\vert w_1)$ 的续词概率。 很容易看出，token 序列 $\\mathbf{w}=\\langle w_1,\\dots,w_n \\rangle$ 的 $P_\\mathcal{M}(\\mathbf{w})$ 概率正是马尔可夫模型经过状态 $\\langle start \\rangle,w_1,\\dots,w_n,\\langle end \\rangle$ 的概率。 一个简单的马尔可夫语言模型： 增加 N 值由于实际上人类语言过于复杂，无法满足低阶马尔可夫假设，因此具有更高 N 值（如 N=3,4 甚至 5）的 N-gram 模型通常具有更好的内在和外在性能。不幸的是，随着 N 的增加，语言学上可能的 N-gram 数量急剧增加。例如，在谷歌的 1,024,908,267,229 token 的 N-gram 语料库 中，N-gram 计数为： 一元模型：13,588,391 二元模型：314,843,401 三元模型：977,069,902 四元模型：1,313,818,354 五元模型：1,176,470,663 对于较高 $N$ 值，语言学上可能的 $N$-gram 数量极高，这带来了两个重要问题： 数据稀疏性: 即使在大型文本语料库中，许多可能的组合也不会出现，或者只会很少出现，因此很难估计它们的概率； 模型大小: 即使估计是正确的，模型的大小也会非常庞大。 平滑加法平滑Additive smoothing。我们如何解决在语料库中从未或很少出现的 $N$-gram 的问题？一个简单的解决方案是通过某个数值过度计数每个 $N$-gram，并使用 $$P(w_{i} \\vert w_{i-k},\\dots,w_{i-1}) \\approx \\frac{C(\\langle w_{i-k},\\dots,w_{i}\\rangle)+\\delta}{C(\\langle w_{i-k},\\dots,w_{i-1} \\rangle) + \\delta|V|}$$ $|V|$ 乘数来自于这样一个事实：对于每个 $N-1$-gram，恰好有 $|V|$ 个 $N$-gram 是它的延续。 $\\delta$ 的一个广泛选择是 1。 一个重要的问题是： 如果 $C(\\langle w_1,w_2\\rangle)=0$ 和 $C(\\langle w_1,w_3\\rangle)=0$，那么在加法平滑下我们有 $$p(w_1,w_2)=p(w_1,w_3)$$ 假设现在 $w_2$ 比 $w_3$ 常见得多。那么，直观上，我们应该有 $$p(w_1,w_2)&gt;p(w_1,w_3)$$ 而不是上述的相等关系，因此加法平滑的结果似乎是错误的—我们应该以某种方式在一元和二元计数之间进行插值。 插值Interpolation，在二元模型的情况下，我们通过一定的权重添加来自一元模型频率的概率： $$P(w_2 \\vert w_1) \\approx \\lambda_1\\frac{C(\\langle w_1, w_2 \\rangle)}{C(w_1)} + (1 - \\lambda_1)\\frac{C(w_2)}{\\sum_{w\\in V}C(w)}$$ 对于任意 $k$ 的递归解决方案： $$P(w_{k+1} \\vert w_1.. w_k) \\approx \\lambda_k\\frac{c(\\langle w_1 .. w_{k+1} \\rangle)}{c(\\langle w_1 .. w_k\\rangle)} + (1-\\lambda_k)P(w_{k+1} \\vert w_2 .. w_{k})$$ $\\lambda_k$ 是基于语料库经验设置的，通常使用期望最大化（Expectation Maximization）方法。","link":"/AI/NLP/NLP-NGram-LM/"},{"title":"NLP-Pipeline","text":"本章主要讲述了 NLP 的语言结构和传统管道 语言结构表示层次自然语言是非常复杂的符号系统，其符号（单词、短语、句子等）比普通符号具有更多的内部结构。语言学家通常在语言符号中至少区分以下四个表示层次： 音位结构: 个别声音的层次，或在书面语言中，书写符号、字母； 形态结构: 词素的层次，即最小的有意义的语言单位，以及它们组织成单词； 句法结构: 单词组织成语法正确的句子的层次； 语义结构: 意义的层次，即语言符号所指的内容。 列出的表示层次并未涵盖语言符号的所有重要方面： 语义学，至少传统上，不处理非字面、依赖上下文的意义元素，这些元素属于语用学的范畴，而 对大于句子的单位（段落、整个对话等）内部关系的研究是话语分析的主题。 语法依靠语言符号（简称 l. 符号）的概念，我们可以定义更多重要的概念： 语言 是一组 l. 符号。 语法 是一个由以下两部分组成的对偶： 一组 l. 符号，即语言的 词汇，以及 一组有限的操作，这些操作将一个或多个 l. 符号映射到一个 l. 符号。 当且仅当 $\\mathcal G$ 语法生成 $\\mathcal L$ 语言时，$\\mathcal L$ 包含正好那些在 $\\mathcal G$ 的词汇中或通过有限次应用 $\\mathcal G$ 的操作从 $\\mathcal G$ 的词汇中产生的 l. 符号。 换句话说，语言 $\\mathcal L$ 中的所有符号要么直接在语法 $\\mathcal G$ 的词汇表中找到，要么可以通过语法 $\\mathcal G$ 的规则和操作从词汇表中的符号生成。 语法操作通常分解为同时工作的音韵、形态、句法和语义操作。 例如，对于一个作用于语言符号的二元语法操作 $f$，存在相应的音韵、形态等操作，使得 对于 $f$ 的所有可能参数： $$ f \\begin{pmatrix} \\begin{bmatrix} ph_1 \\\\ mor_1 \\\\ syn_1 \\\\ sem_1 \\end{bmatrix}, \\begin{bmatrix} ph_2 \\\\ mor_2 \\\\ syn_2 \\\\ sem_2 \\end{bmatrix} \\end{pmatrix} = \\begin{bmatrix} f_{\\mathrm{ph}}(ph_1, ph_2)\\\\ f_{\\mathrm{mor}}(mor_1, mor_2)\\\\ f_{\\mathrm{syn}}(syn_1, syn_2)\\\\ f_{\\mathrm{sem}}(sem_1, sem_2) \\end{bmatrix} $$ 根据我们的定义，语法不仅涵盖语言的句法，还包括音韵、形态和语义。 在文献中也经常使用一种更有限的语法概念，它仅限于形态和句法，或者仅限于句法。 此外，语言通常被更狭义地定义为仅包含由语法生成的句子（作为声音或书面符号序列）的集合，而不包括它们的形态、句法和语义结构。 描述语法语言学的一个核心目标是描述生成自然语言（或其片段）的语法：英语语法、西班牙语语法等。 语法通常通过以下两种方式描述： 显式地，通过描述词汇并定义从中生成语言元素的操作，或 隐式地，通过提供由语法生成的语言的代表性示例，即带有形态、句法等分析的语音或文本样本。 解析和生成一些与语法相关的任务在 NLP 中尤为重要： 解析 决定一串书面符号是否属于由给定语法生成的语言：它是否由该语言的单词组成，是否在句法上是正确的，以及是否有意义。 确定由给定语法生成的语言中的一串书面符号相对应的形态、句法和语义结构。 生成 无条件生成: 生成语法语言的元素。 条件生成: 生成满足特定条件的语法语言的元素。这些条件通常是语义上的，即生成语义结构（意义）满足特定条件的语言元素。 解析和传统的 NLP 管道解析任务在传统 NLP 中占据了核心地位，因为人们认为大多数 NLP 任务可以通过以下方式解决： 解析文本输入，并根据特定语法生成其表示结构， 使用生成的分析结果作为进一步处理的特征。 因此，传统的 NLP 管道是一个针对一种或多种语法的解析管道，其中每个组件生成输入表示结构的一部分。 传统管道中的处理任务 形态和句法 分词 句子切分 形态分析 词性标注 （浅层或深层）句法解析 语义 命名实体识别 词义消歧 共指消解 / 实体链接 语义角色标注（浅层语义解析） （深层）语义解析 管道任务分词该任务是将输入字符序列分割成称为tokens的小的有意义的单位，通常是单词和标点符号： ‘This is a sentence.’ $\\Rightarrow$ [‘This’, ‘is’, ‘a’, ‘sentence’, ‘.’] 使用 tokens 而不是单词有两个重要的优点： 允许更多的灵活性：标点符号、表情符号等虽然不是单词，但仍然是有用的分割单位； 暗示这些片段是某些类型的实例，这些类型共同构成一个词汇表。 什么应该算作一个 token？答案取决于任务和模型：例如，对于某些目的，标点符号是无关紧要的，而对于其他目的，句子边界和标点符号是重要的。 尽管如此，一些有影响力的分词风格已经达到了“准标准”状态。对于英语来说，“Penn Treebank 规则”是最常见的，具有以下关键特征： 标点符号与单词分开并作为独立的 token 处理， 动词缩写（如“she’s”中的“’s”）和附加成分（如“don’t”中的“n’t”）被分开。 类型分配和标准化分词还可以涉及确定 tokens 属于哪种类型。例如，如果 ‘apple’ 和 ‘Apple’ 是同一类型的实例，那么我们的分词器会将这些标准化或规范化为一个共同的类型，不考虑大小写。典型的规范化实践包括 “纠正”拼写变体和拼写错误，将所有变体分词为同一类型的实例， 标准化数字或日期类型的表达 以及标点符号（例如，将“!!”视为“!”）。 更激进的策略包括将所有数字表达式或所有不在预定义词汇表中的单词分配给单一类型。 分词挑战分词的挑战取决于任务和方法，还取决于输入的 书写/字母系统（例如，没有空格的书写系统！）， 语言， 领域， 噪音量（例如，拼写错误的数量）。 对于欧洲语言和书写系统，特别的挑战包括 缩写（通常以句号结尾）， 数字表达式（可能包含空格、逗号和句号）， “多词表达”（MWEs），如“New York”。 句子切分该任务是将（通常是预先分词的）输入字符序列分割成句子： [‘John’, ‘entered’, ‘the’, ‘room’, ‘.’, ‘It’, ‘was’, ‘empty’, ‘.’]$\\Rightarrow$ [[‘John’, ‘entered’, ‘the’, ‘room’, ‘.’], [‘It’, ‘was’, ‘empty’, ‘.’]] 主要挑战是 句子和 token 切分的相互依赖性，例如分割形式为 ‘xxx yyy. Zzzz’ 的片段（’yyy.’ 是句子结尾还是缩写？）； 标点符号不正确或缺失。 形态学词素 (Morphemes) 是语言中最小的有意义单位。单词可以由几个词素组成，例如 unbearables = un + bear + able + s 词素之间的有用区分： 黏着词素 (Bound) vs 自由词素: 自由词素（例如 bear）可以单独作为独立的单词存在，而黏着词素（例如 -un, -s）只能与其他词素一起构成单词。 词缀 vs 词根: 词根 (roots) 是单词的主要部分，具有最具体的语义内容（例子中的 bear），其他词素，即词缀，可以围绕词根放置。大多数词根是自由的。 词缀类型词缀 (Affixes) 可以根据它们与其他词素的（通常是位置上的）关系进一步分类： 词缀类型 关系 示例 prefix 前缀 前置 un-，anti- suffix 后缀 后置 -s 和 -ing infix 中缀 中间 Singabloodypore circumfix 环缀 环绕 德语中的 ge...t（例如 gespielt） stem 词干变化 变化 阿拉伯语 kitaab（’书’）$\\rightarrow$ kutub（’书籍’） 这远不是完整的列表，其他词缀类型还包括重复、音调/音高变化等。 一个关键的区别是屈折词缀和派生词缀： 屈折词缀 inflectional，创建同一个词的不同形式，可以表示语法方面如人称、时态等。英语中的例子包括复数 -(e)s 和进行时 -ing。 派生词缀 derivational，则形成新词，例如，bearable 中的 -able 将动词变为形容词。 词干和词元 一个词的 词干 (stem) 由词的基本部分组成，这部分在所有屈折形式中都是共同的。因此，词干通常不是一个有意义的词，例如，produced 的词干是 produc（因为有 producing 等形式）。 词元 (lemma) 与此相反，总是一个完整的词，即屈折形式的未屈折基本形式。继续上面的例子，produced 的词元是 produce。 形态分析任务Morphological 决定一个字符串是否是一个格式正确的单词。 词干提取: 确定一个单词的词干。 词元化: 确定一个单词的词元。 形态标注: 根据词形变化等表达的语法信息标注输入单词。 形态分割: 将输入单词分割 (segmentation) 成词素。 完整的形态分析: 将单词分割成词素，并根据类型和它们传达的语法信息对每个词素进行分类。通常也包括词元化。 形态分析挑战 歧义 / 依赖上下文: 许多单词有多种分析，只有根据上下文才能消除歧义 (Ambiguity) ，例如 chairs 中的 -s。参见： The president chairs the meeting.There were hundreds of chairs in the room. 复合词: 许多语言有由两个或更多简单词组成的复合词 (Compounds)：例如，德语中的 Schadenfreude (幸灾乐祸) 由 Schaden（“损害”）和 Freude（“快乐”）组成。 形态丰富的语言: 英语的形态相对简单。其他语言，例如匈牙利语和土耳其语则复杂得多…… 词性标注词性（Part-of-speech）类别对应于单词在句子中可以扮演的基本句法角色。例如，在句子 Peter ate the apple. 中，Peter 和 apple 是名词，ate 是动词，the 是限定词。词性标注任务是确定已分词（并可能已句子切分）的输入文本中每个单词的词性类别，例如： [‘Peter’, ‘ate’, ‘the’, ‘apple’, ‘.’] $\\Rightarrow$[ (‘Peter’, [‘名词’]), (‘ate’, [‘动词’]), (‘the’, [‘限定词’]), (‘apple’, [‘名词’]), (‘.’, [‘标点’])] 同样地，词性的类别也是依赖于上下文的。例如，比较以下句子： John hit the ball.His first song was a huge hit in Europe. 具体的词性类别列表及其划分也取决于所使用的语言和特定的语法理论，尽管有些类别是相当普遍的，例如，[名词]、[动词]、[形容词] 和 [副词] 几乎总是存在。 开放 vs. 封闭词性类别 封闭词性类别，例如英语中的限定词，由相对较小的词集组成，这些词集不会轻易改变：添加一个新的限定词到一种语言中是一个罕见的现象。 开放词性类别，例如英语动词，包含大量的词，并且每天都会添加新成员。 一个相关的区别是功能词和内容词之间的区别。属于开放词性类别的词通常是内容词：它们自身具有明确的语义内容。封闭词性类别包含的功能词则没有太多独立的内容。 词性标记集在 NLP 中，词性类别通常用简写编码，称为词性标记。即使是英语，也有几种标记集在使用；一个非常重要的、与语言无关的标记集是为 Universal Dependencies 项目 开发的： 开放类标记 标记 描述 示例 [adj] 形容词 big, old, green, African, first [adv] 副词 very, well, exactly, tomorrow [intj] 感叹词 psst, ouch, bravo, hello [noun] 名词 girl, cat, tree, air [propn] 专有名词 Mary, John, London, NATO [verb] 动词 run, eat, runs, ate 封闭类标记 标记 描述 示例 [adp] 介词 in, to, during [aux] 助动词 has, is, should, was, must [cconj] 并列连词 and, or, but [det] 限定词 a, an, the, this, which, any, no [num] 数词 0, 1, 2, one, two [part] 小品词 not, ‘s (as in “Andrew’s table”) [pron] 代词 I, myself, who [sconj] 从属连词 that, if 其他标记 标记 描述 示例 [punct] 标点符号 . , ; [sym] 符号 $, ¶, © [y] 其他 用于无法分析的元素 句法解析句法理论旨在描述“支配单词如何组合成短语、形成良构 (well formed) 词序列的规则或原则集。” 在这个背景下，最重要的“良构词序列”是句子：句法理论的核心目标是为特定语言找到描述/划定该语言中良构句子的结构规则或原则。 一个句子是良构的，如果它具有结构描述或句法解析，并且满足所讨论理论的句法约束。句法上的良构性并不保证连贯性或有意义性。引用乔姆斯基的著名例子： Colorless green ideas sleep furiously. 在句法上是良构的，但毫无意义，而 Furiously sleep ideas green colorless. 甚至不是良构的。 成分句法（也称为短语结构）和依存句法理论对 NLP 尤为重要。 成分 (constituent) 是单个单词或一组连续单词，形成一个“自然单位”。例如，短语 a nice little city： 可以放入各种句子框架中，如 I wanted to visit ...，Budapest is ...； 可以作为问题的答案：What did you visit?； 可以用代词替换：I have visited a nice little city. $\\Rightarrow$ I have visited it. 基于成分的句法基于成分的句法理论 对成分进行分类，并且 制定规则，根据这些规则可以将成分组合在一起构建更大的成分，最终构建一个完整的句子。 一个良构句子的句法结构就是它的成分结构，例如，对于句子 The students love their professors： $$[ [ The_\\mathrm{D} \\space students_\\mathrm{N} ]\\mathrm{NP} \\space [ love\\mathrm{Vt} \\space [ their_\\mathrm{D} \\space professors_\\mathrm{N} ] _\\mathrm{NP} ] _\\mathrm{VP}] _\\mathrm{S}$$ 在更透明的成分树形式中： 123456789S├── NP│ ├── Det: the│ └── Noun: students└── VP ├── Vt: love └── NP ├── Det: their └── Noun: professors 这是基于成分的解析器输出的结构。 基于依存的句法与此相反，依存语法将单词之间的依存关系 (dependency) 视为基本关系。 具体标准因理论而异，但通常在一个句子中，如果一个 $d$ 单词依赖于一个 $h$ 单词（等价于 $h$ 支配 $d$），则 $d$ 修饰 $h$ 的意义，使其更具体，例如 eats $\\Rightarrow$ eats bread，eats slowly 等； 并且它们之间存在不对称的可省略关系：可以从句子中省略 $d$ 而保留 $h$，但反之则不行。 依存语法对一个良构句子中的依存关系施加了重要的全局约束，例如： 恰好有一个独立的词（句子的根）。 所有其他词直接依赖于一个词。 由于这些约束，句子的直接依存图是一个树。 大多数依存语法使用类型化的直接依存关系：存在有限的直接依存关系类型列表，并对它们何时可以成立施加特定的约束。 一个依存解析树的例子： 与成分树相比，它包含更少的节点（每个单词一个），但边缘标有相应的依存类型。 命名实体识别命名实体识别 (Named entity recognition) 是在输入文本中找到命名实体的表达并将其标记为相应实体类型的任务： 通常使用的实体类型有人名、组织和地点，但许多 NER 模型涵盖了其他类型，如日期、事件、艺术作品、法律等。 共指消解NER 确定名称所指实体的类型，但不决定它们是指相同还是不同的实体。相反，共指消解 (Coreference resolution) 任务是定位输入中的更广泛的指称表达，包括普通名词和代词，并将它们聚类到指向同一实体的组中： 实体链接与共指消解类似，实体链接也关注引用的身份，但在两个重要方面与之不同： 像命名实体识别一样，它仅限于类似名称的表达， 它通过将名称连接到外部知识库中的实体记录来确定实体的身份，例如： 词义消歧词义消歧 (disambiguation) 也将表达与外部词汇表中的意义/词义连接起来，但 它关注普通名词和其他类型的内容词：动词、形容词和副词； 词义集合通常是专门构建的词汇资源——准标准是使用 WordNet 词汇数据库。 例如，一个基于 WordNet 的词义消歧系统应该将句子 The scroll wheel in my mouse has stopped working. 中的 mouse 名词消歧为 WordNet 词义 [Mouse]#4: ‘一种手动操作的电子设备，用于控制光标的坐标 [...]‘。 WordNet 中的其他可能性： [Mouse]#1: ‘任何数量众多的小型啮齿动物 [...]‘ [Mouse]#2: ‘一个肿胀的瘀伤 [...]‘ [Mouse]#3: ‘一个安静或胆小的人 [...]‘ 语义角色标注语义角色标注 (Semantic role labeling) 是识别输入文本中的谓词 (predicate) 和论元 (argument) 表达，确定哪个论元属于哪个谓词，以及它们之间关系的任务。在这个背景下， 谓词 是指代事件/情况的表达（例如，指代动作的动词）， 论元 则指这些事件/情况的参与者， 而任务中的角色标注部分是确定与论元对应的参与者在谓词所指的情况中扮演的角色类型。 一个相对简单的例子，使用宾夕法尼亚大学认知计算组的SLR 演示。 语义解析这是完整或深层语义解析的任务，它不仅涵盖共指消解、词义消歧和谓词-论元结构，还旨在提供一个完整的形式语义表示，其特点是： 表示输入文本的意义的形式结构， 表示字面意义， 尽可能消歧， 在某种程度上是规范的，即一个文本意义有一个唯一的表示， 有高效的算法来确定它们与其他语义和知识表示的逻辑和语义关系。 句子 Thetis loves a mortal 的基于一阶逻辑的语义表示：","link":"/AI/NLP/NLP-Pipeline/"},{"title":"NLP-PreExamA","text":"期中考试，人已死 A1 语言结构和语法Linguistic structure and grammars (Linguistic structure, representation levels, grammars, parsing task, generation task, relation to NLP pipelines) 语言结构表示层次phonological 也就是类似于字母表，音素音标的最小单元，通常本身没有意义 随后它们可以构成 morphological，也就是词根，词缀，词尾等，这些构成了词，是有意义的最小单位 词可以构成句子，这就是 syntactic，但是光满足语法要求不能说明句子有意义 所以我们有 semantic，去解释句子的意义和指代的对象等 语法grammar 指导你如何构建句子，如何解析句子 同时也包括 phonological，也就是发音的规则，声调，哪些音可以拼在一起等 当然也包括 morphological，比如进行时过去时之类的 解析任务基本上来说就是判断一个句子是否符合语法规则 然后再分析它们的结构，找出句子表达的意义 生成任务有两种，一种是很傻的无条件生成，也就是不管句子是否有意义，直接按语法规则生成 另一种是有条件生成，生成满足一定需求的句子，也就是有意义的句子 与 NLP 管道的关系在那时我们还没有 transformer 和端到端模型，所以我们需要一步一步的去拆解和分析句子 也就是我们在管道中执行人为设计的算法，帮助计算机理解句子 A2 传统 NLP 管道中的元素和任务Elements and tasks in the traditional NLP pipeline (Structure/order of the pipeline, tokenization, sentence splitting, morphology, POS tagging, syntactic parsing, NER, coreference resolution, entity linking, WSD, semantic role labeling, semantic parsing) 管道的结构/顺序实际上 PPT 中有一个重要的内容没有提到，那就是管道的第一步：预处理 预处理基本就是删除特殊字符，然后统一大小写，去除停用词 the a an 等 随后遵循以下步骤： 先分词，然后拆句子，标词性（POS），解析句法，找命名实体，合并相同指代，链接实体，消除歧义，标语义角色，最后解析语义 分词简而言之就是将句子拆成一个个词，具体怎么拆看需求，同时还可以有规范化的过程 对于如何处理缩写，数字，特殊表达，还有多个词组成的词等，都有不同的处理方式 更进一步的细节看下面专门的章节 句子切分有的时候我们的输入是一大段话，所以我们需要将其拆成一个个句子 这个过程也不是那么简单，比如句号后面的 Mr. Mrs. Dr. 等不应该拆开 形态学分析其实也就是把词再拆开，比如动词的时态，名词的复数等 我们可以通过这个方式确定一个词的格式是否正确 然后我们就能进行时态标注一类的任务了 stem 通常不完整，而 lemma 是完整的，比如 produc 和 produce 词性标注Part-of-speech tagging，简称 POS，就是给每个词标标记角色 none (名词)，verb (动词)，adj (形容词), adv (副词), pron (代词), prep (介词), conj (连词), interj (感叹词), det (限定词), num (数词), art (冠词), aux (助动词), modal (情态动词), cop (系动词), part (分词), punct (标点符号), sym (符号) 句法解析其实也就是通常意义上的语法了，基于 constituent 的解析就是找出句子中谁是 NP(noun phrase)，VP(verb phease)，VT (transitive verb 及物动词)等 更重要的是 dependency parsing，找出句子中的依赖关系，比如主谓宾关系 具体的后面会有专门的章节 命名实体识别就是找出句子中的专有名词，比如人名，地名，机构名等，还有时间，日期等 指代消解就是把指向相同对象的指代词标记出来 比如，我的姐姐，她…，这里的她就是指代消解的对象 实体链接就是把命名实体链接到知识库中的实体，比如把北京这个词指向百科中的北京 词义消歧就是找出一个词在句子中的具体含义，比如 bank 是银行还是河岸 语义角色标注也就是谁做了什么，对谁做了什么，在哪里，什么时候 句法解析主要关注语法，而角色标注关注的是含义 语义解析这就是一个合并任务了，把前面的步骤整合起来，找出句子的含义 A3 经典（全词）分词Classical (whole-word) tokenization (Tokenization task definition, whitespace splitting, regular expressions, and regex cascades, lexers) 分词任务定义前面也说到，把文本切分成合适的小块，这个小块就是 token 空白分割这还用说吗，就是按空格分 这种粗暴的方式问题很多，比如中文，或者缩写就分不了 正则表达式和级联regex 其实是一个 regular language 的 finite acceptor 这里就需要提到形式语言，正则语言，上下文无关，上下文有关，递归可枚举 级联就是多个正则表达式串联起来，比如先找出数字，再找出字母 在执行替换前，把有问题的部分先替换掉 词法分析器也就是用正则表达式来匹配文本，找出 token 的工具 SpaCy 其实就跟 flex 一样 A4 编辑距离和子词分词Edit distance and subword tokenization (Edit distance, subword tokenization, Byte Pair Encoding, WordPiece, SentencePiece) 编辑距离就跟汉明距离很像，Levenshtein 就是在计算要把一个字符串变成另一个字符串需要多少步，然后每个操作还可以有权重 子词分词一种可以无需人工预分词的，基于大数据的办法，文本会分割为最常见的组合 字节对编码先把单词拆散成字符，然后根据常出现的组合合并字符，比如 th 是一个常见的组合 贪婪的它只关心当前最常见的组合，然后合并，直到达到预设的词表大小，可能会生成不常见的组合 优化可以用 dropout，也可以使用 unigram WordPiece更智能的 BPE，从最高频的子词开始合并，尝试用更少的子词表示一个单词 但是它会考虑到生成的子词组合的概率，也就是尽可能增大召回率，更注重质量，生成的子词更有意义 SentencePiece对不需要空格分隔的语言，直接对整段文本进行分词，甚至包含标点符号 它将文本视为连续的序列，然后利用类似于 BPE 等的方法来构建词表 A5 一般语言建模Language modeling in general (Language model, continuation probabilities, role of start and end symbols, text generation, LM evaluation) 语言模型定义就是有一个 L，还有一堆 w 属于 L，然后 sum(P(w)) = 1 连续概率P(Wn | W1, …, Wn-1)，我下一个词的概率只跟我前面的词有关 起始和结束符号的作用因为链式法则需要一个确定的开始和结束符号才能计算概率 文本生成使用概率模型来生成文本，可以有贪婪搜索，也可以是 beam 搜索，去找一个置信度最高的组合 语言模型评估外部评估也就是看拼写，语法之类的 而内部评估是把每个词的概率相乘，然后变换来看整体置信度，或者 Perplexity A6 基于 N-gram 的语言建模N-gram-based language modeling (Estimating sequence and word probabilities, N-gram models, markov models, Smoothing) 序列和词概率估计我们想估计某个单词在语料库中出现的概率，我们可以直接计数 但是对于句子（序列），我们不光要考虑词的独立概率，还要考虑每个单词跟前面的词一起出现的概率 也就是上面说的连续概率，但是有可能我们的语料库中没有这个序列，直接用的话会导致数据 sparse 那为了解决 0 概率问题，我们可以采取 n-gram 模型 N-gram 模型其实就是把连续改成离散，比如 bigram 就是只考虑前一个词，trigram 就是考虑前两个词 马尔可夫模型就是一个有限状态自动机，二元以上才能马尔可夫 平滑但是就算 N-gram 也会有数据稀疏的问题 所以我们给每个词的计数都加一，但是加完了以后可能会导致一个情况 如果说 W1, W2 的计数是 0，那么 P(W1, W2) = 0 W1, W3 的计数是 0，那么 P(W1, W3) = 0 但是 W2 比 W3 常见，那应该有 P(W1, W2) &gt; P(W1, W3) 这就和我们之前得到的结果不符合，所以我们需要插值 比如在二元模型下，把一元模型的频率加进去 A7 使用经典方法进行文本分类Text classification with classical methods (Classification tasks, bag of words, TF-IDF, naive Bayes, discriminative methods) 分类任务跟图像分类差不多，判断是不是垃圾邮件之类的 词袋模型就是把文本中的词拿出来记录词频，然后用这个向量来表示文本 通常可以省略 stopword，也可以用 TF-IDF 来加权 TF-IDF也就是 (全部文档 / 包含 w 的文档)，然后再取对数 本质上是假设一个词出现的频率越低，它的重要性越高 朴素贝叶斯NB 的假设和 unigram 一样，就是每个词都是独立的 那就很适合 BOW，因为它不关心词的顺序，纯粹看词频 我们本质上在推测文本属于不同 c 的概率，然后取最大的那个 也就是 P(x, c)，然后由于我们是连续概率，所以会有个累乘 判别方法Logistic Regression，Random Forest 和 Gradient Boosting，它们都是用于分类任务的算法 A8 使用经典方法进行序列标注Sequence tagging with classical methods (Sequence tagging tasks, IOB tagging, supervised methods, HMM, Viterbi algorithm, MEMM, CRF, optimization and inference, generative and discriminative models) 序列标注任务就是给句子中的每个词打标签，比如词性标注，命名实体识别等 IOB 标注名词短语不是有多个词么，整个标记为 NP，然后用 IOB 把这个 NP 拆开 某个实体的开头标 B，里面的标 I，不属于任何实体的标 O 然后我们就能明确的区分实体边界，处理连续或者重叠的实体时就不会混乱 监督方法无非就是生成模型（P(X,Y) 联合）和判别模型（P(Y|X) 条件） 隐马尔可夫模型本质上就是有一个不可见状态 Y 集，那可见状态 X 就是每个 token，不可见状态就是词性 Y 指向 X，一一对应 Y 是连续的，然后我们就可以预测下一个词的词性 它还假设生成（发射）概率跟位置无关，随后通过最大似然估计来学习概率 转移概率就是词性转移的概率，发射概率在已知词性的情况下，生成某个词的概率 维特比算法HMM 通过 Viterbi 来对新的输入进行标注 它的目标是在给定观测序列 O 的情况下，找到最可能的隐藏序列 Q max = argmax P(Q|O) Q 是隐藏序列 实际就是一个动态规划，每一步都留存了上一步的距离 在一个节点同时接到多个来源的时候，只留最小（大）的那个 然后我们可以通过反向引用来恢复路径 最大熵马尔可夫模型之前那玩意是个生成模型，但是在只需要打标签的时候，生成模型就显得有点多余 那我们就可以让整个 X 指向每一个 Y，一对多 随后 MEMM 就不用转移和发射概率了，而是使用最大熵 给定前一个状态 Y，来观测 X，预计下一个 Y’ 的条件概率为 P(Y’|Y, X) 然后由于我们是连续的 Y，按顺序一个一个判断，所以需要累乘一下 它有 label bias 问题，也就是它会陷入局部最优解 条件随机场那么我们就需要 CRF，直接根据整个句子来判断，考虑上下文 变成无向图，然后我们再用一个 potential 特征函数来建模 关键区别是它的归一化因子会保证 P(Y|X) 的合为 1 优化和推理比如梯度下降，然后用 Viterbi 来推理 生成模型和判别模型A9 依存句法解析Dependency parsing (Dependency grammar, projectivity, transition-based parser, graph-based parsers, non-projective parsing) 依存语法前面提到过，找出谁依赖谁，谁支配谁，并且修饰词可以省略 依存语法对句子有个类似于 AST 一样的约束，也就是有一个根 投射性但是很显然人类的语言不可能随时满足 AST，所以我们需要判断 projectivity 比如，我喜欢吃苹果，有 我 -&gt; 喜欢 &lt;- 吃 &lt;- 苹果 的线性关系，这就是投射的 但是：苹果，我喜欢吃。这句话就会导致 苹果 -&gt; 吃 与 ROOT -&gt; 喜欢 的关系线交叉，这就是非投射的 注意，一定有一个 ROOT 节点去指向句子的动词 基于转换的解析器 操作 Stack Buffer Arcs INIT [ROOT] [I, like, apples] [] SHIFT [ROOT, I] [like, apples] [] SHIFT [ROOT, I, like] [apples] [] LEFT-ARC [ROOT, like] [apples] [(like, I)] SHIFT [ROOT, like, apples] [] [(like, I)] RIGHT-ARC [ROOT, like] [] [(like, I), (like, apples)] RIGHT-ARC [ROOT] [] [(ROOT, like), (like, I), (like, apples)] 非投射性解析转换解析器只能生成投射树，这肯定是不够高的 那我们可以使用 pseudo-projective parsing，它将非投射关系进行变形 比如重新标注，插入额外标记等，等解析完成后，再将预处理的部分还原 基于图的解析器graph LR ROOT --> I ROOT --> like ROOT --> apples like I like apples I apples 使用 ChuLiu 等评分算法对每一条边打分 然后通过 maximum spanning tree 来找出最可能的依存关系 A10 基于词汇资源和潜在语义分析的词汇语义学Lexical semantics based on lexical resources and LSA (Word senses and dictionaries, lexical relations, word vectors, latent semantic analysis) 词义和词典从词典中找出一个词的含义，查字典哥们 词汇关系synonymy 和 antonimy 同义词反义词 还有动物（上）和老鼠（下）的关系，hypo-hypernymy 还有 finger 和 hand 的 meronymy 可以使用 WordNet 来查找这些关系并进行消歧 词向量WN 是手动标注的，这不好，我们可以从语料库中学习词向量 也就是根据词的上下文，和相似分布，来猜测词的含义 使用共现矩阵 词-文档 文档 1 文档 2 词 1 1 0 词 2 0 1 是统计词在文档中出现的次数 和 词-词 词 1 词 2 词 1 1 词 2 1 是统计词在同一个文档中一起出现的次数 潜在语义分析然后我们使用 SVD 来降维，找出词的潜在语义 LSA C = USV，U 和 V 是 orthonormal，S 是 diagonal U：词矩阵，V：文档矩阵，S：不同维度的重要性 A11 Word2vec 和 GloVeWord2vec and GloVe (CBOW and Skipgram tasks, neural embeddings, training architectures, negative sampling, GloVe algorithm) CBOW 和 Skipgram 任务首先，Word2vec 只能生成静态词向量，也就是说即使一个词有不同的含义，它的词向量仍然是一样的 所以不好处理多义词，比如 bank Skipgram 通过中心词来预测它周围的词，它是 n-gram 的扩展，但可以跳过一些非中心词 反过来，Continuous BOW 通过上下文来预测中心词，输入是 One-hot 编码的上下文 神经嵌入嵌入指的是把高维的数据映射到低维的空间，比如把词映射到一个向量 而神经嵌入就是通过神经网络来学习这个映射 训练架构对于 Skipgram，假设我们有单词序列 W，那么给定中心词 Wt，模型最大化 P(W(t-i), W(t-i+1), …, W(t+i) | Wt), i 是窗口大小 那其实也就是当有 Wt 的时候，把窗口大小内的词的概率最大化 对于 CBOW，给定上下文 W(t-i), W(t-i+1), …, W(t+i)，模型最大化 P(Wt | W(t-i), W(t-i+1), …, W(t+i)) 当有上下文的时候，最大化中心词的概率 传统的 softmax 需要计算词汇表中所有单词的概率，这不好 我们将词汇表变成一颗 Huffman 树，然后使用 hierarchical softmax 来计算 简单来说，我们将单词预测变成二叉决策 负采样实际上，语料库中的大部分词都是不应该和目标词一起出现的，与其把所有词都计算一遍，不如只计算一部分 这种随机抽取一些不应该一起出现的词来配对的方法就是负采样，随后每次模型只会更新一小部分参数 而正样本，就是上下文中出现的词 GloVe 算法Word2Vec 主要基于局部上下文窗口进行训练，而 GloVe 则是基于全局的共现矩阵 它更好的保留了词之间的语义关系 A12 评估词嵌入和基于内部词结构的嵌入Evaluating word embeddings and embeddings based on internal word structure (Intrinsic evaluations, extrinsic evaluations, subword [fastText] embeddings) 内在评估我们可以通过词类比 Analogy，词相似度，词类别等 对于词类比，我们可以测试类似于 Wking - Wman + Wwoman = Wqueen 的概率，概率越大，表现越好 而对于词相似度，我们可以比作看词联想游戏 比如看到猫，可以想到狗，我们使用余弦相似度来衡量 在合理的模型中，sim(猫, 狗) &gt; sim(猫, 汽车) 外在评估可以使用 NER 等实际任务来评估词向量的性能 子词[fastText]嵌入传统方法对没见过的词无能为力，但是 fastText 可以通过子词来生成词向量，类似于 n-gram 它跟 W2V 很像，只不过用了子词 A13 使用 RNN 进行语言建模和序列处理Language modeling and sequence processing with RNNs (Four types of sequence processing, sequence tagging, bidirectional RNNs, sequence encoding, sequence generation, seq2seq tasks, LSTM architecture) 四种类型的序列处理 单输入单输出，如图像分类 单输入多输出，如图像描述 多输入单输出，如情感分析 多输入多输出，如机器翻译 序列标注之前就提到过，比如 POS NER 等，可以使用一组 embedding -&gt; LSTM -&gt; softmax 来实现 双向 RNN也就是用两个 RNN，一个正向一个反向，然后把结果合并，这样能更好的捕捉上下文 序列编码首先我们要知道 Seq2Vec 是把序列编码成一个固定维度的向量 那我们就可以使用 LSTM 的最后一层输出来表示整个序列 双向 RNN 的话就用最大池化 RNN 就是 h_t = tanh(W_hx * x_t + W_hh * h_t-1 + b_h) h_t 输出，W_hx 输入到隐藏权重，x_t 输入 W_hh 隐藏到隐藏权重，h_t-1 前一刻的隐藏状态 ，b_h 隐藏偏置 序列生成Seq2Vec 或其他模型，比如ConvNN，可以生成一个向量，然后交给 LSTM 来生成序列 那么 Vec2Seq 公式为 y_t = softmax(W_hy * h_t + b_y) y_t 输出，W_hy 隐藏到输出权重，h_t 隐藏状态，b_y 输出偏置 seq2seq 任务把 Seq2Vec 和 Vec2Seq 结合起来，就叫 seq2seq 任务 我们可以使用 教师强制 来训练，它是把真实的输出作为下一时刻的输入 这样可以帮助模型更快的收敛，但是会导致推理时的性能下降 LSTM 架构是 RNN 的一种增强，它有三个门，Input Forget Output 它可以更好的处理长期依赖，避免梯度 vanishing 和 exploding 流程如下 遗忘门决定丢弃多少信息 输入门决定添加多少信息 将遗忘门的输出与记忆单元相乘，然后加上输入门的输出 输出门决定输出多少信息，然后生成新的隐藏状态 import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}});","link":"/AI/NLP/NLP-PreExamA/"},{"title":"NLP-PreExamB","text":"论文加考试，要死了 B1 注意力机制Seq2seq 基础S2S 是基于 RNN 的，将一个任意长度的序列，变成另一个任意长度的序列。 它由 编码器 和 解码器 组成。 编码器输出一个固定长度的向量，其维度是隐藏层的大小。一般是编码器最后的状态（单向 RNN），或者是平均或最大池化（双向 RNN）。 瓶颈问题这会导致问题，如果信息量太大，而隐藏层向量太小，会导致信息丢失。 为了解决此问题，我们需要注意力机制。 RNN 网络中的注意力解码器使用自身当前状态，与 编码器 的各个时间步的隐藏状态 进行比较，计算出每个输入的权重，它表示了每个输入对当前输出的重要性。 随后，用权重 对编码器所有隐藏状态进行加权求和，得到一个上下文向量。 解码器结合上下文与自身的隐藏状态，生成更好的输出。 注意力的属性所以，注意力有 权重分配：通过计算 Query 和 Key 的相似度，得到每个 Key 的权重。 上下文向量：根据权重，对 Value 进行加权求和。 可反向传播：注意力机制是可微的。 其中 Query：当前输入 或 当前解码器状态。 Key：信息的摘要，编码器的隐藏状态。 Value：信息的实际内容，通常与 Key 相同。 B2 注意力作为层和 Transformer 架构点积注意力前面提到了 “比较”，而使用点积是最简单有效计算权重的方法。 简单来说，将 $Q · K_i$ ，相似性越高，点积越大。 为了避免过大的点积，我们可以将结果除以 $\\sqrt{d_k}$，其中 $d_k$ 是 Key 的维度。 然后对所有 Key 的点积进行 softmax，得到一个权重向量，表示了每个 Key 对当前 Query 的重要性。 最后，将 $Value_i$ 与权重相乘，然后求和，得到上下文向量。 缩放的作用我们只需要将点积除以 $\\sqrt{d_k}$，就能稳定计算结果，避免点积过大过小。 当 $Q$ 和 $K$ 的维度很大时，点积的值会很大，导致 softmax 的梯度很小，使得训练困难。 多头注意力简而言之，让模型在多个视角下观察输入。比如，对于翻译任务，一个头关注主语，一个关注宾语，一个关注动词。 首先，用线性变化生成多组 $Q$、$K$ 和 $V$，一组对应一个头，每个头都有自己的权重。 并行计算权重，然后将结果拼接，再次进行线性变换，得到最终结果。 自注意力而自注意力，主要是捕捉元素之间的依赖关系。 简单来说，这次的 Query、Key 和 Value 都是出自同一个输入序列。 比如 I Love AI. 我们分别查询： I 与 I, Love, AI 的关系，得到一个权重。Love 与 I, Love, AI 的关系，得到一个权重。AI 与 I, Love, AI 的关系，得到一个权重。 然后对所有权重进行加权求和，得到一个上下文向量。 交叉注意力CrossAttention 也就是前面说的给 编码器 和解码器 之间建立联系的注意力。 Query 是解码器当前状态，Key 和 Value 是编码器的隐藏状态。 解码器逐步生成每个单词，每次生成时，都会用交叉注意力参考编码器的隐藏状态。 B3 使用 RNN 和 Transformer 的上下文嵌入Transformer 架构它包含： 注意力机制 自注意力 （双向） 多头注意力 （可选） 位置编码 （可选） Feedforward 残差归一 编码器 输入序列 -&gt; 输入嵌入-&gt; 位置编码 -&gt; 编码器 [6…12] -&gt; 输出 每个编码器：上一个输出 -&gt; 多头自注意 -&gt; 残差归一 -&gt; 前馈 -&gt; 残差归一 -&gt; 输出 编码器的输入是源序列（比如需要翻译的文本） 解码器 输出序列 -&gt; 输出嵌入 -&gt; 位置编码 -&gt; 解码器 [6…12] -&gt; 输出 每个解码器：上一个输出 -&gt; 掩码多头自注意 -&gt; 残差归一 -&gt; 多头交叉注意力 -&gt; 残差归一 -&gt; 前馈 -&gt; 残差归一 -&gt; 输出 解码器的输入： 训练时：教师强制（比如翻译 I Love AI. 输入为 “我爱”） 推理时：模型已经生成的部分 位置编码由于输入的每个词都会被转换为向量表示，导致模型无法区分词的位置。位置编码通过将位置信息添加到向量中，解决这个问题。 我们使用 sin 和 cos 函数，它们的周期性与它们不同频率的组合，使得每个位置的编码都是唯一的，并且有助于模型理解单词之间的距离关系。 掩码控制模型在处理数据时的可见性。 padding 掩码：在对较短句子进行填充后，将填充的数据位置标记为 0，使模型不会关注这些 [PAD]。 Look-ahead 掩码：在训练解码器时，确保模型不会看到未来的信息，使其只基于已经生成的单词进行预测。 推理和训练训练时使用教师强制，计算损失，反向传播，梯度下降 推理则前向传播，逐步生成单词，直到生成结束标记。 ELMoEmbeddings from Language Models，第一个上下文嵌入模型。它与 Word2Vec 不同，能够判断多义词。 首先它使用 CNN 将单词转为向量 然后使用双向 LSTM，将单词的前后文结合起来 将多层 LSTM 的输出加权和 GPT 训练目标Generative Pre-Training 仅使用解码器，目标是预测下一个单词。它不能像 BERT 一样考前后文，它只考虑前文。 与 ELMo 类似，它提供一个预训练的“特征提取”模块 BERTBidirectional Encoder Representations，用于生成上下文嵌入。它能够考虑单词的前后文，更好的理解单词的含义。 它使用了 Masked Language Model，它随机隐藏一些单词，然后让模型猜。 还使用了 Next Sentence Prediction，它随机给模型两个句子，让模型判断这两个句子是否相邻。 B4 对话系统对话系统的类型 task-oriented：帮助用户完成特定任务 open-domain：用于娱乐或其他目的 或者 用户发起：如问答系统 系统控制：系统主动发起，如日历提醒 混合：用户和系统都可以发起 一般对话需求 Grounding：确认理解对方所说内容，建立一个共同语境。 一个人说出新内容，另一个人确认，有不明白的地方，再次确认。 Adjacency pairs：问与答，请求与回应等。 是话语与响应的相关性。 Pragmatic inferences：根据对话的上下文，推断对方的意图。 假设对方是有理性的，说的话是有意义，真实，清晰的。 开放对话系统基于规则，比如模式匹配。（古老） 基于检索或生成，比如知识库和GPT。（现代） 任务导向对话系统在确定任务后，用槽值填充，它类似于表单，系统通过提问每一个槽位，填充信息并执行。 对话状态系统与任务导向系统相比，它广泛使用机器学习。 对话状态系统组件和使用语言模型的实现 Dialog State Tracker使用 BERT 来选择对话状态。根据历史，跟踪用户目标和信息。 Dialog Policy使用强化学习，根据对话状态，选择下一步的动作。 NUL使用机器学习来识别用户的领域，意图，槽值。 NLG使用Transformer来生成自然语言响应。 简化的任务导向对话系统使用单一S2S模型，如SimpleTOD，来完成所有任务，减少复杂性和错误。 模式引导系统它使用预定义的schema graph来生成对话。 对话系统的评估 attractive：继续对话的意愿 有多像人类 上下文的连贯性 流畅性 有多少车轱辘话 任务成功率 填充正确率 用户满意度 等 B5 LLM 推理通用推理参数 topP将元素概率从大到小排列，然后从大到小加起来，加到 P 为止。 topK保留最大的 K 个元素。 采样比如 greedy，beam search，random sampling logit 偏置使模型更倾向于选择某些词。 温度文本多样性 边缘推理在资源有限的设备上，量化到 4 bit，优化 CPU 向量操作，内存映射 高效推理使用 GPU 等进行推理，问题是内存带宽 缓存保存先前计算的键和值对，重用它们高内存占用低 GPU 利用率，因为 batch size 不能很大 Flash并行，将 Q·K 矩阵分块高 GPU 利用率复杂，高内存占用 Softmax 耗时，所以用 Flashdecoding 并行计算 处理并发可以使用分页缓存，预填充，将多个小序列合并为一个序列，以及将长序列分割为多个序列。 辅助生成先用一个小模型生成草稿，然后大模型修正草稿。 推测解码 有限状态机引导类似于根据 schema 生成 分类器引导比如区分特定风格的文本，小模型生成多个候选，分类器打分 专家引导和分类器类似，专家模型根据其领域，对生成的文本进行打分和反馈 水印水印用于溯源和检测。 Red list生成过程中，有一组不允许的词，从绿名单中采样 soft mark在绿名单上加偏置，比 red list 更好 水印一般用概率检验。 B6 LLM 对齐对齐在 AI 中的作用确保模型符合人类期望，和道德标准。 指令跟随模型 有帮助的：真正尝试执行所描述的任务 诚实的：提供准确的信息，包括在适当情况下表达不确定性 无害的：不具有攻击性、歧视性，也不推荐或帮助危险或不道德的行为 合成指令数据集通过生成并收集大量正确的AI 问答，来训练模型。 监督微调在特定数据集上进一步训练。 人类反馈强化学习Reinforcement Learning from Human Feedback 通过人类对答案的打分，通过强化学习，如 Proximal Policy Optimization，微调模型 聊天模型指令微调不支持多轮对话，所以需要聊天模型。我们直接使用历史对话数据（而不是一问一答），来训练模型。 B7 提示与答案工程LLM 提示基础提示词应该 详细、具体 和 精确，它可以包括一些描述，约束，示例，步骤等。 提示挖掘与改写挖掘，是从数据中提取有效提示词，以便模型能够更好的生成答案。 假设我们有一个需要从 France is the capital of Paris 中提取国家和首都之间关系的任务 中间词提示可以使用提示词 [x] is the capital of [y] ，来提取 依存关系提示可以使用提示 capital of [x] is [y] ，来提取 而改写，就是生成多个提示，并选择最佳的。 基于梯度的提示优化我想要莎士比亚风格的诗，但是我不知道怎么描述。 初始提示可能是：请写一首关于爱情的诗。随后我们可以使用梯度下降，来优化提示：请写一首关于爱情的莎士比亚风格的诗。 提示生成模型一类专门生成提示词的模型。通常使用 T5 或 Transformer。 前缀微调添加一小段前缀，来让模型生成更好的答案。 比如，你让AI生成一个故事，是一个悬疑故事，那么你可以在前面加上：请写一个悬疑故事。然后我们使用训练数据，使 AI 看到 “悬疑” 后，能够生成类似的故事。最后，每次你让 AI 生成故事时，都加上这个前缀，它就会生成更好的悬疑故事。 答案工程也就是对回答进行调优。 定义输出格式比如，你要求 AI 回答问题时，只说 “是” 或 “否”。 映射输出比如，它回答 这是真的，我们可以映射为 “是”。 优化答案根据具体情况进一步优化，比如需要专业回答，那么 天气有点冷 可以改为 温度较低。 提示集成你同时准备多个提示词，然后让模型分别回答，最后综合回答，得到全面准确的答案。 基于推理结构的提示为复杂问题提供一个清晰的思路，一步步解决问题 Chain-of-Thought因为 xxx, 并且 yyy, 所以 zzz Self-consistency尝试多个解决问题的方法，然后选择最一致的结果 Self-askAI 自己问自己问题，然后回答 Knowledge-generating比如先写出标准数学公式，然后再进行代入计算 Tree / Graph of-thought通过多条路径，如果不通，则回到上一步，选择另一条路径 程序辅助比如使用 Python 代码，来协助 AI 解决问题 B8 嵌入模型与向量搜索向量相似性搜索在增强 LMs 中的作用它就像是一个搜索引擎，帮助 AI 找到最相关的信息。 近似最近邻搜索首先它将知识文本转换为向量，构建索引，储存起来，当需要查找信息的时候，把问题转为向量，然后计算问题向量与所有文本向量之间的相似性，找到最相似的文本，然后用这个文本来回答问题。 局部敏感哈希通过 Binning 分箱，将数据分为多个桶，搜索时先找到相似的桶，然后再在桶内搜索。 [product] Quantization 量化将复杂数据转为简单数据，比如将浮点数转为整数，减少计算量。 我们使用 Product 量化，将向量拆分成多个子向量，然后对每个子向量进行量化，然后组合。 KD 树与优先搜索KD 树是一个多层分类系统，将数据按不同特征分层。 比如，高的在左，低的在右，然后再按颜色分，再按大小分，等等。 当需要查找的时候，使用优先搜索，找到最近的点。 优先搜索总是先找最有可能包含答案的节点，然后计算当前位置与最有可能包含答案的节点的距离，并将其设置为初始距离限制，然后递归地搜索其他节点，直到找到最近的点。 图索引通过连接相似的节点，形成网络。 小世界是一种特殊的图，你可以通过很少的中间节点找到任何一个节点。 Navigable SW 直接沿着相似的边查找Hierarchical NSW 在小世界中增加层次结构，减少搜索时间 嵌入模型一个专门将数据转为向量的模型。比如 Word2Vec，BERT，TF-IDF 等。 其中，我们有句子嵌入，和指令嵌入等。 B9 检索与工具增强的 LLMs增强 LMs 概述我们需要额外的工具来给 AI 提供知识，减少 hallucination。 一种是直接将内容填到提示词中，另一种就是嵌入空间向量。 检索增强生成Retrieval-Augmented Generation 将用户问题转为查询，关键词 使用向量数据库或搜索引擎检索 将收集到的信息聚合 生成答案 假设文档嵌入AI 为问题生成一个假设答案，然后用这个假设答案去搜索 RAG 微调模型Retrieval-Augmented Language Model 使用 检索器（查文档），编码器（文档和输入一起编码），生成器（生成答案） 三个模块。关键是在训练时，同时优化三个模块。 Retrieval-Enhanced Transformer 增强的 Transformer，检索使用 BERT，然后用在编码器中用 交叉注意力 整合检索信息。 自我独白模型通过 Chain-of-Thought 来进行多次生成，完成复杂任务，如 AutoGPT。 Think, Reason, Plan, Reflect, Act 工具微调的可能性引导模型调用外部工具，按成功率排序，将最好的结果纳入数据集。 B10 高效注意力机制稀疏注意力传统注意力需要计算输入序列每个元素之间的权重，这会导致计算量过大。 所以我们将全局注意力转为多个小矩阵，比如行和列两个方向的矩阵。 因式分解其中，有固定注意力，每个位置只关注固定数量的其他位置，适合文本。 跨步注意力，跳跃选择位置，每个位置只关注间隔一定步长的其他位置，适合图像。 位置嵌入类型Extrapolation 是指模型的泛化能力，比如模型是用短句训练的，但是要它生成长句。 传统方法使用 Sinusoidal，sin 和 cos 函数，将位置信息嵌入到向量中。 ALiBiAttention with Linear Biases，引入相对位置偏差。 它根据 Q 与 K 的距离，静态添加一个非学习的偏置。 RoPeRotary Positional Embedding，将 Sinusoida 嵌入到每个 Q 和 K 上 位置插值也就是将长序列，映射到短序列上。 假设模型支持的最大序列长度为 512，位置信息是线性分布的，例如：位置编码：[0, 1, 2, …, 511] 扩展到 2048 的上下文窗口，PI 会根据比例映射新位置：新位置编码：[0, 0.25, 0.5, …, 511.75] 闪电注意力按块逐步计算注意力得分和上下文向量，避免了直接存储整个注意力矩阵。并且让每块分别计算 softmax，减少了内存占用。 B11 LLM 的蒸馏与量化蒸馏设置与训练目标我们用一个大模型作为教师，一个小模型作为学生。在训练学生时，我们不再用 one-hot，而是直接使用教师的输出，它包含了更多信息，而不是简单的 0 和 1。 这种方法叫做 Knowledge Distillation。它会有一定的损失。 权重量化算法它将连续值映射到离散值，从高精度转为低精度，从而减少内存和计算量。量化后会引入误差，有时需要再训练。 算法有 GPTQ， AWQ 等。 模型尺寸增加对量化误差的影响模型越大，量化误差的积累就越多，导致整体误差增加。简单的量化方法无法捕捉复杂的分布模式，导致更大的误差。 我们可以使用分块和混合精度来减少误差。 B12 参数高效微调方法高效适应的优势节省时间和资源，只训练模型的小部分就能完成微调，更灵活，适应性强。 适配器在大模型前插入一个小模块，冻结原始模型，只训练适配器，可以有效避免灾难性遗忘问题。 适配器可以插入到模型的每一层中。 瓶颈适配器而适配器的结构就是瓶颈一样的，它使用一个降为层，减少训练参数，然后 ReLu，再升维。 低秩适应引入低秩矩阵分解，将权重矩阵分解为两个低秩矩阵的乘积。然后在模型的每一层中插入这两个矩阵，训练时只修改这两个矩阵，保持原有模型不变。 P*-微调类似于前缀微调 在输入的特定位置插入可学习的提示，模型会使用这些提示来完成任务。训练时，只训练这些提示的参数，保持原有模型不变。 内在维度与模型尺寸的关系Intrinsic Dimensions 实际上就是模型在特定任务上的最小参数数量。这表明大模型对特定任务，存在一个低维的有效子空间。 这就为什么我们可以通过适配器，低秩适应等方法，来减少模型的参数数量，提高效率。 B13 专家混合MoE 的属性Mixture of Experts 本质是将多个模型组合在一起，每个模型专注于不同的任务。 数据集划分每个专家处理的输入，这一般由门控网络动态决定 专家模型每个模型的架构都由可能不同，但是有相同的输入输出 门控网络为每个输入选择合适的专家 混合策略决定如何将专家的输出加权组合 路由屏蔽那些低权重，不合适的专家 稀疏性激活的专家只有少数，高效 现代 MoE 架构在深度学习中的应用如 NLP，CV，多模态任务等。 基于 MoE 的语言模型如 Switch Transformer，它使用一个门控网络，根据输入选择不同的模型。 MoE 适配器结合 MoE 和 Adapter，通过在模型中加入多个专家，并使用适配器来动态选择与组合专家输出。 快速前馈层UltraFastBERT 使用 FFL，主要是将权重分解为两个低秩矩阵的乘积来减少计算量。Hierarchical MoE，将 MoE 分为多个层次，也使用 FFL。 B14 数据集与自举LM 训练步骤所需的数据集类型 预训练数据集如网络文本，书籍论文，代码等 微调数据集如 NER，QA 等特殊任务的数据集 指令数据集用于训练模型理解指令的数据集，内容一般是 指令-回答可以人工编写，也可以 Self-instruct 基准测试数据集用于评估模型性能的数据集，包含标准化的测试用例 不同数据源的特征 网络易于获取，多样，质量参差不齐，包含大量噪声，偏见等 artistic比如书籍，音乐，不容易获取，需要一定程度的转码 专业如论文，报告等，高质量，结构化 使用 LLMs 自举训练也是用大模型生成数据，然后用小模型学习。但是小模型使用的是大模型批量生成的数据集，而不是向量，和蒸馏不同。","link":"/AI/NLP/NLP-PreExamB/"},{"title":"NLP-PreExamC","text":"TDK 演讲忙的我似乎拼好饭中毒 C1 自监督学习理论与仅文本对比模型通过未标注的数据进行学习，给数据打标签，学习其特征 基于能量的建模假设数据分布能由一个能力函数表示，能量越低，数据越真实 目标是通过优化能量函数，使模型能分辨真实数据与生成的负样本 对比学习 生成正负样本对正：原始数据和它的变换，比如旋转、裁剪、翻转负：原始数据和其他随机数据，比如猫和狗 距离函数用来衡量两个样本之间的相似度，比如欧式距离、Cosine Similarity 拟合通过最小化正样本距离和最大化负样本距离，来拟合模型 对比学习就是“找相似”和“区分不同”的过程，让模型学会在没有明确标签的情况下提取有意义的特征 基于距离的损失函数 Pair Loss相似样本距离更小，不相似的距离会大于某个阈值 Triplet Loss三元组：Anchor、Positive、Negative锚点和正样本要尽量靠近锚点和负样本之间至少要有一个 安全距离 NCENoise Contrastive Estimation 将概率估计问题转化为一个分类问题 模型的任务是区分哪些是真实数据，哪些是噪声数据 InfoNCE损失函数，让相似的样本靠近，不相似的样本远离 负采样示例正样本：一张猫的图片和猫的裁剪版负样本：一张猫的图片和狗的裁剪版 标签监督的对比学习将监督学习引入对比学习，损失函数通常基于扩展的 InfoNCE 对比学习中的不变性与协变性特征Invariance：对于输入的变换，如旋转缩放，输出保持不变 Covariance：捕捉输入数据中有意义的变化，比如几何关系，输出也会变化 仅文本模型中的对比学习Word2Vec 中，将 Skip-gram 看作是一个使用多个编码器来生成词嵌入的自监督学习任务 我们可以将上下文词和中心词分别看作是由不同的编码器生成的嵌入表示 BERT 下一句预测 也是一个对比学习任务 C2 多模态对比学习与解码方法CLIP收集 图像/文本 对，然后用 (ResNet/ViT) / Transformer 嵌入 随后通过对比学习，如 InfoNCE，训练模型 多模态系统中涌现的模态连接不同模态（如图像、文本、音频等）之间的关联和相互作用 通过训练，使得不同模态的数据在同一个向量空间中表示 通过对齐机制，使得不同模态的数据能够相互对应 跨模态注意力 迭代解码iterative 在生成过程中，中间文本输出被迭代地编码到联合 CLIP 空间，然后用于下一次生成 不准确（无指导），效率低 前缀解码prefix decoder 使用 seq2seq，结合 CLIP 和 LM （GPT），需要一个映射网络来对齐 零样本解码zero-shot 使用 仅文本前缀微调解码器，且替换 CLIP 空间映射 对比描述生成器Contrastive Captioner 使用预训练编码器，并训练解码器 使用图像编码，和文本编码，通过对比学习生成描述 C3 视觉标记化与变分自编码器将图像数据转换为离散标记（tokens）的技术 Patching将图像分割成较小块（patches）可以更容易地处理和分析图像数据 对每个小块进行独立分类 学习图像的局部特征 连续切片嵌入方法 将高维数据沿不同方向进行切片，生成一系列低维切片 对每个切片进行特征提取 将特征嵌入到一个低维空间中 调整嵌入，使其更适合特定任务 变分定理（含义、相关损失函数、与 MLE 的关系）Variational Theorem 是用一个简单的分布来近似一个复杂的分布 使用 evidence lower bound 作为损失函数 通过最大化 ELBO 来近似最大化对数边际似然，从而实现参数估计 变分自编码器Variational Autoencoder 是一种生成模型，通过学习数据的潜在表示来生成新的数据 它首先将输入数据编码为潜在空间中的分布，然后从该分布中采样，最后解码为原始数据 它的损失函数是由 Reconstruction Error 和 KL Divergence 组成的 dVAEDiscrete VAE 的潜在表示是离散的 VQ-VAEVector Quantized VAE 同样使用离散的潜在表示 将连续的潜在空间离散化，通过 矢量量化 将潜在表示映射到一个固定的离散 codebook 中 C4 视觉变压器与视觉-语言模型编码器式视觉变压器（ViT） patches，变成向量 position encoding linear embedding，将每个小块映射到一个高维空间 transformer encoder，处理序列，捕捉不同的依赖关系和特征 classification head，用于分类 它能够很好地捕捉图像中不同部分之间的全局关系 使用不同输入分辨率的 ViT使用 SWIN，基于 Shifted Window 的 Transformer，能够使用多种分辨率级别处理任意大小的图像 将输入图像逐层处理。每一层的特征图尺寸逐渐减小，通道数逐渐增加 切片合并将特征图的多个小块（patches）合并成一个更大的块，从而减少特征图的分辨率并增加通道数 合并操作通常通过拼接或平均池化等方法实现，随后进行线性变化，映射到更高维的空间 窗口化注意力通过在局部窗口内计算自注意力，显著降低了计算复杂度 在相邻层之间引入了窗口平移操作，使得模型能够更好地捕捉图像中的长距离依赖关系 完整堆栈的视觉-语言模型（如 TrOCR）TrOCR 使用 vision transformer 作为编码器，text transformer 作为解码器，执行 OCR 任务 编码器-前缀-解码器模型（如 LLaVa）结合了视觉和语言处理能力，能够从图像中提取信息并生成相应的文本描述 使用 视觉编码器（ViT） 输出的 特征向量 生成一个前缀序列 语言解码器 将前缀序列和文本提示（如问题或上下文）结合起来，生成相应的文本输出 具有模态专家的视觉-语言模型引入专门处理不同模态（如图像和文本）的专家模块，比如 GPT，来提高模型的性能和灵活性 C5 文本到图像方法T2I GANsText-to-Image Generative Adversarial Networks 生成器试图生成逼真的图像，而判别器试图区分这些图像是真实的还是生成的。 它还会检查生成的图像是否与输入的文本描述一致 T2I VAEsDALL-E 是基于 transformer 的自回归模型 首先使用 ResNet 风格的 dVAE， ELBO 训练。然后用 transformer 解码器生成图像 扩散的目标Diffusion 通过逐步添加和去除噪声来生成图像 DDPM（图模型、ELBO、简化损失、不足、插值）Denoising Diffusion Probabilistic Models 正向扩散 从噪声开始，逐渐生成图像 反向扩散 从图像开始，逐渐生成噪声 ELBO（evidence lower bound ），旨在最大化数据的对数似然 简化的损失函数，直接衡量每一步去噪的误差 由于需要逐步去噪，生成图像的过程计算成本较高 插值是指在两个图像之间生成过渡图像，实现平滑的图像变换 DDIM（图模型、与 DDPM 的关系、x0 预测的作用、简化损失、加速生成）Denoising Diffusion Implicit Models DDIM 和 DDPM 都基于扩散过程和去噪过程来生成图像。 DDIM 使用 non-Markovian chain 的方式，每一步的去噪过程不再依赖于前一步的结果 DDIM 采用确定性采样方法，而不是随机采样。这使得生成过程更加稳定和可控 在每一步去噪过程中，通过直接预测原始图像 x0 来指导每一步的去噪操作 C6 潜在扩散模型的应用与扩展分类器引导在去噪过程中，使用预训练的分类器来评估当前生成的图像是否符合目标类别。 如果不符合，调整生成过程，可以更好地控制生成图像的内容。 需要扩散模型与分类器一起训练，并且在生成过程中也需要分类器梯度 无分类器引导在训练期间向分类器添加 0 标签 潜在扩散模型（编码到潜在空间、扩散过程、条件化方法、从潜在空间解码）在VAE或GAN的潜在空间中进行扩散的方法 通过在扩散过程中引入条件信息（如类别标签），可以控制生成的结果。 将低维的潜在表示转换回高维的原始数据。 DALL-E 2使用unCLIP的模型作为VAE，并具有基于Transformer的扩散先验 Stable Diffusion 利用 VQ-GAN 生成器和 U-Net 风格的先验Prior 多阶段网络提高扩散和潜在扩散模型的效率，它将任务分解为多个阶段 初步输出作为下一阶段的输入，进一步处理和细化 多阶段网络可以共享特征表示，从而减少计算开销和参数数量。 条件上采样将低分辨率的图像或数据生成高分辨率的版本 可以理解为在生成高分辨率数据时，利用额外的信息来指导和优化生成过程 inpainting通过用生成的部分替换原始图像的部分，通过使用用户提供的掩码来完成的 适应方法（textual inversions、适配器、ControlNets、控制适配器、潜在一致性建模）文本反转：在少量特定数据上训练，并将嵌入层进行扩展，使模型能够学会特定的风格或者特征 适配器 LoRA-s：进行微调 ControlNets：在不重新训练的情况下，在生成过程中，通过控制器来调整生成器的参数 Latent Consistency Model：确保生成的图像在潜在空间中保持一致和连贯 C7 视觉-语言-行动模型视觉-语言导航在环境中导航并到达由自然语言指令指定的目标 视觉-语言-行动模型结合视觉、语言和行动三个方面的信息 VLA 模型与 VL 模型的关联VLA（视觉-语言-行动）模型和VL（视觉-语言）模型都是多模态模型 两者都需要理解视觉信息（如图像或视频）和语言信息（如文本或语音指令） VL模型主要关注视觉和语言信息的理解和关联，不涉及具体的行动生成。 VLA模型不仅需要理解视觉和语言信息，还需要生成和执行具体的行动。 VL模型通常用于图像描述生成、视觉问答 VLA模型则用于更复杂的任务，如机器人控制、自动驾驶 VLN 和 VLA 任务所需的数据集环境图像或视频，语言指令，路径标注 / 行动标注 VLN：Room-to-RoomVLA：ALFRED C8 语音转文本处理STT 任务定义输入是包含语音的声学信号，输出是对应的文本 语音信号处理（采样、傅里叶变换、梅尔频谱）通过以一定的速率采样（8k）进行数字化 数字信号通过滑动窗口（20-40 毫秒是典型长度，10 毫秒是典型步长）转换为一系列短信号 窗口化信号通过离散傅里叶变换（DFT）转换为各自的频谱 Mel Spectrogram 使用 Mel Scale 来表示频率 梅尔刻度是一种模拟人耳感知频率的非线性刻度。人耳对低频和高频的感知不同，梅尔刻度在低频部分更精细，在高频部分更稀疏。 声学建模通过特征提取和模型训练，将音频信号转换为对应的音素序列 常用的声学模型包括隐马尔可夫模型（HMM）、深度神经网络（DNN）、卷积神经网络（CNN）、长短期记忆网络（LSTM）等 语言模型与声学模型的结合语言模型负责将音素或音节序列转换为连贯的单词和句子 用来在给定声学输入的情况下找到最可能的单词序列 连接时序分类Connectionist Temporal Classification 解决序列对齐问题的方法，特别适用于输入序列（如音频信号）和输出序列（如文本）长度不一致的情况 通过引入一个特殊的“空白”符号，允许模型在输出序列中插入或跳过某些时间步，从而实现对齐","link":"/AI/NLP/NLP-PreExamC/"},{"title":"NLP-Prompt","text":"提示词 预训练、提示和预测描述 GPT-3 的论文介绍了一种使用预训练语言模型进行下游任务的新范式：只需适当地提示模型，并将输出映射到任务的输出域，而无需任何微调。他们区分了三种场景： 一般提示规则 指令应尽可能 详细、具体 和 精确 指定输出的 预期受众（如果适用）通常是有用的 复杂的提示还可以包括 人物描述 上下文示例 约束（例如，预期输出格式的模板） 解决方案所需的步骤 – 这引出了“链式思维提示”的概念 Pretrain, prompt and predict提示范式的一个重要特征是任务性能对提示的细节非常敏感： 示例选择 示例排序 任务表述 都可能产生巨大影响，因为模型具有各种偏差，其中包括： 多数标签 (majority)（imbalance 不平衡）偏差 新近性 (recency) 偏差（后面的标签更有影响力） 常见标记 偏差（更常见的标记更可能被预测） 提示工程列出的偏差（以及其他偏差）使得 优化 用于基于大型语言模型的零样本或少样本任务解决方案的提示变得至关重要，即使用适当的 提示工程 方法。 任务表述formulation 提示挖掘mining 给定一个监督数据集 ${\\langle x_i, y_i \\rangle}_{i=1}^{N}$，可以取一个语料库（例如，维基百科）并 搜索连接 $x$ 和相应 $y$ 的词或句法结构。变体： 中间词提示Barack Obama was born in Hawaii $\\Rightarrow$ [x] was born in [y] 基于依存关系的提示取包含 $x$ 和 $y$ 之间最短依存路径的最小跨度： France $\\xleftarrow{pobj}$ of $\\xleftarrow{prep}$ capital $\\xleftarrow{nsubj}$ is $\\xrightarrow{attr}$ Paris $\\Rightarrow$ capital of [x] is [y] 提示释义从一个 种子提示 开始，通过 释义 生成候选提示（例如，通过翻译和回译）。 示例种子: [x] shares a border with [y] $\\Rightarrow$ [x] has a common border with [y] $\\vdots$ [x] adjoins [y] [示例] 然后可以通过选择在目标任务的训练数据上表现最好的候选提示来选择最佳提示。 基于梯度的搜索构建一个由触发词组成的提示模板，例如 AutoPrompt 算法： 这些词由与坐标下降相关的算法找到： 初始化一个长度为 $L$ 的起始列表，填充掩码标记 对于每个 $i \\in 1 \\dots L$ 的标记位置 计算位置中标记嵌入的训练数据对数似然的 $\\mathbf{g}$ 梯度 对于每个词汇条目，使用梯度近似在该位置使用该词会带来的对数似然变化，并选择前 $k$ 个词 从中选择对数似然值最大的一个词，并用它替换当前位置的标记 这显然假设梯度是可访问的，尽管不需要更改参数。 提示生成可以将提示生成视为条件文本生成问题，并使用标准的 seq2seq 模型来解决。例如，使用预训练的 T5 生成在数据集上具有 高对数似然 的提示候选（使用束搜索）： 一种更激进的方法是提示大型语言模型生成指令： 提示评分最后，基于 BERT 的常识知识提取器，基于一组手工设计的提示模板，但对于任何具体的数据点，选择根据第二个预训练的单向语言模型（测量“连贯性”）具有最高概率的模板实例。 示例选择嵌入空间中的相似示例从训练数据中选择相似和随机的示例用于少样本预测： 对比学习依靠对比学习找到最有用的示例。提出的方法是： 使用（通常较小的）评分 $LM$ 在训练数据中找到正面和负面 $(e, x)$ 对，其中评分只是 $P_{LM}(y | e, x)$ 使用对比学习训练一个度量嵌入模型，该模型可用于为任何（示例，$x$）对分配分数 对于任何 $x$，检索包含根据模型评分最高和最低的 $k$ 个示例的正面和负面示例，并在少样本提示中使用这些示例 连续（“软”）策略前缀微调学习任务特定的嵌入向量序列，以作为实际输入（以及编码器-解码器的输出）嵌入的前缀： 这些向量仅使用训练集上的对数似然目标进行微调 作者实验了仅将前缀的 输入 嵌入作为可学习参数与在 所有层 中前缀嵌入的处理方式，后者方法带来了显著更好的结果 该方法的表现与完全微调相似 前缀微调变体连续前缀微调主题的变体： 离散初始化：优化可以从为任务自动或手动创建的离散提示开始，而不是随机初始化 离散-连续 混合微调：也可以固定提示的一些离散部分（使用“锚定标记”），并仅将前缀的其余部分作为可学习参数 辅助网络 (Auxiliary)：建模前缀嵌入之间的交互使用（相对）简单的网络，例如 LSTM，结果非常有用 答案工程LM 输出到下游任务输出域的映射也可以进行优化。 根据架构和任务，输出可以是 标记：这是分类任务的常见选择 Span：包含几个标记，通常用于“填空提示 cloze prompts” 句子：语言生成任务的自然选择 对于某些任务，直接使用 LM 输出是可行的，例如文本生成，但当 $\\mathcal{Y}$ 输出空间不同或受限时，需要进行映射，例如分类或命名实体识别（NER）任务。 一个简单的映射示例：$v(\\cdot)$ “口头化”函数将下游主题分类任务的类标签映射到答案标记。（输入是一个“填空问题”，模型预测其中的内容。） 找到每个 $y\\in \\mathcal{Y}$ 对应的合适答案集的方法包括 答案释义手动设计的种子答案集通过释义扩展。 修剪后搜索创建一个初始集合，例如通过释义，然后在该集合中搜索 $y$ 的最佳答案，例如通过选择在训练数据集上具有最大对数似然的替代答案。 组合提示提示集成类似于模型集成，将多个未回答提示的 LM 答案组合到相同的 $x$ 输入可以带来更好或更稳定的性能。组合方法可以是 均匀平均 uniform：将组合提示的答案概率分布简单平均 加权平均 weighted：最终分布是答案分布的加权平均——权重可以来自提示在训练数据集上的表现 简单的多数投票 majority 也可以用于分类 对于文本生成，组合提示并不那么简单，但一种方法是在每个生成时间步使用所有下一个词概率分布的平均值来生成下一个词。 基于推理结构的提示连锁思维提示对于涉及复杂推理的任务，例如数学问题解决或规划，提供逐步演示可以显著提高性能。例如， 问题：Tom 和 Elizabeth 进行了一场爬山比赛。Elizabeth 爬山用了 30 分钟。Tom 爬山的时间是 Elizabeth 的四倍。Tom 爬山需要多少小时？ 答案：Tom 爬山需要 30*4 = 120 分钟。Tom 爬山需要 120/60 = 2 小时。所以答案是 2。 问题：Jack 是一名足球运动员。他需要买两双袜子和一双足球鞋。每双袜子 9.50 美元，鞋子 92 美元。Jack 有 40 美元。Jack 还需要多少钱？ 答案：两双袜子的总成本是 9.50 x 2 = 19。袜子和鞋子的总成本是 19 + 92 = 111。Jack 需要 111 - 40 = 71 美元。所以答案是 71。 问题：Marty 有 100 厘米的丝带，他必须将其切成 4 等份。每个切割部分必须再分成 5 等份。每个最终切割部分有多长？ 答案： 更令人惊讶的是，“零样本连锁思维”在没有示例的情况下也有效： 问题：Marty 有 100 厘米的丝带，他必须将其切成 4 等份。每个切割部分必须再分成 5 等份。每个最终切割部分有多长？ 答案：让我们一步一步地思考。 自洽采样用于连锁思维提示Self-consistency sampling for COT，通过采样多个答案，即多个推理路径，而不是单一的贪婪解码，并将结果集成，例如通过多数投票，可以经常改善结果： 自问自答Self-ask 提示模型明确提出并回答后续问题也是一种有用的策略： 知识生成对于常识推理任务，提示大型语言模型生成相关知识也可能是有益的。（具体的表述和示例取决于任务。）生成的知识片段用于回答问题： 通过采样生成多个知识提示的答案，并使用它们生成问题的答案。可以通过多数投票选择最佳答案： 更复杂的思维结构关于连锁思维提示的一个常见观察是它假设了一条直接通向答案的顺序链（sequentialchain），但复杂的人类推理经常涉及 探索从共同起点分支的替代思维序列 丢弃一些思维分支 并回溯 直到找到最终结论。 思维树提示框架支持使用适当的提示执行这种类型的推理步骤。 思维树提示 主要组件是： 明确定义当前任务的 单元思维（unit thought） 是什么（一个段落、一个公式等） 为一个分支生成 延续思维（continuation thoughts，例如，通过采样） 评估 思维 决定下一个扩展节点的 搜索策略（例如，广度优先搜索） 有尝试通过单一提示引出类似思维树的推理，例如，@tree-of-thought-prompting 使用以下示例提示： 123456想象三个不同的专家在回答这个问题。所有专家将写下他们思考的第1步，然后与小组分享。然后所有专家将继续进行下一步，等等。如果任何专家在任何时候意识到他们错了，他们就会离开。问题是... 图思维提示树思维理念的自然扩展是添加思维路径的聚合。这导致将 T-o-t 提示推广到支持任意有向无环图拓扑的Graph-of-thoughts框架： 当然，增加的复杂性需要更复杂的架构，例如，使用以下模块（适应实际任务）： Prompter 用于准备编码图结构的提示 Parser 从输出中提取思维状态并更新动态的图推理状态结构 Scorer 和 Validator 用于评估思维 Controller 用于控制图构建过程的步骤 程序辅助的连锁思维推理连锁思维提示的一个有趣研究方向是提示 LLM 进行形式推理或计算步骤（例如，Python 语句），并通过外部解释器或推理器执行这些步骤生成最终答案。 漏洞除了与 LLM 相关的常见问题（可能的幻觉、危险或有害内容等），将外部输入纳入 LLM 提示的方法可能容易受到各种类型的对抗性提示（adversarial）的攻击，并且必须加以防范： 提示注入 影响 LLM 的行为，使其忽略原始指令做一些意想不到的事情 提示泄漏 注入内容，使 LLM 泄露其提示的细节，这些提示可能包含敏感信息 尾声：元提示 LLM 作为提示优化器Metaprompted LLM 作为优化器使用（元 meta）提示的 LLM 作为通用优化器： \\dots LLM 生成目标函数的新解，然后将新解及其得分添加到元提示中以进行下一步优化。 LLM 作为优化器：在提示中的应用 LLM 作为优化器：在提示中的应用 I LLM 作为优化器：在提示中的应用 II发现元提示优化器方法在 GSM8K 数学问题数据集上表现优于众所周知的手动提示工程方法，如“积极思考”和“链式思维”： 意想不到的最佳提示此外，最佳提示通常是令人惊讶和古怪的：","link":"/AI/NLP/NLP-Prompt/"},{"title":"NLP-RNNs","text":"递归神经网络 介绍使用神经网络进行语言建模正如我们所见，使用学习到的词嵌入的前馈神经网络语言模型已经比传统的 $n$-gram 模型表现得更好： 与最好的 $n$-gram 模型相比，困惑度提高了24%。 但这些模型仍然与$n$-gram模型共享一个重要的限制：续接（continuation）预测基于固定大小的上下文窗口，没有任何关于早期历史的信息： $$ \\hat P(w_{t}~|~w_0,\\dots,w_{t-1}) = \\phi(w_{t-k},\\dots, w_{t-1}) $$ 其中 $\\phi(\\cdot)$ 是由前馈神经网络计算的函数。 循环神经网络 (RNNs)Recurrent Neural Networks与此不同，它们不受限于固定长度的输入序列，并且至少在理论上可以形成有用的任意长历史的内部表示。它们可以逐步处理顺序输入，并在每一步更新内部状态： RNNs 可以非常简单，例如曾经广泛使用的 Elman 网络具有以下结构： $$h_t = a_h(U x_t + W h_{t-1} + b_h )$$ $$o_t = a_o(Vh_{t} + b_o )$$ 反向传播通过时间RNNs 的标准优化方法是backpropagation through time (BPTT)，这是应用于时间展开网络的反向传播： 由于展开的 RNN 的深度随着展开的时间步数线性增长，通常无法对所有时间步进行反向传播。 在这些情况下，展开和误差的反向传播仅在一定数量的时间步内进行 - 反向传播是截断的（backpropagation is truncated）。实际上，大多数神经网络框架实现了截断反向传播。 RNN 训练挑战训练 RNNs 存在显著的挑战： 一个展开了多个时间步的 RNN 在反向传播方面表现得像一个深度前馈网络，因此梯度消失（vanishing）和梯度爆炸（exploding gradients）都可能成为问题，尤其是因为完全相同的层被重复使用。 特别是梯度消失，意味着 RNN 无法学习长期依赖（long-term dependencies），而这在理论上应该是它的强项。 长短期记忆网络Long Short-Term Memory (LSTM)一种复杂的门控拓扑（gated topology）结构，使 RNNs 具有长期记忆，并解决了 梯度消失/爆炸 问题。 Cell stateLSTM 的单元状态充当“信息传送带”（conveyor belt），信息可以在时间步之间传递。 Forget gate遗忘门计算一个 $f_t\\in (0,1)^d$ 掩码，用于从单元状态中移除信息： $$f_t=\\sigma(W_f[h_{t-1}, x_t] + b_f)$$ Input gate and update vector计算输入掩码 $i_t$ 和更新向量 $\\tilde C_t$： $$i_t=\\sigma(W_i[h_{t-1}, x_t] + b_i)$$ $$\\tilde C_t = \\tanh(W_C[h_{t-1}, x_t] + b_C)$$ 计算新的单元状态使用 $f_t, i_t$ 和 $\\tilde C_t$ 计算新的单元状态： $$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde C_t$$ 输出最后，生成输出 $h_t$： $$o_t = \\sigma(W_o[h_{t-1}, x_t] + b_o)$$ $$h_t = o_t \\odot \\tanh(C_t)$$ LSTM 优势门控 LSTM 架构通过确保梯度可以流向远处的时间步，解决了梯度消失/爆炸的问题。 更新是加性（additive）的，这意味着梯度不会像 Elman 网络那样被相乘，并且门控可以在训练期间获得权重，使网络能够在输入和输出值之间表现出长距离依赖关系。 LSTM 变体：窥视孔连接Peephole connections 通过允许门控访问实际的单元状态来扩展 LSTM 架构： LSTM 变体：门控循环单元Gated Recurrent Unit (GRU) 是一种简化的 LSTM 变体，它去除了单独的单元状态，并合并了遗忘门和输入门： 使用 RNNs 进行语言建模 该模型最显著的特点是： 之前的词（“left context”）逐步处理，每次一个词 第一层是静态词嵌入 $h_t$ RNN 的直接输出（隐藏状态）通过仿射（affine）变换和 $\\mathop{\\mathrm{softmax}}$ 非线性变换，转化为词汇表上的续接概率分布 序列元素虽然传统的 RNN 语言模型是基于词的，即序列元素是词，但有两个重要的替代方案： 字符级 语言模型将character视为序列元素，并根据之前的字符预测下一个字符 子词级 语言模型基于subword分词（例如 BPE），并预测词汇表中的下一个子词 这两种类型的模型都可以利用相应的字符和子词嵌入。 训练基于 RNN 的语言模型与所有参数化语言模型一样，使用通常的负对数似然损失进行训练：如果训练序列是 $\\langle w_1,\\dots, w_n \\rangle$，并且 $\\hat P_i$ 是模型对第 $i$ 个续接概率的输出分布，那么损失是 $$- \\sum_{i=1}^n \\log \\hat P_i(w_i)$$ 但是在训练期间，每个时间步 RNN 的输入应该是什么？应该来自训练数据，还是来自 RNN 之前的预测？ RNN 语言模型通常使用训练数据作为输入进行训练。这称为teacher forcing。 Exposure bias尽管教师强制是目前最常用的训练方法，但它有一个主要问题，即所谓的 曝光偏差 现象： 使用教师强制训练的语言模型仅暴露于其输入完全来自训练语料库的情况 相比之下，在推理期间，它们必须为不在训练数据中的文本生成续接，最重要的是，在文本生成期间，它们必须继续自己的输出 解决方案 计划采样：在每个时间步随机选择使用训练数据作为输入还是从模型的预测中采样。选择从训练集中的概率从 1.0 开始，并在训练期间逐渐减少 可微采样：在原始 Scheduled sampling 中，误差不会通过使用的采样操作进行反向传播，因为它是不可微的。对此，开发了 Differentiable 的替代采样解决方案，最重要的是使用所谓的 Gumbel softmax 重参数化（reparametrization） 多层 RNN现代基于 RNN 的架构经常将多个 RNN 单元堆叠在一起作为层，类似于多层前馈网络： 性能在 transformer 出现之前，基于 LSTM 的语言模型在性能上始终优于其他架构，即使在现在也非常具有竞争力。 在 NLP-progress 跟踪的 9 个语言建模数据集中，有 5 个数据集上基于 LSTM 变体的模型（所谓的 Mogrifier LSTM）表现最好，而在剩下的 4 个数据集中，基于 LSTM 的模型非常接近（transformer 产生的）最先进水平。","link":"/AI/NLP/NLP-RNNs/"},{"title":"NLP-ReducedComplexity","text":"精简 介绍从第一天开始，LLM 的参数数量就一直在增加，即使在神经 LMs 的扩展规律确立之前也是如此。如前所述，大型模型存在各种问题： 不利的环境影响 非常高的硬件要求 推理 微调 在今天的讲座中，我们将看到一些可能缓解这些问题的方法。 这些“规律”不是严格的数学构造，更像是摩尔定律。 蒸馏知识 distillationLMs（或任何分类模型）通常通过最小化模型预测与独热训练标签之间的交叉熵来进行训练。 这种设置忽略了单词之间的关系（例如同义词）。例如，模型最终会学到汽车、火车和卡车都是车辆，但在任何训练句子中，只有一个是正确的，并且只有它的概率会增加。这会减慢训练速度。 知识蒸馏使用较大模型（教师）的输出来替换训练较小模型（通常是学生）时的独热标签。 学生通过蒸馏损失进行训练：即与教师的（软）目标分布的交叉熵： $$L_{ce} = \\sum_i t_i * log(s_i)$$ 还使用了参数化的 softmax 版本 $$p_i = \\frac{\\exp{(z_i / T)}}{\\sum_j \\exp{(z_j/T)}}$$ 其中 $T$ 是控制分布平滑度的温度。在训练期间，使用 $T&gt;1$ 的值来放大教师知识中的隐含 implicit 泛化 generalization。 DistilBERTDistilBERT 将 BERT-base 蒸馏为一个层数减半的模型。训练损失有三个组成部分： 蒸馏损失 $L_{ce}$ 掩码语言模型 损失 $L_{mlm}$ 余弦嵌入损失 $L_{cos}$ 用于对齐隐藏向量 小模型保留了 BERT 在 GLUE 上 $97%$ 的性能，同时体积减少了 $40%$，推理时间加快了 $60%$。 蒸馏主要用于预训练，但在一个任务中，微调后的模型也通过蒸馏进行训练。 Switch TransformerSwitch Transformer 是一个拥有 1.6T 参数的 LLM。该模型使用 专家混合 设置来实现稀疏性： Hard 专家切换：一次只激活一个专家 MoE 仅应用于 FF 层 预训练速度提高 $7\\times$ 该模型非常强大，但太大而无法有效使用。使用与 DistilBERT 相同的技术： 从教师模型初始化学生权重 硬损失和软（教师）损失的 $75$–$25%$ 混合 蒸馏后的 密集 dense 模型（压缩率为 $80-99%$）仍保留了教师模型质量提升的约 $30%$。 量化量化 是将连续值映射到一小组离散 discrete 值的过程。除了蒸馏，它是另一种减少 LLM 内存使用的方法，使得在单个 GPU 上运行大型模型成为可能。 形式上，量化的目标是给定（层）权重矩阵 $\\mathbf{W}$ 和层输入 $\\mathbf{X}$，找到量化后的权重矩阵 $\\mathbf{\\hat{W}}$ 使得 $$\\mathbf{\\hat{W}} = \\textrm{argmin}_\\mathbf{W_q} |\\mathbf{WX} - \\mathbf{W_qX}|_2^2$$ 量化 LLMs量化 LLMs 并不是一项简单的任务： 最简单的四舍五入到最接近（round-to-nearest）方法仅在 8 位/权重时效果良好 需要模型再训练的高级方法在 GPT-3 级别的模型（如 OPT-175B 或 BLOOM）上非常昂贵 训练后（一次性）方法复杂且在大约 15 亿参数时变得不可行 引入了 GPTQ / OPTQ 算法，这是第一个可以将 OPT 或 BLOOM 量化到 3-4 位的算法。 算法该算法是Optimal Brain Quantization算法的增强版本。OBQ 逐行逐个权重地量化 $\\mathbf{W}$，始终更新剩余权重以补偿量化误差。 OBQ 需要 4 小时来量化一个 1 亿参数的模型。为了处理大型 LLMs，该算法 每列仅更新一次权重 使用惰性批处理以实现高内存吞吐量 解决数值不稳定性 量化仅改善模型的内存需求。为了加速推理（$3.2-4.5\\times$），实现了特殊的反量化内核。 结果GPTQ 可以在大约 4 小时内将 OPT 和 BLOOM 量化到每个权重 4 位和 3 位。 观察结果： 最大量化模型的困惑度在 fp16 模型的 1-2 点以内 对于较小的模型，差异更大，因为量化不那么重要 数据高效量化GPTQ 算法确实需要大量高质量数据来优化量化权重，因为它旨在匹配量化模型和原始模型之间的激活。现代量化方法利用不同的假设/指标来实现更高效的数据量化。 NormalFloat 4-bit [“bitsnbytes” 或 “bnb” 风格] 量化假设权重的某种分布来设计最佳量化级别。它不需要任何数据来量化权重 Activation-aware Weight Quantization (AWQ) 仅使用激活幅度来选择性地量化权重，从而使其对数据的变化或缺乏更具鲁棒性 基本量化标准量化将原始表示范围映射到较小的范围，四舍五入到固定（较小）数量的量化级别 $$\\mathbf{X}^{\\text{Int8}} = \\text{round}(c^{\\text{FP32}} \\cdot \\mathbf{X}^{\\text{FP32}})$$ 其中 $c^{FP32} = \\frac{127}{\\text{absmax}(\\mathbf{X}^{\\text{FP32}})}$ 是基于最大值的最佳量化常数。 为了防止异常权重影响最大值，我们可以根据权重分布的分位数选择量化常数，并选择权重矩阵的块进行单独量化。 “BitsnBytes” 或 QLoRA 风格量化结合了块级和基于分位数的方法。 由于大多数深度学习模型权重是通过归一化训练的，它们大多遵循正态分布。缩放这些权重很容易，因为如果我们假设均值为 0，则只需要一个 $\\sigma$ 参数。 这将导致一个缩放的正态分布，其中 Normal Float 数据格式非常有用。在这里，我们定义量化级别，使它们之间的概率质量相等，而不是算术四舍五入。 为了进一步减少内存消耗：块的量化常数（在这种情况下为 $\\sigma$ 值）再次量化（双重量化）。 NF4 可能值 激活感知权重量化Activation-Aware Weight 是一种数据高效的方法，其主要创新是保持一组显著权重在原始精度（fp16）下，并在量化前按重要性比例缩放权重（同时按此缩放因子划分输入通道）$Q(w) = 1/c \\cdot \\text{round}(c\\cdot w \\cdot s)$，而输入则反向缩放传递 $x/s$ 到层。这里我们使用块状线性绝对最大缩放 ($c$) 和通道级缩放因子 ($s$)，该因子由小数据集上的激活幅度确定。 激活幅度计算为：$A_d = \\sum_{i=1}^{N} |x_{i,d}|$，其中 $N$ 是数据集中的样本数量，$d$ 是通道索引。通道 $\\hat{d} = \\text{argmax}_d (A_d)$ 的权重保持为 fp16，其余部分进行量化。 AWQ 基准测试结果缩放因子 $s$ 为每个通道确定为 $s_d = A_d^{\\alpha}$，其中 $\\alpha$ 是通过网格搜索找到的可调参数。使用 $\\alpha=0$ 意味着没有缩放，而通常考虑最多线性缩放 $\\alpha=1$。在量化之前，放大的权重在给定通道上分布得更广，这导致较小的量化误差，同时可能增加其他通道的误差。AWQ 不使用基于梯度的优化，而是在前向传递中使用小数据集进行 $A_d$ 和 $\\alpha$ 计算。 高效量化推理CPU 和 GPU 并不总是为混合精度操作做好准备（因此每个操作可能需要在使用全精度输入之前暂时反量化权重）。因此，需要专门的内核或表示来存储和处理量化模型，以避免内存或计算开销。目前首选 MARLIN 内核。 对于内存高效的权重存储，应使用特定平台的打包数据类型（例如：在 32 位变量中存储 8x 4 位权重）。 高效适应Efficient Adaptation 动机自 BERT 以来，通过微调将 LLM 知识转移到 NLP 任务上一直是实现最先进性能的方法。然而，微调在参数上效率低下：每个任务都需要一个新模型。 两个相关概念： 多任务学习 在多个任务上微调模型。然而，在微调时可能并非所有任务都可用——我们感兴趣的任务可能会缺失。 持续学习 系统旨在从任务流中学习。每当出现新任务时，模型需要能够处理它而不会忘记以前的任务。 适配器适配器通过以下方式解决了持续学习和微调浪费的问题： 向原始模型添加特定任务的小型适配器模块 adapter 冻结原始模型的权重 在微调期间仅训练适配器模块 在 transformer 层的两个子层之后插入适配器 将它们初始化为接近身份 通过使用瓶颈适配器将 $d$ 维数据投影到 $m$ 维并返回来限制附加参数的数量 性能适配器方法的替代方法是仅微调顶层。下层通常计算通用特征；顶层特定于任务。 然而，适配器以两个数量级更少的参数（$1.14-3.6%$）实现了相同的结果： 低秩适应 (LoRA)Low-rank adaptation 通过稍微不同的方式解决了与适配器相同的问题。它不是在原始模型的组件之后添加新的可训练层，而是添加低秩分解矩阵，以并行于原始冻结矩阵表示适应所需的变化： LoRA 类似于适配器： 添加小型、低维模块——通常 $r=2$ 或 $4$ 就足够了 为每个任务训练一组不同的模块 模块大小与适配器相似 确保高效微调 然而，有一些关键区别： LoRA 仅应用于自注意力矩阵 ($W_k, W_q, W_v, W_o$) LoRA 模块可以在推理时与冻结矩阵合并，这不会产生与适配器相比的推理延迟 LoRA 通常在下游任务上取得略好的结果 内在维度为什么我们可以使用 SGD 在特定任务的小数据集上微调百万/十亿参数模型，而无需归一化？为什么低秩适应技术（瓶颈适配器、LoRA）适用于微调？Intrinsic Dimensions 可能提供了答案。 目标函数的内在维度是解决优化任务所需的最小维度。在我们的情况下，这转化为： 我们需要多少参数（除了未微调的预训练模型）才能达到至少 $90%$ 的完全微调模型的性能？ 数学公式计算最低维度 $d$ 是不可行的；我们只能通过启发式方法近似。设 $\\theta^D$ 为微调模型的 $D$ 维参数，$\\theta_0^D$ 为原始模型的参数。那么，我们正在寻找最低的 $d$ 使得 $$\\theta^D = \\theta_0^D + P(\\theta^d)$$ 其中 $P: \\mathbb{R}^d \\rightarrow \\mathbb{R}^D$ 在原始公式中，$\\theta_0^D$ 是完整模型的参数。此公式扩展为考虑多个层。LoRA 在此框架中定义为 $P(\\theta^d) = B$。 寻找 $d$找到 $d$ 的唯一方法是通过超参数搜索。 内在维度是下游任务相对于预训练模型的最小描述长度 从这个角度看，内在维度与压缩有关，因此它也与模型的泛化能力相关 较大的模型允许更小的内在维度 P^*^-Tuningp^*^-tuning 是一组用于轻量级微调的方法。它的灵感来自 prompting。在这里，可训练的组件是任务特定的自由参数“tokens”，插入到实际输入之前（也称为软提示）。 p^*^-tuning 适用于仅解码器和全栈模型。 前缀微调前缀微调 将软 tokens（前缀）添加到输入嵌入和每一层的输入中。 前缀微调需要大约 $0.1%$ 的额外参数 与适配器相比，这是 $30\\times$ 的减少 前缀微调 优于适配器 获得与微调相当的性能 在低数据设置中优于微调 其他方法提示微调 类似于前缀微调，但提示仅添加到输入嵌入中。 P-tuning 训练一个 LSTM 来生成软提示（不仅仅是前缀）。它在多个数据集上比提示微调高出 $15-20$ 分。 P-tuning V2 对于 Transformer 编码器模型，实际上与前缀微调相同。 PEFT 库参数高效微调 (PEFT) 库 支持所有这些方法（以及更多）。","link":"/AI/NLP/NLP-ReducedComplexity/"},{"title":"NLP-STT","text":"语音转文字 语音转文字任务语音转文字 (STT) 任务，也称为自动语音识别 (ASR)： 输入是包含语音的声学信号（例如，一个 wav 文件） 输出是口语内容的书面转录，通常没有标点和大写 生成的转录不一定分段成句子或包含正确的标点和大写 该任务是监督的：模型在转录的语音语料库上进行训练 挑战挑战源于语音和书写之间的差异，以及上下文依赖性： 分段：书写中的单词边界通常不会通过语音中的静音来指示，反之亦然，语音中的静音不一定表示单词边界 歧义：不同书写的文本可以发音相同，例如，在英语中 bare 和 bear 发音相同 连音现象：相邻的语音可以相互作用并影响彼此的发音，例如，在 I have to 中的 v 发音为 f（在快速语音中），因为后面的无声 t 所谓的 隆巴德效应：不能简单地通过添加噪音来扩充数据集，因为人们在嘈杂环境中会改变说话方式（不仅仅是说得更大声…） 与典型的书面语言相比，语音可能包含不合语法的结构、不完整的句子或单词、纠正、单词/音节重复和中断 说话者适应：不同性别、年龄、文化背景等的人在发音上有很大差异 人类的语音理解在很大程度上依赖于上下文背景信息来进行可接受的解释——我们使用上下文线索主动“感知”/“听到”语音。一个戏剧性的例子可以在这里听到 任务变体 连续与孤立识别： 在孤立情况下，输入要么由单个单词组成，要么可以轻松分段成单个单词（因为有分隔的静音） 在连续情况下，单词之间可以没有任何静音，就像正常语音一样。连续语音识别要困难得多 联合识别（可能带有说话者分离）：基本的语音识别是针对一个说话者的：更复杂的变体是有多个说话者（例如，在对话中），并且，选择性地，转录必须指示谁在说什么（说话者分离）。在这种情况下，重叠语音可能是一个特别困难的问题 评估最常见的评估指标是词错误率 (WER)，它基于与正确转录相比的词级编辑距离。如果 $\\hat{W}$ 是输出，$W$ 是正确的转录，那么 WER 简单定义为 $$\\frac{\\mathrm{Levenshtein}(\\hat W, W)}{\\mathrm{length}(W)},$$ 即，从正确转录得到输出所需的每个词的平均词级编辑操作数。 训练数据一般来说，训练数据包括录制的语音音频和时间对齐的书面转录。 过去，转录是音素级的，并在音素级别对齐，因此注释者必须通过听和查看波形来确定音素边界： 训练方法的改进使得音素级对齐变得过时：现代 ASR 数据集包含正常书写的转录，只需在句子级别进行时间对齐。 尽管有这些改进，创建好的 ASR 数据集仍然需要大量工作，因为可用语料库的大小从多个说话者（包括男性和女性）的 20 小时语音开始。由于相关成本，即使是最广泛使用的语言，免费语料库的数量也很少，对于许多语言，根本不存在免费的数据集。 LCD 数据集对于英语，直到最近，大多数公共数据集都是由语言数据联盟 (LDC) 发布的。这些包括 华尔街日报音频语料库（阅读报纸文章，80 小时，1993 年） Fisher 语料库（电话语音，1600 小时，2004/2005 年） Switchboard 语料库（电话语音，300 小时，1993/1997/2000 年） TIMIT 语料库（阅读示例句子，有限的语法/词汇变异性，1986 年） 最近，其他语言的数据集也被添加到 LDC 目录中，现在它包含西班牙语、普通话和阿拉伯语等。 开放计划不幸的是，LCD 数据集通常不是免费的，访问大多数数据集需要 LDC 会员或支付费用。 最近创建和管理免费数据集的计划： 开放语音和语言资源页面 列出了几种语言的多个免费数据集，其中包括重要的 LibriSpeech 语料库，包含约 1000 小时的有声读物语音 Common Voice：Mozilla 项目，旨在为尽可能多的语言收集 ASR 数据集。已经收集并验证了 2484 小时的英语转录语音，其他语言也在进展中，截至撰写本文时，德语为 1290 小时，法语为 958 小时 语音信号处理时间上的连续语音信号当语音被记录时，空气压力的变化会移动麦克风的振膜，这些运动被转换为电子电流的变化——因此，语音被表示为连续信号： 采样这是一个连续的模拟信号，可以通过以一定的速率采样进行数字化（至少 8kHz，以表示 100 Hz–4 kHz 范围内的音素）： 窗口化数字信号通过取重叠的窗口（20-40 毫秒是典型长度，10 毫秒是典型步长）转换为一系列短信号： 窗口通常包含接近窗口端逐渐衰减的加权值。一种流行的加权方案基于余弦函数：对于具有原始信号值 $s_0,\\dots,s_{N-1}$ 的窗口，加权值为 $$w(n) = a - (1 - a)\\cos\\left(\\frac{2\\pi n}{N}\\right)$$ 选择 $a = 0.54$ 会导致常用的 Hamming 窗口。 傅里叶变换窗口化信号通过离散傅里叶变换（DFT）转换为各自的频谱： 进一步处理尽管许多最新的方法直接使用频谱，但传统上，进一步的转换是通过以下方式完成的，例如： 使用滤波器组 取（平滑）频谱的对数 执行进一步的傅里叶变换 其目的是提供接近人类感知和处理语音的特征压缩表示。历史上最重要的表示是 MFCC（梅尔频率倒谱系数），它结合了上述几个步骤。 梅尔尺度FFT 返回的频谱信息并不对应于人类感知声音的重要特征： 我们的听觉在频率较低时更敏感和辨别力更强， 反映声音之间感知距离的听觉频率尺度实际上是对数的。 对应于频率 $f$ 的感知音高可以通过计算其在对数梅尔尺度上的位置来表示（其中 mel [来自 melody] 是听觉音高距离的单位）： $$ mel(f) = 1127 \\ln \\left(1+\\frac{f}{700} \\right ) $$ 梅尔滤波器组梅尔滤波器组是一组根据梅尔尺度均匀间隔的重叠（通常是三角形或余弦形状）滤波器。它可以用于将频谱转换为包含感知信息频带的梅尔频谱。 MFCC（梅尔频率倒谱系数）MFCC 是语音识别领域中最广泛使用的频谱表示。“倒谱”是 DST 步骤的结果。 典型的 MFCC 帧特征向量包含以下 39 个值： 12 个基本 MFCC 特征（倒谱中的 12 个能量值） 倒谱中的总能量 12 个 delta MFCC 特征（MFCC 导数） 12 个 double delta MFCC 特征（MFCC 二阶导数） 1 个总 delta 能量特征 1 个总 double delta 能量特征 语音建模我们尝试在给定（预处理）语音信号 $\\mathbf s$ 的情况下找到最可能的 $\\mathbf w=\\langle w_1,\\dots,w_n\\rangle$ 词序列，即 $$ \\underset{\\mathbf w}{\\operatorname{argmax}} P(\\mathbf w \\vert \\mathbf s). $$ 使用贝叶斯规则，这可以重新表述为 $$\\underset{\\mathbf w}{\\operatorname{argmax}}(P(\\mathbf s \\vert \\mathbf w) \\cdot P(\\mathbf w)).$$ 这里 $P(\\mathbf w)$ 可以通过语言模型建模，而给定词序列的声音信号的条件概率 $P(\\mathbf s \\vert \\mathbf w)$ 则通过声学模型建模。 声学模型在经典的 STT 中，声学模型通常包含目标语言音素的 HMM 模型。一个常见的选择是使用 3 状态 HMM 来建模音素，并使用高斯混合作为发射分布（3 个状态分别表示音素的开始、中间和结束）： 上下文相关的音素模型自然语言中的音素是上下文相关的：它们的物理实现取决于前后的音素。因此，更复杂的语音识别器使用上下文相关或“三音素”模型： 由于音素组合的数量庞大，一些 HMM 状态被共享或**“绑定”**在一起：假设它们具有相同的发射分布，以减少模型参数的数量。 使用 MLE 优化的音素决策树将隐藏状态聚类为可以绑定在一起的组。 声学模型训练基于 HMM 的声学模型与 GMM 发射分布通过期望最大化 (EM) 使用以下内容进行训练： 转录的语音样本，其中的转录精确地对齐时间 描述转录中所有单词发音的音素词典 在早期，转录是音素级别并逐个音素对齐，但现代系统使用单词或句子对齐的转录，其音素转录是使用音素词典自动生成的。 由于 HMM 可以组合（在这种情况下是串联的），使用音素词典，音素模型可以用于构建单词模型，单词模型又可以提供用于更高级别训练的单词序列模型： 现代基于 HMM 的系统如 Kaldi ASR 不直接在训练数据集上训练其最复杂的模型，而是训练一系列模型： 首先训练一个单音素声学模型，并将该模型与音频对齐 训练好的单音素模型用于开始训练三音素模型 进一步的训练和对齐步骤使用额外的训练算法重复进行，以获得更高质量的模型（例如，使用 delta 特征等） 添加语言模型由于传统的 N 元语言模型也基于马尔可夫假设，基于 HMM 的声学模型可以很容易地与它们结合，形成一个 联合声学 + 语言 HMM $\\mathcal A + \\mathcal L$，可以用来在给定声学输入的情况下找到最可能的单词序列。 $$ \\underset{\\mathbf w}{\\operatorname{argmax}}~P_{\\mathcal A + \\mathcal L}(\\mathbf w \\vert \\mathbf s) $$ 理论上，可以使用完整的维特比算法，但其在状态数量方面的二次时间复杂度使得这在连续的大词汇量语音识别中不可行，因为组合的 HMM 非常大。","link":"/AI/NLP/NLP-STT/"},{"title":"NLP-Seq2Seq","text":"RNN 序列模型和注意力 基于 RNN 的序列处理根据输入、输出和 hidden/cell 状态的处理方式，RNN 可用于各种序列转换和处理任务： 也许最基本的是将 $\\langle \\mathbf{x}_1,\\dots,\\mathbf{x}_n \\rangle$ 输入序列转换为 $\\langle \\mathbf{y}_1,\\dots,\\mathbf{y}_n\\rangle$ 序列的对应输出。 这种类型的架构可以用于序列标注，当输出是标签的分布时。例如，语言建模可以被视为序列标注的一个特例，当文本中每个单词的正确“标签”只是下一个单词： $$\\mathbf{x} = \\langle w_1,\\dots,w_{n-1}\\rangle$$ $$\\mathbf{y} = \\langle w_2,\\dots,w_{n}\\rangle$$ 序列标注一个简单的标注示例：基于 LSTM 的词性标注器，具有词嵌入输入和 softmax 输出层。 双向 RNN作为序列标注任务的语言建模有一个非常特殊的属性：模型不能访问要标注元素之后的元素信息。 对于其他序列标注任务，这种情况并不成立：元素之后的上下文是输入的重要组成部分。但 RNN 单元本质上是单向的：隐藏状态只能包含关于较早时间步输入的信息。一种广泛使用的方法是使用双向 RNN 并在每个元素处连接它们的隐藏状态。这就是所谓的 Bidirectional RNN 层。 自然地，双向 RNN 层可以像普通的单向 RNN 一样堆叠： Seq2vec: 序列编码有许多任务需要将可变长度的输入序列映射到固定长度的输出，例如情感分类等序列分类任务。 如何使用一个或多个堆叠的 RNN 将输入序列映射到一个有用的表示整个输入的向量？关键在于 RNN 的 隐藏状态（加上 LSTM 的 cell 状态）可以表示到给定时间步的整个输入序列。 对于单向 RNN，显而易见的解决方案是使用最后的隐藏状态（在 LSTM 的情况下可能还包括 cell 状态）来表示整个输入序列。例如，对于分类任务： 相比之下，双向 RNN 的隐藏状态在每个时间步都包含关于整个输入的信息，因此更有意义的是聚合所有隐藏状态，例如，使用平均或最大池化。 Vec2seq: 序列生成基于固定大小向量的序列生成类似于使用语言模型的语言生成，但在这种情况下，生成是有条件的：我们希望建模序列概率 $$P(\\langle y_1,\\dots, y_n\\rangle ~|~ \\mathbf{x})$$ 其中 $\\mathbf{x}$ 是一个固定长度的向量。类似于基于 RNN 的无条件语言模型，我们可以将问题简化为使用 RNN 建模个体 $$P( y_n|~ \\langle y_1,\\dots,y_{n-1} \\rangle, \\mathbf{x})$$ 续接概率。 标准的基于 RNN 的语言模型架构可以通过一个简单的修改来重用：RNN 的隐藏状态也依赖于条件向量 $\\mathbf{x}$。模型具有以下条件独立结构： 在神经网络架构层面，可以通过多种方式将 RNN 的隐藏状态依赖于 $\\mathbf{x}$： 使用 $\\mathbf{x}$（直接或经过转换）作为 RNN 的初始隐藏状态（对于 LSTM 也作为初始 cell 状态） 使用 $\\mathbf{x}$（直接或转换后）作为第一个时间步的输入 使用 $\\mathbf{x}$（直接或转换后）作为每个时间步的输入（除了已经生成的序列元素之外） 最常用的两种解决方案，例如，以下图像字幕模型使用图像的特征向量作为第一个 LSTM 输入： Vec2seq 模型的训练同样类似于无条件语言模型的训练： 主流策略是 教师强制：训练数据集的序列用作 RNN 输入，预测的续接概率仅用于计算损失（负对数似然）。 与无条件情况一样，教师强制会导致 暴露偏差（训练和推理设置之间的不健康差距），因此也使用诸如计划采样等替代训练策略。 基于 RNN 的 Seq2seq通过将 RNN Seq2vec 与 RNN Vec2seq 模块结合，我们可以构建一个 Seq2seq 模型，该模型通过首先将输入编码为固定大小的向量表示，然后将该向量解码为另一个序列，从而将可变长度的输入序列转换为另一个未对齐（unaligned）的序列。组合模型的概率结构如下： 历史上，基于 RNN 的 Seq2seq 模型是 RNN（更具体地说，是 LSTM 变体）最成功的应用之一。应用包括： 机器翻译（LSTM Seq2seq 模型是第一个与传统短语翻译解决方案竞争并后来优于它们的神经机器翻译模型） 摘要生成 问答系统 对话系统 在架构上，这些模型通常是： 基于嵌入的 在编码器和解码器中使用多个 LSTM 层 使用编码器的（最后或聚合的）隐藏状态和 cell 状态初始化解码器的隐藏状态和 cell 状态 像往常一样，通过教师强制和负对数似然损失进行训练 虽然解码器不能包含反向 RNN（显而易见的原因），但编码器通常包含双向 RNN 层。 这个模型展示了如何将一个输入序列翻译成另一个语言的输出序列。编码器将输入序列编码成一个固定长度的向量，解码器则根据这个向量生成目标语言的序列。该模型通常使用注意力机制来提高翻译质量。 注意力机制在基本的 RNN Seq2seq 模型中，如我们所见，解码器只能以编码器生成的固定大小向量表示形式访问编码的输入序列。 显著的是，这个固定大小的“摘要”并不依赖于解码器在解码过程中的位置，尽管我们知道对于典型的 Seq2seq 任务，例如翻译，输入的不同部分在不同的解码阶段是相关的。 即使固定大小的向量是通过对整个编码器隐藏状态序列进行池化生成的，解码器的上下文对池化没有影响。 注意力机制通过在每个解码时间步提供对编码器隐藏状态的动态池化版本的访问来解决这个问题，基于编码器的上下文，即 $h_{t-1}^d$ 隐藏状态： 具体来说，注意力机制基于 $h^d_{t-1}$ 解码器上下文使用 $s(\\cdot, \\cdot)$ 评分函数对 $\\mathbf{h}^e=\\langle h_1^e\\dots,h_n^e \\rangle$ 编码器隐藏状态进行评分，并使用得分的 softmax 产生加权和： $$\\mathbf{s}(\\mathbf{h}^e, h_{t-1}^d ) =\\langle s({h}^e_1, h_{t-1}^d),\\dots, s({h}^e_n, h_{t-1}^d) \\rangle$$ $$\\mathcal A(\\mathbf{h}^e, h_{t-1}^d) = \\mathop{\\mathrm{softmax}}(\\mathbf{s}(\\mathbf{h}^e, h_{t-1}^d )) \\cdot \\mathbf{h}^e$$ 注意力机制：评分函数根据评分函数的类型，注意力机制主要有两种类型： 加性 或 MLP 或 Bahdanau 注意力：评分通过一个简单的具有一个隐藏层的前馈网络计算： $$s_{add}(\\mathbf{a}, \\mathbf{b}) = \\mathbf{v^\\intercal}\\tanh(\\mathbf{W_1\\mathbf{a} + \\mathbf{W_2} \\mathbf{b}})$$ 其中 $\\mathbf{v}$、$\\mathbf{W}_1$ 和 $\\mathbf{W}_2$ 是学习到的参数。 乘性 或 Luong 注意力：评分计算为 $$s_{mult}(\\mathbf{a}, \\mathbf{b}) = \\mathbf{a}^{\\intercal} \\mathbf{W} \\mathbf{b}$$ 其中 $\\mathbf{W}$ 同样是学习到的参数。 点积注意力Dot product 评分是一种重要的、简单的乘性评分变体，其中 $\\mathbf{W}$ 是单位矩阵，即， $$s_{dot}(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\sqrt d}$$ 其中 $d$ 是 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的维度，除以 $\\sqrt d$ 确保如果 $\\mathbf{a}$ 和 $\\mathbf{b}$ 输入具有 0 均值和 1 方差，则得分也具有 0 均值和 1 方差。 注意力机制带来的性能提升将注意力机制添加到 RNN Seq2seq 架构通常会带来显著的性能提升，在翻译任务中困惑度降低了 11%，BLEU 分数提高了 20%。 因此，最先进的 RNN Seq2seq 模型几乎总是包含某种类型的注意力机制。 注意力权重可视化显示了它们如何反映对解码步骤的相关性： 前言：卷积神经网络（CNNs）尽管我们的讨论集中在 RNN 上，但卷积网络在许多 NLP 任务中也相当有竞争力。它们使用一维卷积： …以及一维（通常是最大或平均）池化层。事实上，表现出色的 fastText 分类模型使用了没有卷积的池化：","link":"/AI/NLP/NLP-Seq2Seq/"},{"title":"NLP-StaticNeuralEmbeddings","text":"静态嵌入式神经网络 词向量和神经网络LSI 和 LSA 的成功表明，基于分布的词向量表示对于 NLP 任务非常有用。在神经网络 NLP 模型中，连续的、密集的词表示尤其重要，因为它们 可以用作信息丰富且经济的表示，而不是简单地对词进行独热编码 可以帮助减少模型参数的数量 可以通过神经网络从文本语料库中以自监督的方式学习 一个由神经网络学习到的词向量的最早实例之一可以在语言模型中找到： $C$ 是一个嵌入层，将词汇索引映射到实数向量： $$C: [0, |V|-1] \\rightarrow \\mathbb R^d$$ （静态）词嵌入的维度通常在 50 到 600 之间。 从技术上讲，嵌入层可以通过多种方式实现，例如，作为一个以独热编码词索引为输入的密集层（在这种情况下，词向量表示为层的权重矩阵），或者作为一个表示为数组的查找表等。 关于嵌入层的重要经验教训： 嵌入是静态的：相同类型的标记在不同上下文中具有相同的嵌入 使用端到端训练的词嵌入层的模型比传统的 n-gram 语言模型表现更好 使用词共现频率矩阵的前几个主成分作为词特征向量，而不是训练的嵌入，没有同样的性能优势 使用神经网络学习词嵌入是一种扩展训练语料库的可行方法 Word2vec区别特征Word2vec，也是一个神经网络家族，从语料库中学习有用的分布式词表示，但具有几个新颖的特征： 它是一个专用架构：表示学习 （representation learning）是其唯一目标 它基于一种新的基于语料库的自监督预测任务 架构被故意保持非常简单，以便能够在具有大词汇量的巨大语料库上进行训练 SkipgramsWord2vec 基于 skipgrams，它是 $n$-grams 的推广：虽然 $n$-gram 是文本的连续、长度为 $n$ 的子序列，但 skipgrams 可以包含一定数量的“jumps”：如果基本序列是 $\\langle w_1, \\dots ,w_N \\rangle$，那么具有最多 $k$ 跳距的 $n$ 长度 skipgrams 集合是 $${\\langle w_{i_1} ,\\dots ,w_{i_n}\\rangle | i_1&lt;\\dots&lt;i_n\\in[1, N],i_n - i_1 \\leq n -1 + k }$$ 可以有额外的限制，例如对单个跳跃的数量和长度的限制。 Word2vec 任务Word2vec 任务具体基于长度为 $2c$ 的 skipgrams，在中心有一个单词跳跃。有两种任务变体及其相关的模型架构： CBOW: Continuous Bag of Words 预测 skipgram 中心的缺失词 SkipGram: 给定 缺失/跳过 的词，预测 skipgram 的元素。与 CBOW 任务不同，每个 skipgram 对应一个分类示例，SkipGram 任务为每个 skipgram 生成多个 $\\langle$ 中心词，skipgram 中的词 $\\rangle$ 示例 skipgram 任务的简单示例： 架构 虽然 SkipGram（右）只是将 $E(\\cdot)$ 嵌入映射应用于其一个词输入，CBOW（左）嵌入输入 skipgram 中的所有词并计算它们的和。 在将输入投影到词嵌入空间后，这两种架构都仅使用一个带权重矩阵 $W \\in \\mathbb R^{|V|\\times d}$ 的线性投影和一个最终的 softmax 层来生成词汇表中所有词的预测概率： $$CBOW(\\langle w_{t-c},\\dots ,w_{t+c} \\rangle) = \\mathop{\\mathrm{softmax}}(W\\sum_{i}E(w_i))$$ $$SkipGram(w_t) = \\mathop{\\mathrm{softmax}}(W_{}E(w_t))$$ 这两种模型都使用标准的负对数似然损失和 SGD 进行训练，但在示例采样方面有一些有趣的差异。 值得注意的是，投影矩阵 $W \\in \\mathbb R^{|V|\\times d}$ 也可以看作是词汇表在相同 $R^d$ 空间中的 $E’(\\cdot)$ 嵌入。使用这种表示法，两个模型对于特定单词 $w_j$ 的 logits（线性输出）可以简单地写成： $$CBOW_{linear}[\\langle w_{t-c}, \\dots ,w_{t+c} \\rangle](w_j) = \\sum_{i}E(w_i) \\cdot E'(w_j),$$ $$SkipGram_{linear}[w_t](w_j) = E(w_t) \\cdot E'(w_j)$$ 如这种表示法所示，最小化负对数似然训练目标是一种增加输入嵌入和正确预测嵌入的点积的方法。 由于这种表示法所显示的对称性，可以选择绑定两层的权重，使得对所有 $w\\in V$ 都有 $E(w) = E’(w)$。 尽管这种方法经常被采用，但通常也会保持它们的不同，并且仅使用输入嵌入 $E(\\cdot)$ 的向量作为最终结果，或者将它们结合起来，例如取它们的平均值。 数据点生成和采样对于 CBOW 变体，我们只需将 $c$ 半径的上下文窗口滑动通过语料库，并在每一步生成一个 $$\\langle \\langle w_{t-c}, \\dots ,w_{t-1}, w_{t+1}, \\dots ,w_{t+c} \\rangle, w_t \\rangle$$ $\\langle$ 输入，正确输出 $\\rangle$ 数据点。 对于 SkipGram，过程更为复杂，因为在每一步中，实际使用的上下文窗口半径 $r$ 是从 $[1, c]$ 区间内随机选择的，并且为每个 $w_i\\in \\langle w_{t-r}, \\dots ,w_{t-1}, w_{t+1}, \\dots ,w_{t+r}\\rangle$单词生成一个 $\\langle w_t, w_i\\rangle$ 数据点。其效果是离目标词越近的词被采样的概率越高。 避免 full softmax由于对一个 $|V|$ 长度的向量计算全 softmax 对于大 $V$ 来说是昂贵的，Word2vec 实现通常使用更便宜的输出层替代方案。 一种解决方案是 hierarchical softmax，它基于一个二叉树，其叶子是词汇表中的单词。网络的线性输出对应于内部节点，分配给一个单词 $w$ 的概率可以通过仅计算路径上 $o$ 输出的 $\\sigma(o)$ 值来计算。使用平衡树，这个技巧将训练期间 softmax 计算的复杂度从 $\\mathcal O(|V|)$ 降低到 $\\mathcal O({\\log |V|})$，并且通过巧妙的树结构可以进一步减少。 Hierarchical softmax 说明：如果路径上的线性输出是 $o(w_2, 1), o(w_2, 2), o(w_2, 3)$，那么分配给 $w_2$ 的概率可以计算为 $(1-\\sigma(o(w_2,1)))(1-\\sigma(o(w_2,2)))\\sigma(o(w_2,3))= \\sigma(-o(w_2,1))\\sigma(-o(w_2,2))\\sigma(o(w_2,3))$。 负采样另一种替代方案是 Negative sampling。这涉及将 SkipGram 任务重新表述为一个二元分类问题。 我们将语料库中的早期 SkipGram $\\langle$ 中心词，背景词 $\\rangle$ 数据点视为正例 并且通过从代表整个语料库的噪声分布中采样，为每个中心词生成一定数量的负例“假背景词” 负采样技巧使得简化网络架构成为可能，达到 $$SGNS(w_{t}, w_{c}) = \\sigma(E_t(w_t)\\cdot E_c(w_c))$$ 其中 $E_t(\\cdot)$ 是目标（中心）词嵌入，而 $E_c(\\cdot)$ 是背景词嵌入。对于从 $P_n$ 噪声分布中采样的 $k$ 个负样本，每个真实 $\\langle w_t, w_c\\rangle$ 数据点的负对数似然损失将是 $$- [ \\log SGNS(w_{t}, w_{c}) + \\sum_{\\substack{i=1 \\ w_i \\sim P_n}}^k \\log(1 - SGNS(w_{t}, {w_i}))]$$ Word2vec 作为矩阵分解在 Word2Vec 成功之后，许多研究调查了它与基于计数的矩阵分解方法的关系，结果发现它们密切相关：SGNS 目标等价于分解基于词共现的 $M$ 矩阵，其元素为 $$m_{ij} = \\max(0, PMI(w_i, w_j )- \\log k)$$ 其中 $PMI(w_i,w_j)$ 是 $w_i$ 和 $w_j$ 的 $\\log\\left(\\frac{P(w_i, w_j)}{P(w_i)P(w_j)}\\right)$ 点互信息，$k$ 是负样本的数量。 Pointwise Mutual InformationPMI 衡量单词在彼此上下文中出现的频率与它们独立出现的频率相比的差异。上下界由 $w_i$ 和 $w_j$ 从不 ($P(w_i, w_j) = 0$) 或总是 ($P(w_i, w_j) = P(w_i)$ 或 $P(w_i, w_j) = P(w_j)$) 共现的情况提供： $$-\\infty \\leq PMI(w_i, w_j) \\leq \\min(-\\log(p(w_i)), -\\log(p(w_j)))$$ PMI 公式中的 $\\frac{P(w_i, w_j)}{P(w_i)P(w_j)}$ 比例可以基于目标词-上下文词共现计数估计为 $$\\frac{C(w_i, w_j)C(\\mathrm{\\langle target~word, context~word\\rangle~pairs~in~corpus})}{C(w_i)C(w_j)}$$ 在一个大型维基百科片段中，PMI 分数最高和最低的三组二元组： 单词 1 单词 2 PMI puerto rico 10.03 hong kong 9.72 los angeles 9.56 $\\cdots$ $\\cdots$ $\\cdots$ to and -3.08 to in -3.12 of and -3.70 GloVeGloVe [Global Vectors] 是另一种从非常大的语料库中学习静态词嵌入的算法。它不是一种神经方法，但在这里讨论是因为它在 Word2vec 之后（一年）发表，作为对其的反应，并且是其最重要的替代方案之一。 与 LSA 方法类似，GloVe 明确基于固定大小上下文窗口中词共现的矩阵的低秩分解，但矩阵元素实际上是词共现的对数。 关注共现的对数是基于以下观察的动机：共现概率的比率在语义上非常有信息量： 该表显示了比率在区分与词对冰、蒸汽相关的词（即固体和气体）与噪声词方面做得很好。 直接分解共现对数概率矩阵需要对于任何 $w_i$, $w_j$ 词对满足 $$ E_w(w_i)\\cdot E_c(w_j)\\approx \\log (P(w_j~|~ w_i)) \\approx \\log (C(w_i, w_j)) - \\log (C(w_i)) $$ 其中 $E_w(\\cdot)$ 词嵌入和 $E_c(\\cdot)$ 上下文嵌入满足这个要求，$\\log(P(w_k \\space | \\space w_i)/P(w_k \\space | \\space w_j))$ 对数概率比可以简单地表示为 $(E_w(w_i) - E_w(w_j))\\cdot E_c(w_k)$，即语义上信息丰富的共现关系对应于嵌入之间的简单几何关系。 GloVe 不尝试最小化 $E_w(w_i) \\cdot E_c(w_j) + \\log (C(w_i)) - \\log (C(w_i, w_j))$ 的差异对于 $w_1,w_2\\in V$，而是最小化密切相关的 $$\\sum\\limits_{i, j=1}^{|V|} f(C(w_i,w_j)) (E_w(w_i)\\cdot E_c({w}_j) + b_w(w_i) + {b_c}(w_j) - \\text{log} C(w_i, w_j))^2$$ 目标。差异在于 $f(\\cdot)$ 加权函数对稀有共现进行降权， 为每个词学习的 $b_w$ 和 $b_c$ 偏差，提供了 $\\log(C(w_i))$ 的对称替代。 GloVe 训练与通过滑动上下文窗口训练的 Word2vec 不同，GloVe 的训练分为两个步骤： 组装全局共现计数矩阵 通过随机梯度下降（SGD）优化上述目标中的 $E_w, E_c, b_w, b_c$ 参数，随机采样共现矩阵的元素 与 Word2vec 相比，GloVe 由于处理共现矩阵（尽管是稀疏的）可能需要更大的内存，但这可以通过在之后对非零矩阵元素进行优化来补偿，其数量通常在语料库长度上是次线性的。 评估评估类型如何衡量词嵌入的质量？作为学习到的表示，词向量可以通过以下方式进行评估： 内在地，intrinsically 根据它们与人类对词语语义和形态特征的判断的对应程度 外在地，extrinsically 根据它们在下游 NLP 任务解决方案中的有用程度 从内在的角度来看，使用适当调整参数并在大型高质量语料库上训练的 Word2vec 可以生成几何特性与人类相似性判断惊人接近的嵌入。 内在评估评估词嵌入质量的两种最常用的内在方法是测试它们在两个词汇语义任务中与人类判断的相关性： 词相似度 Word similarity 类比 Analogy 相似度相似的词应该有相似的向量。 语义：dog - hound 语法：dogs - pears 两个词的相似度通过它们表示的余弦相似度来衡量：$\\frac{E(w_1)\\cdot E(w_2)}{|E(w_1)|\\times |E(w_2)|}$。 注意：归一化很重要，因为向量的长度大致与词频的对数成正比。 相似度可以通过使用降维技术（例如 t-SNE 或 UMAP）进行可视化，例如： 类比Analogy 任务测试词之间的 关系，例如 $king:queen$ 和 $man:woman$，它们在向量空间中的几何关系是否相似。 这些关系对应于向量的差异，即 $E(king)-E(queen)\\approx E(man)-E(woman)$ 或者，以稍微不同的形式，嵌入最接近 $E(king)-E(queen) + E(woman)$ 的词是否是 $man$。 语义和句法类比的示例： 数据集也有一些专门用于内在评估的数据集，例如： WordSim-353 数据集包含 353 对英语单词及其语义相似度分数，范围从 0.0 到 10.0。（注意：原始数据集混淆了相似性和相关性；链接版本大多修正了这一点。） SimLex-999 取代了 WordSim-353，包含 999 对单词及其相似度分数，使用相同的评分尺度。 BATS（The Bigger Analogy Test Set）包含 98000 个类比问题，用于测试单词类比与向量偏移之间的对应关系。 外在评估Extrinsic 评估可以使用任何 NLP 任务进行，但通常使用标准的序列标注任务，例如命名实体识别。 可以通过在嵌入式架构中切换不同的嵌入来评估它们，同时保持其他部分不变。 在使用嵌入时，有一个重要的区别是直接使用嵌入（“冻结”）而不改变它们，还是对它们进行 微调，即在任务数据集上与其他参数一起训练它们。 评估结果在某些共现矩阵上，Word2vec 变体、GloVe 和传统 SVD 之间的性能差异不大。最重要的是，他们发现 超参数调优对性能的影响大于算法的选择 SGNS 被证明是一个非常强的基线，在任何情况下都没有“显著表现不佳” 两个学习到的嵌入（目标和上下文）的和通常比单独使用其中一个表现显著更好 利用内部词结构Utilizing internal word structure 黑箱问题我们讨论的词嵌入完全基于分布，词的内部结构不起作用。因此， 词汇表外的词，和 在训练语料库中罕见的词 没有足够的嵌入，即使它们的 内部形态/字符结构（internalmorphological/character structure） 可以提供关于其语义和句法属性的丰富信息。 除了使用需要形态分析器的词素（morpheme）嵌入外，还出现了一些自监督解决方案。 fastTextfastText 算法基于 SGNS，但将 $n$-grams ($3\\leq n \\leq 6$) 添加到词汇表中，并将目标词建模为其所有组成部分嵌入的总和。 例如，对于单词 where 和 $n=3$，其组成部分是 &lt;wh、whe、her、ere、re&gt;，加上整个单词 &lt;where&gt;。 SGNS 架构被修改为 $$\\sigma(\\sum_{w\\in G(w_t)}E_t(w)\\cdot E_c(w_c))$$ 其中 $G(w_t)$ 是 $w_t$ 的所有组成部分的集合。 在相似性任务中，fastText 向量通常比原始 Word2vec 表现更好，尤其是在形态丰富的语言中。 一个额外的重要优势是，使用 fastText 可以通过将其组成 $n$-grams 的嵌入相加来生成未见词的有信息嵌入。 子词嵌入解决黑箱问题的一个更激进的解决方案是切换到子词分词（例如，使用 BPE）并使用已建立的算法仅为词汇表中的子词生成嵌入。 例如，PBEmb 使用 GloVe 为 BPE 分词生成的子词生成嵌入。类似于 fastText，可以通过组合组成子词的嵌入（例如，取平均值）来生成 OOV 词的嵌入。虽然表现相似，但这种类型的解决方案所需的词汇表明显小于 fastText。","link":"/AI/NLP/NLP-StaticNeuralEmbeddings/"},{"title":"NLP-TextImageModels","text":"条件文本到图像模型 介绍条件文本到图像生成条件文本到图像生成是一项任务，其中模型被训练为根据给定的文本描述生成图像。该任务可以通过以下方法之一来制定： 序列到序列 (seq2seq) 生成（与自回归 autoregression 的联系） 生成对抗网络 (GAN) 方法 自回归方法 扩散方法 序列到序列生成2015年，DeepMind发布了DRAW，这是一个顺序的、无条件的图像生成模型。此类模型用于生成MNIST数据集等图像。 同年晚些时候，AlignDRAW发布了，这是DRAW的条件版本。它能够根据给定的文本描述生成图像。 AlignDRAWAlignDRAW首先通过双向LSTM (BiLSTM)编码器将文本描述编码为潜在向量。然后解码器是一组“绘图”操作，尝试根据潜在向量生成图像。 训练是变分下界 (ELBO) 优化（最大化）。 给定$x$，图像，$y$，文本描述，以及$Z$，一系列潜在向量，损失为： $\\mathcal{L} = \\sum\\limits_{Z}Q(Z|x,y)logP(x|y,Z)-D_{KL}(Q(Z|x,y)||P(Z|y))$ 这里$Q(Z|x,y)$是近似后验分布。$P(x|y,Z)$是给定文本描述和潜在向量的图像的似然。$P(Z|y)$是给定文本描述的潜在向量的先验分布。 神经分布建模$Q(Z_t|x,y,Z_{1:t-1})$ 和 $P(Z_t|Z_{1:t-1})$ 由高斯分布建模，分别基于推理和生成网络参数化。潜在变量以顺序方式相互依赖。 $P(Z_t|Z_{1:t-1}) = \\mathcal{N}\\left(\\mu(h_{t-1}^{gen}),\\sigma(h_{t-1}^{gen})\\right)$ $Q(Z_t|x,y,Z_{1:t-1}) = \\mathcal{N}\\left(\\mu(h_t^{infer}),\\sigma(h_t^{infer})\\right)$ $\\mu(h) = tanh(W_{\\mu}h)$ $\\sigma(h) = exp\\left(tanh(W_{\\sigma}h)\\right)$ 读取和写入操作读取和写入操作由不同大小、步幅和位置的固定高斯（模糊）滤波器组参数化。写入操作是滤波器组 ($F_x$, $F_y$) 和生成的 ($K$) 补丁的组合。 $write(h_t^{gen}) = F_x(h_t^{gen})K(h_t^{gen})F_y(h_t^{gen})^T$ 而读取操作是该操作的逆操作。 GAN生成对抗网络架构 生成对抗网络回顾GAN是一种生成模型，由两个网络组成：生成器和判别器。生成器尝试生成与真实数据集相似的数据，而判别器尝试区分真实数据和生成的数据点。 对抗游戏的目标如下： $ min_G max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\left[log(D(x))\\right] + \\mathbb{E}_{z\\sim p(z)}\\left[log(1-D(G(z)))\\right] $ 因此，生成器尝试最大化 $log(D(G(z)))$，而判别器尝试最大化 $log(D(x)) + log(1-D(G(z)))$。这里 $z$ 是从随机先验分布 $p(z)$ 中采样的，$x$ 是从真实数据分布 $p_{data}(x)$ 中采样的。 文本条件GAN架构提出了一种文本条件GAN架构，该架构将文本编码作为潜在向量的一部分。该架构是一个反卷积-卷积网络。 文本条件GAN训练朴素GAN判别器任务：区分真实和虚假图像。 通过文本条件，我们获得了额外的任务： 拒绝任何文本描述的虚假图像。 拒绝不匹配的文本-图像对。 后者通过在每个训练批次中提供一组不匹配的示例来实现。 $ \\mathcal{L}_{CLS} = log(D(I_{real}, T_{real})) + 0.5 log(1-D(I_{real}, T_{fake})) + 0.5 log(1-D(I_{fake}, T_{real})) $ 文本嵌入插值由于当时文本-图像数据集稀疏，作者使用了一种文本嵌入插值方法来为未见过的文本描述生成更多的训练示例。这样，输入的文本嵌入是两个文本嵌入的线性组合。一个是正确的文本嵌入，另一个是数据集中的随机文本嵌入。然后将其传递给生成器。即使判别器没有给定对的真实示例，它仍然可以学习何时拒绝生成的图像。这增强了生成器。作者建议对于 $t_1$ 和 $t_2$ 文本嵌入使用 $\\beta=0.5$： $D(G(z, t_1)) \\rightarrow D(G(z, \\beta t_1 + (1-\\beta)t_2))$ 文本条件GAN结果文本输入：灰色的鸟有一个浅灰色的头和灰色的蹼足 风格编码怀疑潜在变量应该包含文本中缺失但可以从图像（或一组图像）中推断的信息。他们称之为图像的“风格”，并提出了一种将此信息编码到潜在变量中的方法。 即他们提出了一种反转生成器的方法。$S(x)$ 通过以下目标进行训练，其中 $x$ 是图像：$\\mathcal{L}_{style}||z - S(G(z,t_1))||_2^2$ 风格迁移推理过程如下： $s \\leftarrow S(x), \\hat{x} \\leftarrow G(s, t_1)$ 风格编码结果 ControlGANControlGAN 提供了一种细粒度的多阶段生成过程，并通过额外的监督方法来实现更好的结果。 他们添加了： 词和图像特征级别的判别器 多阶段生成和判别 无条件和条件损失、感知损失、词/图像特征级别的相关损失、文本到图像的余弦损失 定制的类似注意力机制 架构 局部性 感知损失感知损失用于生成一致的图像，包括未直接由文本引导的部分。这是通过使用预训练网络（在 ImageNet 上进行分类训练）来完成的。该网络用于从生成的图像和真实图像中提取特征。损失是特征之间的 L2 距离。特征从网络的中间层提取，以获得抽象但不太低级的表示。 $\\mathcal{L}_{perceptual}^i(I, I’) = \\frac{1}{C_iH_iW_i} ||\\phi_i(I) - \\phi_i(I’)||_2^2$ 其中 $\\phi_i$ 是特征提取器，$C_i$、$H_i$ 和 $W_i$ 分别是网络第 $i$ 层的通道数、高度和宽度。 词级特征 自回归方法如果潜在先验包括文本条件，变分自编码器 (VAE) 也可用于根据文本描述创建图像。包括文本条件的一种方法是使用自回归先验模型。 这种自回归先验类似于语言建模中使用的自回归模型。不同之处在于词汇不仅是文本标记，还有使用与 VAE 相同表示的潜在图像特征。 图像编码和解码通常由 VAE 处理，而文本编码是自回归模型的一部分。 DALL-E 架构 DALL-E 训练第一个 DALL-E 模型是基于变压器的自回归模型，使用 dVAE 进行编码，并使用稀疏变压器进行自回归潜在条件。 训练包括两个阶段： 首先，带有中间瓶颈块的 ResNet 风格 VAE 使用 ELBO 损失进行训练。潜在特征使用 argmax（贪婪采样）进行量化。此阶段的目标是图像重建。这一阶段学习了一个约 8k 的视觉代码本（因为 dVAE 利用 argmax 进行量化），该代码本稍后在自回归模型中使用。 DALL-E dVAE 重建 DALL-E 自回归先验在第二阶段，dVAE 权重被固定，解码器风格的潜在变压器被训练以学习条件先验。模型使用交叉熵损失进行训练，其中图像标记的权重是文本标记的 7 倍。 BPE 标记化的文本与特殊的填充标记（如果需要）和特定的 [START OF IMAGE] 标记连接在一起。然后将图像标记序列化并添加到末尾。文本具有 1D 位置编码，而图像标记具有单独的列和行位置编码。模型使用稀疏注意力来预测文本和图像的下一个标记。 DALL-E 注意力机制文本标记具有因果注意力，而图像标记具有单独的行和列注意力，以及最后一层的 $3x3$ 局部注意力。列注意力被转置为行以减少计算量。行和列注意力以 (r, c, r, r) 的方式交替进行。 DALL-E 生成的图像 扩散方法扩散模型扩散模型是依赖于马尔可夫过程生成图像的高效模型。扩散由迭代的加噪和去噪过程定义。加噪是一个高斯噪声注入过程。维度不变。 前向（编码）和反向（解码）扩散可以看作是 VAE 的等价物。 DDPM去噪扩散概率模型 前向过程 $x_0$ 是起始图像，而 $x_T$ 是扩散过程的最终步骤 $t\\in[0,…, T]$。 每一步 $q(x_t|x_{t-1})=\\mathcal{N}(x_t;\\sqrt{1-\\beta_t}x_{t-1}, \\beta_tI)$ 马尔可夫转移分布添加由固定 $\\beta_t$ 调节的噪声。 反向过程 $x_T$ 从最终的 $p(x_T)=\\mathcal{N}(x_T;0,I)$ 分布中采样。 每个反向步骤学习一个 $p_\\theta(x_{t-1}|x_{t})=\\mathcal{N}(x_{t-1};\\mu_\\theta, \\Sigma_\\theta)$ 高斯分布作为由 $\\theta$ 参数化的转移。 两个马尔可夫过程在以下方程中建模： $q(x_{1:T}|x_0)=\\prod\\limits_{t=1}^Tq(x_t|x_{t-1})$ $p_\\theta(x_{0:T})=p(x_T)\\prod\\limits_{t=1}^Tp_\\theta(x_{t-1}|x_t)$ 给定 $\\alpha_t = 1-\\beta_t$ 和 $\\bar\\alpha_t=\\prod\\limits_{s=1}^t\\alpha_s$，可以直接计算 $q(x_t|x_0)=\\mathcal{N}(x_t;\\sqrt{\\bar\\alpha_t}x_0,(1-\\bar\\alpha_t)I)$。这加速了训练，因为不需要递归。 学习反向过程我们必须再次优化（作者取负并最小化）变分下界 $L = \\sum\\limits_{t=0}^TL_t$（直接应用计算的项）： $ L_T = \\mathbb{E}_q(D_{KL}(q(x_T|x_0)||p_\\theta(x_T))) $ 这确保了第一个反向步骤接近最后一个前向步骤。 $ L_{1 \\ldots t-1} = \\mathbb{E}_q(D_{KL}(q(x_{t-1}|x_t,x_0)||p_\\theta(x_{t-1}|x_t))) $ 这里 $ q(x_{t-1}|x_t,x_0) $ 是后验（贝叶斯后）分布，这是每一步的最优反向分布。 $L_0 = \\mathbb{E}q(-logp\\theta(x_0|x_1))$ 数据对潜在链末端的对数似然。 简化一切有关训练目标推导的更多详细信息，请参见附录A。 如果我们固定两个过程的标准差并在每一步将它们绑定在一起（在每个高斯中使用 $\\beta_tI$），则 $L_{t-1}$ 项回归到两个均值的距离。 $L_{1 \\ldots t-1} = \\mathbb{E}q\\left(\\frac{1}{2\\sigma_t^2}||\\tilde\\mu(x_t,x_0)-\\mu\\theta(x_t, t)||^2\\right) + C$ 这里 $\\tilde\\mu(x_t,x_0)$ 是前向后验分布的均值（通过贝叶斯反转），而 $\\mu_\\theta(x_t, t)$ 是可学习的反向分布的均值。$C$ 是一个常数。 将重参数化技巧应用于 $q(x_t|x_0)=\\mathcal{N}(x_t;\\sqrt{\\bar\\alpha_t}x_0,(1-\\bar\\alpha_t)I)$ 我们得到： $x_t = \\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon$ 其中 $\\epsilon\\sim\\mathcal{N}(0,I)$ 重新排列方程得到：$x_0 = \\frac{x_t-\\sqrt{1-\\bar\\alpha_t}\\epsilon}{\\sqrt{\\bar\\alpha_t}}$ 贝叶斯后：$\\tilde\\mu(x_t,x_0)=\\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1-\\bar\\alpha_t}x_t+\\frac{\\sqrt{\\alpha_t}(1-\\alpha_{t-1})}{1-\\bar\\alpha_t}x_0$ 替换 $x_0$ 我们得到：$\\tilde\\mu(x_t,\\epsilon)=\\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon\\right)$ 噪声预测最后我们得出结论，为了最小化 KL 散度（通过近似 $\\tilde\\mu(x_t,x_0)$ 和 $\\mu_\\theta(x_t,t)$ 来最小化），我们必须预测 $\\tilde\\mu(x_t,x_0)$ 的未知部分，即 $\\epsilon$，因为 $x_t$，$\\alpha$ 和 $\\beta$ 是已知的。为此，我们创建了一个 $\\epsilon$ 的近似器，即 $\\epsilon_\\theta(x_t, t)$，因此 $\\mu_\\theta(x_t, \\epsilon_\\theta(x_t, t))=\\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta\\right)$。这可以在推理过程中使用。 如果我们忽略 $C$，$L_0$ 和 $L_T$，我们得到以下优化函数： $ L_{simp}(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} ||\\epsilon - \\epsilon_\\theta(x_t, t) ||^2 = \\mathbb{E}_{t, x_0, \\epsilon} ||\\epsilon - \\epsilon_\\theta\\left(\\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t\\right) ||^2 $ ，在训练过程中我们使用第二种形式，因为 $x_0$ 和 $t$ 是输入。 训练和推理 总结 前向过程是一个马尔可夫过程，向图像添加噪声 我们可以直接计算前向过程的任意深度 $q(x_t|x_0)$ 通过取前向过程的贝叶斯后验，我们有了反向过程的标签 $q(x_{t-1}|x_t,x_0)$ 在推理过程中 $x_0$ 是未知的，因此我们需要一个不依赖于 $x_0$ 的反向后验近似器。这是 $p_\\theta(x_{t-1}|x_t)$ 优化目标是最小化（训练期间已知的）后验和近似后验之间的 KL 散度 $D_{KL}(q(x_{t-1}|x_t,x_0)||p_\\theta(x_{t-1}|x_t))$ 我们固定方差，因此只需通过 $\\mu_\\theta$ 近似均值 使用重参数化技巧，我们可以将不确定性分解为标准高斯噪声项 $\\epsilon$，在 $x_0 \\rightarrow x_t$ 转换过程中使用 这样 $\\mu_\\theta$ 的唯一非确定性部分是我们必须预测的 $\\epsilon_\\theta$。因此训练目标变为 $||\\epsilon - \\epsilon_\\theta(x_t, t) ||^2$。其中 $\\epsilon$ 是在前向过程中添加到图像的噪声项（训练期间可用） 特性DDPM 使用小步长，累积约 500-1000 步生成。$\\beta$ 的时间调度是线性的。作者使用相对较小的 $256\\times256$ 尺寸的 U-Net 架构进行 $\\epsilon_\\theta$ 预测。 潜在插值 DDIM去噪扩散隐式模型DDPM 报告说，采样一批 $128$ 张 $256\\times256$ 尺寸的图像大约需要 $300$ 秒。这是由于大量的小去噪步骤。 DDIM 通过放松马尔可夫约束并在前向和反向过程中制定隐式步骤来解决这个问题，从而使用更少的去噪步骤。 重新定义为非马尔可夫过程在 DDPM 中，我们可以直接计算每一步的前向分布 $q(x_t|x_0)$。利用这一特性，我们可以在任何给定步骤 $t$ 直接计算 $L$，因为 DDPM 损失仅依赖于预测误差 $\\epsilon_\\theta(x_0, t)$。 DDIM 通过使用一个正系数向量 $\\gamma$ 来权衡每一步的损失（由于 $t$ 仅影响添加的噪声 $\\epsilon$，我们用 $\\epsilon^t$ 表示 $t$ 依赖性）： $ L_{\\gamma}(\\epsilon_\\theta) = \\mathbb{E}_{x_0, \\epsilon^t, t} \\sum\\limits_{t=1}^T\\gamma_t||\\epsilon^t - \\epsilon_\\theta^t(x_0, \\epsilon^t)||^2 $ 通过将所有步骤的 $\\gamma$ 固定为 1，我们得到原始的 DDPM 损失。 如果我们选择一组 $Q$ 前向分布，使它们可以边缘化为 DDPM 使用的相同 $q(x_t|x_0)$ 分布，我们得到相同的训练目标，因此可以使用相同的 DDPM 训练模型进行前向和反向过程，即使这些过程由于我们选择的 $Q$ 分布而是非马尔可夫的。 对于给定的正 $\\sigma$ 标准差向量，存在这样的非马尔可夫过程。首先可以通过生成过程定义它。 $q_\\sigma(x_{1:T}|x_0) = q_\\sigma(x_T|x_0)\\prod\\limits_{t=2}^Tq_\\sigma(x_{t-1}|x_{t},x_0)$ 通过取 $q_\\sigma(x_{t-1}|x_{t},x_0)$ 的后验（贝叶斯），我们得到 $q_\\sigma(x_{t}|x_{t-1},x_0)$。通过对 $x_{t-1}$ 进行边缘化，我们得到 $q_\\sigma(x_{t}|x_{0})$，因此我们可以使用（$\\gamma$）广义 DDPM 训练方案。 我们也可以重新定义反向过程 $p_\\theta(x_{t-1}|x_t)$，它应该近似 $q_\\sigma(x_{t-1}|x_{t},x_0)$。在生成过程中 $x_0$ 是未知的，但如果我们知道所有的误差 $\\epsilon_t$，我们可以近似它。我们也有一个近似器 $\\epsilon_\\theta^t$。 让 $f_\\theta(x_t)$ 通过从 $x_t$ 中减去适当缩放的误差近似 $\\epsilon_\\theta^t$ 来近似这个 $x_0$ 原始输入。 反向过程是 $p_\\theta(x_{t-1}|x_t) = q_\\sigma(x_{t-1}|x_t, f_\\theta(x_t))$ 对于 $t&gt;1$ 和 $\\mathcal{N}(f_\\theta(x_1), \\sigma_1^2I)$ 对于 $t=1$。 优化目标可以表述为 ELBO，其中 $\\simeq$ 用于描述等于一个不依赖于 $\\theta$ 的常数，对于 $t&gt;1$： $ \\mathbb{E}_{x_{0:T}}(\\sum\\limits_{t=2}^TD_{KL}(q_\\sigma(x_{t-1}|x_{t},x_0)||p_\\theta(x_{t-1}|x_t)) - logp_\\theta(x_1|x_0)) $ $ \\simeq \\mathbb{E}_{x_0, x_t}(\\sum\\limits_{t=2}^TD_{KL}(q_\\sigma(x_{t-1}|x_{t},x_0)||q_\\sigma(x_{t-1}|x_{t},f_\\theta(x_t)))) $ $ \\simeq \\mathbb{E}_{x_0, x_t}(\\sum\\limits_{t=2}^T||x_0 - f_\\theta(x_t)||^2) \\simeq \\mathbb{E}_{x_0, \\epsilon, x_t}(\\sum\\limits_{t=2}^T||\\epsilon - \\epsilon_\\theta^t(x_0, \\epsilon)||^2)$ $=L_{\\gamma}(\\epsilon_\\theta)+C $ 鉴于此，如果我们选择正确的 $\\gamma$ 和 $C$ 项，我们将得到原始的 DDPM 损失。 反向过程如果我们定义 $p_\\theta(x_{t-1}|x_t) = q_\\sigma(x_{t-1}|x_t, f_\\theta(x_t))$ 并对其使用重参数化技巧（不包含详细信息），我们得到以下内容： $x_{t-1} = \\sqrt{\\alpha_{t-1}}f_\\theta(x_t)+\\sqrt{1-\\bar\\alpha_{t-1}-\\sigma_t^2}\\epsilon_\\theta^t + \\sqrt{\\sigma_t}\\epsilon$ 其中第一项是缩放的预测 $x_0$ 输入（也包括 $\\epsilon_\\theta^t$ 误差项），第二项是指向 $x_t$ 的“方向”，第三项是 $x_{t-1}$ 和 $x_t$ 之间的独立噪声差异。 如果我们为所有 $t$ 选择 $\\sigma_t = \\sqrt{(1-\\bar\\alpha_{t-1})/(1-\\bar\\alpha_t)}\\sqrt{1-\\bar\\alpha_t/\\bar\\alpha_{t-1}}$，则前向过程变为马尔可夫过程，反向过程变为 DDPM。 如果 $\\sigma_t = 0$，则前向过程在已知 $x_0$ 和 $x_{t-1}$ 的情况下变为确定性。反向过程将不包含独立噪声项，因此可以使用固定程序进行预测。 我们还可以通过超参数 $\\eta$ 在两种版本之间进行插值： $\\sigma_t = \\eta \\sqrt{(1-\\bar\\alpha_{t-1})/(1-\\bar\\alpha_t)}\\sqrt{1-\\bar\\alpha_t/\\bar\\alpha_{t-1}}$ 加速生成 由于我们现在可以使用固定的反向过程（除了我们必须从 $x_t$ 预测 $x_0$），我们可以直接从任何一组 $x_t$ 中采样，包括跳过步骤或子采样步骤，甚至考虑基于连续时间的采样。 只要 $q_\\sigma(x_{\\tau_i}|x_{\\tau_{i-1}},x_0)$ 是已知的，加速生成适用于一组步骤 $\\tau_i \\in [0, T]$，因为反向过程可以通过预测 $\\epsilon_\\theta^{\\tau_i}$ 来近似 $q_\\sigma(x_{\\tau_{i-1}}|x_{\\tau_i},x_0)$，这也用于 $f_\\theta(x_{\\tau_i})$。 重要的是，仅通过近似 $\\epsilon_\\theta^t$ 才能实现这种采样步骤的重新调度（至少在 DDIM $\\eta=0$ 的情况下），因为我们可以在数学上解释这些变化。 这样，采样不再与训练（前向）步骤数绑定，可以实现大约 $10-50$ 倍的加速生成，从而促进在接近实时应用中使用更大的模型。 结果 超越 DDIM通过将 DDIM 重新表述为 ODE 求解器（常微分方程），得出它等效于 ODE 求解的欧拉方法。还可以使用其他扩展的 ODE 求解器，例如 DPM++。到 2023 年底，这些是最流行的扩散采样器。在更高阶 ODE 求解器领域也有一些研究，但尚未观察到广泛使用。 还提出了超越 DDPM 和 DDIM 使用的线性 $\\beta$ 的新噪声调度方法。 DDIM 总结 DDIM 使用非马尔可夫过程进行扩散，使用跳到 $T$ 的想法，然后逐渐反转到 $t$。$q_\\sigma(x_{1:T}|x_0) = q_\\sigma(x_T|x_0)\\prod\\limits_{t=2}^Tq_\\sigma(x_{t-1}|x_{t},x_0)$ 然后反向过程可以直接使用 $q_\\sigma(x_{t-1}|x_t,x_0)$。这里 $x_0$ 仅在训练期间已知，因此在推理过程中我们必须使用预测器来近似它，而不是像在 DDPM 中那样近似完整的后验 我们定义 $f_\\theta(x_t)$ 从 $x_t$ 近似 $x_0$，并使用相同的表示技巧将问题转化为噪声 $\\epsilon$ 预测问题 证明了 DDIM 和 DDPM 的训练目标是等效的，只是包围误差预测的数学结构不同 DDIM 推理过程实现了 $x_t \\rightarrow f_\\theta(x_t) \\rightarrow x_0 \\rightarrow x_{t-1}$ 的直觉。注意 $t-1$ 预测不显式依赖于 $t$，因此我们可以跳到任何先前的步骤而不是 $t-1$ 然而，$f_\\theta(x_t)$ 预测并不完美，因此反向过程也应该采取多个步骤的细化以确保一致的质量 现代实现将时间步长处理为连续变量，因此它们使用 ODE 求解器来指导反向过程 引导扩散分类器扩散引导也可以类似于文本依赖的GAN和VAE。在这种情况下，我们的扩散模型的估计器应该受到引导信号（例如文本嵌入）的扰动。 在反向过程中，给定噪声估计器 $\\epsilon_\\theta$，我们将条件偏移加到噪声项的估计中。 $\\hat\\epsilon_\\theta(x_t,y) = \\epsilon_\\theta(x_t,y) + s\\sigma_t \\nabla_{x_t}logp_\\phi(y|x_t)$ 其中$s$是引导尺度，$p_\\phi(y|x_t)$ 是一个分类器，使用关于我们想生成的类别的对数似然的导数来引导扩散过程。 无分类器这需要扩散模型与分类器一起训练，并且在生成过程中也需要分类器梯度。为了避免这种情况，无分类器网络在无条件估计器 $\\epsilon_\\theta(x_t)$ 和条件估计器 $\\epsilon_\\theta(x_t,y)$ 上操作，通过与无条件预测的差异来实现 $\\hat\\epsilon_\\theta(x_t,y) = \\epsilon_\\theta(x_t,y) + s(\\epsilon_\\theta(x_t,y)-\\epsilon_\\theta(x_t))$ 这本质上是通过在训练期间向分类器添加$0$标签来完成的，因此无分类器估计器只是 $\\epsilon_\\theta(x_t,0)$。 CLIP引导扩散: GLIDE引入了一种方法，用CLIP点积相似度度量替换分类器。 $\\hat\\epsilon_\\theta(x_t,y) = \\epsilon_\\theta(x_t,y) + s\\sigma_t \\nabla_{x_t}(f(x_t)\\cdot g(y))$ 这里$f$是图像编码器，$g$是文本编码器。重要的是，这个CLIP版本是用噪声图像训练的，以匹配扩散模型的噪声水平。 还得出结论，无分类器引导在小众任务上似乎比CLIP引导更有效。这里文本由类似GPT的模型编码，利用最后的嵌入向量。 GLIDE结果 潜在扩散潜在扩散是指在VAE或GAN的潜在空间中进行扩散的方法。DALL-E 2和Stable Diffusion是这种方法的两个流行示例。 虽然DALL-E 2使用类似CLIP的模型作为VAE，并具有基于Transformer的扩散先验，但Stable Diffusion利用VQ-GAN生成器和U-Net风格的先验。 DALL-E 2 解码器DALL-E 2 包含一个由 CLIP 文本编码器构建的 VAE 和一个用作图像解码器的扩散模型（因此 OpenAI 也将 DALL-E 2 背后的模型命名为“unCLIP”）。该解码器以 CLIP 图像嵌入为条件，也可以选择以字幕文本嵌入为条件。它使用 GLIDE 的架构，并通过在解码器训练期间偶尔丢弃 CLIP 嵌入和字幕嵌入来包括一些无分类器的改进。训练使用锐度感知最小化。 解码器在 DDIM 过程中使用 $\\eta&gt;0$ 以允许生成图像的变化。 先验他们比较的 VAE 先验是 DALL-E（1）风格的自回归先验和扩散先验，后者被证明更优越。扩散过程也使用 Transformer 解码器来预测下一个潜在标记版本。损失不是基于 $\\epsilon$ 的，而是预测和真实潜在表示之间的 L2 损失。这被解释为扩散过程中由 $f_\\theta(x_t, t, y)$ 参数化的预测 $x_0$ 的损失。 在生成过程中，先验生成两次，选择与文本嵌入点积较高的那个。 Stable DiffusionSD 架构 VQ-GAN在 Stable Diffusion 中，为了将图像投影到潜在空间，使用 VQ-GAN 对图像进行编码。VQ-GAN 由 VQ-VAE 生成器和对抗性和感知损失的判别器组成。在 Stable Diffusion 的情况下，VQ-VAE 得到轻微的 KL 散度正则化，以生成更接近高斯分布的潜在表示。 此外，判别器后来被忽略，只使用生成器 VQ-VAE，以一种将量化与解码器合并的方式使用。使用 2D 表示的压缩因子 $4-8$ 被发现表现最佳。 SD 先验先验本身是一个卷积 U-Net 架构，每一层都有交叉注意力块。这些交叉注意力关注于编码的条件模态。这个 U-Net 执行反向扩散过程（预测 $\\epsilon_\\theta$）。 作为条件编码的模态可以是文本（transformer-decoder 或 CLIP）、图像、分割掩码等……甚至低分辨率图像也可以用来构建潜在的超分辨率模型。无分类器引导也被探索并且有益。 这是一个潜在扩散，这意味着名称 LDM（潜在扩散模型），它是 Stable Diffusion 中使用的模型的泛化。 零样本 放大 分割掩码合成 布局合成 DiT在一些最近的模型中，UNet 被一种特殊的扩散变压器 (DiT) 架构所取代，该架构使用类似 ViT 的主干，并通过条件输入来预测误差图像（在某些情况下甚至是复杂扩散用例中使用的 $\\Sigma$ 协方差）。 这样，DiT 的输出是两个预测的“图像”（如 UNet 的情况）——误差和协方差，它们通过线性层和补丁过程的逆过程从输出标记中组装而成。 作者观察到，与卷积 UNet 相比，该模型具有更好的扩展性。 条件还探索了注入条件的最佳方式。他们发现自适应层归一化是最佳解决方案，具有零缩放初始化（因此在开始时只有残差是活跃的）。这意味着条件信号通过 MLP 映射到潜在大小，MLP 发出输入缩放、输出缩放和我们应用于变压器数据流的移位值。 作者还指出，这优于上下文内条件、交叉注意力，甚至是具有非零缩放初始化的自适应层归一化。 DiT 架构 扩散模型的扩展多阶段网络多阶段网络用于提高扩散和潜在扩散模型的效率。DALL-E 2 在像素空间中使用多阶段扩散，结合基于 CLIP + 字幕的文本条件超分辨率模型。DALL-E 3 论文还提到他们在不同分辨率上使用了三阶段扩散模型。细节未披露。 最新的发展还引入了精炼器，这些精炼器经过训练以提高生成图像的细节和一致性（整体质量）。这些精炼器在高质量图像上进行训练，并在生成原始潜在图像后使用。 Imagen 在先验扩散上使用仅文本条件，然后在像素空间中进行两个文本条件超分辨率。 自回归模型也可以以多阶段方式使用。例如，Parti 由 ViT-VQ-GAN 标记器和解码器组成，用于编码和解码图像。自回归模型是一个全栈变压器，其中条件被编码并生成图像。 最近的升级，Würstchen 是一种潜在模型，使用类似于 Stable Diffusion 的 VQ-GAN 生成器（即 VQ-VAE）的编码器-解码器架构，但量化后来被放弃。先验是一个多阶段扩散模型，在高度压缩步骤上使用仅文本条件，然后将此压缩潜在先验和文本用作潜在上采样器的条件步骤，生成最终先验。 修复修复是通过用生成的部分替换原始图像的部分（无论是在像素空间还是潜在空间）来实现的。这是通过使用用户提供的掩码来完成的。在扩散过程中，在扩散过程的每一步中使用未掩盖部分的充分加噪版本。掩盖部分通过加噪的原始 $x_0 \\rightarrow x_T$ 或生成的随机初始值进行初始化。 文本反演文本反演用于扩展文本到图像模型的功能。它们在一小组图像上进行训练，这些图像被输入到预训练的文本到图像模型中。模型被冻结，除了文本编码器的嵌入层。这个嵌入层通过一小组嵌入向量（可以不止一个）进行扩展，这些嵌入向量在一小组图像的扩散损失上进行训练。这样，模型就学会了生成具有新添加的嵌入向量中编码的相同对象或风格的图像。 适配器 / LoRA-s开源扩散模型通常使用全微调或适配器（如 LoRA-s）进行微调。这需要更多的 GPU 内存、训练数据和时间来训练，但质量也更高。 如前所述，可以通过多种方式融合这些适配器或文本反演。这些 LoRA-s 可以通过取它们的加权平均值或通过在从各个 LoRA-s 提取的特征上训练融合的 LoRA 来组合。$W = \\sum\\limits_{i=1}^n w_i W_i$ $W = argmin_W \\sum\\limits_{i=1}^n ||(W_0 + \\Delta W_i) X_i - W X_i||_F^2$ 潜在一致性引入了 LDMs 的另一个加速方法，即潜在一致性模型。与在反向过程中预测 $\\epsilon_\\theta$ 不同，LCMs 直接训练 $f_\\theta$ 估计器来预测 $x_0$。作为一种自蒸馏任务，我们可以运行长生成序列的反向过程，然后使用较低阶时间步长的 $x_0$ 预测作为目标。 $ \\mathcal{L}_{LCM} = \\mathbb{E}_{x, y, w, i} [d(f_\\theta(x_{\\tau_{i+1}}, w, y, \\tau_{i+1}), f_{\\theta'}(x^{\\psi,w}_{\\tau_{i}}, w, y, \\tau_{i}))] $ 其中 $\\theta’$ 是一组扩展参数，$\\psi$ 是一个求解器，如 DDIM，$w$ 是引导权重，$d$ 是距离函数，$\\tau$ 是一组解码时间步长。 DALL-E 3 使用这种方法实现 $2-4$ 步生成。 潜在一致性结果 潜在一致性 LoRA上述训练目标也适用于 LoRA 训练。此 LoRA 模型可用作多个 LDM 的加速器，原始 LDM 的适配器也可与此 LCM-LoRA 一起使用。 ControlNet控制 LDM 的条件注入很难，添加额外的控制模态需要重新训练。ControlNet 系列创建了一组适应方法，可用于在不重新训练的情况下控制文本到图像模型。 原始 ControlNet 是 SD UNet 编码器的完整并行副本，经过训练以引导原始模型在额外的模态（如分割掩码、姿势、涂鸦等）上进行操作。 文本到图像适配器和 LoRA 也可用于在不重新训练的情况下实现控制。 这些方法可以在推理时相互混合使用。 T2I 适配器 ControlNet 结果","link":"/AI/NLP/NLP-TextImageModels/"},{"title":"NLP-Tokenization","text":"本章主要讲述了 NLP 的令牌化 基准：按空白字符分割 对于许多书写系统，按空白字符分割文本是一个有用的基准： ‘This isn’t an easy sentence to tokenize!’ $\\Rightarrow$[‘This’, &quot;isn’t&quot;, ‘an’, ‘easy’, ‘sentence’, ‘to’, ‘tokenize!’] 问题： 我们通常希望将标点符号视为单独的标记（但仅当它们确实是标点符号时，例如 ‘U.K.’ 或 ‘10,000.00$‘）； 这种解决方案无法分隔没有空白字符的标记对，例如带有附加成分的表达式，如 &quot;isn’t&quot;。 正则表达式和语言正则表达式我们需要引入更复杂的模式来以上下文相关的方式描述标记边界。一种流行的解决方案是使用正则表达式（简称 regex）。 给定一个有限的 $\\Sigma$ 符号字母表，$\\Sigma$ 上的正则表达式及其在 $\\Sigma^*$ 中的匹配通过同时递归定义如下： 空字符串和 $\\Sigma$ 中的任何单个符号都是 $\\Sigma$ 上的正则表达式，并匹配其自身。 如果 $r_1$ 和 $r_2$ 是 $\\Sigma$ 上的正则表达式，那么 它们的 连接，$r_1 r_2$ 也是 $\\Sigma$ 上的正则表达式，并且匹配那些恰好是匹配 $r_1$ 的字符串和匹配 $r_2$ 的字符串连接起来的字符串，且 它们的 交替，$r_1 \\vert r_2$ 也是 $\\Sigma$ 上的正则表达式，并且匹配那些恰好匹配 $r_1$ 或 $r_2$ 的字符串。 如果 $r$ 是 $\\Sigma$ 上的正则表达式，那么对 $r$ 应用 Kleene 星号 运算符，我们可以形成一个新的正则表达式 $r^*$，它恰好匹配那些由 0 个或多个匹配 $r$ 的字符串连接起来的字符串。 形式语言给定一个有限的字母表 $\\Sigma$，一个 形式语言 $\\mathcal L$ 是 $\\Sigma$ 上字符串的任意集合。这些字符串通常通过 语法 定义。 根据语法的复杂性，语言可以分为不同的 类型。最著名的是乔姆斯基层次结构： 正则语言：可以描述线性结构 编程：状态机 语言：单词，名词短语 上下文无关语言：可以描述树结构 编程：XML DOM，解析树 语言：短语结构语法（句子） 上下文相关语言：大多数人类语言是轻度上下文相关的 递归可枚举语言：所有可以通过算法解决的问题 回到正则表达式一个形式语言 $\\mathcal L$ 当且仅当存在一个正则表达式恰好匹配 $\\mathcal L$ 的元素时，才是 正则的。 有一些简单的形式语言不是正则的，例如“孪生语言” ${ww \\vert w \\in {a, b}^* }$。 尽管如此，正则表达式对于许多实际任务来说已经足够灵活，并且存在高效的算法来决定字符串 $s$ 是否匹配正则表达式（时间复杂度为 $\\mathcal O(\\mathrm{length}(s))$）。 有限状态接受器与正则语言有限状态接受器是消耗字符输入序列并可以“接受”或“拒绝”输入的有限状态机。它们与最简单的 FSA (有限状态自动机) 不同之处在于： 有一个明确的 开始状态， 一组指定的 接受状态，以及 它们的转换由有限字母表中的符号或空字符串标记。 当且仅当有限状态接受器具有从开始状态开始、在接受状态结束的转换序列，并且转换标签的连接是所讨论的输入时，它才 接受 输入。 接受单词“car”、“cars”、“cat”和“cats”的接受器： 可以简化为： 有限状态接受器与 正则语言/表达式 之间的联系由 Kleene 的 等价定理 建立： 当且仅当存在一个 FSA 接受器恰好接受其元素时，一个语言是正则的。 这种等价性在理论和实践中都很重要：有非常高效的算法可以 简化/最小化 有限状态接受器，并决定它们是否接受一个字符串。 正则表达式：扩展便利扩展 不增加表达能力，只是添加了一些有用的快捷方式，例如： 字符类匹配集合中的任何单个符号，例如 [0-9]； 补充字符类匹配 不在 补充集合中的任何字符，例如 [^ab]； 用于指定模式重复次数的运算符，例如，$r{m,n}$ 匹配 $s$ 如果 $s$ 重复 $r$ 模式 $k$ 次，其中 $m\\leq k \\leq n$。 可选匹配：$r? = r{0,1}$ Kleene plus：$r+ \\approx r{1,\\infty}$ 正则表达式：反向引用所谓的 反向引用 结构，允许命名和引用与正则表达式的早期部分相对应的匹配项，从而增加了表达能力。 例如，大多数当前的正则表达式库允许类似于以下的正则表达式： 1(?P&lt;a&gt;[ab]*)(?P=a) 它使用反向引用来定义前面提到的非正则“孪生语言”。 基于正则表达式的查找和替换除了将整个字符串与正则表达式匹配之外，还有两个基于正则表达式的常见任务： 查找与正则表达式匹配的字符串子串， 基于正则表达式的查找和替换：在其最简单的形式中，这是用给定的字符串替换匹配的子串，但现代正则表达式库提供了两个显著的额外功能： 正则表达式可以有前瞻和后顾部分，这些部分在查找匹配时使用，但不计入被替换的部分； 替换不必是固定的—它们可以包含对匹配部分的反向引用。 基于规则的分词基于正则表达式级联的分词核心思想：对输入执行基于正则表达式的替换，最终只需按空白字符分割即可。 Penn Tree Bank 附带的 分词器 sed 脚本 是一个很好的例子。几个具有代表性的规则（\\&amp; 指代完整匹配，\\n 指代第 $n$ 个组）： ‘...’ $\\Rightarrow$ ‘ ... ‘（分隔省略号） [,;:#$%&amp;] $\\Rightarrow$ ‘ \\&amp; ‘（分隔各种符号） ([^.])([.])([])}&quot;‘]*)[]*\\ $\\Rightarrow$ ‘\\1 \\2\\3’（假设句子输入并仅分隔最终句号） &quot;‘ll&quot; $\\Rightarrow$ &quot; ‘ll&quot;（分隔缩略词 ‘ll） 主要问题是如何正确处理例外情况：例如，单词结尾的句号应被分割，除了缩写。 标准解决方案是在执行相关替换之前，将有问题的表达式替换为无问题的占位符，例如： (etc\\. $\\vert$ i\\.e\\. $\\vert$ e\\.g\\.) $\\Rightarrow$ &lt;abbrev&gt; 此解决方案需要跟踪占位符替换，并在执行有问题的规则后恢复原始内容。 基于词法分析器的解决方案它们使用现成的“词法分析器”（lexical analyzers），最初是为计算机程序的 令牌化/词法分析 而开发的。 一个典型的词法分析器将字符流作为输入，并从中生成分类的标记流： 大多数词法分析器实际上是词法分析器生成器。它们的输入是标记类（类型）、正则表达式模式和 [RegexPattern] $\\Rightarrow$ [Action] 规则（其中最重要的操作是将实际匹配分类为给定类型的标记），并生成一个具体的、优化的词法分析器来执行给定的规则，例如通过生成分析器的 C 源代码。 SpaCy 的基于规则的分词器 输入文本按空白字符分割。 然后，分词器从左到右处理文本。对于每个子字符串，它执行两个检查： 子字符串是否匹配分词器异常规则？例如，“don’t”不包含空白字符，但应被分割。 前缀、后缀或中缀是否可以被分割？例如，逗号、句号等标点符号。 如果有匹配，则应用规则，分词器继续循环，从新分割的子字符串开始。 一个简单的例子：对 “Let’s go to N.Y.!” 进行分词 编辑距离除了将输入分割成单元外，分词还涉及将标记分类为类型，例如决定哪些类型 ‘Apple’, ‘apple’, ‘appple’ 属于。在许多情况下，这些决策需要字符串之间的相似性度量。 在这个领域中，最重要的度量家族之一是所谓的 编辑距离 家族，它通过将两个字符串相互转换所需的最少编辑操作次数来衡量它们之间的距离。 给定 一组 编辑操作（例如，从字符串中删除或插入一个字符），以及 一个 权重函数，它为每个操作分配一个权重， 两个字符串之间的 编辑距离（一个源字符串和一个目标字符串）是将源字符串转换为目标字符串所需的最小总权重。 Levenshtein 距离最重要的变体之一是所谓的 Levenshtein 距离，其中操作是 删除， 插入，和 替换字符 且所有操作的权重均为 1.0。 子词分词分词 与 子词分词经典的分词旨在将输入字符流精确地分割成语言学上有意义的单元：单词和标点符号。 这种类型的分词对于人类语言分析很有用，但对于构建大型语言模型却不适用，因为它 相当具有挑战性，因为存在各种书写系统和语言，它们都需要（有时是根本不同的）规则/模型 在较大的语料库上会生成巨大的词汇表，并且仍然会导致词汇外单词的问题 一种最近开发的替代方法是 subword tokenization。许多现代的深度端到端 NLP 架构使用子词分词而不是经典分词来分割输入。其主要优点是： 需要很少或几乎不需要预分词 统计和数据驱动：从语料库中学习分割模型（无需手动编写规则） 词汇表大小可以自由选择；它将包含最常见的单词和子词单元 与书写和语言无关 这对文本意味着： 输入文本将被分割成最常见的单词和子词 分割质量取决于词汇表大小 对于单一语言，30,000 个类型就足够了 一个常规的词汇表通常有几十万甚至几百万个类型 没有词汇外单词（在正确设置下！） 子词片段通常是有信息量的，边界经常接近形态学（morphological）边界 字节对编码 (BPE)Byte Pair Encoding 最初是一种用于字节序列的简单压缩技术，但可以推广到由有限字母表中的符号组成的任何序列。为了生成字母表上的序列的 编码/压缩 版本， 用字母表中的符号初始化符号列表，并且 反复计算所有符号对，并用新的 ‘AB’ 元素替换每个最频繁对 (‘A’, ‘B’) 的出现，并将 ‘AB’ 添加到符号列表中 这种技术如何用于文本的子词分词？诀窍是通过对文本应用 BPE，从训练语料库中学习用于分割的词汇。修改如下： 从粗略的预分词开始（通常非常简单，例如按空白字符分割） 不允许 BPE 合并跨越单词边界。 在实践中，这些修改通常通过向字母表中添加一个新的 ‘_‘ 单词起始（或单词结束）符号来实现，并规定 ‘_‘ 只能结束（或开始）合并项。 一个简单的例子：在不同数量的合并操作后，句子的 BPE 编码版本。 随着合并次数的增加，越来越多的符号变成完整的单词。 贪婪 BPE 子词分词使用 BPE 处理语料库会产生 一个包含所有字符及其合并结果的 词汇表 以及按执行顺序排列的 合并列表 然后，通过按照合并列表中的顺序执行所有适用的合并，对新的预分词输入进行子词分词。 WordPieceWordPiece 是一种子词分词方法，与 BPE 只有略微不同。不同之处在于： 合并 AB 对是那些具有最高值的对 $\\frac{freq(AB)}{freq(A) \\times freq(B)}$，其中 $freq(\\cdot)$ 是训练语料库中类型的频率 使用生成的词汇进行分词时，使用 MaxMatch 算法： 子词采样BPE 和 WordPiece 的默认子词分词策略会确定性地生成单词的贪婪匹配分解，即使存在有信息的替代分割： unrelated = unrelate + d unrelated = un + related 为了解决这个问题，开发了从可能的替代分解中概率采样的解决方案。 BPE dropout 在分词过程中随机丢弃一些 BPE 合并规则，而 Unigram 语言模型 基于一种新颖的概率子词分词方法，该方法从启发式估计的最优词汇表的超集开始，并递归地删除对构建训练语料库的简单（单项）概率语言模型最不有用的条目。 与 BPE 相比，递归 Unigram 语言模型词汇构建步骤的概率性质使得可以为替代分割分配合理的概率，并从中进行采样。 SentencePiece在其原始形式中，BPE 和 WordPiece 需要（粗略的）预分词作为预处理步骤。与此相反，SentencePiece 分词器库能够以相同的方式处理每个字符，甚至包括空格，并且可以将 BPE 或单项语言模型方法应用于原始句子甚至段落，从而消除了预分词的需要。 因此，SentencePiece 是从原始文本生成深度端到端模型输入的最流行解决方案之一。","link":"/AI/NLP/NLP-Tokenization/"},{"title":"NLP-Tooling","text":"工具 增强语言模型Augmenting Language Models 动机从2020年代初期开始，语言模型可以通过以下特性来描述： Few-shot learners 能够推理逻辑问题 容易产生幻觉 hallucinations（由于活跃的知识空白） 能够逐步遵循指令 知识可以以少样本的方式注入，这可以解释为克服幻觉。通过逐步处理，增强模型可以使用低复杂度的知识源来回答复杂问题。 与提示的连接有两种方法可以将外部信息注入类似Transformer的语言模型： 嵌入空间中的向量序列（cross-attn，prefix等） 将文本信息注入提示（特殊标记，格式等） 重要提示！在考虑增强的同时，应考虑使用适当的提示技术。基于Transformer的模型的上下文窗口具有固定长度，这是一个限制！ 检索最简单的解决方案：检索增强生成（RAG）。 获取一个外部知识库并查询它。然后，模型可以利用查询结果来回答问题。 示例提示： 1234567仅使用提供的上下文回答以下问题！问题：&lt;USER_INPUT\\&gt;上下文：&lt;RETRIEVED_CONTEXT\\&gt;答案：&lt;LLM\\&gt; 如何检索信息？查找相关信息的最常见方法是： 基于关键词的搜索（出现次数，正则表达式等） 基于向量相似度的搜索（TF-IDF，LM-embedding等） 关系查询 基于分类法（Taxonomy）的搜索（词典，维基，WordNet） 直接访问（链接，文档） 搜索方法基于向量相似度的搜索方法假设我们有某些文档的特征向量 ($e^i$)，其中 $i\\in I$，且 $||e^i||_2^2 = 1$。 检索过程应返回与嵌入的用户查询 $e^q$ 最接近的文档。 这是通过经典的最近邻搜索实现的。假设 $e \\in \\mathcal{R}^d$ 且 $|I| = N$，则检索的复杂度为 $O(Nd)$。 这随着嵌入大小（质量）和文档数量的增加而变得困难。搜索 $k$ 个最近邻也是如此。 近似最近邻搜索Approximate nearest neighbor search 预构建的索引可以减少推理时间，但内存和构建时间仍然是一个限制。存储和索引构建需要近似。 可能的解决方案： 哈希 量化 树结构 基于图的 上述原则在实践中经过改进并经常结合使用。 哈希与返回精确结果不同，哈希函数构建了分箱。使用LSH（Locality-Sensitive Hashing）函数族时，两个向量距离增加时碰撞概率单调递减。 通过分箱减少复杂度。在找到最近的分箱后可以进行细粒度搜索。 基于树的解决方案在树结构中，分支因子 $b$ 将搜索复杂度减少到 $\\log_b(N)$。 对于二叉 KD 树 $b=2$，构建此类树的简单解决方案是在最高方差数据维度的中位数处绘制一个垂直超平面。然后每一半使用相同的原则进行拆分。这继续进行，直到每个节点仅包含一个元素。 然后可以结合树和嵌入空间搜索算法来找到最近邻。例如：优先搜索。 优先搜索首先选择包含查询的节点（或单元），然后访问由查询与查询单元中的嵌入向量之间的距离初始化的最大嵌入空间距离限制的最近邻树节点。 量化给定由质心 $\\mathcal{C} = {c_i | i\\in I}$ 定义的码本，其中 $I = {0, 1, … m-1}$ 是有限的。 我们将每个实向量映射到最近的质心 $q(\\cdot)$。映射到 $c_i$ 的实向量集合是其 Voronoi 单元，用 $V_i$ 表示。 这意味着 $q(x) = \\text{arg}\\min\\limits_{c_i \\in C}d(x, c_i)$，其中 $d(\\cdot)$ 是距离函数。 $c_i = E_x[x|i] = \\int_{V_i}p(x)\\cdot x dx$，应定义为 Voronoi 单元的中心。 Product Quantization简单量化仍然效率低下，因为聚类中心需要使用复杂的算法（如 k-means，复杂度 $O(dm)$）来计算。在简单的 1 位/组件 $128$ 维量化向量的情况下，需要计算和存储 $m = 2^{128}$ 个质心。 这太多了！ 解决方案：我们应该将向量分解为多个段（类似于 MHA）。 在将向量分成 $L$ 段的情况下，每个段可以通过其特定的量化器进行量化。这意味着 $\\mathcal{C} = \\mathcal{C}_1 \\times \\mathcal{C}_2 \\times … \\times \\mathcal{C}_L$ 和 $I = I_1 \\times I_2 \\times … \\times I_L$ 应分解为子量化器和子索引的笛卡尔积。 在这种情况下，复杂度减少到 $O(dm^{\\frac{1}{L}})$。 每个段的量化值之间的距离可以计算并存储以供搜索步骤使用。 使用预计算的 $d(c_i, c_j)$ 表，我们可以轻松计算完整向量 $e^i$ 和 $e^q$ 的距离。在欧几里得距离的情况下等于： $$d(e^i, e^q)=d(q(e^i), q(e^q))=\\sqrt{\\sum\\limits_{l \\in L} d(q_l(e^i), q_l(e^q))^2}$$ 这导致平均搜索复杂度为 $N$ 次比较加上查找和求和 $L$ 查找表中的相应距离。如果 $N&gt;&gt;L$，则简化为 $O(N + L\\ \\log L \\cdot \\log\\ \\log N )$。 基于图的图方法构建一个索引，该索引采用适合邻居关系表示的形式。例如 Delaunay 图、相对最近邻图、k 最近邻图、最小生成树等。 这些图很难构建和存储，因此在构建过程中会进行近似。通常，具有“小世界”特性的图被构建。这些网络具有以下特性，给定一个常规网络的边重连概率 $p$： $L(p)$ 两个顶点之间的最短路径平均值应较小 $C(p)$ 聚类系数（完全连接的三元组（三角形）与图中所有三元组的比率）应较大 Small world 构建图NSW（navigable small worlds）用于创建可导航的小世界。在这里，顶点被迭代地插入到网络中。连接是通过一个随机性水平选择的，这创建了一个小世界网络，同时确保整个网络是可遍历的。 HNSW（hierarchical NSW）更进一步，通过将节点和链接组织成层次结构。那些具有长链接距离的层应插入到顶层，而较小距离（后插入）的节点放置在较低层。 HNSW 推理一个贪婪搜索算法从顶层节点之一初始化。然后它在层中寻找局部最小值，并在找到后切换到较低层，直到找到最接近查询的点。该算法的平均复杂度为 $O(\\log(N))$。 图推理一般来说，其他基于图的解决方案也遵循类似的原则。它们从一个种子顶点开始，然后通过图遍历，朝着与查询距离较小的方向前进。 检索增强Retrieval Augmentation 嵌入模型语义向量用于检索文档。这些文档通常被拆分成较短的片段。语义向量可以来自 TF-IDF、Word2Vec 嵌入、Masked- 或 Causal-LM 嵌入。也可以使用多模态选项。 专门的嵌入模型语言模型的预训练可能不会产生具有所需属性的嵌入空间。 一些额外的目标可以帮助对其进行调整： 监督语义相似性 Supervised semantic similarity 分类 聚类 Clustering 监督检索或重新排序 问答映射 更长的（句子、段落）文本表示 句子嵌入需要对句子级别进行微调，以正确表示较长文本的语义。 句子级别的监督数据集示例包括：句子相似性数据集、情感分析数据集、自然语言推理数据集（前提和一个蕴涵、矛盾或中性对），等等。 指令嵌入指令嵌入作为多任务训练嵌入出现，其中执行的任务取决于给模型的自然语言指令。指令训练也提高了领域适应性。 检索增强生成RAG 通常包括以下步骤： 问题形成：将用户查询重新表述为独立查询（考虑历史），关键词列表等 检索：使用嵌入和向量存储系统或搜索引擎等检索有用的段落 文档聚合：aggregation 将所有文档一起“填充”或“映射”一个转换（例如摘要） 答案形成：查询和上下文被输入到生成答案的语言模型中 假设文档嵌入Hypothetical 文档嵌入有助于为基于嵌入向量的检索系统生成更好的查询。HyDE 问题形成步骤被生成步骤取代，该步骤生成问题的“假”示例答案，并将其用作数据库中的查询。 实体记忆另一个可能的、更复杂的用例是当 LLM 也有能力修改数据库时。在这个数据库中存储了一个实体列表和相关知识。模型被迭代地提示更新这个数据库，然后它可以从数据库存储的实体信息中检索。 RAG 预训练模型将解码的信息传输到文本实际上效率不高。 检索增强预训练对于模型是可能的，其中预嵌入向量附加到编码输入，或者通过类似交叉注意力的机制提供信息。 REALM检索增强语言模型预训练使用由类似 BERT 的嵌入模型组成的神经检索器。这些模型是训练网络的一部分。检索器在 MLM 训练期间将检索到的文档嵌入与查询连接起来。 RETRO检索增强 Transformer 引入了一种技术，其中相关的上下文信息通过交叉注意力进行处理。检索是通过冻结的 BERT 嵌入进行的。检索到的块然后基于输入信息使用交叉注意力在编码器中进行修改。 在解码器中，交叉注意力将修改后的检索信息合并到输入中。 RETRO 块输入被切分成块，每个块分别检索信息。前面的块（及相关信息）按因果关系处理。 整个模型是可微分的，梯度可以通过网络流动。 在训练期间，检索到的信息是预先计算的。 工具API 调用基于文本的 API 可以通过 API 的输入和输出定义轻松调用。大多数 LLM 都经过微调，可以很好地处理 JSON 或 XML 格式。 此类 API 的一些示例包括： 搜索引擎 网络抓取 实时数据流 可执行文件，命令（例如：计算器） 代码解释器，模拟器 其他 LLM 实例 AutoGPT - 自我独白AutoGPT 通过在链式思维和反思类型提示中应用多次生成，能够进行更高阶的规划。AutoGPT 应用 $4+1$ 步骤的类似 CoT 的过程来控制动作： 思考：根据目标解释用户输入。 推理：关于如何处理此输入的 CoT。 计划：计划要执行的操作。 批评：反思行动结果。 行动：由 AutoGPT 生成输入的动作。 在计划和行动阶段，可以调用额外的专家 LLM 和外部工具。AutoGPT 系统通常只提示一组目标，其余由模型自行解决。示例工作流程（发送电子邮件）： 思考：联系 Joe，邮箱 Joe@inf.hu，发送一封礼貌的电子邮件，表明他应该完成 NLP 幻灯片。 推理：目标明确。我需要发送一封电子邮件给 Joe，邮箱 Joe@inf.hu，礼貌地要求他完成 NLP 幻灯片，并表明我是一个 AI 助手。 计划（+批评 Criticism）：使用 send_email 动作。{ “action”: “send_email”, “action_input”: &lt;JSON&gt;} 观察：邮件已发送。 Agent 循环 会话专家代理 工具微调模型微调模型以选择工具是困难的。引导可能是一个解决方案，其中使用大量 LLM 调用构建 API 调用图。这些连续调用按成功率排序，并选择通过率最高的几个解决方案纳入数据集。这样的微调可以增强语言模型的工具利用能力。 总结总结 I增强语言模型使用外部信息源来增强其能力。这些信息源的一个重要组是矢量化文档数据库。嵌入模型用于通过近似 NN 搜索算法检索相关信息。其他工具包括 Web API，甚至代码解释器。应用自我独白过程的模型能够通过规划和执行连续的动作来实现目标。 总结 II在检索增强生成过程中，检索到的文档被连接或总结，然后在第二个 LLM 步骤中输入模型以生成答案。 微调模型以使用检索到的信息或外部工具是可能的，并且可以提高性能。","link":"/AI/NLP/NLP-Tooling/"},{"title":"NLP-Transformers","text":"Attention is all you need 介绍最早的有影响力的 seq2seq 模型是 RNN，但后来的发展是通过发明 transformers 实现的，这是一种使用注意力机制作为完整层（full-fledged layers）的新型架构，而不是作为辅助 RNN 组件。 新架构的主要构建块是： 作为软字典查找的注意力 自注意力层，和 transformer 模块 直观感受经典数据库查询（宠物店）： 查询：Key = “cat” Key（动物） Value（价格） cat 1 dog 2 cat 3 parrot 4 Key（动物） Value（价格） 选择权重 cat 1 1 dog 2 0 cat 3 1 parrot 4 0 Output = $1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot 1 + 4 \\cdot 0 = 4$ 软数据库查询（宠物店）： 查询：Key ~ “cat” Key（动物） Value（价格） 选择权重 cat 1 0.4 dog 2 0.15 cat 3 0.4 parrot 4 0.05 Output = $1 \\cdot 0.4 + 2 \\cdot 0.15 + 3 \\cdot 0.4 + 4 \\cdot 0.05 = 2.1$ 数学公式回顾一下，注意力机制提供了基于查询的 $\\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$ 向量序列的聚合：给定一个 $\\mathbf{x^*}$ 查询向量，它们计算一个相关性分数序列 $$\\mathbf{s} = \\langle s(\\mathbf{x}_1, \\mathbf{x}^),\\dots, s(\\mathbf{x}_n, \\mathbf{x}^) \\rangle$$ 并返回加权和 $$\\mathop{\\mathrm{softmax}}(\\mathbf{s})\\cdot \\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$$ 作为根据相关性分数对 $\\mathbf{x}_i$ 进行总结或聚合的结果。 $s(\\cdot, \\cdot)$ 评分函数有所不同，我们看到一个选项是使用缩放点积： $$s(\\mathbf{x}_i, \\mathbf{x}^) = \\frac{\\mathbf{x}_i\\cdot \\mathbf{x}^}{\\sqrt{d}}$$ 其中 $d$ 是 $\\mathbf{x_i}$ 和 $\\mathbf{x^*}$ 的维数。 基于这个模式，transformer 注意力机制做了一个关键的改变：将 $\\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$ 视为一个 字典，其中有 $\\mathcal K(\\cdot)$ 和 $\\mathcal V(\\cdot)$ 映射，将每个 $\\mathbf{x}_i$ 映射到相应的 $\\mathcal K(\\mathbf{x}_i)$ 键和 $\\mathcal V(\\mathbf{x}_i)$ 值。 假设还有一个 $\\mathcal Q(\\cdot)$ 查询 映射，它将 $\\mathbf{x}^*$ 映射到 $\\mathcal K$(.) 的范围（“key-space”），评分可以重新表述为计算查询和键之间的点积相似度分数 $$s(\\mathbf{x}_i, \\mathbf{x}^) = \\frac{\\mathcal K (\\mathbf{x}_i)\\cdot \\mathcal Q (\\mathbf{x}^)}{\\sqrt{d}}$$ （$d$ 现在是“key-space”的维数），检索到的值将是加权和 $$\\mathop{\\mathrm{softmax}}(\\langle s(\\mathbf{x}_1,\\mathbf{x}^),\\dots,s(\\mathbf{x}_n,\\mathbf{x}^) \\rangle)\\cdot \\mathcal V(\\langle \\mathbf{x_1},\\dots,\\mathbf{x}_n)\\rangle$$ Scaling然而，这种注意力机制存在一个问题。假设所有序列的每个向量元素都来自标准正态分布 $\\mathcal{N}(0, 1)$。它们的点积 $\\sum\\limits_{d}\\mathbf{x}_i\\cdot\\mathbf{x}_i^*$ 将具有 $\\mathcal{N}(0, d)$ 的分布，其中 $d$ 是向量的维数。为了将输出缩放回标准正态分布，点积被缩放为 $\\frac{1}{\\sqrt{d}}$。 Attention as a layer所述的注意力机制可以用作独立层来转换输入向量序列 $\\mathbf{I} = \\langle \\mathbf{i}_1,\\dots, \\mathbf{i}_n \\rangle$： 给定另一个序列 $\\mathbf{X} = \\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_m \\rangle$ 和 $\\mathcal K(\\cdot),\\mathcal V(\\cdot),\\mathcal Q(\\cdot)$ 映射，对于每个输入 $\\mathbf{i_k}$，我们可以计算相应的 $\\mathcal Q(\\mathbf{i}_k)$ 查询，并使用它与 $\\mathcal K$ 和 $\\mathcal V$ 来 关注 $\\mathbf{X}$ 并计算相应的注意力响应 $\\mathbf{o}_k$。 结果是一个 $\\mathbf{O}=\\langle \\mathbf{o}_1,\\dots,\\mathbf{o}_n \\rangle$ 输出序列，整体上是输入 $\\mathbf{I}$ 的层输出。 注意力层类型根据层关注的位置（$\\mathbf{X}$ 的来源），我们可以区分自注意力层和交叉注意力层。 在 自注意力 层中，从输入生成的查询用于查询输入本身：$\\mathbf{X}=\\mathbf{I}$ 在 交叉注意力 层中，查询的是外部向量序列，例如，在编码器-解码器 transformer 架构中，由编码器创建的序列 至于映射 $\\mathcal K(\\cdot),\\mathcal V(\\cdot),\\mathcal Q(\\cdot)$，这三者通常都实现为线性投影，具有学习到的权重矩阵 $W_K, W_V, W_Q$。 多头注意力为了能够关注输入的多个方面，transformers 中的注意力层包含几个并行的注意力“头”，每个头都有不同的 $W_K, W_V, W_Q$ 三元组： 头输出被组合成一个层输出： Transformer 模块transformers 的构建块是由注意力和简单的分段前馈层组成的 transformer 模块。最简单的变体只包含一个自注意力层： 编码器编码器由 $N$ 个相同的层组成，这些层具有自注意力和逐元素（element-wise） FFN 模块，以及残差连接。编码序列（上下文）是最后一个编码器层的输出。每个自注意力都是双向的。 解码器解码器由 $N$ 个相同的层组成，这些层具有自注意力、交叉注意力和 FFN 模块，以及残差连接。交叉注意力将编码序列作为键和值，而查询来自解码器。每个自注意力是单向的，交叉注意力是双向的。 嵌入和位置编码Transformers 是为符号序列（例如文本）发明的，因此使用嵌入层将输入标记转换为向量表示。然后将此嵌入添加到位置编码向量中，该向量用于向模型传达位置信息。 Seq2seq Transformer 原始的 全 transformer 模型 是一个完全由 transformer 块构建的 Seq2seq 编码器-解码器 模型。在推理过程中，解码器部分逐步预测，类似于 RNNs 消耗已经预测的输出，但在训练过程中，它只需要通过教师强制进行一次前向传递。 训练通过向解码器添加分类头，可以在两个序列上训练模型。给定完整的输入序列，解码器被训练来预测输出序列中的下一个元素。 为了生成完整的序列，模型以自回归（auto-regressive）方式使用。模型的输出用作下一步的输入。然而，单个错误预测将导致错误的级联。为避免这种情况，模型通过教师强制进行训练。 掩码掩码用于防止模型关注某些元素。Transformers 中主要有两种类型的掩码： 填充（Padding）掩码 前瞻（Look-ahead）掩码（因果 causal 掩码） 编码器风格和解码器风格的模型某些应用只需要模型处理单个序列（例如语言建模）。在这种情况下，不需要交叉注意力和两个模块。我们只使用编码器或解码器（没有交叉注意力）。当存在双向信息时，使用编码器风格的模型，而对于因果问题，则使用解码器风格的模型。因此，两者之间的唯一区别是因果掩码。 上下文嵌入词嵌入的局限性传统的基于共现矩阵的词向量和第一代神经词嵌入有几个重要的局限性： 上下文独立性: 一个表面形式只有一个表示。例如，bank 在以下句子中的嵌入是相同的： I went to my bank to withdraw some money. （我去银行取了一些钱） We explored the river bank. （我们探索了河岸） 尽管这两个意思显然是不同的 单词是黑箱: 单词有内部结构：它们由字符组成，可以由几个词素组成，但 Word2vec、GloVe 等忽略了单词的内部结构 对未见过或罕见单词没有有用的表示: 由于单词被视为黑箱，这些模型无法为训练语料库中未出现或非常罕见的单词生成有用的表示 良好的覆盖需要巨大的模型尺寸: 一个单词只有在明确包含在模型的词汇表中时才会获得有意义的表示，但内存消耗通常是覆盖词汇表的线性函数 利用内部单词结构、处理 OOV 单词和减少词汇量的问题已通过以下方法有效解决： fastText 嵌入，尤其是 子词嵌入 但这些嵌入仍然是静态的，即将相同形式的标记映射到相同的嵌入向量。 NLP 领域最近最重要的发展之一是上下文嵌入的出现，与之相反，上下文嵌入可以根据上下文的不同来改变相同表面形式的嵌入，以反映语言差异。 Contextual embeddings上下文嵌入 是由深度网络（通常是基于 LSTM 或自注意力机制）生成的单词或子词表示，这些网络在自监督的、广泛的语言建模目标上进行（预）训练。 与静态嵌入不同，这些表示不能简单地以查找表的形式存储和部署，因为它们是根据每个标记的上下文动态计算的：对于一个 $\\mathbf{w} = \\langle w_1,\\dots ,w_n \\rangle$ 输入标记序列，网络生成一个嵌入序列 $$E(\\langle w_1,\\dots ,w_n \\rangle) = \\langle E_\\mathbf{w}(w_1),\\dots,E_\\mathbf{w}(w_n)\\rangle$$ 由于这种动态特性，网络本身必须用作 特征提取模块。 在 NLP 中，生成上下文嵌入的网络的预期用途类似于传统 NLP 中处理管道的角色：它们应该生成对下游任务有用的特征向量，实际上，希望只需要少量的进一步处理（例如，以浅层神经网络的形式）就能构建有用的 NLP 模型。 巨大的区别在于，上下文嵌入可以通过自监督方式学习，而不需要昂贵的监督训练集。 ELMoELMo（来自语言模型的嵌入，Embeddings from Language Models），第一个历史上重要的上下文嵌入模型，通过两个标准的单向语言建模任务学习词表示。 该架构首先使用字符级卷积生成上下文无关的嵌入，然后使用前向和后向双向 LSTM 层（它们的数量 $n$ 是一个可变的超参数）通过权重共享的 softmax 层预测下一个/上一个标记。 在第一近似（approximation）中，上下文相关的嵌入是模型生成的所有 $2n +1$ 个中间表示（$2n$ 个基于上下文的 LSTM 和一个静态字符的表示）。 尽管这些向量可以一起被视为“完整的”ELMo 表示，但对于实际的下游 NLP 任务，ELMo 的创建者实际上建议不要使用这种非常高维的表示，而是使用这些向量的低维组合。他们建议的解决方案是 简单地连接顶层 LSTM 层（前向和后向）的输出 在监督任务上学习 ELMo 表示的任务特定线性组合 FLAIRFLAIR 是一种与 ELMo 密切相关的上下文嵌入模型，但 完全由循环字符级语言模型（一个前向和一个后向）组成 从 LSTM 隐藏状态在标记的第一个和最后一个字符（从后向 LM 的第一个字符和从前向 LM 的最后一个字符）生成标记级嵌入 FLAIR 嵌入在序列标注任务中被证明非常有用，使用它们的浅层模型目前在命名实体识别（NER）和词性标注（POS-tagging）中排名第二。 基于 Transformer 的上下文嵌入Transformer 架构最初用于翻译（2017 年），但从 2018 年开始，开发了一系列基于 Transformer 的模型来生成上下文嵌入。最重要的研究领域是： 寻找有助于学习高质量表示的自监督任务 架构改进，特别是找到更高效的注意力变体 如何为下游任务 adapt/fine-tune 预训练的 representation 网络 GPTGPT（Generative Pre-Training）是一种基于 BPE 的，仅使用解码器的 transformer 模型，使用传统的“预测下一个标记”语言建模目标进行训练。上下文嵌入只是顶层 transformer 模块的输出。 与 ELMo 类似，GPT 的主要目标是提供一个有用的预训练“特征提取”模块，可以针对监督的 NLP 任务进行微调。微调意味着在监督下游任务上以端到端的方式更改预训练的 GPT 权重。 BERT下一个具有高度影响力的模型是谷歌的 BERT（Bidirectional Encoder Representations from Transformers），其主要创新是 使用了两个新的自监督目标，而不是传统的语言建模 掩码语言模型（masked language modeling）以及 下一句预测（next sentence prediction, NSP）和 相应的架构变化：该模型基于 transformer 编码器 架构 掩码语言模型目标是猜测随机掩码的标记： 下一句预测第二个目标是判断两句话在训练语料库中是否相互跟随或是随机抽取的： 微调上下文嵌入预训练语言模型生成的上下文嵌入不一定适用于具体的下游任务（分类、语义搜索等），因此可以通过微调预训练权重来提高性能。 微调可以通过以下方式进行： 在更能代表目标领域的语料库上使用无监督任务（这些任务通常与预训练任务相同） 在与目标任务相同或相关的监督任务上进行，例如语义搜索的相似性排序 后续趋势更新的模型在 NLP 任务中不断刷新最先进的技术，但通常伴随着参数数量的增加和更大的数据集： 虽然最初的 ELMo 模型有 9360 万个参数，但 GPT-3 有 1750 亿个参数，数据集的规模从 8 亿个标记增加到 3000 亿个标记。 知识蒸馏模型规模的巨大增加导致了对知识蒸馏 （distillation）方法的深入研究，以便能够基于原始模型生成更小、更高效的模型，而不会显著损失性能。 一个很好的例子是DistilBERT，这是一个经过蒸馏的 BERT 版本，旨在模仿 BERT 的输出。DistilBERT 保留了 BERT 97% 的性能，但参数减少了 40%，推理速度提高了 39%。 稀疏注意力变体提高效率的另一种方法是减少自注意力层中的注意力范围，因为在全注意力中，计算点积的数量与输入标记的数量成平方关系。线性替代方案包括： 全局注意力: 一组全局标记关注整个序列； 随机注意力: 对于每个查询，计算一组 $r$ 个随机键，该查询关注这些键； 窗口注意力: 仅关注固定半径内的局部邻居。 Big Bird 上下文嵌入模型结合了所有这些线性注意力类型，以显著增加输入标记的数量，而不会显著改变内存需求： 少样本学习、单样本学习和零样本学习一个有趣的方向是尝试直接使用模型，而不在下游任务上添加层和进行梯度更新。一些最近的模型，最重要的是 GPT-3，在各种下游任务中表现出令人惊讶的效果，这些任务在输入中进行了说明。有三种学习设置： 零样本学习：输入仅包含监督任务的简短描述和一个具体的输入实例提示，例如“将英语翻译成法语：cheese =$&gt;$ ” 单样本学习 和 少样本学习：除了简短的任务描述外，输入还包含一个或几个训练示例，然后是提示","link":"/AI/NLP/NLP-Transformers/"},{"title":"NLP-VisionActionModels","text":"视觉-语言-行动模型 Introduction一个重要的方向是控制具身AI代理（机器人），它们应该根据口头指令和来自环境的视觉输入采取行动。这类任务包括： 视觉-语言-导航：根据人类的口头指令在真实的3D环境中导航 移动物体，即将物体从一个位置转移到另一个位置 操作物体，例如打开和关闭抽屉，敲击物体，将它们竖立等 方法和挑战 目前，主要的架构方法是使用编码器-解码器架构将视觉观察和语言输入映射到适当的机器人动作 架构的骨干通常是一个transformer（编码器、解码器或两者） 挑战包括： 利用预训练组件 收集足够大的指令机器人行为数据集 泛化：创建在不同任务中表现良好的模型，包括在未见过的环境中执行未见过的任务 减少硬件需求 使用情景transformer扩展的视觉语言导航视觉语言导航任务视觉语言导航任务是让一个人工代理 在环境中导航并到达由自然语言指令指定的目标。 情景transformer模型的具体设置由ALFRED基准数据集提供，其中指令指定了“日常任务”，特别是在室内环境中移动物体。 ALFRED数据集 两种类型的自然语言指令： 一个单一的“总体”目标 几个子目标指令，导致最终目标的实现 数据集由“专家演示”组成，展示了如何在给定环境中通过执行适当的动作来实现描述的目标和子目标 具体来说，ALFRED中的单个演示数据点包括： 简短的总体目标描述 自我中心的视觉观察时间序列，以及在每个时间步执行的动作和相应的交互掩码（如果动作有目标物体） 子目标指令序列，与观察/动作时间序列时间对齐 评估指标 任务成功率：如果在动作序列结束时，对象位置和状态变化正确地对应于任务目标条件，则为1，否则为0。 目标条件成功率：在一个回合结束时完成的目标条件与完成任务所需的目标条件的比率。 示例：“将一个热的土豆片放在柜台上” 目标条件： 土豆必须被切片 土豆必须被加热 土豆片应放在柜台上 加热后的土豆片（2）必须放在柜台上 路径加权版本对于上述两种评分（任务和目标条件成功率），都有路径加权版本，将基本评分乘以实际执行的动作数（$\\hat L$）与演示中的动作数（$L^*$）的比率： 评分 $s$ 的路径加权版本$$p_s = s \\cdot \\frac{L^}{\\max(L^, \\hat L)}$$ 情景transformer动机 过去的VLN模型基于递归架构（ALFRED基准模型也是如此） 递归网络不能很好地捕捉长期依赖关系，因为历史（先前的观察和动作）被编码在隐藏状态中 相比之下，transformer可以访问整个回合的整个历史 更正式的对比 [$\\hat a_i$ 是预测动作，$x_{1:L}$ 是指令，$v_i$ 和 $h_i$ 是视觉观察和历史表示]： $$ \\hat{a}_t, h_t = \\mathrm{RNN}(x_{1:L}, v_t, \\hat{a}_{t-1}, h_{t-1}) $$ $$ \\hat{a}_t = \\mathrm{Transformer}(x_{1:L}, v_{1:t}, \\hat{a}_{1:t-1}) $$ 架构 三个历史组件的独立初始编码器： 语言指令：一个transformer编码器嵌入文本标记 相机观察：一个 ResNet-50 - 2 个卷积和 1 个全连接层独立嵌入所有观察 先前的动作 通过一个学习的查找表简单地嵌入 一个多模态transformer编码器融合单模态嵌入 文本标记、视觉观察和先前动作的顺序由位置和时间嵌入表示 使用“因果注意”防止视觉和动作嵌入关注后续时间步 输出层是一个全连接层，预测下一个动作 $\\hat a_t$ 使用基于预测目标对象类别的预训练实例分割模型预测目标对象的位掩码 指令编码器预训练编码器在将自然语言指令转换为合成的、受控的“翻译”（由专家路径规划器参数生成）的编码-解码任务上进行预训练： 使用合成指令的数据增强除了预训练语言编码器外，合成指令还用于生成额外的训练数据点： 训练 预训练 如我们所见，语言编码器在合成翻译任务上进行预训练 视觉编码器和掩码生成器都在训练数据集的帧和相应的类别分割掩码上进行预训练 训练 整个模型的训练使用教师强制： 对于专家演示输入 $(x_{1:L}, v_{1:T}, a_{1:T})$，所有 $\\hat{a}_{1:T}$ 动作一次性预测 要最小化的损失是 $a_{1:t}$ 和 $\\hat{a}_{1:T}$ 之间的交叉熵损失 结果 结果优于原始的 ALFRED LSTM 基线（在已见任务上的任务成功率为 33.8% 对 23.3%） 特别有趣的是，使用预训练的 BERT 进行编码实际上降低了性能 作为通用 VLA 模型的 VLMs：RT-2起点 目标是适应预训练的 VLMs 作为通用指令跟随 VLA 模型 具体实现基于 PaLI-X 和 PaLM-E，这两个基于transformer的 VLMs 使用 ViT 变体将图像编码为视觉标记，并使用线性投影将它们映射到 LM 嵌入空间 使用的机器人动作特定数据集使用相对简单的指令和任务，预期在其上微调预训练的 VLMs 将导致复杂的指令跟随能力 机器人指令跟随数据集RT-1 数据集包含 130K 个示例，涉及 13 个人类远程操作机器人在办公室厨房环境中遵循 700 多条不同指令。 任务/技能的分布如下： “演示是在操作员和机器人之间有直接视线的情况下，使用 2 个虚拟现实遥控器收集的。” 收集的动作数据包含： 3 个用于底座移动的连续变量：$x$，$y$，偏航 7 个用于手臂移动的连续变量：$x$，$y$，$z$，滚转，俯仰，偏航，以及夹爪的开合 一个用于在三种模式之间切换的离散变量：控制手臂、底座或终止回合 模型架构 模型架构：PaLM-E使用的 VLM 之一是 PaLM-E，一个基于预训练 PaLM 语言模型的 12B 参数 VLM，它是一个transformer解码器类型的 LM。 图像使用 ViT 或 Object Scene Representation Transformer (OSRT) 进行编码。表示为 LLM 嵌入空间中的向量序列的多个图像可以与文本标记嵌入交错形成多模态句子作为输入，例如： Q: What happened between &lt;img 1&gt; and &lt;img 2&gt;? 其中 &lt;img 1&gt; 和 &lt;img 2&gt; 是表示图像的向量序列。 模型架构：PaLI-X另一个使用的 VLM 是 PaLI-X，它 使用一个非常大的（22B 参数）ViT 作为视觉组件，预训练于 OCR 中心的分类任务 一个 32B transformer编码器-解码器作为架构骨干 其视觉输入可以是多个图像（或视频帧），其表示与文本嵌入连接（而不是交错） 其较小的变体 PaLI-3B 也进行了实验，具有 2B ViT 和 3B 骨干。 VLM 预训练 视觉编码器单独在图像任务上进行预训练，例如 PaLI 的 OCR 分类任务 语言骨干使用标准的 LLM 预训练进行下一个标记预测（在 PaLI 的情况下还包括各种去噪任务） VLM 训练本身是在大量视觉语言数据集上进行的，包括 WebLI 数据集，其中包含 100 亿对图像-文本对（来自替代文本字段、OCR 等） 视觉问答数据集 机器人动作微调适应后的 VLM 需要输出机器人动作，因此需要将可能的动作映射到标记序列。为此， 使用 256 个箱对连续动作值进行离散化 所有可能的变量值都映射到 VLM 的词汇表条目（对于 PaLI-X，前 1000 个整数有自己的条目并被使用，对于 PaLM-E，覆盖了 256 个最不常见的条目） 动作向量映射到相应的值-标记序列，用空格分隔 例如，形式为 $\\langle$ terminate $\\Delta pos_x$, $\\Delta pos_y$, $\\Delta pos_z$, $\\Delta rot_x$, $\\Delta rot_y$, $\\Delta rot_z$, gripper_extension $\\rangle$ 的动作向量可以使用 PaLI-X 编码映射到字符串 “1 128 91 241 5 101 127” 关键发现：与其在机器人数据上天真地微调模型，不如在原始 VL 数据和机器人数据上共同微调，因为这会导致更具普遍性的策略，因为模型同时暴露于抽象的视觉概念和低级别的机器人动作。 在共同微调期间，机器人数据集示例的采样权重在小批量中逐渐增加 训练目标是标准的下一个标记预测目标，这对应于机器人学中的行为克隆（一种模仿学习） 结果 对于机器人动作提示，采样仅限于有效的机器人动作标记，以避免生成不可执行的输出 评估重点是： 在已见任务上的表现，以及对新对象、背景和环境的泛化 新兴能力的可观察性 模型大小和架构对性能的影响 链式思维推理的可观察性 未见任务基于 VLM 的 RT-2 比没有 VLM 预训练的模型泛化得更好： 新兴能力新兴能力分为三类： 推理：将 VLM 推理应用于控制任务 符号理解：VLM 转移语义知识，这些知识不在任何机器人数据中 人类识别：以人为中心的理解和识别 链式思维推理RT-2 模型在额外的数据上进行了微调，包括指令后的“计划”部分，例如， Instruction: I’m hungry. Plan: pick rxbar chocolate. Action: 1 128 124 136 121 158 111 255. 根据“定性观察”，这种微调使模型能够遵循更复杂的指令。","link":"/AI/NLP/NLP-VisionActionModels/"},{"title":"NLP-VisualModels","text":"编码器-解码器式视觉语言模型 介绍条件语言建模任务是对条件分布进行建模 $$P(\\langle y_1,\\dots,y_n\\rangle|C)$$ 其中 $C$ 表示生成的 $\\langle y_1,\\dots,y_n\\rangle$ 文本的一些条件，例如： 某种风格的文本 某个主题的文本 机器翻译 问答 从结构化数据生成自然语言（例如新闻） 图像描述 视觉条件图像描述并不是唯一的条件语言建模任务，其中条件至少部分是视觉的，其他任务包括： 光学字符识别 (OCR) 视觉问答 (VQA)：回答关于图像的问题 自然语言视觉推理 (NLVR)：判断自然语言陈述在两张图像中是否为真 多模态翻译：基于上下文图像从一种语言翻译到另一种语言 多模态聊天：与混合图像和文本的用户输入进行聊天 编码器-解码器的解决方案使用 编码器-解码器 架构来解决这些建模任务是一种自然的方法，其中 使用通常用于语言建模的 自回归文本解码器 生成文本（例如，LSTM 或 transformer 解码器） 解码器的文本输出通过接收来自 编码器 的适当编码形式的（部分）视觉输入来进行条件化 我们已经看到的一个经典示例是使用基于 CNN 的编码器和 LSTM 作为解码器的图像描述模型： 挑战在基于 transformer 的预训练 LLMs 的最新进展背景下，将这种编码器-解码器方法应用于视觉条件文本生成的主要挑战是 编码图像，尤其是高分辨率图像，转换为适合 transformer 文本解码器的输入。由于标准输入是符号序列，这需要某种形式的 “视觉标记化” 扩展预训练的 LLM 解码器 以能够处理视觉输入： 架构上：如何准确地连接编码器 训练方面：如何利用 预训练 的编码器和解码器组件？ 视觉标记化符号表示Transformers 设计用于处理符号序列。在视觉数据的情况下，这提出了一系列问题： 图像如何变成符号序列？ 如何为这些符号分配有意义的嵌入向量？ 需要什么样的位置编码？ 多尺度处理怎么办？ 视觉标记器视觉标记化通常包含以下步骤： 分块（将图像拆分成较小的部分） 块嵌入（通过学习层、CNN 等） 位置编码（学习的、固定的、1D、2D 等） 最激进的视觉标记器不是使用 连续 变换将图像块嵌入到嵌入空间，而是将块映射到有限的 代码簿 中的嵌入，通常只包含几千个嵌入条目。 结果是编码的图像表示几乎完全类似于现代语言模型中使用的文本表示： 存在一个视觉 词汇表 在代码簿中有相关的 嵌入 图像表示为按顺序或网格排列的词汇元素（“视觉词”） 生成这些离散表示的一种突出方法依赖于 离散变分自编码器。 变分自编码器变分方法在概率建模中经常出现以下情况： 我们对复杂的 $p^{*}$ 分布的性质感兴趣， 但只能计算未归一化的 $\\tilde{p}$ 函数的值，其中 $$ p^*(\\mathbf x) = \\frac{\\tilde{p}(\\mathbf x)}{Z} $$ $Z$ 是常数归一化因子（对于连续的 $p^*$，$Z = \\int \\tilde{p}(\\mathbf x)d\\mathbf x$），其计算是不可行的。 解决该问题的变分方法是用一个更简单、可处理的 $q$ 分布来近似复杂的 $p^*$ 目标分布，该 $q$ 分布由一些可调参数 $\\Theta$ 参数化。 近似需要某种距离度量，KL 散度 $$ \\mathbb{KL}(p^*\\Vert q) = \\mathbb E_{\\mathbf x \\sim p^*}\\log\\frac{p^*(\\mathbf x)}{q(\\mathbf x)} $$ 是一个自然的选择，但计算这个也是有问题的，因为它需要对 $p^*$ 进行期望计算。 选择反向 KL 散度 $$ \\mathbb{KL}(q\\Vert p^) = \\mathbb E_{\\mathbf x\\sim q}\\log\\frac{q(\\mathbf x)}{p^(\\mathbf x)} $$ 将对假设可处理的 $q$ 进行期望计算，但仍然需要逐点评估 $p^*$，因此变分目标是最小化 $q$ 和未归一化的 $\\tilde p$ 之间的“准 KL 散度”：我们试图找到 $$ \\underset{\\Theta}{\\operatorname{argmin}} \\left(\\mathbb E_{\\mathbf x \\sim q_\\Theta}\\log\\frac{q_\\Theta(\\mathbf x)}{\\tilde p(\\mathbf x)}\\right) $$ 就我们的目标 $p^*$ 而言，目标可以写成 $$ \\mathbb E_ {\\mathbf x \\sim q_\\Theta}\\log\\frac{q_\\Theta(\\mathbf x)}{p^(\\mathbf x)Z} = \\mathbb{KL}(q_\\Theta\\Vert p^)-\\log Z $$ 由于 Gibbs 不等式保证 $\\mathbb{KL}(q_\\Theta\\Vert p^*)\\geq 0$，所有值将是 $-\\log Z$ 的上界，任务是找到最小的（所谓的变分）上界。 等效的最大化任务目标： $$\\mathbb E_{\\mathbf x\\sim q_\\Theta}\\log\\frac{p^(\\mathbf x)Z}{q_\\Theta(\\mathbf x)}d\\mathbf x = \\log Z - \\mathbb{KL}(q_\\Theta\\Vert p^)$$ 是找到 $\\log Z$ 的最大（变分）下界。 应用 近似以下形式的 基于能量函数的分布 $$ p(\\mathbf x) = \\frac{e^{-E(\\mathbf x)}}{Z} $$ 其中 $E(\\cdot)$ 是能量函数，上界 $- \\log Z$ 被称为 自由能 变分贝叶斯：近似 $$ p_\\Theta(\\mathbf z | \\mathbf x) =\\frac{p_\\Theta(\\mathbf x | \\mathbf z) p_\\Theta(\\mathbf z )}{p_\\Theta(\\mathbf x)}$$ 生成模型的 $\\mathbf z$ 潜变量的后验分布。在这种情况下，目标是找到 证据 $\\log p_\\Theta(\\mathbf x)$ (ELBO) 的变分下界 变分自编码器 (VAE)起点是包含潜变量的模型 潜变量 $\\mathbf z$ 具有指数族分布，例如高斯分布 可观测变量 $\\mathbf x | \\mathbf z$ 具有分布 $p_\\Theta(\\mathbf x | \\mathbf z ) = \\pi_d (\\mathbf x | d_\\Theta(\\mathbf z))$，其中 $d_\\Theta(\\cdot)$ 是一个解码器，例如 ANN，$\\pi_d$ 是一个简单的分布，例如以 $d_\\Theta(\\mathbf z)$ 为中心的高斯分布 由于存在复杂的解码器，计算 $p(\\mathbf z | \\mathbf x)$ 后验或 $p(\\mathbf x)$ 是不可行的，因此引入了一个辅助编码器来变分近似后验： 近似为 $q_\\Phi(\\mathbf z | \\mathbf x)= \\pi_e(\\mathbf z | e_\\Phi(\\mathbf x))$，其中 $\\pi_e$ 也是一个简单的分布，通常是均值和方差由 $e_\\Phi(\\cdot)$ 编码器输出的高斯分布 组合组件可以被认为是确定性自编码器的概率版本： 对于具体的 $\\mathbf x$，用 $q_\\Phi(\\mathbf z | \\mathbf x)$ 近似真实后验的变分目标是最小化 $$\\begin{align*}\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}\\log\\frac{q_\\Phi(\\mathbf z | \\mathbf x)}{p_\\Theta(\\mathbf x | \\mathbf z)p(\\mathbf z)} &amp;= \\= \\mathbb{KL}(q_\\Phi(\\mathbf z | \\mathbf x)&amp;\\Vert p(\\mathbf z))-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}(\\log p_\\Theta(\\mathbf x | \\mathbf z))\\end{align*}$$ 在第二种形式中， $\\mathbb{KL}(q_\\Phi(\\mathbf z | \\mathbf x) \\Vert p(\\mathbf z))$ 相似性 可以以封闭形式计算 $-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}(\\log p_\\Theta(\\mathbf x | \\mathbf z))$ 可以解释为期望的 重构误差 重构误差VAE 损失的 $$-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}\\log p_\\Theta(\\mathbf x | \\mathbf z)$$ 部分的重构误差解释需要将 $$- \\log p_\\Theta(\\mathbf x | \\mathbf z) = -\\log \\pi_d(\\mathbf x | d_\\Theta(\\mathbf z))$$ 重写为 $\\mathbf x$ 和 $p_\\Theta(\\mathbf x | \\mathbf z)$ 分布模式之间的某种距离，但在大多数情况下，这可以很容易地完成。 例如，如果 $\\pi_d$ 是一个标准的球形 $m$ 维高斯分布，均值为 $d_\\Theta(\\mathbf z)$，则 $$ p_\\Theta(\\mathbf x | \\mathbf z)= (2\\pi)^{-m/2}\\exp(-\\Vert d_\\Theta(\\mathbf z) - \\mathbf x\\Vert^2/2) $$ 因此，$$ - \\log p_\\Theta(\\mathbf x | \\mathbf z)= \\Vert d_\\Theta(\\mathbf z) - \\mathbf x\\Vert^2/2 - \\log ((2\\pi)^{-m/2}), $$ 即负对数概率是 $\\mathbf x$ 和分布均值 $d_e(\\mathbf z)$ 之间平方欧几里得距离的移位和缩放版本，可以看作是“重构的 $\\mathbf x$”，即 $\\mathbf{\\hat{x}}$。 VAE因此，使用高斯分布的 $\\pi_e$、$\\pi_d$ 和 $p(\\mathbf z)$ 我们有 讨论的变分目标最小化与最大化训练集数据点的 $p_\\Theta(\\mathbf x)$ 的通常 MLE 目标有何关系？如我们所见，目标 $$\\underset{\\Theta, \\Phi}{\\operatorname{argmin}}\\left(\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}\\log\\frac{q_\\Phi(\\mathbf z | \\mathbf x)}{p_\\Theta(\\mathbf x | \\mathbf z)p(\\mathbf z)}\\right)$$ 也可以重写为 $$\\underset{\\Theta, \\Phi}{\\operatorname{argmax}}\\left( \\log p_\\Theta(\\mathbf x)- \\mathbb{KL}(q_\\Phi(\\mathbf z | \\mathbf x) \\Vert p_\\Theta(\\mathbf z | \\mathbf x))\\right)$$ 因此，找到最小化 $\\Theta$ 和 $\\Phi$ 实际上等同于找到对数似然的最大变分下界，即我们有一个 MLE 优化的变分近似。 重参数化技巧VAE 通常使用梯度下降进行优化，但重构损失 $-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}(\\log p_\\Theta(\\mathbf x | \\mathbf z))$ 涉及从 $q_\\Phi(\\mathbf z | \\mathbf x)$ 采样，这使其不可微。 “重参数化技巧”通过将采样操作分解为从标准分布采样（与参数无关）和样本的依赖变换来解决这个问题。 通过从常量分布 $q_0$（例如标准正态分布）采样和基于编码器输出的 $t$ 变换进行重参数化，我们可以将梯度运算符推入期望值内部： $$\\nabla_{\\Phi, \\Theta}-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}\\log p_\\Theta(\\mathbf x | \\mathbf z)$$ 可以重写为 $$-\\mathbb E_{\\epsilon \\sim q_0}\\nabla_{\\Phi, \\Theta} \\log p_\\Theta(\\mathbf x | t(e_\\Phi(\\mathbf x), \\epsilon))$$ 并使用蒙特卡罗方法近似为 $$-\\frac{1}{n}\\sum_{i=1}^{n}\\nabla_{\\Phi, \\Theta} \\log p_\\Theta(\\mathbf x | t(e_\\Phi(\\mathbf x), \\epsilon_i))$$ 确定性 vs 变分自编码器与确定性自编码器相比，VAE 是具有明确定义分布的真正生成模型。一个结果是，它们可以通过对潜在先验进行采样并解码它来生成高质量的新样本： $\\beta$-VAE图像 VAE 使用标准 VAE 损失容易产生模糊图像，因为损失激励优化的解码器输出 $\\mathbf{\\hat{x}}=d_\\Theta(\\mathbf z)$ 重构，这是解码器映射到 $\\mathbf z$ 的所有输入的平均值。 减少此问题的一种简单方法是减少相似性损失的权重，使自动编码器更接近确定性编码器： $$\\mathcal L_{\\beta-VAE} = \\beta\\mathbb{KL}(q_\\Phi(\\mathbf z | \\mathbf x) \\Vert p(\\mathbf z))-\\mathbb E_{\\mathbf z \\sim q_\\Phi(\\mathbf z | \\mathbf x)}(\\log p_\\Theta(\\mathbf x | \\mathbf z))$$ 当 $\\beta&lt; 1$ 时，重构损失的权重大于正常 VAE 损失，而 $\\beta=0$ 则导致完全确定性的自动编码器。 离散 VAE到目前为止，我们假设潜在变量 $p(\\mathbf z)$ 是连续的，但该架构也可以与 离散潜在变量 一起使用。 与连续情况相比，这需要 编码器中的 离散化层，将输入映射到离散代码 一种 训练方法，与 $p_\\Theta(\\mathbf z)$ 和 $q_\\Phi(\\mathbf z | \\mathbf x)$ 为离散变量兼容 离散化离散化编码器输出的策略包括 简单地将输入坐标 逐个舍入 到最近的整数代码，例如，当潜在变量被假定为二进制向量时，舍入到 0 或 1 完整的 向量量化：如果潜在变量是具有 $K$ 个离散值的分类集合（例如向量或矩阵），则来自 $\\mathbb R^D$ 的输入向量可以使用学习的 代码簿 ${\\mathbf e_k\\in \\mathbb R^D}_{k\\in[1\\dots K]}$ 映射到分类值。每个 $\\mathbf e_i$ 输入嵌入被映射到最近代码簿条目的索引作为其潜在表示 $z_i$： $$ z_i = \\underset{k}{\\operatorname{argmin}}(\\Vert \\mathbf e_i - \\mathbf e_k\\Vert_2) $$ VQ-VAE 离散化在 VQ-VAE 方法中，$q(\\mathbf z| \\mathbf x)$ 潜在代码在第一个解码步骤中映射回相应的代码簿条目 $\\mathbf e_{z_i}$： VQ-VAE 分布和损失由于 VQ-VAE 解码器是确定性的且先验是均匀的，因此 $\\mathbb {KL}(q(\\mathbf z| \\mathbf x)\\Vert p(\\mathbf z))$ 相似性损失是常数，可以忽略。量化是不可微的，因此只能使用所谓的 直通估计器，其中梯度从解码器传递通过量化层，就像它是恒等函数一样： 使用直通学习代码簿基于直通方法的一个后果是代码簿没有梯度。学习代码簿的解决方案包括 引入一个额外的 代码簿损失 项，测量编码器输出和最近代码簿条目之间的距离。总损失变为 $$ \\mathcal L=-\\log p_\\Theta (\\mathbf x | \\mathbf z_q(\\mathbf x)) + \\Vert sg(\\mathbf z_{\\mathbf e}(\\mathbf x)) - \\mathbf e\\Vert_2^2 $$ 其中 $sg$ 是 stop_gradient 操作符 定期更新代码簿条目，使其更接近分配给它们的输入的 移动平均值 使用 Gumbel-softmax 的离散 VAE一种更有原则的方法来训练离散的、基于代码簿的、但真正概率的 VAE 使用一种适用于分类潜在变量的重参数化技巧版本。 该方法基于这样一个事实，即类似于从任何高斯分布采样，从任何分类分布采样也可以分解为从常量分布采样，然后确定性地变换样本。 所讨论的分布是具有密度函数的 标准 Gumbel 分布 $$\\mathcal G(x) = e^{-(x+e^{-x})}$$ 使用 Gumbel-softmax 的离散 VAE 续$\\mathcal G$ 标准 Gumbel 分布的一个重要性质是，如果分类分布由对数几率（logits）描述 $$a_1, \\dots, a_n$$ 那么可以通过从 $\\mathcal G$ 中抽取 $n$ 个样本来对其进行采样： $$g_1, \\dots, g_n\\sim\\mathcal G$$ 然后计算 $$\\underset{i}{\\operatorname{argmax}} (a_i + g_i)$$ 样本变换中的 argmax 的存在使其不可微，但这可以通过以下方式解决 用 softmax 操作符替换它 让 $\\mathbf z$ 潜在变量具有描述分类分布的任何向量作为值，而不仅仅是 one-hots 并将代码簿条目的 $\\mathbf z$ 加权和传递给解码器 例如，对于输出单个分类潜在变量的对数几率的 $e_\\Phi$ 编码器，这种 Gumbel-softmax 重参数化 产生的重构损失为 $$\\mathcal L_{rec}= - \\mathbb E_{g_1,\\dots,g_n \\sim \\mathcal G}\\log p_\\Theta(\\mathbf x | softmax_\\tau(e_\\Phi(\\mathbf x)+ \\langle g_1,\\dots,g_n\\rangle))$$ 并且可以通过通常的蒙特卡罗方法估计梯度。 softmax 对 argmax 近似的紧密性取决于 $\\tau$ 温度参数： $$softmax_\\tau(\\langle x_1,\\dots,x_n\\rangle)= \\left\\langle\\frac{e^{ x_1/\\tau}}{\\sum_{i=1}^n e^{ x_i/ \\tau}},\\dots, \\frac{e^{x_n/\\tau}}{\\sum_{i=1}^n e^{x_n / \\tau}}\\right\\rangle$$ 因此在训练期间逐渐降低 $\\tau$，直到它接近 0。 DALL-E 视觉标记器基于离散 VAE 的视觉标记器的一个重要示例是 DALL-E 中使用的标记器： 输入图像为 256x256 编码器和解码器都是卷积的 潜在变量 $\\mathbf z$ 是一个 32x32 的分类变量网格，具有 8192 元素的“视觉词汇表”的均匀先验 解码器使用一种特殊的“logit-Laplace”分布，而不是通常的高斯和拉普拉斯分布（分别对应于 $L_2$ 和 $L_1$ 重构误差度量） KL 相似性损失的权重为 $\\beta=6.6$，这导致了更好的代码簿使用，并在训练结束时导致更好的重构误差 $\\tau$ softmax 温度从 1 开始，在训练期间逐渐降低到 1/16 视觉 Transformer (ViT)通用 ViT 架构 ViT 嵌入通过使用特定的补丁大小 $P$ 对图像进行分块来创建嵌入。也可以使用步幅，$1\\times1$ 的补丁也适用于逐像素处理。 每个补丁然后被输入到以下任一层： 展平后的线性投影层（学习的） CNN 主干（通常是固定的） 实验表明，对于普通的 ViT，1D 绝对位置编码效果最好。 ViT 分类标记虽然补丁嵌入适用于局部图像表示，但分类还需要全局表示。这是通过一个特殊的标记称为分类标记的可学习池化过程来实现的。 这个 CLS（或“类”）标记被预先添加到补丁嵌入中。该标记的初始值在训练期间被学习。 对应于该标记的输出用于分类。在预训练期间，这被输入到一个 3 层 MLP，而在微调期间使用单个线性层。 更高分辨率处理由于较大的图像将被分解为较长的补丁序列，因此我们应该检查模型是否能够处理这一点。 MHA 和 FFN 仅包含逐点层，因此它们能够处理较长的序列。（由于 $W_Q, W_K, W_V$ 矩阵未针对这一点进行训练，可能会出现性能下降。） 唯一的限制因素是学习的位置编码。为了扩展这一点，可以使用简单的线性方法插值较长序列的位置编码值，以保持信息完整。 多尺度处理SWIN - 分层 TransformerSWIN 是一种基于 Shifted Window 的 Transformer 架构，能够使用多种分辨率级别处理任意大小的图像。这种方法基于局部注意力的思想，其中注意力仅限于输入的某个特定区域。这是通过非重叠注意力窗口的窗口机制实现的。 在每个层次级别，标记通过可学习的投影进行合并（池化）（其他方法，如 T2T，将这些向量连接起来）。合并因子通常小于注意力窗口大小（例如：2x2 池化，4x4 注意力窗口）。 SWIN - 基于窗口的 MHA通过使用这种窗口化注意力机制，MHA 的计算复杂度从二次降低到线性，其中 $h$ 和 $w$ 是补丁中 $C$ 通道图像的高度和宽度。 为了给出计算复杂度的下限，我们可以假设： $\\Omega(MHA) = 4\\cdot hw \\cdot C^2 + 2\\cdot(hw)^2\\cdot C$ $\\Omega(MHA_{Windowed}) = 4\\cdot hw \\cdot C^2 + 2\\cdot M^2 hwC$ 假设 $M$ 是注意力窗口大小。 SWIN - 窗口移动这种简化禁用了远距离补丁之间的信息流。为了解决这个问题，引入了窗口移动机制。这种移动机制确保在连续层中注意力窗口被移动，从而通过多层实现信息流动。 通过移动窗口，其中一些将部分为空。尽管可以使用填充来填充这些窗口，但在这些移动操作期间循环滚动图像更为高效。 SWIN - 可学习的相对注意力偏差作者发现，相对于绝对位置编码，一个简单的可学习偏差项更适合在注意力窗口中编码相对位置信息。 由于每个窗口是一个 $M \\times M$ 的正方形，每个轴的相对位置在 $[-M+1, M-1]$ 范围内。因此，偏差矩阵的大小为 $[(2M-1)^2\\cdot heads]$。$B$ 是从这个学习的矩阵中组装的，并应用于注意力中： $$O = softmax(QK^T/ \\sqrt{d_k} + B)V$$ 在更高分辨率的输入情况下，使用双三次插值来上采样偏差矩阵。 分层 ViT 的优势 研究表明，这些分层 transformer 在性能和准确性方面比原始 ViT 提供了更高的组合。 学习通用表示通用模型已经存在了一段时间（ImageNet 挑战等），这些模型的大规模预训练通常包括单一的分类任务。 然而，随着基础 transformer 表示模型的兴起，对更强预训练方法的需求也随之增加。通过额外的预训练任务，这些模型具有更好的泛化能力，甚至可能实现少样本学习。 迷你模型库TrOCRTrOCR 是一个简单的、基于 transformer 的编码器-解码器模型，执行 光学字符识别。 它基于原始的、完整的编码器-解码器 transformer 架构，由以下部分组成： 一个 视觉 transformer 作为编码器 一个 文本 transformer 作为解码器 编码器和解码器的权重均从预训练的单模态模型初始化，并在 OCR 特定的训练数据上进行预训练和微调。 TrOCR: 编码器编码器将输入调整为固定大小，将其分解为补丁，并将每个展平的补丁线性投影到嵌入中。补丁的绝对空间位置由可学习的 1D (!) 位置嵌入表示。 TrOCR: 解码器解码器是一个标准的 transformer 解码器，交叉关注编码器的输出： TrOCR: 初始化和训练 编码器权重使用预训练的视觉 transformer 权重（DeiT 或 BEiT）初始化 解码器权重使用仅解码器的 LLM 权重（RoBERTa 或 MiniLM）初始化，因此结构差异（大小、缺少交叉注意力）通过手动设置映射和随机初始化来处理 整个模型首先在一个非常大的合成数据集上进行 预训练，然后在较小的现实数据集上进行预训练 在下游任务上的最终测试是通过任务特定的微调完成的 LLaVALLaVA [大型语言和视觉助手] 是一个大型视觉语言模型，通过扩展一个指令微调的 LLM 以处理混合视觉和语言输入的多模态指令，从而训练用于 视觉指令跟随。 LLaVA 基于 Vicuna，一个指令微调的 LLaMA，它是一个基于 transformer 解码器的 LLM 一个预训练的、基于 ViT 的 CLIP 图像编码器 一个可训练的投影矩阵，将视觉 CLIP 嵌入映射到 LLaMA 模型的词嵌入输入空间 在架构上，与 TrOCR 不同，LLaVA 并不是基于原始的完整 transformer 架构，因为解码器没有交叉关注编码的视觉输入，而是通过因果自注意力处理它。 LLaVA: 数据集视觉指令跟随数据集是使用仅语言的 GPT-4 作为强大的教师生成的： 视觉上下文始终是单个图像 图像的描述以两种形式提供： 作为描述上下文图像的标题列表 作为边界框坐标列表及其各自的类型 使用来自 COCO 数据集 的图像，GPT-4 被少样本提示生成 助手和用户之间关于图像的 对话 图像的 详细描述 基于图像的 深入逐步推理 LLaVA: 训练通常，仅为示例的助手回答部分生成交叉熵损失。训练包括两个阶段： 预训练：首先，模型在 595K 图像-标题对上进行预训练，冻结 CLIP 编码器和 Vicuna 解码器，使用简单的图像描述指令上下文。这可以解释为训练投影矩阵成为 Vicuna 的视觉标记器 端到端微调：解冻 Vicuna 权重，并在 GPT-4 生成的 158K 多模态指令跟随数据集上联合微调投影矩阵和 LLM 权重 LLaVA 1.5最近（2023 年 10 月），发布了一个新的改进版本 1.5 的 LLaVA，它目前是公共 VL 基准测试中表现最好的 VLM。更改相对较小： 使用 3 层感知器进行视觉语言映射，而不是线性投影 使用更大的 LLaMA 模型（13B 参数而不是 7B） 放大输入图像分辨率 提炼提示 在额外的学术 VQA 数据集上训练","link":"/AI/NLP/NLP-VisualModels/"},{"title":"NLP-Zoo","text":"模型介绍 神 TM 动物园 LLM Zoo我们已经看到了动物园中的一些居民… 但还有更多！我们将看看一些最重要的语言模型。 （注意：大多数模型在发布时在许多 NLP/NLU 数据集上达到了最先进的水平。我们不会在每个模型下提到这一点。） BERT 家族BERT提醒一下：BERT 是一种基于transformer encoder架构的上下文（子）词表示。它在两个自我监督任务上进行了训练： 掩码语言模型（MLM） 下一句预测（NSP） 它有几种尺寸： 基础版：12 个 Transformer 块，110M 参数 大型版：24 个 Transformer 块，340M 参数 BERT 催生了一整个模型家族，它们保留了架构并通过微调细节寻求改进。 超参数Hyperparameters，BERT 带来了两个新的训练任务，但 NSP 被证明太简单了。 ALBERT 用句子顺序预测替代了它 RoBERTa 完全放弃了这个任务 RoBERTa 证明了训练更长时间和使用更多数据的重要性。 数据大小：16GB $\\rightarrow$ 160GB 批量大小：256 $\\rightarrow$ 8K 训练步骤：100K（相对）$\\rightarrow$ 500K 动态掩码：[MASK]标记的位置每次运行都会改变 这些变化在各种任务上带来了$3-4%$的改进（例如在 SQuaD 上减少了$60%$的错误率）。 跨距Spans，BERT 的掩码方案（[MASK]替换单个标记）使其在生成任务中难以使用（例如在问答中填充答案）： 奥克尼群岛上最古老的定居点是什么？ 最古老的定居点是[MASK]。 最古老的定居点是[MASK] [MASK]。 … （Skara Brae 实际上是 4 个标记：S ##kara B ##rae） 另一个问题是被掩码的标记被假定为条件独立的。 SpanBERT 掩码随机长度的跨距（平均 3.8 个标记） 基于跨距周围的标记预测它们： $$ \\mathbf{y}_i = f(\\mathbf{x}_{s-1}, \\mathbf{x}_{e+1}, \\mathbf{p}_{i-s+1}) $$ 引入了跨距边界目标 $\\mathcal{L}_{SBO}$，使得 $$ \\mathcal{L}(x_i) = \\mathcal{L}_{MLM}(x_i) + \\mathcal{L}_{SBO}(x_i) = -\\log P(x_i|\\mathbf{x}_i) - \\log P(x_i|\\mathbf{y}_i) $$ XLNet 完全不使用[MASK]标记或 MLM 自回归 autoregressive 训练任务在排列序列上（仍然是双向上下文） 可以建模上下文和目标之间的依赖关系 性能训练类似 BERT 的模型速度慢且占用大量内存。ALBERT通过以下方式解决了这些问题： 将$V \\times H$嵌入矩阵分解为两个矩阵：$V \\times E$ 和 $E \\times H$；（$V$：词汇表，$H$：隐藏层大小，$E$：嵌入大小；在 BERT 中，$E = H$） 层之间的权重共享 结果模型的参数比相应的 BERT 模型少 18 倍，训练速度快约 1.7 倍。然而，更大的模型（xxlarge）在性能上超过了 BERT Large （如果它们能收敛的话…）。 新技术DeBERTa 通过技术创新改进了常规 BERT： 解耦注意力（disentangled）机制为每个标记分配两个向量： 内容 位置 相对位置编码 在 softmax 层之前引入绝对位置 它在 SuperGLUE 中表现优于人类基线（90.3 对 89.8）。 全栈模型T5文本到文本转换 Transformer通过以下方式解决 NLP 任务： 将它们转换为带提示的 seq2seq 问题 用解码器替换 BERT 上的分类器头 它的训练方式为： 去噪 Denoising 目标：丢弃 15%的标记（类似于 MLM；优于自回归目标） 多任务预训练 在单个 NLP 任务上进行微调 最大的模型有 110 亿参数，并在 1 万亿个标记上进行了训练。 解码器模型GPT 家族GPT 家族是最著名的大型语言模型（LLM）。它们由OpenAI创建，规模不断增加： 模型 参数量 语料库 上下文长度 GPT-1 110M 1B 512 GPT-2 1.5B 40GB 1024 GPT-3 175B 300B 2048 InstructGPT 175B 77k 2048 GPT-4 ? ? 8192 GPT-3.5 和 GPT-4 的详细信息尚不可用。有一些估计，但许多甚至无法正确描述之前的模型。 GPT-1最初，GPT 被设计为一个自然语言理解（NLU）框架，类似于 ELMo 或 BERT： 它是第一个推广预训练 + 微调方法用于 NLP 任务的模型 自回归预训练并非出于文本生成的动机 结果： GPT-1 在测试的 12 个任务中有 9 个达到了最先进的水平 它展示了一些零样本能力 GPT-2更大的模型尺寸带来了更好的零样本性能： GPT-3架构和训练的变化： 交替使用密集和稀疏（dense and sparse）注意力层 采样训练（并非使用所有训练数据） 在几个任务上的少样本性能非常接近最先进水平。 问题： 防止基准测试的记忆化 输出中的偏见（性别、种族、宗教） 训练期间的高能耗（通过相对较小的训练语料库缓解） InstructGPT增加了指令支持。 RLHF（之前提到过） 与增加预训练分布对数似然的更新混合，以防止模型退化 1.3B 的 InstructGPT 比 175B 的 GPT-3 更受欢迎 API prompts 比 FLAN 或 T0 数据集更好 降低了毒性（toxicity），但没有减少偏见（bias） GPT-4更大、更好、多模态（视觉）。在考试中表现达到人类水平（前 10%）。 指令： 对考试没有帮助 扭曲（Skews）了置信度校准（calibration）（答案的对数似然与实际表现的相关性） 两种安全方法： RLHF 基于规则的奖励模型（RBRMs） 其他模型家族GPT 并不是唯一的 LLM 模型“家族”。还有一些竞争对手，包括开源和闭源的。 闭源 Claude（版本 3） Google 的 Gemini 开源 Meta 的 Llama（版本 3.2） Mistral（版本 0.3） 阿里巴巴的 Qwen（版本 2.5） 其他模型仅解码自回归模型已成为事实上的 LLM 标准，并且提出了许多其他模型。以下是一些值得注意的例子。 Megatron GPT（8.3B）和 BERT（3.9B）版本。训练于 174GB 文本 引入了模型并行（parallelism） Gopher 280B，训练于 MassiveText，但仅在 2350B 中的 300B 标记上（12.8%） 使用相对位置编码，允许对比训练期间看到的更长序列进行推理 GLaM 一个稀疏模型，具有 1.2T 参数，训练于 1.6T 标记 使用专家混合（Mixture of Experts）层与 transformer 层交错 每个标记仅激活模型的 8%（96.6B）训练成本是 GPT-3 的 $\\frac{1}{3}$ LaMDA 137B，训练于 1.56T 标记 一个专门用于对话的模型；训练语料库的 50% 由对话组成 针对质量、安全性和基础性（“基础指标”）进行微调 端到端模型，包括调用外部 IR 系统以确保基础性 FLAN 基于 LaMDA。使用数据集成方法进行指令微调，来自 62 个 NLP 数据集 比 LaMDA、GPT-3 或 GLaM 更好的零样本性能 PaLM 最大的模型之一：540B 参数，训练于 780B 文本 使用Pathways技术在 2 个 Pods 中的 6144 个 TPU v4 芯片上训练 不连续的改进：在某个模型大小之后准确性急剧跳跃（而不是连续的幂律） 突破性表现。在几个任务上，它比 平均人类表现 监督系统更好 负面趋势扩展法则已经证明，增加模型规模会沿着幂律曲线提高性能。这导致了越来越大的模型被发布。 问题大型模型有几个问题： 它们的训练和推理成本很高 只有少数参与者能够负担得起训练它们 即使在“低端”设备（例如 8 个 A100）上运行它们也是有问题的 它们有相当大的碳足迹，以至于论文现在通常会报告它 大多数模型是专有的和闭源的 新趋势 Chinchilla最近出现了一种新趋势，即在更多的标记上训练较小的模型，以实现可比甚至更好的结果。这是可能的，因为 上述模型通常训练不足 指令微调非常有效且便宜 Chinchilla 70B 参数，训练于 1.5T 标记 使用与 Gopher 相同数量的 FLOPs 和相同的训练集 性能优于 GPT-3 和 Gopher LLaMaChinchilla 是闭源的。LLaMa 是基于开放数据源创建类似 Chinchilla 模型的尝试。 最大的模型是 65B，训练于 1.4T 标记 包括架构上的“最佳实践” 预归一化（GPT3）：在输入而不是输出上归一化 SwiGLU 激活（PaLM） 旋转位置嵌入（GPTNeo） 即使是 13B 模型也优于 GPT-3 注意：不能用于商业用途。 LLaMa 变体 LLaMa2 更大（70B 参数，2.0T 标记，4k 上下文） 聊天指令 可以用于商业用途 Alpaca 斯坦福基于 LLaMa 7B 的指令模型。便宜（$600） 基于 ChatGPT 的 Self-instruct（不可商业使用） Vicuna 基于 LLaMa 13B + 来自 ShareGPT 的 70k 交互，成本 $300 比 Alpaca 好 90%，在 GPT-4 评判下接近 ChatGPT 10% 以内 多语言模型上述大多数模型仅在英语数据上训练，或最多包含 10%的非英语文本。然而，有几个模型有多语言版本。 mBERT： 一个多语言的 BERT 基础模型 在 104 种语言的维基百科上训练 XLM-RoBERTa 在 2.5TB 的 Common Crawl（CC）数据上训练，涵盖 100 种语言 在低资源语言上比 mBERT 高出 23% 性能与单语言的 RoBERTa 相当 XLM-RoBERTa 证明了维基百科不足以训练一个有竞争力的模型。 mT5 在包含 10,000 页或更多页面的 101 种语言的 CC 数据上训练 单语言性能接近 T5 跨语言零样本性能是最先进的，但偶尔会意外翻译成英语 BLOOM 一个在 46 种自然语言和 13 种编程语言上训练的解码器模型 1.61TB 的 ROOTS 语料库由国际研究人员合作编译 BLOOMZ 变体经过多语言多任务微调 迄今为止最强大的多语言 LLM 编码 许多 LLM 在预训练语料库中使用了一些源代码。这有助于推理，并允许它们进行一定程度的代码生成。而编码模型则明确为后者任务进行训练。 Code Llama是基于 LLaMa 2 的模型。它有相同的尺寸。由于编码模型还需要理解自然语言（NL）指令，因此基于常规 LLM 的模型表现更好。 它有三个版本： Code Llama：基础模型 Code Llama - Instruct：微调版本 Code Llama - Python：进一步在 Python 代码上训练 Code Llama 详情 训练语料库（500B）： 85% 来自 GitHub 的源代码 8% 与代码相关的 NL 讨论（如 StackOverflow 等） 7% NL 批次以保持 NLU 性能 Python 模型使用额外的 100B 个 Python 代码标记进行训练。 训练特点Code Llama 有两个额外的训练目标： 填充：在给定上下文的情况下预测程序的缺失部分 用于代码补全、文档生成等 仅较小的模型进行训练 长输入上下文：以实现库级别的推理 将最大上下文长度从 4096 增加到 100,000 在专门的长上下文微调阶段进行训练 指令微调通过自我指令完成： 生成单元测试和代码 添加通过测试的第一个代码片段 结果 指令：LLaMa 2 + 自我指令。生成单元测试和代码，并添加通过单元测试的代码。 其他模型闭源： Codex/copilot AlphaCode phi-1 GPT-4 开源： SantaCoder StarCoder 多模态图像-文本模型与 GPT-3 相比，GPT-4 的主要创新是其多模态性；特别是其使用图像输入的能力。然而，它并不是第一个具有图像到文本能力的系统。 主要的视觉机器学习目标是图像分类：给定一张图像，系统必须返回描述其内容的标签（集）。这通常通过在数百万标记图像上训练的监督系统来完成。 使用大型语言模型（LLM），可以在大型未标记的文本+图像语料库（网络数据）上预训练具有良好零样本性能的通用模型。以下是两个例子。 CLIPCLIP 通过将图像和文本编码到相同的嵌入空间来执行图像分类。 在训练期间，编码器使用对比目标进行训练。在测试时，类标签被编码，并返回与图像最（余弦）相似的标签。 FlamingoFlamingo 是一个“视觉语言模型”，可以基于混合的文本和视觉输入生成文本。 它使用冻结的视觉和文本编码器（例如 CLIP 和 Chinchilla），并且只训练操作其输出的语言模型。 开源模型上面讨论的许多模型都是闭源的；通常，训练数据也由专有语料库组成。然而，现在有几个开源的 LLM 可在 Hugging Face Hub 上使用： BLOOM 是完全开源的，数据和模型都是如此。然而，它的开发已经完成，不再进一步更新 LLaMa 是在开放数据上训练的，LLaMa 2 及以上版本可以免费使用。Llama 3.x 提供从 1B 到 405B 的模型 Mistral 是另一个替代方案，提供指令微调和 MoE 模型供下载 LAIONLAION（Large-scale Artificial Intelligence Open Network 大规模人工智能开放网络）旨在提供 100% 免费和开放的 LLM 管道，包括数据集、工具和模型。 一些精选项目： Openclip：CLIP 的开源重新实现 LAION5B：一个包含近 60 亿图像-文本对的语料库 OpenAssistant：正在开发的开源对话 AI。你也可以通过以下方式提供帮助： 添加新对话 标记现有对话 等等","link":"/AI/NLP/NLP-Zoo/"},{"title":"Numerical Methods II - Part 2","text":"时隔一年，老师添加了一点新题，所以又来更新一下。 Numerical Integral, Matrices of Geometrical Transforms近似计算定积分Write an M-file for using quadrature formulas.The name of the function be: numint Input arguments: integrand (as a string),the endpoints of the interval (a, b),number of divisors (n),type of the quadrature (rectangle, trapezoid, simpson) Output argument: the result of the integral. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117% 7.1 近似计算定积分% 积分（字符串）% 区间 (a, b) 的端点% 除数 (n)% 正交类型（矩形、梯形、辛普森形）function integralResult = numint(integrand, b, a, n, method)arguments % 检查integrand是否为字符串 integrand (1,1) string % 检查a和b是否为数值，且a小于b b (1,1) double {mustBeNumeric} a (1,1) double {mustBeNumeric, mustBeLessThan(a, b)} % 检查n是否为正整数 n (1,1) double {mustBeInteger, mustBePositive} % 检查method是否为有效的字符串选项 method (1,1) string {mustBeMember(method, [&quot;rectangle&quot;, &quot;trapezoid&quot;, &quot;simpson&quot;])}end % 将字符串形式的被积函数转换为函数句柄 f = str2func(integrand); % 根据所选的方法计算积分 switch method case 'rectangle' integralResult = rectangleMethod(f, a, b, n); case 'trapezoid' integralResult = trapezoidMethod(f, a, b, n); case 'simpson' integralResult = simpsonMethod(f, a, b, n); otherwise error('Unknown method. Please choose rectangle, trapezoid, or simpson.'); endend% 首先计算每个小区间的宽度 h，然后遍历每个小区间% 计算每个区间中点的函数值，并将所有这些值累加起来% 最后，将累加的和乘以小区间的宽度，得到积分的近似值% 这个方法在处理高度振荡或非常不规则的函数时可能不够精确% 在这种情况下，可能需要更多的区间（即更大的 n）function result = rectangleMethod(f, a, b, n) % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = 0; % 对每个小区间进行迭代 for i = 1:n % 计算当前小区间的中点 x_mid = a + (i - 0.5) * h; % 计算函数在中点的值并累加 integralSum = integralSum + f(x_mid); end % 计算最终的积分近似值 result = h * integralSum;end% 首先计算每个小区间的宽度 h% 然后，我们初始化积分和为区间两端点处函数值的平均值% （这是因为在梯形法中，区间两端的点只被计算一次）% 接着，我们遍历每个小区间的内部点，将这些点处的函数值累加到积分和中% 最后，将累加的和乘以小区间的宽度，得到积分的近似值% 这种方法比矩形法更精确，尤其是在函数比较平滑的情况下% 然而，对于高度振荡或非常不规则的函数，它仍然可能不够精确function result = trapezoidMethod(f, a, b, n) % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = 0.5 * (f(a) + f(b)); % 对每个小区间的内部点进行迭代 for i = 1:(n-1) x = a + i * h; integralSum = integralSum + f(x); end % 计算最终的积分近似值 result = h * integralSum;end% 我们首先确保 n 是一个正的偶数。然后，我们计算每个小区间的宽度 h% 接着，我们初始化积分和为区间两端点处函数值的和% 在遍历每个小区间的内部点时，我们根据这些点是奇数位置还是偶数位置% 分别乘以 4 或 2（这是辛普森法的特点）% 最后，将累加的和乘以 h/3，得到积分的近似值function result = simpsonMethod(f, a, b, n) % 确保n为偶数 if mod(n, 2) ~= 0 error('n must be a positive even integer.'); end % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = f(a) + f(b); % 对每个小区间的内部点进行迭代 for i = 1:n-1 x = a + i * h; if mod(i, 2) == 0 integralSum = integralSum + 2 * f(x); else integralSum = integralSum + 4 * f(x); end end % 计算最终的积分近似值 result = (h / 3) * integralSum;end 原点 affine 变换Write an M-file, what gives the matrix of any affin transform with fixed point in OriginThe name of the file: affin1 Input arguments: The images of points (0, 1) and (1, 0). Output argument: The matrix of the transform. If someone calls the function without input arguments give them an opportunity for the graphical input. 12345678910111213141516171819202122232425262728% 7.2 计算具有原点固定点的 affine 变换矩阵% 输入参数:% imageOf01 - 点 (0, 1) 变换后的图像% imageOf10 - 点 (1, 0) 变换后的图像% 输出参数:% A - 变换的矩阵function A = affin1(imageOf01, imageOf10) if nargin == 0 % 如果没有输入参数，通过图形界面获取输入 disp('请图形化输入点 (0, 1) 和 (1, 0) 变换后的图像'); [x1, y1] = ginput(1); % 获取点 (0, 1) 变换后的图像 [x2, y2] = ginput(1); % 获取点 (1, 0) 变换后的图像 imageOf01 = [x1; y1]; imageOf10 = [x2; y2]; end % 验证输入参数 if ~isequal(size(imageOf01), [2, 1]) || ~isequal(size(imageOf10), [2, 1]) error('输入参数的大小必须是 2x1'); end % 计算 affine 变换矩阵 A = [imageOf10, imageOf01]; % 输出变换矩阵 disp('Affine 变换矩阵为:'); disp(A);end 12% 输入示例A = affin1([2; 3], [4; 1]) 三角变换Write an M-file, what gives the matrix of any affin transform.The name of the m-file: affin2 Input arguments: a triangle (with the coordinates of the edges) and the image of the triangle (also with the edges) Output argument: The matrix of the transform. Give an opportunity for graphical input (as in the previous exercise) Draw a figure in both cases. 123456789101112131415161718192021222324252627282930313233343536% 7.3 计算基于一个三角形及其映射后的三角形的仿射变换矩阵%% 使用方法:% A = affin2(triangle, image_triangle)% 其中 triangle 和 image_triangle 是包含三角形顶点坐标的 3x2 矩阵% 如果没有给出参数，则使用图形输入function A = affin2(triangle, image_triangle) if nargin == 0 % 没有输入参数，使用图形输入 disp('点击以定义原始三角形的顶点：'); triangle = ginput(3); disp('点击以定义映射后三角形的顶点：'); image_triangle = ginput(3); end if size(triangle, 1) ~= 3 || size(image_triangle, 1) ~= 3 error('两个三角形都必须有 3 个顶点。'); end % 构造变换矩阵 % 添加一行 1 以处理仿射变换 T = [triangle, ones(3, 1)]; T_image = [image_triangle, ones(3, 1)]; % 求解变换矩阵 A = T_image' / T'; % 绘制原始三角形和变换后的三角形 figure; plot([triangle(:,1); triangle(1,1)], [triangle(:,2); triangle(1,2)], 'b-o'); hold on; plot([image_triangle(:,1); image_triangle(1,1)], [image_triangle(:,2); image_triangle(1,2)], 'r-o'); legend('原始三角形', '变换后的三角形'); title('三角形的仿射变换'); hold off;end 1234% 输入示例triangle = [0, 0; 1, 0; 0, 1];image_triangle = [2, 3; 4, 1; 5, 5];A = affin2(triangle, image_triangle) 等边三角形Give 3 points in the plane. Two of them, P (2; 3) and Q (4; 2), lie on different sides of an equilateral triangle.The third point, S (3; 3), is the centroid of the triangle.Use MATLAB to find the vertices of a triangle (by adding the coordinates of the vertices) and make an illustration for the exercise. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162% 定义点 P, Q 和 SP = [2, 3];Q = [4, 2];S = [3, 3];% 计算三角形的边长side_length = sqrt((Q(1) - P(1))^2 + (Q(2) - P(2))^2);% 计算外接圆的半径R = side_length / sqrt(3);% 计算三角形的顶点% 我们已经有两个顶点（P 和 Q），我们需要找到第三个顶点（R）% 计算 PQ 的中点mid_PQ = (P + Q) / 2;% 计算中点到质心的向量vec_mid_to_centroid = S - mid_PQ;% 计算 PQ 的垂直向量perpendicular = [vec_mid_to_centroid(2), -vec_mid_to_centroid(1)];% 归一化垂直向量perpendicular = perpendicular / norm(perpendicular);% 计算第三个顶点R_vertex = S + R * perpendicular;% 检查 R_vertex 是否与 S 在 PQ 的同一侧% 如果不是，反转方向if dot(R_vertex - mid_PQ, vec_mid_to_centroid) &lt; 0 R_vertex = S - R * perpendicular;end% 绘制三角形figure;hold on;grid on;axis equal;% 绘制点plot(P(1), P(2), 'ro');plot(Q(1), Q(2), 'ro');plot(S(1), S(2), 'bo');plot(R_vertex(1), R_vertex(2), 'go');% 绘制三角形的边plot([P(1), Q(1)], [P(2), Q(2)], 'r');plot([P(1), R_vertex(1)], [P(2), R_vertex(2)], 'r');plot([Q(1), R_vertex(1)], [Q(2), R_vertex(2)], 'r');% 添加注释text(P(1), P(2), ' P');text(Q(1), Q(2), ' Q');text(S(1), S(2), ' S (质心)');text(R_vertex(1), R_vertex(2), ' R');title('具有顶点 P, Q 和 R 的等边三角形');xlabel('X 轴');ylabel('Y 轴');hold off;","link":"/Math/Matlab/Numerical-Methods-II-1/"},{"title":"Numerical Methods II","text":"很多很好玩的数值方法是 Matlab 苦手，所以很多高血压代码 Machine Numbers机器数转十进制Our first M-file computes the value of a machine number. Let us choose fl1 as name of function and of course as name of the file also.We give a vector as input parameter. The last coordinate of vector gives thecharacteristic of machine number (in tenary numeral system). We store the signedmantissa in the other coordinates. The output argument be the real number what is represented by our machine number. The first bit of mantissa we can use for storing the sign of the number.(Originally this bit is surely 1.) When the number is positive, then the signbit be 0,in case of negative numbers we use 1 as first bit. We don’t have to know the parameters of machine number set for convertingthe number. The length of mantissa can be read from input data. And weassume that the bounds of characteristic are such that our carachteristic be allowed. Before starting computation let us check whether the given data can be amachine number or not. (All but last coordinates are from set {0,1} and last is an integer.) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546% 1. 机器数转十进制% 第一位是正负号% 中间是二进制% 最后一位是指数位function dec = fl1(vector)arguments % 限定输入必须是一维数组 vector (1,:)end isaninteger = @(x) isfinite(x) &amp; x == floor(x); % 判断 最后一位是整数 if ~isaninteger(vector(end)) % 如果不是，将返回值标记为无效 dec = nan; return end % 对数组内容进行验证，起始 到 倒数第二位 for n = vector(1:end-1) % 只能是二进制 if ~(n == 0 || n == 1) dec = nan; return end end % 初始化赋值 dec = 0; % 从 第二位 到 倒数第二位 for n = 2:length(vector)-1 if vector(n) == 1 % 二进制转十进制算法 dec = dec + 1/(2^(n-1)); end end % 位移，应用指数位 dec = dec * 2^vector(end); % 检查正负号 if vector(1) dec = -dec; return endend 在数轴上展示机器数Let us write anothe M-file, called fl2. It displays the elements of a given machinenumber set on the real axis. Compute the number of elements and the followingparameters: M∞, ε0, ε1. (They will be the output arguments of the function) The function waits 3 (integer) number as input.They are the parameters of the set: t, k1, k2. Let us check whether the input parameters are appropriate.(t ∈ N+ and k1, k2 ∈ Z, and of course k1 &lt; k2) For the computation we can call our first function (fl1) The set is symmetric. We can use this property for the faster computation. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859% 1. 在数轴上展示机器数，输出最大最小值，和与1的偏差function [max, min, diff] = fl2(digits, bottomExp, topExp, draw)% M∞, ε0, ε1arguments % 限定它们只能是一位数字 digits (1,1) bottomExp (1,1) topExp (1,1) % 布尔值，可选参数，默认为真 draw (1,1) = 1end isaninteger = @(x) isfinite(x) &amp; x == floor(x); % 最大位数必须大于零 且 是整数 % 低指数 小于或者等于 高指数，同时是整数 if ~(digits &gt; 0 &amp;&amp; isaninteger(digits)) ... || bottomExp &gt; topExp ... || ~isaninteger(bottomExp) ... || ~isaninteger(topExp) max = nan; return end mn = []; % 遍历出全部位数的机器数可能性 % n 从 1 开始枚举 到 最大位数 for n = 1:digits % 括号里面是十进制数组，长度为 2^n % 如 [0, 1, 2, 3]，-1 的原因是从 0 开始 % de2bi 会把数组里面的每一个数都转换成二进制 % 矩阵 m 有 2^n 行 n 列 % 这样写的好处是写起来简单，问题是会产生大量重复内容 m = de2bi(0:(2^n)-1); % 按行遍历矩阵，取出每一个二进制结果 for k = 1:size(m, 1) % 遍历所有的指数大小可能性，同样会产生大量重复内容 for e = bottomExp:topExp % 把二进制结果转换为机器数，并储存 % 这种持续变换矩阵大小的行为效率低下，但是写起来简单 mn = [mn, fl1([0, m(k, :), e])]; end end end % 将所有重复项排除，此方法会自动从小到大排序 mn = unique(mn); max = mn(end); min = mn(1); % 找出 1 的位置，并且取出它的下一位，算出误差 diff = mn(find(mn == 1) + 1) - 1; % 对称 mn = [-mn, mn]; if draw plot(mn, repelem(0, length(mn)), &quot;o&quot;) endend 十进制转机器数The third function finds the machine number what representates the given real number. The name be fl3. The function waits the real number and parameters of set ofmachine numbers (t, k1, k2.) as input. And gives back a vector with t+1 coordinates.The last coordinate be the characteristic and the firs t stores the signedmantissa. (As in case of input argument of function fl1). The first bit of mantissa is the sign-bit as in exercise 1.The value of sign is 0 when number is positive and 1 when it is negative. Check the input arguments whether they are appropriate.And the real number whether can representate in machine number set. (ε0 ≤ |r| ≤ M∞) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667% 1. 十进制转机器数function vector = fl3(digits, bottomExp, topExp, dec) % fl2 自带检查了所以这里就不再重复检查 [max] = fl2(digits, bottomExp, topExp, 0); % min &lt;= dec &lt;= max 防止溢出 if isnan(max) || ~((-max &lt;= dec) &amp;&amp; (dec &lt;= max)) vector = nan; return end sgn = 0; % 记录十进制正负 if sign(dec) == -1 sgn = 1; end % 取十进制绝对值 dec = abs(dec); % 抹掉小数，把整数位转换成二进制 int = fix(dec); bin = []; % 只有整数不为零的情况才需要转换 if int bin = de2bi(int); end % 整数二进制的长度就是未标准化的机器数的指数 % 我们可能得到这样两种情况：111.2222... 和 0.1111... % 只有第一种情况我们需要把整数位全部位移到小数位上 % 这时候就产生了指数位（指数位是可以为零的） power = length(bin); % 0.小数部分 * 2^(1:位数) 再取它 除以二 的余，并且抹掉小数 % 乘2取整，顺序排列，不断的在小数位上乘2 bin = [bin, fix(rem(rem(dec,1) * pow2(1:digits), 2))]; if power % 强行截断超出部分，只留超出的第一位，进行舍零入一 bin = bin(1:digits + 1); end % 是否需要进位 over = 0; % 只有当整数向后位移的情况才可能超出 if power over = bin(end); end % 逆向遍历数组 for n = digits:-1:1 if over % 是 1 则变成 0，继续进位 if bin(n) bin(n) = 0; else % 如果是 0 则 停止进位 bin(n) = 1; over = 0; end else break end end % 我们不需要考虑溢出的情况，因为最开始就已经检查过范围了 vector = [sgn, bin(1:digits), power];end 机器数相加Let us write a function for addition between machine numbers. Let us call the file to fl4. It waits for two vectors as input. (They are representatethe machine numbers as before). The output be a vector with the machine number of the sum. Use machine-addition. The double conversion is not acceptable. (To computethe real numbers belongs to inputs, summing them and reconverting tomachin number is not allowed.) Check the inputs. (They have to have same length and have to be machine numbers) If one of the numbers is negative (the first bit is 1) then in real the operationis a substraction. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596% 1. 机器数相加function vector = fl4(a, b)arguments a (1,:) b (1,:)end % 检查合法性，但是并没有检查完整 if ~isvector(a) || ~isvector(b) || length(a) ~= length(b) vector = nan; return end % 取出两个的指数位 ac = a(end); bc = b(end); % 目标指数 char = ac; % 取出两个的二进制数据 abin = a(2:end - 1); bbin = b(2:end - 1); % 二进制长度 len = length(abin); % 如果两个指数不相等 if ac ~= bc diff = ac - bc; if ac &gt; bc % align % A 大所以扩大 B for n = 1:diff bbin = [0, bbin]; end bbin = bbin(1:len); else for n = 1:-diff abin = [0, abin]; end % 目标指数转为大的那个 char = bc; abin = abin(1:len); end end % fliplr 将数组从左向右翻转 % 当使用 bi2de 或者 de2bi 时 % 第一位是 least significant bit 最低有效位 % 最后一位是 most significant bit 最高有效位 % 所以是小端序的，我们必须反转它 ad = bi2de(fliplr(abin)); bd = bi2de(fliplr(bbin)); % 处理符号 if a(end - 1) ad = -ad; end if b(end - 1) bd = -bd; end % 相加并转回二进制 dres = ad + bd; bin = fliplr(de2bi(abs(dres))); % 新结果与原始数据长度差 dlen = length(bin) - len; % 增加指数位 char = char + dlen; if length(bin) &gt; len % 如果太长了就截断，我们不改变机器数的长度 bin = bin(1:len); elseif length(bin) &lt; len % 如果不足，就在后面补 0 for n = 1:-dlen bin = [bin, 0]; end end % 处理符号 sgn = 0; if sign(dres) == -1 sgn = 1; end % 基本上只是简单实现了两个机器数的加减 % 没有判断两个输入的合法性 % 也没有判断是否溢出 % 而且实际还用的是十进制加减 % 总的来说不是很合格 vector = [bin, sgn, char];end Gaussian Elimination计算高斯消去Write an M-file to compute Gaussian Elimination.The name of the file be gaussel1 Input parameters: the coefficient matrix (A) and the right-side vector (b) of LES. Output argument: the solution vector x Use the Matlab row-operations for organisation of algorithm. If GE can’t be solved without row or coloumn swap write an error messageand terminate the program. In case of underdetermined LES give a base solution and warn the user of this. In case the user asked it, display the matrices A(i) during computation. To checking our function we can use the exercises from numerical I. +1 We can prepare our function to accept LES with multiple right sides. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384% 2. 计算高斯消去function x = gaussel1(A, b, display)arguments A % 右向量，只能有一列 b (:,1) display (1,1) = 0end [ARow, ACol] = size(A); BRow = size(b, 1); if ~ismatrix(A) || ARow ~= BRow error(&quot;ValidationException&quot;); end % 方程个数小于未知量个数的方程组 % 此时有无穷多组解，展示一个基本解 if(ARow &lt; ACol) warning('A is underdetermined, the basic solution with at most m nonzero components is') disp(A\\b) % 超定是方程个数大于未知量个数的方程组，且列满秩 % 一般是不存在解的矛盾方程，只能求一个最接近的解 elseif(ARow &gt; ACol &amp;&amp; rank(A) == ACol) % 显示一个使用最小二乘法，且 norm(A*x-b) &amp; norm(x) 最小 % 线性方程的最小范数最小二乘解，指示它是离原点最近的解，但仍然进行GJ warning('A is overdetermined, the minimum norm least-squares solution is') disp(lsqminnorm(A, b)) end M = [A, b]; [rows, cols] = size(M); % 主元容差，主要是为了控制精度问题，如 magic(4) % https://ww2.mathworks.cn/help/matlab/ref/rref.html#mw_5f53d9c8-72e8-42cc-bda8-ef84cf56ba93 tolerance = eps * max(rows, cols) * norm(M, inf); % Gauss-Jordan r = 1; for c = 1:cols % 找出当前列中，绝对值最大的数字，及其所在的行 % 使用部分主元消去法可减少（但会不消除）计算中的舍入误差 % 主元位置：行中最左边的非零元素 [num, target] = max(abs(M(r:end, c))); % 加上 r 的原因是因为上面 max 判断的是被截断的矩阵 target = r + target - 1; if (num &lt;= tolerance) % 跳过当前列，将近似零的项直接变成零 % 这可以防止使用小于容差的非零主元元素进行运算 M(r:end, c) = zeros(rows - r + 1, 1); if display disp(M) end else % 交换最大行与当前行 M([target, r], c:end) = M([r, target], c:end); if display disp(M) end % 标准化最大行（把主元变成1） M(r, c:end) = M(r, c:end) / M(r, c); if display disp(M) end % 消除当前的列（消元），但是要除开当前行 erow = [1:r - 1, r + 1:rows]; M(erow, c:end) = M(erow, c:end) - M(erow, c) * M(r, c:cols); if display disp(M) end % 检查是否完成行遍历 if (r == rows) break; end r = r + 1; end end x = M(:, end);end Whole PivotingExtend the previous m-file (but save as a new name for example gaussel2) withsteps of partial and whole pivoting method. Using partial or whole pivoting could be choosen by user(for example according to a boolean input parameter), but if the partial pivoting is stuckedthen automatically switch to whole pivoting method. If we used whole pivoting despite user has choosen partial pivoting, then inform user about the switch Give an opportunity for displaying matrices A(i) during computation. Don’tforget that pivoting method can be changed the matrix so we have to displayit after row and coloumn swap. Don’t forget that the pivoting method can be changed the solution. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869% 2. 完全交换，注释看前面一个function x = gaussel2(A, b, display)arguments A b (:,1) display (1,1) = 0end M = [A, b]; [rows, cols] = size(M); xOrd=(1:length(b))'; tolerance = eps * max(rows, cols) * norm(M, inf); % Whole Pivoting r = 1; for c = 1:cols - 1 % 找出行列最大值 [maxc, rowI] = max(abs(M(r:end, c:end - 1))); [num, colI] = max(maxc); row = rowI(colI) + c - 1; col = colI + c - 1; if (num &lt;= tolerance) M(r:end, c) = zeros(rows - r + 1, 1); if display disp(M) end else % 交换列 M(r:end, [col, c]) = M(r:end, [c, col]); if display disp(M) end % 交换行 M([row, r], c:end) = M([r, row], c:end); if display disp(M) end % 交换X oldOrd = xOrd(c); xOrd(c) = xOrd(col); xOrd(col) = oldOrd; % 标准化 M(r, c:end) = M(r, c:end) / M(r, c); if display disp(M) end % 消元 erow = [1:r - 1, r + 1:rows]; M(erow, c:end) = M(erow, c:end) - M(erow, c) * M(r, c:cols); if display disp(M) end if (r == rows) break; end r = r + 1; end end % 调换回正常顺序 x = M(xOrd, end);end 求逆矩阵Apply Gaussian elimantion for computing inverse of an square matrix.The name of function: gaussel3 Check input argument(s) before computing Compute the determinant of matrix.If you have written the function gaussel1 such that it accepts multipleright-sides, then you can call it during computation. 12345678910111213141516171819202122232425262728293031323334353637383940414243% 2. 求逆矩阵function x = gaussel3(A) [row, col] = size(A); if row ~= col error(&quot;A is not a square matrix&quot;) end % 判断是否是奇异矩阵，如果是则不可逆 if det(A) == 0 warning(&quot;A is singular matrix&quot;) end A = [A, eye(row)]; for c = 1:row % 在消元操作之前选择一个最大的元素作为主元 % 这样可以避免主元为零的情况，从而提高精度 [~, maxI] = max(abs(A(c:row, c))); % 得到原来矩阵A中的行索引 maxI = maxI + c - 1; % 将矩阵A的第maxI行作为主元行，并将主元行转化为单位矩阵 % （主元行中的第c个元素是1，其余元素都是0） % 这样一来，矩阵A的第maxI行就成为了消元的基准行 % 在后续的消元操作中，其他行都需要根据这一行进行消元 A(maxI, :) = A(maxI, :) / A(maxI, c); temp = A(c, :); % 将矩阵A的主元行移动到第c行，使得在后续的消元操作中 % 只需要对矩阵A的第c行以下的部分进行消元 A(c, :) = A(maxI, :); A(maxI, :) = temp; for j = 1:row if(j ~= c) % 消元操作，使得矩阵A的第j行的第c个元素变为0 A(j, :) = A(j, :) - A(j, c) * A(c, :); end end end x = A(:, row + 1:size(A, 2));end QR-decompositionGram-SchmidtWrite an M-file for QR-decomposition using Gram-Schmidt orthogonalization. Letus call the function to: gramschmidt Input parameter: a square matrix (A) Output arguments: an orthogonal matrix (Q) and an upper triangular matrix (R),such that satisfy A = Q·R To check existence of decomposition (the columns of A have to be linearindependent) we can use any included function of Matlab. The included functions can be used for computing norms,but we can compute via definition also. 123456789101112131415161718192021222324252627282930313233343536373839404142434445% 3. Gram-Schmidt正交法% 选择一组线性无关的向量。然后通过计算每个向量与之前所有向量的投影% 并将这些投影从原始向量中减去，来逐步构造出一组正交向量% 1. 对于矩阵A的每一列，计算该列向量在之前处理的所有基向量上的投影分量% 2. 减去投影分量，得到一个正交化的基向量% 3. 更新正交矩阵Q和上三角矩阵Rfunction [Q, R] = gramschmidt(A) [m, n] = size(A); if (m ~= n) error(&quot;A should be a square matix&quot;) end if (rank(A) ~= size(A, 2)) % 加了这个 magic 就过不了了 warning(&quot;the columns of A have to be linear independent&quot;) end Q = zeros(m); R = zeros(m); % 从最左侧的列向量向右 for col = 1:n a = A(:, col); q = a; % 减去 A 中当前列向量在之前已找到的基向量上的投影分量 for b = 1:col-1 % 计算给定列向量a在已处理的基向量Q的第b列上的投影分量 r = Q(:, b)' * a; % 减去当前列向量在之前处理的基向量上的投影分量 q = q - r * Q(:, b); % 记录对应 R 矩阵中的元素值 R(b, col) = r; end % 对当前基向量进行正交化 q = q / norm(q); % 更新结果 Q(:, col) = q; R(col, col) = a' * q; endend HouseholderWrite an M-file to give the matrix of a Householder transformation, from a knownpoint and its image. The name of function let be: householder Input parameters: the coordinatas of the point and its image (P, P’) PointP (and ofcourse P’ also) can be from Rn where n is not predetermined. Output argument: the matrix of Householder-transformation Take care of choosing sign during transformation (the parameter σ effectsthe stability of the method) 123456789101112131415161718% 3. Householder 变换主要就是那个公式，没有什么别的function H = householder(P, Prem)arguments P (:,1) Prem (:,1) % P'end % 解题参考 NumSampleTest1SolutionsP1 213 if (size(P) ~= size(Prem)) error(&quot;Size P not equal to Size ImgP&quot;) end u = P - Prem; v = u / norm(u); % H(v) = I - 2 * v * v' H = eye(size(P, 1)) - 2 * (v * v');end 点映射The third function will asking data via graphical input. (It works for 2D points)Display points and the hyperspace of reflection. Ask for another point (also viagraphical input) and apply the transformation to the new point. The functionhouseholder can be called during the algorithm.the name of function: hhgraph 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172% 3. 交互点映射function hhgraph() clf; hold on; ax = gca; ax.XAxisLocation = &quot;origin&quot;; ax.YAxisLocation = &quot;origin&quot;; button = questdlg(&quot;Click a point&quot;, &quot;First Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX, PointY] = ginput(1); plot(PointX, PointY, &quot;rd&quot;) R = distance(PointX, PointY, 0, 0); viscircles([0, 0], R); button = questdlg(&quot;Click another point&quot;, &quot;Second Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX2, PointY2] = ginput(1); plot(PointX2, PointY2, &quot;rd&quot;) syms x y u; % 圆的标准方程 c = x ^ 2 + y ^ 2 - R ^ 2; % 计算点 (x,y) 到第二个点（PointX2,PointY2）之间的欧几里得距离 d = (x - PointX2) ^ 2 + (y - PointY2) ^ 2; % 求出第二个点（PointX2,PointY2）在反射变换后的位置，以确定反射变换矩阵 H h = d + u * c; % 前两个参数表示 h 关于 x 和 y 的一阶导数，它们用来求解 h 关于 x 和 y 的根 % 这些根是 h 关于 x 和 y 的极值点，它们决定了反射变换后第二个点的位置 % 第三个参数表示 h 关于 u 的一阶导数，它用来求解 h 关于 u 的根 % 这个根是 h 关于 u 的极值点，它决定了反射变换矩阵 H 的值 res = solve(diff(h, x) == 0, diff(h, y) == 0, diff(h, u) == 0); x = res.x; y = res.y; % 它们的值分别是第二个点反射变换后的两个可能位置与原点之间的欧几里得距离 d1 = (x(1) - PointX2) ^ 2 + (y(1) - PointY2) ^ 2; d2 = (x(2) - PointX2) ^ 2 + (y(2) - PointY2) ^ 2; % 选择更小的那一个作为反射变换后第二个点的位置 % 反射变换后第二个点的最终位置应该是离原点最近的那一个 if (d1 &lt;= d2) PointX2 = x(1); PointY2 = y(1); else PointX2 = x(2); PointY2 = y(2); end plot(PointX2, PointY2, &quot;rd&quot;) H = householder([PointX, PointY]', [PointX2, PointY2]'); button = questdlg(&quot;Click new point&quot;, &quot;Third Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX3, PointY3] = ginput(1); plot(PointX3, PointY3, &quot;rd&quot;) res = (H * [PointX3, PointY3]')'; plot(res(1), res(2), &quot;rd&quot;)end Householder QR 分解Write an M-filet to realize QR-decomposition with Householder algorithm. Letus call our function to: hhalg Input parameter: a square matrix (A) Output arguments: an orthogonal matrix (Q) and an upper triangular matrix (R),such that satisfy A = Q·R The previous functions can be called. 1234567891011121314151617181920212223242526272829303132333435363738394041424344% Householder QR 分解function [Q, R] = hhalg(A) [m, n] = size(A); if (m ~= n) error(&quot;A should be a square matix&quot;) end % 预分配，减少动态内存分配，提高性能 % 反射变换矩阵、正交矩阵和上三角矩阵 H = eye(m); Q = eye(m); R = A; for col = 1:n % x = aₖ x = R(col:m, col); % 跳过已满足条件不需要反射的部分 % 非零矩阵元素的数目 % 这是因为反射变换的作用是将向量 x 的第一个元素变为正数 if ~nnz(x(2:end)) continue end % v = aₖ - βeₖ，其中 eₖ 为单位正交基 v = x; % β=‖x‖取值保持与x(1)一致，β 是向量 x 的模长 v(1) = v(1) + sign(x(1)) * norm(x); v = v / v(1); % 反射变换：I - 2*u*conj(u) 可整理得下式 % 随着逐列推进，Householder 反射变换部分占右下部分越来越小 % (v * v') / (v' * v) 表示反射变换矩阵 H 的右下角部分 h = eye(m - col + 1) - 2 * (v * v') / (v' * v); H(col:m, col:m) = h; % 使用反射变换矩阵 H 更新正交矩阵 Q 和上三角矩阵 R R = H * R; Q = Q * H'; % 将预分配的内存重置 H(col:m, col:m) = eye(m - col + 1); endend Iterative solutions of LESJacobi 迭代Write an M-file for Jacobi iteration. The file name be: jacobi Input parameters: The matrix of LES A and a vector for the right-side: b Output argument: the approximation of the solution vector: x We can use the vectorial form of the iteration 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778% 4. Jacobi迭代function [x, k, index] = jacobi(A, b, ep, itMax)arguments A b (:,1) ep (1,1) = 1e-5 itMax (1,1) = 100end % 求线性方程组的雅可比迭代法，其中， % A为方程组的系数矩阵； % b为方程组的右端项; % ep为精度要求，缺省值为1e-5; % itMax 为最大迭代次数，缺省值为100; % x为方程组的解; % k为迭代次数; [row, col] = size(A); bRow = length(b); %当方程组行与列的维数不相等时，停止计算，并输出出错信息。 if row ~= col error('The rows and columns of matrix A must be equal'); end % 当方程组与右端项的维数不匹配时，停止计算，并输出出错信息。 if col ~= bRow error('The columns of A must be equal the length of b'); end % 迭代次数 k = 0; % 上一次迭代的结果 x = zeros(row, 1); % 当前迭代的结果 y = zeros(row, 1); % index为指标变量，index=0表示迭代失败，index=1表示收敛到指定要求 index = 1; % A = U + L + D % Ax = b % (U + L + D)x = b % Dx = -(U + L)x + b % Dx = -(A - D)x + b % x = -D^-1 * (U + L) * x + D^-1 * b % x(k+1) = Bj x(k) + cj % Bj = -D^-1 (L + U) % cj = D^-1 * b while 1 for r = 1:row y(r) = b(r); for j = 1:row if j ~= r % 用当前的 x 来更新 y y(r) = y(r) - A(r, j) * x(j); end end % A 中第 r 行第 r 列的元素过小，导致无法更新 y，无法进行下一次迭代 if abs(A(r, r)) &lt; 1e-10 &amp;&amp; k == itMax index = 0; return; end % 更新迭代解 y(r) = y(r) / A(r, r); end k = k + 1; if norm(y - x, inf) &lt; ep break; end x = y; endend Gauss SeidelWrite an M-file for Gauss-Seidel iteration. The file name be: gaussseid As in previously at Jacobi iteration. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455% 4. 用 Gauss Seidel 迭代法解线性方程组 Ax=b% A为方程组的系数矩阵% b为方程组的右端项%epsilon：近似解的误差%Max：迭代的最大次数function x = gaussseid(A, b, epsilon, Max)arguments A b (:,1) epsilon (1,1) = 1e-5 Max (1,1) = 1000end [row, col] = size(A); bRow = length(b); %当方程组行与列的维数不相等 if row ~= col error('The rows and columns of matrix A must be equal'); end % 当方程组与右端项的维数不匹配 if col ~= bRow error('The columns of A must be equal the length of b'); end %迭代初始值 x = zeros(bRow, 1); %diag(A)是取出对角元的向量，对该向量再作用diag()函数表示以该对角元向量生成对角矩阵 D = diag(diag(A)); %将矩阵分裂为A=D-L-U %下三角 L = -tril(A, -1); %上三角 U = -triu(A, 1); %G-S迭代法的迭代公式 Xk+1 = (D-L)^(-1) * U * Xk + (D - L)^(-1) * b B = (D-L) \\ U; g = (D-L) \\ b; %开始迭代Xk+1 = B * x + g %最大迭代次数 for k=1:Max %计算Xk+1用y存放 y=B*x + g; %相邻两次迭代之间相差小于阈值 if norm(x-y) &lt; epsilon break; end %存放单步结果用于判断收敛 x = y; endend Iterative solution of non-linear equations, Interpolation二分法Write an m-file for bisection method and call the file: bisect Input arguments: the function f (we want to find one of the zeros). Give itas a string (the variable can be denoted by x or we can give the notationas another parameter. We will need the ends of the starting interval (a, b),the number of steps (n). Output arguments: the appropriate approximation of root: x^∗and the error estimation ε. Before start we have to check the interval (is there a root inside?) To evaluate function we can use function eval 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162% 5. 二分法% x 根% tolerance 迭代误差function [x, tolerance] = bisect(f, a, b, k_max)arguments % 一元标量函数 如 f = @(x) x^2-1 f (1,1) function_handle % 起始区间 a (1,1) % 结束区间 b (1,1) % 最大迭代数 k_max (1,1) = 200end % 第一次迭代的 root 估计 % 接下来会持续更新 c 也就是每一次迭代的值 c = (a + b) / 2; % 如果是f(x)的根，直接返回根的估计值 if f(c) == 0 x = c; return end % 第一次迭代时，函数在左区间和中点的值 % 同样，这两个值在接下来会持续更新 fa = f(a); fc = f(c); % bisection iteration for k = 1:k_max % 为 0 就是已经找到根了 if fc == 0 break; % 两个y相乘为正就说明还在x轴上方 elseif (fa * fc &gt; 0) % 向右收敛 a = c; % 无需重复计算 fa = fc; else % 如果小于零就说明有一个y在x轴下方了 % 这时向左收敛 b = c; end % 更新区间中点（估计的根） c = (a + b) / 2; % 更新 y 轴结果 fc = f(c); end % 结果 x = c; % 误差 tolerance = b - a;end Least Squares Method, Generalised inverse最小二乘法Write an m-file for approximation with least squares method.The name of file: lsmapprox Input arguments: order of polynomial (n), nodes of approximation (in avector), vector of function values in nodes Output argument(s): the coefficients of the polynomial Let us draw a picture to illustrate the approximation. (We can use theincluded function polyval) 12345678910111213141516171819202122232425262728293031323334353637383940414243% 6. 最小二乘法计算拟合多项式系数% Polynomial curve fitting% 返回 p 向量保存多项式系数，由最高次向最低次排列function p = lsmapprox(x, y, n)arguments % x，y为拟合数据向量 x y % 拟合多项式次数 % 如 1 为 一次函数 n (1,1)end if ~isequal(size(x), size(y)) error(&quot;x, y require the same dimensionality&quot;) end % 但实际上我们需要的是列向量 x = x(:); y = y(:); % 使用一维向量 x 构造具有 n + 1 列 和 m = length(x) 行 的 % 范德蒙（Vandermonde）矩阵 V = [x^n ... x^2 x ones(size(x))] % p(x) = p1·x^n + p2·x^(n-1) + ... pn·x + pn + 1 V(:, n + 1) = ones(length(x), 1, class(x)); for j = n:-1:1 % TIMES (.*) 执行按元素相乘 V(:, j) = x .* V(:, j + 1); end % 然后我们把 V 进行 QR 分解，然后再使用 \\ 除法进行求解，随后得到多项式系数p [Q, R] = qr(V, 0); % p = V\\y p = R \\ (Q' * y); % 返回行向量 p = p'; % 绘图 y1 = polyval(p, x); plot(x, y, 'o', x, y1, '-')end 广义逆矩阵Write an m-file to find the generalised inverse of a given matrix.The name of file: geninv Input argument: the matrix (A). Output argument: The generalised inverse (A+) Use the rank factorisation if the matrix is not fullranked. For the matrixoperations we can use the included functions of Matlab (eg.: rank, inv,instead of solving LES we can use the command G=F\\A, etc.) 123456789101112131415161718192021% 6. 求矩阵的广义逆矩阵% 当 A 不是 fullranked （列满秩）的时候，逆不唯一% A ∈ C^(m * n) 若存在 C 满足 AXA = A XAX = X 则 X 是 A 的广义逆矩阵function APlus = geninv(A) r = rank(A); % 如果 A 不是 fullranked，则使用 秩分解 % rank factorization 来计算GINV if r == size(A, 1) % Moore-Penrose 伪逆 APlus = pinv(A); else % A = U * S * V' % 奇异值分解得到的矩阵 U、奇异值矩阵 S 和 V 的转置矩阵 [U,S,V] = svd(A); SPlus = zeros(size(A)); % 将 S 的逆矩阵插入到秩分解中 SPlus(1:r, 1:r) = inv(S(1:r, 1:r)); APlus = V * SPlus * U'; endend","link":"/Math/Matlab/Numerical-Methods-II/"},{"title":"OpenStack 学习日记 | 第一天","text":"由于本人最近需要从事 OpenStack 相关工作，所以急需对 OpenStack 进行学习本系列日记仅作为本人的学习记录学习材料为 《每天 5 分钟玩转 OpenStack》 学习前需要知道的OpenStack 涉及的范围广计算，储存，网络，虚拟化，可用性，安全性，灾备等一些列关于 IT 基础设施的范围 OpenStack 都有涵盖 OpenStack 是一个平台它的各个组件都采用了 Driver 架构，支持各种的具体实现。比如 OpenStack 储存服务 Cinder 只定义抽象 API，而具体实现交给具体的 Driver比如基于 LVM 的 iSCSI， EMC，或者开源的 Ceph，GlusterFS 等等 这里我们可以类比到 Entity Framework，它只定义了上层的 API而具体的数据库操作交给了你指定的 Driver，如 Npgsql OpenStack 是一个分布式系统这也是学习它的比较大的阻碍，因为它原生就是分布式的，各个组件拆的很散不过我们学习的时候都使用 All-in-one 部署模式 我们要学习的内容 预备知识 虚拟化 云计算 核心组件 架构 认证 Keystone 镜像 Glance 计算 Nova 储存 Cinder 网络 Neutron 写在最前面 – 每天 5 分钟玩转 OpenStack（1） 虚拟化虚拟化是云计算的基础虚拟机(Guest)共享物理机(Host)的资源，比如 CPU，内存，硬盘，网络，磁盘等 这主要通过 Hypervisor 来实现，比如 KVM，Xen，VMWare 等等 1 类虚拟化Hypervisor 是一个操作系统，直接安装在物理机上最典型的就是 Windows 上的 Hyper-V其他的还有 Xen 和 ESXi 2 类虚拟化Hypervisor 作为操作系统中的一个程序或者模块运行最典型的有 KVM 和 VMware Workstation 对比理论上讲，1 类虚拟化性能比 2 类的要好而 2 类虚拟化会更灵活，比如支持嵌套虚拟化 KVM对我来说 KVM 已经是一个听过无数次的词了OpenStack 对 KVM 的支持最好，全称叫 Kernel-based Virtual Machine也就是说它基于 Linux 的内核实现，它有一个模块叫 kvm.ko，只用于管理虚拟 CPU 和内存 那我们就要问了，那 IO 虚拟化呢，这个交给 Linux 内核与 QEMU 实现 Libvirt这是 KVM 的管理工具，包含三个模块后台 daemon，api 库，和 命令行工具 virshvirsh 和 virt-manager 是一定要会用的 虚拟化 – 每天 5 分钟玩转 OpenStack（2） 安装我们使用 Ubuntu，安装 KVM 需要的包 1sudo apt install qemu-kvm qemu-system libvirt-bin virt-manager bridge-util qemu-kvm 和 qemu-system 是 KVM 和 QEMU 的核心包，提供 CPU、内存和 IO 虚拟化功能 libvirt-bin 就是 libvirt，用于管理 KVM 等 Hypervisor virt-manager 是 KVM 图形化管理工具 bridge-utils 和 vlan，主要是网络虚拟化需要，KVM 网络虚拟化的实现是基于 linux-bridge 和 VLAN 准备 KVM 实验环境 – 每天 5 分钟玩转 OpenStack（3） 对于我自己来说，使用 KVM 等本来就是轻车熟路了，所以我跳过这一部分 启动第一个 KVM 虚机 – 每天 5 分钟玩转 OpenStack（4） 远程管理 KVM 虚机 – 每天 5 分钟玩转 OpenStack（5） CPU 虚拟化KVM 虚拟机 在宿主机中其实是一个 QEMU-KVM 进程，与其他进程一同被调度虚拟中的每一个 vCPU 就对应 QEMU-KVM 进程中的一个 线程 这就表明 vCPU 的总数可以超过物理机的 CPU 总数，这叫 CPU OverCommit 超配这个特性让虚拟机能充分利用宿主机的 CPU 资源，但是这也导致了 VPS 中令人诟病的超售行为 内存虚拟化这一段算是我看的比较迷糊的一段不过说到底也不需要了解多少，只需要知道它并不是像一个普通程序那样分配内存即可中间存在大量的内存地址转换，各个厂家也为了转换效率做了很多特殊的优化Guest Virtual Address -&gt; Guest Physical Address -&gt;Host Virtual Address -&gt; Host Physical Address 内存也是可以超配的，所以超售机一大堆 CPU 和内存虚拟化原理 – 每天 5 分钟玩转 OpenStack（6） 储存虚拟化目录类型文件目录类型是最常用的KVM 将宿主机目录 /var/lib/libvirt/images/ 作为默认的 Storage Pool 这个目录下面的每一个文件就是一个 Volume说白了就是用文件来当磁盘，我们最常用的方式存储方便、移植性好、可复制、可远程访问KVM 支持 raw, qcow2, qed, vmdk, vdl 格式的磁盘文件 KVM 存储虚拟化 – 每天 5 分钟玩转 OpenStack（7） LVM 类型这个用的不多，也就是把实际的磁盘划出来给虚拟机用，跳过 LVM 类型的 Storage Pool – 每天 5 分钟玩转 OpenStack（8） 网络虚拟化这章是虚拟化中最复杂，最重要的部分 Linux Bridge其实就是网桥，用来做 TCP/IP 二层协议交换的模块对于我来说这玩意接触的也比较多 KVM 网络虚拟化基础 – 每天 5 分钟玩转 OpenStack（9） 这里记录几个重点 修改 /etc/network/interfaces 以配置网桥 使用 ifconfig 查看 IP 配置 brctl show 查看当前 Linux Bridge 的配置 动手实践虚拟网络 – 每天 5 分钟玩转 OpenStack（10） virbr0virbr0 是 KVM 默认创建的一个 Bridge，其作用是为连接其上的虚机网卡提供 NAT 访问外网的功能。virbr0 默认分配了一个 IP 192.168.122.1，并为连接其上的其他虚拟网卡提供 DHCP 服务。这没啥好难的就是一个 NAT 网关而已 理解 Virbr0 – 每天 5 分钟玩转 OpenStack（11） VLAN也就是虚拟局域网，隔离用，二层交换机，不需要想的太复杂在一张网卡下面划分多个空间而已 Linux 如何实现 VLAN – 每天 5 分钟玩转 OpenStack（12） 具体如何配置就等到要用的时候现查不过还是修改 /etc/network/interfaces 动手实践 Linux VLAN – 每天 5 分钟玩转 OpenStack（13） 云计算 IaaS（Infrastructure as a Service）提供的服务是虚拟机典型的有 AWS，OpenStack 等 PaaS（Platform as a Service）提供的服务是应用的运行环境比如 Github Pages SaaS（Software as a Service）提供的是应用服务对象通常是最终用户，就像 Gmail OpenStack is a cloud operating system that controls large pools of compute, storage,and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface. OpenStack 对数据中心的计算、存储和网络资源进行统一管理 云计算与 OpenStack – 每天 5 分钟玩转 OpenStack（14） OpenStack写日记的时候最新版本是 Yoga，下一个版本是 Zed 首先列出模块列表 名称 用途 中文 cyborg Accelerator Life Cycle Management 用于管理硬件和软件加速资源（如 GPU）的框架 freezer Backup, Restore, and Disaster Recovery service 备份、恢复和灾难恢复服务 ironic Bare Metal service 裸机服务 cinder Block Storage service 存储服务 ceilometer Data collection service 数据收集服务 kuryr Bridge between container framework and OpenStack abstractions 容器框架和 OpenStack 抽象之间的桥梁 keystone Identity Service 管理身份验证、服务规则和服务令牌功能 senlin Clustering service 集群服务 storlets Compute inside Object Storage service 对象存储服务中的计算 nova Compute service 计算服务，管理 VM 的生命周期 neutron network connectivity as a service 网络连接服务，负责创建和管理 L2、L3 网络， 为 VM 提供虚拟网络和物理网络连接 zun Containers service 容器服务 horizon Dashboard 仪表盘 designate DNS service DNS 服务 ec2-api EC2 API compatibility layer EC2 API 兼容层 glance Image service 启动镜像服务 watcher Infrastructure Optimization service 基础设施优化服务 masakari Instances High Availability Service 实例高可用性服务 barbican Key Manager service 密钥管理器服务 octavia Load-balancer service 负载均衡器服务 neutron Networking service 网络服务 tacker NFV Orchestration service NFV 管理器，用于监视、配置 NFV 和管理 NFV 全生命周期 swift Object Storage service 对象存储服务 heat Orchestration service REST 服务，能够基于一个声明式的模板，通过装配引擎装配组合若干个云应用 placement Placement service REST API 堆栈和数据模型，用于跟踪资源提供程序的清单和使用情况，以及不同的资源类别 cloudkitty Rating service 计费服务 vitrage RCA (Root Cause Analysis) service 用于组织、分析和扩展 OpenStack 的告警和事件 blazar Resource reservation service 资源保留服务 manila Shared File Systems service 共享文件系统服务 aodh Telemetry Alarming services 遥测报警服务 ceilometer Telemetry Data Collection service 遥测数据采集服务 https://www.openstack.org/software/project-navigator/这么一大堆模块一时半会肯定是学不完的，我们挑重点学习搞清楚 OpenStack 是图和对计算，网络，储存资源进行管理的 核心组件 Nova 管理计算资源，是核心服务。 Neutron 管理网络资源，是核心服务。 Glance 为 VM 提供 OS 镜像，属于存储范畴，是核心服务。 Cinder 提供块存储，VM 怎么也得需要数据盘吧，是核心服务。 Swift 提供对象存储，不是必须的，是可选服务。 Keystone 认证服务，没它 OpenStack 转不起来，是核心服务。 Ceilometer 监控服务，不是必须的，可选服务。 Horizon 大家都需要一个操作界面吧。 OpenStack 本身是一个分布式系统，不但各个服务可以分布部署，服务中的组件也可以分布部署这也使得 OpenStack 比一般系统复杂，学习难度也更大 OpenStack 架构 – 每天 5 分钟玩转 OpenStack（15） 搭建 Dev 环境我一般使用 MicroStack 一键解决 搭建 OpenStack 实验环境 – 每天 5 分钟玩转 OpenStack（16） 部署 DevStack – 每天 5 分钟玩转 OpenStack（17） Keystone对于天天跟 OAuth 打交道的我这部分其实可以跳过 Authentication 解决的是“你是谁？”的问题 Authorization 解决的是“你能干什么？”的问题 Keystone 负责管理和维护每个 Service 的 Endpoint Service 通过 Endpoint 暴露自己的 API 理解 Keystone 核心概念 – 每天 5 分钟玩转 OpenStack（18） 通过例子学习 Keystone – 每天 5 分钟玩转 OpenStack（19） Glance这玩意还储存快照 Glance 支持多种 backend，包括 A directory on a local file system（这是默认配置） GridFS Ceph RBD Amazon S3 Sheepdog OpenStack Block Storage (Cinder) OpenStack Object Storage (Swift) VMware ESX 没啥好讲的，需要用到时候现查，而且大部分操作都可以通过 GUI 完成 理解 Glance – 每天 5 分钟玩转 OpenStack（20） 创建 Image – 每天 5 分钟玩转 OpenStack（21） 如何使用 OpenStack CLI – 每天 5 分钟玩转 OpenStack（22） NovaCompute Service Nova 是 OpenStack 最核心的服务，负责维护和管理云环境的计算资源。OpenStack 作为 IaaS 的云操作系统，虚拟机生命周期管理也就是通过 Nova 来实现的。 nova-api接收和响应客户的 API 调用， 还支持 Amazon EC2 API nova-scheduler虚机调度服务，负责决定在哪个计算节点上运行虚机 nova-compute管理虚机的核心服务，通过调用 Hypervisor API 实现虚机生命周期管理 nova-conductornova-compute 经常需要更新数据库，比如更新虚机的状态出于安全性和伸缩性的考虑，nova-compute 并不会直接访问数据库 nova-console用户可以通过多种方式访问虚机的控制台：nova-novncproxy，基于 Web 浏览器的 VNC 访问nova-spicehtml5proxy，基于 HTML5 浏览器的 SPICE 访问nova-xvpnvncproxy，基于 Java 客户端的 VNC 访问 nova-consoleauth负责对访问虚机控制台请求提供 Token 认证 nova-cert提供 x509 证书支持 总之我越看越觉得 OpenStack 就是在 Hypervisor 上套了一层又一层而且我个人对 Python 写的大型项目是完全没有好感 理解 Nova 架构 – 每天 5 分钟玩转 OpenStack（23） 部署方案哪里有那么复杂，专门负责装 VPS 的 Hypervisor 就装 nova-compute然后其他服务放别处就行了 OpenStack 默认是用 RabbitMQ 作为 Message Queue，好评 Nova 组件如何协同工作 – 每天 5 分钟玩转 OpenStack（24） 设计思路说那么多到底还是解耦，疯狂解耦然后各种抽象 API，疯狂增加项目体积再加入各种调度，最离谱的是居然默认用 MySQL当然对大型集群这都不算什么 OpenStack 通用设计思路 – 每天 5 分钟玩转 OpenStack（25） 组件 Nova 组件详解 – 每天 5 分钟玩转 OpenStack（26） flavor 就是 plan，选 VPS 配置 Filter scheduler 是 nova-scheduler 默认的调度器 通过过滤器（filter）选择满足条件的计算节点 通过权重计算（weighting）选择在最优（权重值最大）的计算节点上创建 Instance RetryFilter 的作用是刷掉之前已经调度过的节点 为提高容灾性和提供隔离服务，可以将计算节点划分到不同的 Availability Zone 中 RamFilter 将不能满足 flavor 内存需求的计算节点过滤掉 DiskFilter 将不能满足 flavor 磁盘需求的计算节点过滤掉 CoreFilter 将不能满足 flavor vCPU 需求的计算节点过滤掉 ComputeFilter 保证只有 nova-compute 服务正常工作的计算节点才能够被 nova-scheduler 调度 ComputeCapabilitiesFilter 根据计算节点的特性来筛选可以从 Metadata 中筛选架构之类的 ImagePropertiesFilter 根据所选 image 的属性来筛选匹配的计算节点镜像也带 Metadata，可以限定比如只能运行在 kvm 上之类的 ServerGroupAntiAffinityFilter 可以尽量将 Instance 分散部署到不同的节点上 ServerGroupAffinityFilter 会尽量将 instance 部署到同一个计算节点上 nova-scheduler 的默认实现是根据计算节点空闲的内存量计算权重值：空闲内存越多，权重越大，instance 将被部署到当前空闲内存最多的计算节点上 看 Nova-Scheduler 如何选择计算节点 – 每天 5 分钟玩转 OpenStack（27） 每隔一段时间，nova-compute 就会报告当前计算节点的资源使用情况和自己的状态 这不就是微服务么，eureka 既视感 instance 的 launch、shutdown、reboot、suspend、resume、terminate、resize、migration、snapshot Nova-Compute 部署 Instance 详解 – 每天 5 分钟玩转 OpenStack（28） 生命周期OpenStack 的日志格式都是统一的，如下&lt;时间戳&gt;&lt;日志等级&gt;&lt;代码模块&gt;&lt;Request ID&gt;&lt;日志内容&gt;&lt;源代码位置&gt; 教你看懂 OpenStack 日志 – 每天 5 分钟玩转 OpenStack（29）Launch 和 Shut Off 操作详解 – 每天 5 分钟玩转 OpenStack（30）Start Instance 操作详解 – 每天 5 分钟玩转 OpenStack（31）Nova reboot 和 lock 操作 – 每天 5 分钟玩转 OpenStack（32）Terminate Instance 操作详解 – 每天 5 分钟玩转 OpenStack（33）Pause/Resume Instance 操作详解 – 每天 5 分钟玩转 OpenStack（34）Nova Suspend/Rescue 操作详解 – 每天 5 分钟玩转 OpenStack（35）Snapshot Instance 操作详解 – 每天 5 分钟玩转 OpenStack（36）Rebuild Instance 操作详解 – 每天 5 分钟玩转 OpenStack（37）Shelve Instance 操作详解 – 每天 5 分钟玩转 OpenStack（38）Unshelve Instance 操作详解 – 每天 5 分钟玩转 OpenStack（39）Migrate Instance 操作详解 – 每天 5 分钟玩转 OpenStack（40）Resize Instance 操作详解 – 每天 5 分钟玩转 OpenStack（41）Live Migrate 操作 – 每天 5 分钟玩转 OpenStack（42）计算节点宕机了怎么办？Evacuate - 每天 5 分钟玩转 OpenStack（43）1 张图秒懂 Nova 16 种操作 – 每天 5 分钟玩转 OpenStack（44） 上面这一大堆操作都是属于遇到了现查来得更快，而且很多都浅显易懂，盲猜也能用个大概","link":"/Cloud/OpenStack/OpenStack-%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0-%E7%AC%AC%E4%B8%80%E5%A4%A9/"},{"title":"OpenStack 学习日记 第二天","text":"Cinder操作系统挂载储存空间的方法有： Block Storage 块储存：通过本地协议（SCSI、SAS）等挂载裸磁盘，每个磁盘叫做 Volume 卷 文件系统储存：通过网络协议（NFS、CIFS）等挂载远程文件系统，分布式就是这种 Block Storage Service 提供对 volume 从创建到删除整个生命周期的管理从 instance 的角度看，挂载的每一个 Volume 都是一块硬盘 Cinder： 提供 REST API 使用户能够查询和管理 volume、volume snapshot 以及 volume type 提供 scheduler 调度 volume 创建请求，合理优化存储资源的分配 通过 driver 架构支持多种 back-end（后端）存储方式，包括 LVM，NFS，Ceph 和其他诸如 EMC、IBM 等商业存储产品和方案 组件 cinder-api接收 API 请求，调用 cinder-volume 执行操作 cinder-volume管理 volume 的服务，与 volume provider 协调工作，管理 volume 的生命周期运行 cinder-volume 服务的节点被称作为存储节点，LVM 是默认的 provider cinder-schedulerscheduler 通过调度算法选择最合适的存储节点创建 volume volume provider数据的存储设备，为 volume 提供物理存储空间支持多种 volume provider，每种 provider 通过自己的 driver 与 cinder-volume 协调工作 Message QueueCinder 各个子服务通过消息队列实现进程间通信和相互协作因为有了消息队列，子服务之间实现了解耦，这种松散的结构也是分布式系统的重要特征 Database数据库是安装在控制节点上的 其他 理解 Cinder 架构 – 每天 5 分钟玩转 OpenStack（45） 主要还是在讲传统分布式设计 掌握 Cinder 的设计思想 – 每天 5 分钟玩转 OpenStack（46） cinder-api 是整个 Cinder 组件的门户，所有 cinder 的请求都首先由 nova-api 处理 cinder-volume 在存储节点上运行，OpenStack 对 Volume 的操作，最后都是交给 cinder-volume 来完成的cinder-volume 自身并不管理真正的存储设备，存储设备是由 volume provider 管理的。cinder-volume 与 volume provider 一起实现 volume 生命周期的管理 Cinder 组件详解 – 每天 5 分钟玩转 OpenStack（47） 调度器Filter scheduler 是 cinder-scheduler 默认的调度器 AvailabilityZoneFilter为提高容灾性和提供隔离服务，可以将存储节点和计算节点划分到不同的 Availability Zone 中 CapacityFilter将存储空间不能满足 Volume 创建需求的存储节点过滤掉 CapabilitiesFilter不同的 Volume Provider 有自己的特性（Capabilities），比如是否支持 thin provision 等Cinder 允许用户创建 Volume 时通过 Volume Type 指定需要的 Capabilities Weighter通过 scheduler_default_weighers 指定计算权重的 weigher，默认为 CapacityWeigherCapacityWeigher 基于存储节点的空闲容量计算权重值，空闲容量最大的胜出 掌握 cinder-scheduler 调度逻辑 – 每天 5 分钟玩转 OpenStack（48） 操作 准备 LVM Volume Provider – 每天 5 分钟玩转 OpenStack（49） Create Volume 操作（Part I） – 每天 5 分钟玩转 OpenStack（50） Create Volume 操作（Part II） – 每天 5 分钟玩转 OpenStack（51） Create Volume 操作（Part III） – 每天 5 分钟玩转 OpenStack（52） Attach Volume 操作（Part I） – 每天 5 分钟玩转 OpenStack（53） Attach Volume 操作（Part II） – 每天 5 分钟玩转 OpenStack（54） Detach Volume 操作 – 每天 5 分钟玩转 OpenStack（55） Extend Volume 操作 – 每天 5 分钟玩转 OpenStack（56） Delete Volume 操作 – 每天 5 分钟玩转 OpenStack（57） Snapshot Volume 操作 – 每天 5 分钟玩转 OpenStack（58） Backup Volume 操作 – 每天 5 分钟玩转 OpenStack（59） Restore Volume 操作 – 每天 5 分钟玩转 OpenStack（60） Boot From Volume – 每天 5 分钟玩转 OpenStack（61） NFS NFS Volume Provider（Part I） – 每天 5 分钟玩转 OpenStack（62） NFS Volume Provider（Part II） – 每天 5 分钟玩转 OpenStack（63） NFS Volume Provider（Part III） – 每天 5 分钟玩转 OpenStack（64） Neutron“软件定义网络（software-defined networking, SDN）”所具有的灵活性和自动化优势 Neutron 的设计目标是实现“网络即服务（Networking as a Service）”在设计上遵循了基于 SDN 实现网络虚拟化的原则，在实现上充分利用了 Linux 系统上的各种网络相关的技术 Neutron 为整个 OpenStack 环境提供网络支持，包括二层交换，三层路由，负载均衡，防火墙和 VPN 等 二层交换 SwitchingNova 的 Instance 是通过虚拟交换机连接到虚拟二层网络的Neutron 支持多种虚拟交换机，包括 Linux 原生的 Linux Bridge 和 Open vSwitchNeutron 除了可以创建传统的 VLAN 网络，还可以创建基于隧道技术的 Overlay 网络，比如 VxLAN 和 GRE 三层路由 RoutingNeutron 支持多种路由，包括 Linux 原生的 Linux Bridge 和 Open vSwitchInstance 可以配置不同网段的 IP，Neutron 的 router（虚拟路由器）实现 instance 跨网段通信router 通过 IP forwarding，iptables 等技术来实现路由和 NAT 负载均衡 Load BalancingLoad-Balancing-as-a-Service（LBaaS）支持多种负载均衡产品和方案，不同的实现以 Plugin 的形式集成到 Neutron，目前默认的 Plugin 是 HAProxy。 防火墙 FirewallingSecurity Group：通过 iptables 限制进出 instance 的网络包FWaaS：限制进出虚拟路由器的网络包，也是通过 iptables 实现 Neutron 功能概述 – 每天 5 分钟玩转 OpenStack（65） 概念Neutron 支持多种类型的 network，包括 local, flat, VLAN, VxLAN 和 GRE。 locallocal 网络与其他网络和节点隔离。local 网络中的 instance 只能与位于同一节点上同一网络的 instance 通信，local 网络主要用于单机测试 flatflat 网络是无 vlan tagging 的网络。flat 网络中的 instance 能与位于同一网络的 instance 通信，并且可以跨多个节点。 vlanvlan 网络是具有 802.1q tagging 的网络。vlan 是一个二层的广播域，同一 vlan 中的 instance 可以通信，不同 vlan 只能通过 router 通信。vlan 网络可以跨节点，是应用最广泛的网络类型 vxlanvxlan 是基于隧道技术的 overlay 网络。vxlan 网络通过唯一的 segmentation ID（也叫 VNI）与其他 vxlan 网络区分vxlan 中数据包会通过 VNI 封装成 UDP 包进行传输因为二层的包通过封装在三层传输，能够克服 vlan 和物理网络基础设施的限制 gregre 是与 vxlan 类似的一种 overlay 网络。主要区别在于使用 IP 包而非 UDP 进行封装 Neutron 网络基本概念 – 每天 5 分钟玩转 OpenStack（66） 组件 Neutron Server对外提供 OpenStack 网络 API，接收请求，并调用 Plugin 处理请求。 Plugin处理 Neutron Server 发来的请求，维护 OpenStack 逻辑网络的状态， 并调用 Agent 处理请求。 Agent处理 Plugin 的请求，负责在 network provider 上真正实现各种网络功能。 network provider提供网络服务的虚拟或物理网络设备，例如 Linux Bridge，Open vSwitch 或者其他支持 Neutron 的物理交换机。 QueueNeutron Server，Plugin 和 Agent 之间通过 Messaging Queue 通信和调用。 Database存放 OpenStack 的网络状态信息，包括 Network, Subnet, Port, Router 等。 Neutron 架构 – 每天 5 分钟玩转 OpenStack（67） 部署 方案 1：控制节点 + 计算节点控制节点：部署的服务包括：neutron server, core plugin 的 agent 和 service plugin 的 agent计算节点：部署 core plugin 的 agent，负责提供二层网络功能。 方案 2：控制节点 + 网络节点 + 计算节点控制节点：部署 neutron server 服务网络节点：部署的服务包括：core plugin 的 agent 和 service plugin 的 agent计算节点：部署 core plugin 的 agent，负责提供二层网络功能。 Neutron 物理部署方案 – 每天 5 分钟玩转 OpenStack（68） 结构 Core API对外提供管理 network, subnet 和 port 的 RESTful API。 Extension API对外提供管理 router, load balance, firewall 等资源 的 RESTful API。 Commnon Service认证和校验 API 请求。 Neutron CoreNeutron server 的核心处理程序，通过调用相应的 Plugin 处理请求。 Core Plugin API定义了 Core Plgin 的抽象功能集合，Neutron Core 通过该 API 调用相应的 Core Plgin。 Extension Plugin API定义了 Service Plgin 的抽象功能集合，Neutron Core 通过该 API 调用相应的 Service Plgin。 Core Plugin实现了 Core Plugin API，在数据库中维护 network, subnet 和 port 的状态，并负责调用相应的 agent 在 network provider 上执行相关操作，比如创建 network。 Service Plugin实现了 Extension Plugin API，在数据库中维护 router, load balance, security group 等资源的状态，并负责调用相应的 agent 在 network provider 上执行相关操作，比如创建 router。 理解 Neutron Server 分层模型 – 每天 5 分钟玩转 OpenStack（69） Neutron 如何支持多种 network provider – 每天 5 分钟玩转 OpenStack（70） ML2Moduler Layer 2（ML2）是 Neutron 在 Havana 版本实现的一个新的 core plugin，用于替代原有的 linux bridge plugin 和 open vswitch plugin 传统 core plugin 存在两个突出的问题: 无法同时使用多种 network provider 开发新的 core plugin 工作量大 详解 ML2 Core Plugin（I） – 每天 5 分钟玩转 OpenStack（71） ML2 对二层网络进行抽象和建模，引入了 type driver 和 mechanism driver这两类 driver 解耦了 Neutron 所支持的网络类型（type）与访问这些网络类型的机制（mechanism）其结果就是使得 ML2 具有非常好的弹性，易于扩展，能够灵活支持多种 type 和 mechanism。 Type DriverNeutron 支持的每一种网络类型都有一个对应的 ML2 type driver。type driver 负责维护网络类型的状态，执行验证，创建网络等。ML2 支持的网络类型包括 local, flat, vlan, vxlan 和 gre Mechanism DriverNeutron 支持的每一种网络机制都有一个对应的 ML2 mechanism driver mechanism driver 负责获取由 type driver 维护的网络状态，并确保在相应的网络设备（物理或虚拟）上正确实现这些状态 mechanism driver 有三种类型 Agent-based包括 linux bridge, open vswitch 等 Controller-based包括 OpenDaylight, VMWare NSX 等 基于物理交换机包括 Cisco Nexus, Arista, Mellanox 等 详解 ML2 Core Plugin（II） – 每天 5 分钟玩转 OpenStack（72） Service PluginCore Plugin/Agent 负责管理核心实体：net, subnet 和 port而对于更高级的网络服务，则由 Service Plugin/Agent 管理Service Plugin 及其 Agent 提供更丰富的扩展功能，包括路由，load balance，firewall 等 DHCPdhcp agent 通过 dnsmasq 为 instance 提供 dhcp 服务 Routingl3 agent 可以为 project（租户）创建 router，提供 Neutron subnet 之间的路由服务路由功能默认通过 IPtables 实现 Firewalll3 agent 可以在 router 上配置防火墙策略，提供网络安全防护另一个与安全相关的功能是 Security Group，也是通过 IPtables 实现Firewall 安全策略位于 router，保护的是某个 project 的所有 networkSecurity Group 安全策略位于 instance，保护的是单个 instance Load BalanceNeutron 默认通过 HAProxy 为 project 中的多个 instance 提供 load balance 服务 Service Plugin / Agent – 每天 5 分钟玩转 OpenStack（73） 两张图总结 Neutron 架构 – 每天 5 分钟玩转 OpenStack（74） 为 Neutron 准备物理基础设施（I） – 每天 5 分钟玩转 OpenStack（75） 为 Neutron 准备物理基础设施（II） – 每天 5 分钟玩转 OpenStack（76）","link":"/Cloud/OpenStack/OpenStack-%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0-%E7%AC%AC%E4%BA%8C%E5%A4%A9/"},{"title":"RL-Midterm","text":"希望我能顺利过关 大数定理大数定律表述了什么？ 大量 独立 且 相同 的 随机样本 的采样平均值会收敛到真实值。 马尔可夫属性什么是马尔可夫性质？ 下一个状态只跟当前状态有关，与之前的状态无关。 RL 元素强化学习任务的主要元素是什么？绘制示意图来说明。 flowchart LR subgraph s1[\" \"] n4[\"策略\"] n1[\"代理\"] end subgraph s2[\" \"] n5[\"模型\"] n3[\"环境\"] end n1 -- 行动 --> n3 n3 -- 奖励 / 新状态 --> n1 n4 --- n1 n3 --- n5 n1@{ shape: rounded} n3@{ shape: rounded} RL 类型什么是：评估性反馈，指示性反馈，非关联任务，关联任务？ 评估反馈，只使用获得的奖励来决定行动 指示反馈，使用外部信息来决定行动 非关联任务，只在一种情况下学习并采取行动 关联任务，在多种情况下学习并采取行动 网格世界有如下的网格世界，有一个较近的出口回报为 1，另一个较远的出口回报为 10。底部是回报为 -10 的悬崖。网格世界是随机的，噪声为 0.5，奖励为 0，折扣因子 0.99。有两条路可选，对于一个 Q-Learning 代理，最优策略是什么，为什么？ 选择较远的出口，且避免悬崖。 高噪声可能导致行动不按期望执行，掉入悬崖。 高折扣因子导致未来，如终点，的回报很重要。 策略迭代什么是广义策略迭代？ 策略评估与策略改进交替进行的一种方法，不是某个特定算法，值迭代算法是一个实例。 困境探索与利用的困境是什么？ 很难平衡探索与利用的比率，无法同时追求两者 算法对比比较 DP, MC, TD，每种方法的更新规则是什么？画出它们的备份图。 DP MC TD 需要环境模型 不需要环境模型 不需要环境模型 使用自举 不使用自举 使用自举 基于其他估值来更新 基于回合结束后的结果来更新 基于其他估值来更新 期望更新 样本更新 样本更新 $V(S_t) \\leftarrow E_{\\pi} [R_{t+1} + \\gamma V(S_{t+1})]$ $V(S_t) \\leftarrow V(S_t) + \\alpha (G_t - V(S_t))$ $V(S_t) \\leftarrow V(S_t) + \\alpha (R_{t+1} + \\gamma V(S_{t+1}) - V(S_t))$ flowchart TD subgraph s1[\" \"] n2[\"Filled Circle\"] n3[\"Filled Circle\"] n1[\"Small Circle\"] n4[\"Small Circle\"] n5[\"Small Circle\"] n6[\"Small Circle\"] n7[\"Small Circle\"] end n1 --> n2 & n3 n2 --> n4 & n5 n3 --> n6 & n7 n4 --> n8[\"Filled Circle\"] & n9[\"Filled Circle\"] n5 --> n10[\"Filled Circle\"] & n11[\"Filled Circle\"] n6 --> n12[\"Filled Circle\"] & n13[\"Filled Circle\"] n7 --> n14[\"Filled Circle\"] & n15[\"Filled Circle\"] n16[\"Small Circle\"] --> n17[\"Filled Circle\"] n16 -- mark --> n18[\"Filled Circle\"] n17 --> n19[\"Small Circle\"] & n20[\"Small Circle\"] n18 -- \"mark\" --> n21[\"Small Circle\"] n18 --> n22[\"Small Circle\"] n19 --> n23[\"Filled Circle\"] & n24[\"Filled Circle\"] n20 --> n25[\"Filled Circle\"] & n26[\"Filled Circle\"] n21 --> n27[\"Filled Circle\"] n21 -- \"mark\" --> n28[\"Filled Circle\"] n22 --> n29[\"Filled Circle\"] & n30[\"Filled Circle\"] n28 -- \"mark\" --> n33[\"Frames Circle\"] n34[\"Small Circle\"] --> n35[\"Filled Circle\"] n34 -- mark --> n36[\"Filled Circle\"] n35 --> n37[\"Small Circle\"] & n38[\"Small Circle\"] n36 -- \"mark\" --> n39[\"Small Circle\"] n36 --> n40[\"Small Circle\"] n37 --> n41[\"Filled Circle\"] & n42[\"Filled Circle\"] n38 --> n43[\"Filled Circle\"] & n44[\"Filled Circle\"] n39 --> n45[\"Filled Circle\"] & n46[\"Filled Circle\"] n40 --> n47[\"Filled Circle\"] & n48[\"Filled Circle\"] n2@{ shape: f-circ} n3@{ shape: f-circ} n1@{ shape: sm-circ} n4@{ shape: sm-circ} n5@{ shape: sm-circ} n6@{ shape: sm-circ} n7@{ shape: sm-circ} n8@{ shape: f-circ} n9@{ shape: f-circ} n10@{ shape: f-circ} n11@{ shape: f-circ} n12@{ shape: f-circ} n13@{ shape: f-circ} n14@{ shape: f-circ} n15@{ shape: f-circ} n16@{ shape: sm-circ} n17@{ shape: f-circ} n18@{ shape: f-circ} n19@{ shape: sm-circ} n20@{ shape: sm-circ} n21@{ shape: sm-circ} n22@{ shape: sm-circ} n23@{ shape: f-circ} n24@{ shape: f-circ} n25@{ shape: f-circ} n26@{ shape: f-circ} n27@{ shape: f-circ} n28@{ shape: f-circ} n29@{ shape: f-circ} n30@{ shape: f-circ} n33@{ shape: fr-circ} n34@{ shape: sm-circ} n35@{ shape: f-circ} n36@{ shape: f-circ} n37@{ shape: sm-circ} n38@{ shape: sm-circ} n39@{ shape: sm-circ} n40@{ shape: sm-circ} n41@{ shape: f-circ} n42@{ shape: f-circ} n43@{ shape: f-circ} n44@{ shape: f-circ} n45@{ shape: f-circ} n46@{ shape: f-circ} n47@{ shape: f-circ} n48@{ shape: f-circ} E 贪婪在有四个动作且 E=0.8 的 epsilon-greedy 策略中，如果已知只有一个贪婪动作，那么选中它的概率是多少？ 0.2 选中贪婪动作 0.8 选中随机动作其中 0.25 的概率选中贪婪动作 所以，选中贪婪动作的概率是 0.2 + 0.25 * 0.8 = 0.4 多情境你面临一个 3 臂老虎机任务，其真实值随时间步随机变化，动作 1 2 3 的真实值如下： 情况 1 2 3 A 0.1 0.6 0.3 B 0.9 0.5 0.4 C 0.2 0.1 0.2 D 0.5 0.5 0.7 每种情况发生概率相同，问 如果你无法判断现在是哪种情况，你的最佳期望是多少，应如何行动？ 如果你被告知当前的情况，但仍不知道真实值，你的最佳期望是多少，应如何行动？ 如果我不知道当前情况，我只能根据经验选择动作，那么 动作 1 的期望值是 (0.1 + 0.9 + 0.2 + 0.5) / 4 = 0.425 动作 2 的期望值是 (0.6 + 0.5 + 0.1 + 0.5) / 4 = 0.425 动作 3 的期望值是 (0.3 + 0.4 + 0.2 + 0.7) / 4 = 0.4所以，我应该选择动作 1 或 2，最佳期望是 0.425 如果我知道当前情况，我就可以选择最佳动作，那么 情况 A，我选择动作 2，0.6 情况 B，我选择动作 1，0.9 情况 C，我选择动作 1 或 3，0.2 情况 D，我选择动作 3，0.7所以最佳期望为 (0.6 + 0.9 + 0.2 + 0.7) / 4 = 0.6 import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}});","link":"/AI/RL/RL-Midterm/"},{"title":"RL-MonteCarlo","text":"蒙特卡罗方法 入门动态规划需要完整的环境模型且计算量大，而蒙特卡洛方法不需要环境模型，且适用于大规模问题。它只适用于 Episodic 回合任务，即任务有明确的结束点，如玩一局游戏。且只在回合结束后更新价值函数。 采样策略MC 方法通过 经验数据（Estimated value function）来计算价值，有两种策略： 假设在同一个 episode 中，我们经历了状态： $$S_1, S_2, S_2, S_1$$ First-visit MC：每个状态在一个回合中 首次 出现时，它的回报被记录以用于估计 也就是只会记录 $s_1$ 的第一次访问（第一步），这种策略适用于大部分任务，它减少了计算量，但可能浪费一些有用的信息。 Every-visit MC：每个状态在一个回合中 所有访问 该状态的回报都被记录以用于估计 则会在第一步和第四步都记录 $s_1$ 的回报，它利用所有数据，会更快的收敛到正确的估计函数，但可能导致过度计算。 经验采样之前我们提到代理会产生一种叫 Trajectory 轨迹的数据，表示为 $$(s_t, a_t, r_t, s_{t+1}), \\cdots$$ $s_t$：状态 $a_t$：动作 $r_t$：回报 $s_{t+1}$：下一个状态 这个过程也被称之为 episode 回合，是代理在环境中的一次完整尝试。经验采样利用这些数据，不需要知道环境的规则，代理通过多次交互摸索出最佳策略，记录经验并不断优化，且一定需要足够的探索。 Bootstrap自举是指利用已有的估值来更新当前估计。公式 $$V(S_t) \\leftarrow E_{\\pi} [R_{t+1} + \\gamma V(S_{t+1})]$$ 就体现了 DP 中的自举，它利用了下一个状态的估值来更新当前状态的估值。而 MC 方法不使用自举，它通过对实际经历的样本回报进行平均来估计状态的价值。这种特性使得 MC 方法对环境的依赖程度更低，它不需要知道状态之间的转移关系和其他估值。公式 $$V(S_{t}) \\leftarrow V(S_{t}) + \\alpha (G_{t} - V(S_{t}))$$ $\\alpha$：学习率，越大对新样本越重视 $G_t$：是从 t 开始到一个 episode 结束的回报总和 $V(S_t)$：表示当前状态的估计值 $G_t - V(S_t)$：表示当前估计值与实际回报的误差 通过学习率来控制调整的幅度，然后将调整值加到估计值上，得到新的估计值。 21 点游戏21 点的规则是使得手牌总和尽可能接近 21，但是不能超过21。 玩家先行动，可以选择 Hit 要牌或者 Stick 停牌 庄家根据固定规则行动，如果手牌总和小于 17，就要牌，否则停牌 2 到 10 的牌面值为其点数，J、Q、K 的点数为 10，A 的点数为 1 或 11（如果 11 会爆牌就取 1） 游戏可以描述为 MDP： 状态：玩家的手牌和庄家的明牌 动作：Hit 或 Stick 奖励：游戏结束时的奖励，赢了为 1，输了为 -1，平局为 0 折扣因子：$\\gamma = 1$ 无限张牌，每张牌被抽到的概率是相等的 MC 方法在 21 点游戏中，First 与 Every 的效果一致，因为不会回到曾经的状态。从实验结果发现，当玩家手牌总和较大（20，21）时，State Value 跃升，此时玩家通常选择 Stick，胜率较高。如果有可用的 A，则胜率更高，因为可以灵活选择 1 或 11，降低 Bust 的概率。 MC 策略通过采样回合来估计状态价值，但是有一个重要问题：许多 状态-动作 对可能永远不被访问，如果策略是确定性的，即始终选择当前最优策略，则某些 Q 值无法估计。所以我们提供了两种解决方案： Exploring Starts：让每个回合都从随机的状态和动作开始，但在实际环境中我们可能无法随意选择回合的起点。 Stochastic Policy：使策略变得随机，以高概率选择当前最优动作，有概率选择其他动作，可以使用 $\\epsilon$-greedy 策略，soft policy（任何状态下每个动作都有概率被选中）。 MC 只能近似最优策略，它使用广义策略迭代进行收敛，但它理论上要求无限多的回合来保证最终收敛，但现实中不可能，我们可以使用 Funciton Approximation 来近似价值函数。在实际应用中，我们通常不会等待策略评估完全收敛再进行策略改进（Incomplete Policy Evaluation），而是在有误差的情况下就开始改进策略，比如只迭代了一次评估，就开始改进策略，会导致优化过程不稳定。 On / Off-Policy","link":"/AI/RL/RL-MonteCarlo/"},{"title":"RL-动态规划","text":"Dynamic Programming学不动了，真的 动态规划基础我们都知道斐波那契数列计算 12345function fib(n: number): number { if (n === 0) return 0; if (n === 1) return 1; return fib(n - 1) + fib(n - 2);} 这种朴素的递归算法，时间复杂度是指数级别的，$O(2^\\frac{n}{2})$，我们可以用动态规划来优化。 1234567891011const memo = [];function fib(n: number): number { if (n === 0) return 0; if (n === 1) return 1; if (memo[n] !== undefined) return memo[n]; memo[n] = fib(n - 1) + fib(n - 2); return memo[n];} 它简单的将之前的计算结果保存下来，避免了重复计算，时间复杂度降到了$O(n)$。 这就引出了动态规划的两个重要概念： DP = Recursion + Memoization 在强化学习中，动态规划是一组用来计算最优策略的算法集合。使用动态规划时需要给定环境的完美模型，我们使用 MDP 来描述此环境模型。就算使用动态规划，也需要消耗大量计算资源。 但是 DP 在处理大规模问题的时候仍然会遇到维度诅咒，并且需要确切的环境模型，才能进行评估和改进。 Policy Evaluation前面我们讲到 State-value 函数用于评估某个状态的价值 $$v_{\\pi}(s) = E_{\\pi}[R_{t+1} + \\gamma v_{\\pi}(S_{t+1}) | S_t = s]$$ $$= \\sum_{a} \\pi(a|s) \\sum_{s’, r} p[s’, r|s, a](r + \\gamma v_{\\pi}(s’))$$ 由于此方程一般没有解析解，通常采用迭代的方式来求解，这就为我们后续进行策略改进提供了基础。 Grid World我们在之前的 例：值迭代 中已经见过，这次让我们来看一道新的类型题目。 有一个已经计算好的策略如下： x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 x 0.0 -14 -20 -22 -14 -18 -20 -20 -20 -20 -18 -14 -22 -20 -14 0.0 奖励函数：-1，表示每一步都会受到 -1 的惩罚。 现在，让我们添加一个新的状态 15： x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 x - 15 - - 并且规定在 15 处执行： 左：15 -&gt; 12 右：15 -&gt; 14 上：15 -&gt; 13 下：15 -&gt; 15 问 1，设原状态转移的情况保持不变，在等概率随机策略的情况下，状态 15 的价值是多少？ 问 2，现在假设从 13 执行向下会到 15，状态 15 的价值是多少？ 问 1要注意，原状态转移情况不变的意思是，在 13 处向下不会进入到新状态 15。 我们知道 $\\pi(a|s) = 0.25$，$p(s’ | s, a) = 1$，$r = -1$，$\\gamma = 1$。 所以： $v_{\\pi}(15) = \\sum_{4} 0.25 \\sum_{s’, r} 1 \\times [-1 + 1 \\times v_{\\pi}(s’)] =$$0.25 \\times [-1 + -22] +$$0.25 \\times [-1 + -20] +$$0.25 \\times [-1 + -14] +$$0.25 \\times [-1 + v_{\\pi}(15)] =$$-15 + 0.25 \\times v_{\\pi}(15)$ 将 $v_{\\pi}(15)$ 移到左边，得到： $0.75 \\times v_{\\pi}(15) = -15$ $v_{\\pi}(15) = -20$ 问 2由于 15 的移动特性，导致它实际上是 13 的别名，所以不会导致 13 或 15 的价值发生变化。 让我们来计算验证一下： $v_{\\pi}(15) =$$0.25 \\times [-1 + -22] +$$0.25 \\times [-1 + v_{\\pi}(13)] +$$0.25 \\times [-1 + -14] +$$0.25 \\times [-1 + v_{\\pi}(15)] =$$-10 + 0.25 \\times v_{\\pi}(13) + 0.25 \\times v_{\\pi}(15)$ $v_{\\pi}(13) =$$0.25 \\times [-1 + -22] +$$0.25 \\times [-1 + -20] +$$0.25 \\times [-1 + -14] +$$0.25 \\times [-1 + v_{\\pi}(15)] =$$-15 + 0.25 \\times v_{\\pi}(15)$ 联立求解： $0.75v_{\\pi}(15) = -10 + 0.25 \\times (-15 + 0.25v_{\\pi}(15))$ $v_{\\pi}(15) = -20$ $v_{\\pi}(13) = -15 + 0.25 \\times (-20) = -15 - 5 = -20$ 因此，状态13和状态15的价值都是-20。 Policy Improvement如果在某个状态下，选择另一个不同的动作能够带来更高的状态价值，那么就可以更新策略。显然，如果一个策略选择的动作在所有可能的动作中有最高的状态价值，那么这个策略就是最优策略。一种常见的改进方法是贪心策略。 将策略改进和策略评估结合起来，就可以得到策略迭代算法。我们首先评估所有状态价值，然后更新策略，如此循环直到收敛。在有限的 MDP 中，Policy Iteration 算法总是能够收敛到最优策略。 策略改进算法可能导致震荡（Oscillation），即在两个策略之间来回切换，可以引入一个变化率参数，当策略改进的变化率小于某个阈值时停止。我们还需要通过截断评估（Truncated Evaluation）来加速收敛，即只评估一定次数的状态价值。 完整评估的意思是使用贝尔曼迭代方程反复更新，直到变化率小于某个阈值。而截断评估则是只更新一定次数就立刻开始策略改进。 Value Iteration 是一种更高效的策略迭代算法，它不需要完整评估，而是在每次迭代中只更新一次状态价值，然后立刻进行策略改进。这样可以减少计算量，但是可能会导致策略不稳定。 Asynchronous DP我们还可以使用异步 DP，它不需要对所有状态进行同步更新，可以只更新部分状态的值。允许在不同时间更新不同状态，甚至可以有优先级，比如靠近目标的状态可能比远的更重要。异步更新不需要像同步 DP 那样储存当前轮和上一轮的值函数，因为它可以就地更新。 Generalized Policy Iteration广义策略迭代并不是一个具体算法，它就是由上面的 Policy Iteration 和 Value Iteration 两种策略组合而成的。在每次迭代中，我们都会评估当前策略，然后改进策略。这样可以保证策略迭代算法收敛到最优策略。Value Iteration 就是一种应用。 Gambler’s Problem一个赌徒有机会对一系列抛硬币的结果进行下注。如果硬币正面朝上，他赢得的金额与他在该次下注的金额相同。如果硬币反面朝上，他就会输掉所下堵住。当赌徒达到 100 收入则获胜，或者输光所有钱而失败。每次抛硬币时，他需要自己决定下注金额。 此问题可以被描述为一个 $\\gamma = 1$ 的有限 MDP，状态是他的资金 $s \\in {1, 2, …, 99}$，动作是他的下注金额 $a \\in {0, 1, 2, …, \\min(s, 100 - s)}$，奖励是 0，除了在 $s = 100$ 时奖励为 1。策略是从资金水平到下注金额的映射。$p_h$ 表示硬币正面朝上的概率，知道它即可求解。 你能猜出最优价值函数和最优策略是什么样的吗？ 此问题使用 DP 的 Value Iteration 算法可以求解。 最优策略之所以具有这种奇怪的形式，特别是在资本为 50 时选择全押，而资本为 51 时却不全押，是因为最优策略不仅仅是考虑单次胜负，而是考虑达到目标（赢得 $100）的最优路径。在 50 时，全压可以直接赢得游戏，而在 51 时： 51 视为 50 + 1，也就是说我们可以考虑如何利用额外的 1 元来赢得游戏。 如果压 50，赢了就 101 了，但是 101 没有收益，没有意义。输了就回到 1，几乎等于输掉了游戏。赢的概率是 $p_h$。 最好的办法是先压 1 美元，输了回到 50 再继续压。 Problem Buildup如果模型已知，状态空间小且有限，动作空间小且有限的情况下，使用启发式搜索是很好的选择。 Search Trees 中的每个节点都对应着 State Space Graph 中的一条完整路径。 如果搜索空间很大，那么使用 DP 是更好的选择。如果模型未知，就需要使用 Monte Carlo 方法。","link":"/AI/RL/RL-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"RL-多臂老虎机","text":"强化学习强化的不是机器模型而是我的猪脑 老虎机单臂现在在你面前有一台老虎机，它有固定的中奖率，当你拉动它，你就会从固定的概率分布中得到奖励。而这个情况不能视作一个强化学习问题，因为它只有一个状态和一个动作，你不能通过任何方法来优化你的策略。 多臂既然如此，我们就拿来多台老虎机。现在在你面前有数台单臂老虎机，它们各自有不同的中奖分布。现在给定有限的拉动次数 T，你如何拉动这些老虎机来最大化你的收益呢？ 这个问题是一个 非联想的，评估性的反馈问题，及每次反馈只评估当前动作，也就是独立事件。 定义 非联想的：Non-Assocative，即每次动作的结果不会影响到接下来你对其他老虎机的预期收益。你只是单纯的记录下每个老虎机的平均奖励，然后选择最大的那个。 联想的：Associative，当前动作的结果会影响到未来动作的预期收益。你从这次拉动中获得的信息，会影响到你对其他老虎机的选择。在类似于上下文老虎机中，你的动作会影响其他老虎机的中奖概率。 评估性的：Evaluative，你得到的奖励，只是你当前动作的结果，你只能知道你刚刚得到了多少收益，而不能知道其他老虎机的中奖概率。 指导性的：Instructive，在这种情况下，你不光能得到当前的结果，还能得到其他可能的结果信息。比如你拉动了一个老虎机，你不仅得到奖励，还能得到其他老虎机的奖励信息，即使你没有选择它们。 Formalization需要数学的方式表达此问题才能应用到计算机中。所以我们定义： t 时刻 $A_t$ 在 t 时刻选择的动作 $R_t$ 在 t 时刻得到的奖励 $q_*(a)$ 动作 a 的真实值，是一个固定值，但通常未知 $Q_t(a)$ 在 t 时刻对动作 a 的估计值，根据过去的经验得到 例子假设你面前有三个老虎机 1, 2, 3，你有 4 个可用次数： 时刻 t 选择 $A_t$ 奖励 $R_t$ 期望 $Q_t(1)$ $Q_t(2)$ $Q_t(3)$ 1 1 5 5 0 0 2 2 3 5 3 0 3 3 4 5 3 4 4 1 4 4.5 3 4 每次选择一个动作并获得奖励后，需要更新对该动作的估计值。这里我们使用简单的平均值来估计： $$ Q_t(a) = \\frac{\\sum_{i=1}^{t-1} R_i \\cdot \\mathbb{1}_{A_i = a}}{\\sum_{i=1}^{t-1} \\mathbb{1}_{A_i = a}} $$ $\\mathbb{1}_{A_i = a}$ 是一个指示函数，当 $A_i = a$ 时为 1，否则为 0。确保了只有选择了动作 a 的时候才会更新估计值。 这就是 Action-value Methods，即通过动作的估计值来选择动作。 大数定律简而言之，如果一个事情你做的次数足够多，那么它的平均结果（预估收益）就会接近于它的真实情况。比如抛硬币，正反面比例会越来越接近 0.5。 探索和利用让我们来理解一下 探索 (Exploration) 和 利用 (Exploitation) 的概念。 在任何时间步，至少有一个动作的估计值是最大的。也就是说如果我们选择了一个最大的动作，这就是利用，或者贪婪动作。 如果我们选择非贪婪动作，那么就是探索，去试试看能否找到更好的动作。 像之前表中我们在 t=4 的时候选择了 1，这就是贪婪动作。但是我们会发现一个问题： 为了获得最大奖励，我们偏好选择已知的最大动作 但是如果我们不去探索其他动作，我们就无法知道其他动作的真实值 所以我们需要在探索和利用之间找到一个平衡 $\\epsilon$-greedy它是平衡探索和利用的一个简单有效的方法。 以 $\\epsilon$ 的概率进行探索，而不考虑价值估计 以 $1-\\epsilon$ 的概率进行利用（贪心动作），选择已知的最大价值动作 练习：计算概率当 $\\epsilon = 0.5$ 时，计算有两个动作，且选择贪心动作的概率。 two actions 不是说你选两次，而是说你在每次选择动作的时候，一共有两个可能，如选 A 或 B。 情况 1：确定选择 ($1-\\epsilon$)：= 0.5 的概率直接选择贪心动作 情况 2：随机选择所有动作，也包括选中贪心动作的概率，此时： 选择贪心动作的概率 = 非贪心动作的概率 = 0.5 同时发生 情况 2 &amp; 情况 2 选中贪心动作 的概率 = 0.5 * 0.5 = 0.25 所以选择贪心动作的概率 = 情况 1 + 情况 2 = 0.5 + 0.25 = 0.75 12345 选择方式 / \\ 情况1 (0.5) 情况2 (0.5) / / \\选贪心动作 选A(0.5) 选B(0.5) 练习：策略选择有 K 臂老虎机，K = 4，四个动作标记为 [1, 2, 3, 4]。应用 $\\epsilon$-greedy &amp; sample-average 方法来选择动作。所有动作初始值 $Q_1(a) = 0$。假设前五个时间步的动作和奖励序列如下： 时刻 t 选择 $A_t$ 奖励 $R_t$ 1 1 1 2 2 1 3 2 2 4 2 2 5 3 0 问：在哪些时间步 一定 发生了探索？在哪些时间步 可能 发生了探索？ 解： 由于 5 步内未选择 4，所以在表中隐去。情况描述的是从上一个状态到当前状态。 时刻 t 选择 $A_t$ 奖励 $R_t$ 期望 $Q_t(1)$ $Q_t(2)$ $Q_t(3)$ 情况 细节 0 - - 0 0 0 - 初始值 1 1 1 1 0 0 可能 所有动作初始等效，无法区分 2 2 1 1 1 0 一定 选择了一个非最优动作 3 2 2 1 1.5 0 可能 选择了最大值动作，但是 1 和 2 值相同 4 2 2 1 1.66 0 可能 2 成为最优，但 2 可能是被随机选中的 5 3 0 1 1.66 0 一定 选择了一个非最优动作 增量更新记录所有的奖励数据需要占用大量内存，incremental implementation 可以节省内存。通过推导，我们能够得到加权平均的增量更新公式： $$Q_{n+1} = Q_n + \\alpha \\cdot (R_n - Q_n)$$ 其中： $Q_{n+1}$ 是新的估计值 $Q_n$ 是旧的估计值 $R_n$ 是本次奖励 $\\alpha$ 是学习率，通常是一个小于 1 的值 学习率 静态环境当 $\\alpha = \\frac{1}{n}$ 时，即学习率随着时间步的增加而减小，适用于 Stationary Environment，即环境的奖励分布不会随时间变化，保证了所有过去的数据都以同等权重参与更新。 动态环境当学习率是一个固定值，通常 $0 &lt; \\alpha \\leq 1$ 时，适用于 Non-Stationary Environment，即环境的奖励分布会随时间变化，近期的奖励对估计值影响更大，而早期的奖励影响较小。 而使用固定的学习率，其实是一种 指数加权平均 (Exponential Weighted Average)，通过对普通加权平均公式的变形，我们可以得到： $$Q_{n+1} = (1-\\alpha)^n Q_1 + \\sum_{i=1}^n \\alpha(1-\\alpha)^{n-i} R_i$$ 阅读公式我们可以知道： 当 $n$ 很大时，$(1-\\alpha)^n$ 趋近于 0，即初始值的影响越来越小 第二项是一个加权和，权重随着时间步的增加而减小，也就是说近期的奖励对估计值影响更大 较大的 $\\alpha$ 适合快速变化的环境 乐观初始值Optimistic Initial Values 通过人为的为所有动作的估计值设置一个过高的初始值，可以鼓励探索。随着时间步的增加，估计值会逐渐收敛到真实值。相比与 $\\epsilon$-greedy，它不依赖随机探索，而是基于策略性搜索。代理会确保所有动作都被选择一次，然后根据奖励来调整估计值，而不会陷入局部最优。适用于静态环境和早期探索。 上限置信区间一种更智能的决策方案是 Upper Confidence Bound (UCB)。它的公式是： $$A_t = \\arg \\max_a \\left[ Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t(a)}} \\right]$$ 公式直观的分为三部分： $Q_t(a)$ 利用项，是动作 a 当前的最佳估计值，高则 UCB 也高，意味着可能是好选择 $\\sqrt{\\frac{\\ln t}{N_t(a)}}$ 探索项 未被尝试的动作 $N_t(a)$ 较小，置信界较大，需要更多的探索 已被尝试的动作 $N_t(a)$ 较大，置信界较小，主要依赖于 $Q_t(a)$，即利用 随着时间步的增加，探索压力逐渐减小，因为 $ln t$ 的增长速度很慢，而 $N_t(a)$ 一直增加 $c$ 是一个探索参数，控制探索的强度，越大越多探索 $A_t$ 是选择的动作，$\\arg \\max_a$ 来决定最大 UCB 值及其对应的动作 当 UCB 高的时候，代表了两种情况，一是动作本来就很好（$Q_t(a)$ 高），二是动作未被充分尝试过（$N_t(a)$ 低），而这个结果本身代表着 探索 + 利用 的收益估计值。该方法优于 $\\epsilon$-greedy，减少随机性带来的浪费，适用于静态环境。 探索项其实是通过 Hoeffding Inequality 推导出来的，不等式提供了样本均值与真实均值的误差范围，误差项的形式正是 $\\sqrt{\\frac{\\ln t}{N_t(a)}}$。 策略梯度它通过调整每个动作的概率来优化策略。使用 softmax 函数来表示： $$\\pi_t(a) = \\frac{e^{H_t(a)}}{\\sum_{b=1}^K e^{H_t(b)}}$$ 其中： $\\pi_t(a)$ 是动作 a 在 t 时刻被选择的概率 $H_t(a)$ 是动作 a 在 t 时刻的偏好值，不直接表示概率，而是一个中间量 K 是动作的数量 此算法不会死板地只选一个动作，因为所有的选择都有一定概率被探索，更适合非静态环境，但是对学习率较敏感，不容易调优。 梯度上升（Ascent）我们的目标是优化动作选择的概率，而不是直接估计奖励值。在时间 t： 选中动作 a 得到奖励 $R_t$ 计算奖励与 平均奖励 $\\bar{R_t}$ 的差值 $\\delta_t = R_t - \\bar{R_t}$ 如果 $\\delta_t &gt; 0$，则动作 a 是好的，我们希望增加它的概率 如果 $\\delta_t &lt; 0$，则动作 a 是坏的，我们希望减少它的概率 更新偏好值 $H_t(a)$，其他未选中的 $H_t(b)$ 也会轻微变化，因为 softmax 函数的特性 所以公式如下, 其中 $\\alpha$ 是学习率： $$H_{t+1}(a) = H_t(a) + \\alpha (R_t - \\bar{R_t})(1 - \\pi_t(a))$$ 其他未选中的动作： $$H_{t+1}(b) = H_t(b) - \\alpha (R_t - \\bar{R_t})\\pi_t(b)$$ 关联搜索Assocative Search 是对之前 联想任务 的扩展，是在 多情境（context）下的决策优化。 在 Associative 中，动作可能影响未来收益，但问题仍然是单一情境。 而在 Associative Search 中，不仅要学习单个情境下的最优动作，还需要在多个情境中学习不同策略。 对于这种问题，我们为每一种情境学习一个独立的策略。如果动作不仅影响奖励，还影响接下来的情境，那么这个问题就升级为完整的强化学习任务。 练习现在有两组 2-臂老虎机，你面对的老虎机组会在每个时间步随机变化： A 组（概率 0.5）： Arm 1 的真实值：0.1 Arm 2 的真实值：0.2 B 组（概率 0.5）： Arm 1 的真实值：0.9 Arm 2 的真实值：0.8 你无论如何也不知道它们的真实值，问： 如果你 不知道 当前是 A 组还是 B 组，你会如何选择动作？ 如果你 知道 当前是 A 组还是 B 组，你会如何选择动作？ 情况 1如果我不能知道当前情况，那么我只能根据期望值来决策： 对于 Arm 1，它的期望奖励是： $$E[R_1] = 0.5 \\cdot 0.1 + 0.5 \\cdot 0.9 = 0.5$$ 对于 Arm 2，它的期望奖励是： $$E[R_2] = 0.5 \\cdot 0.2 + 0.5 \\cdot 0.8 = 0.5$$ 所以，由于两个动作的期望奖励相同，我会随机选择一个动作。最大期望收益就是 0.5。 情况 2当我知道现在的情况时，我就能够有针对性的选择策略。 在 A 组时（概率 0.5）： 选择 Arm 1 的期望奖励是 0.1 选择 Arm 2 的期望奖励是 0.2 所以我会选择 Arm 2 在 B 组时（概率 0.5）： 选择 Arm 1 的期望奖励是 0.9 选择 Arm 2 的期望奖励是 0.8 所以我会选择 Arm 1 它的最大期望奖励是： $$E[R_{best}] = 0.5 \\cdot 0.2 + 0.5 \\cdot 0.9 = 0.55$$ 有额外的上下文信息（context）可以帮助提高决策质量，这正是 关联搜索（Associative Search） 的关键思想。","link":"/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/"},{"title":"RL-马尔可夫决策过程","text":"Markov Decision Processes流感让我断更一周 基础概念马尔可夫决策过程有点像自动机。简而言之，它：在某个状态下，选择一个动作，获得某种奖励，进入下一个状态。 状态（State）：$S$，环境状态，如棋盘上的位置，角色血量 动作（Action）：$A$，代理可选的动作，如走一步，攻击 奖励（Reward）：$R$，反馈，如吃到食物，受到伤害 转移概率（Transition Probability）：$P$，状态转移概率，如可能的下一步 决策是一个不断重复的过程，每次做出选择都会影响未来的状态和奖励。其本质是代理（Agent）与环境（Environment）之间的交互： Agent 在状态 $S_t$ 选择动作 $A_t$ Environment 返回奖励 $R_{t+1}$ 和新状态 $S_{t+1}$ Agent 根据奖励和新状态更新策略 重复 整个过程形成一个轨迹（Trajectory）$S_0, A_0, R_1, S_1, A_1, R_2, S_2, \\cdots$，我们可以发现它的核心是“状态如何变化”，我们用 转移概率（Transition Probability）来描述这个过程： $$ p(s', r | s, a) \\doteq Pr\\{S_t = s', R_t = r | S_{t-1} = s, A_{t-1} = a\\} $$ 其中： $s, s’$ 是状态 $a$ 是动作 $r$ 是奖励 意思是在状态 $s$ 下，选择动作 $a$，进入状态 $s’$，获得奖励 $r$ 的概率 且 $\\sum_{s’} \\sum_r P(s’, r | s, a) = 1$ 也就是说一定会转移到某个状态并获得某个奖励，不会出现转移到虚空，或者没有奖励的情况，且所有可能的状态和奖励的概率和为 1。 如果状态，动作，奖励是有限个数的，就叫 Finite MDP，我们能够精确计算出最优策略。 此公式还有其他形式： 状态转移概率 $$ p(s' | s, a) \\doteq Pr\\{S_t = s' | S_{t-1} = s, A_{t-1} = a\\} = \\sum_r p(s', r | s, a) $$ 它表示在状态 $s$ 下，选择动作 $a$，进入状态 $s’$ 的概率。由于状态转移可能伴随不同奖励，所以需要对所有可能的奖励求和。 期望即时奖励$$r(s, a) \\doteq E[R_t | S_{t-1} = s, A_{t-1} = a] = \\sum_r r \\sum_{s’} p(s’, r | s, a)$$ 它表示在状态 $s$ 下，选择动作 $a$，期望获得的奖励 $R_t$。每种情况都有不同的概率和奖励，所以需要对所有可能的状态和奖励求和，以计算平均期望奖励。 期望奖励$$r(s, a, s’) \\doteq E[R_t | S_{t-1} = s, A_{t-1} = a, S_t = s’] = \\sum_r r \\frac{p(s’, r | s, a)}{p(s’ | s, a)}$$ 这里是在已经知道从 $s$ 执行 $a$ 后，转移到 $s’$ 的情况下，计算期望奖励。通过对所有可能的奖励加权求和，归一化到特定的状态转移概率 $s \\to s’$。 确定与随机如果一个系统是 Deterministic 的，那么在给定 $s$ 和 $a$ 后，$s’$ 是确定的，即 $p(s’ | s, a) = 1$，每次执行相同的动作，结果都会一样，如棋类游戏。 如果是 Stochastic 的，那么 $p(s’ | s, a)$ 是一个概率分布，且 $\\sum_{s’} p(s’ | s, a) = 1$，表示执行后可能转移到不同状态，如掷骰子，环境有随机变化等。 任何代理无法改变的事物都是环境的一部分，边界代表着代理能够影响的事物的范围极限。 例子假设有环境，你当前处于 C： x 10, A x 0, B 0, C 0, D x 0, E x State Space: $S = [A, B, C, D, E]$ Action Space: $A = [Up, Down, Left, Right]$ 确定性转移代理在 C 选择 Up，进入 A 的概率是 1，奖励是 10，公式表示为 $$p(A | C, Up) = 1$$ 奖励表述为 $$r(C, Up) = 10 \\times p(A, 10 | C, Up) = 10$$ 随机转移设代理有 0.8 的概率向上移动成功，0.1 的概率被环境带到其他位置。 $$p(A | C, Up) = 0.8, p(B | C, Up) = 0.1, p(C | C, Up) = 0.1$$ 奖励计算为： $$r(C, Up) = 10 \\times p(A, 10 | C, Up) + 0 \\times p(B, 0 | C, Up) + 0 \\times p(C, 0 | C, Up) = 8$$ Exercise: Transition Graph你正在玩一个回合制战斗游戏： 你的初始 HP = 2 敌人的初始 HP = 1 你的动作有 Attack 和 Heal 攻击：有 0.2 的几率击杀敌人，获得 5 奖励，其余情况无事发生 治疗：有 0.6 的几率回复 1 HP（最大 HP 2），获得 1 奖励，其余情况无事发生 你执行动作后，敌人有 0.5 的几率攻击你，造成 1 伤害 如果你 HP = 0，游戏结束，获得 -5 奖励 如果敌人 HP = 0，游戏结束，获得 5 奖励 我们能够列出所有的可能状态： flowchart TD B([\"Strong2/1\"]) --> n1[\"H\"] & n2[\"A\"] n3([\"Week1/1\"]) --> n4[\"H\"] & n5[\"A\"] n6([\"Win2/0 or 1/0\"]) n7([\"Die 0/1\"]) 你现在在 Strong，假设你选择了攻击，那么你有 0.2 的概率杀死敌人获得奖励。但还有 0.8 的概率无事发生，这就轮到敌人的回合，它有 0.5 的概率让你受到伤害，则： flowchart LR B([\"Strong2/1\"]) --> n1[\"H\"] & n2[\"A\"] n3([\"Week1/1\"]) --> n4[\"H\"] & n5[\"A\"] n2 -- \"0.2 | 5\" --> n6([\"Win2/0 or 1/0\"]) n2 -- \"0.4 | 0\" --> B & n3 n7([\"Die 0/1\"]) 你现在在 Strong，假设你选择了治疗，但是你满血，所以无论回血是否发生，都无事发生，轮到敌人的回合，它有 0.5 的概率让你受到伤害，则： flowchart LR B([\"Strong2/1\"]) --> n1[\"H\"] & n2[\"A\"] n3([\"Week1/1\"]) --> n4[\"H\"] & n5[\"A\"] n2 -- \"0.2 | 5\" --> n6([\"Win2/0 or 1/0\"]) n2 -- \"0.4 | 0\" --> B & n3 n1 -- \"0.5 | 0\" --> B & n3 n7([\"Die 0/1\"]) 其他情况以此类推，最终得到： flowchart LR B([\"Strong2/1\"]) --> n1[\"H\"] & n2[\"A\"] n3([\"Week1/1\"]) --> n4[\"H\"] & n5[\"A\"] n2 -- \"0.2 | 5\" --> n6([\"Win2/0 or 1/0\"]) n2 -- \"0.4 | 0\" --> B & n3 n1 -- \"0.5 | 0\" --> B & n3 n5 -- \"0.2 | 5\" --> n6 n5 -- \"0.4 | 0\" --> n3 n5 -- \"0.4 | -5\" --> n7([\"Die 0/1\"]) n4 -- \"0.3 | 1\" --> B n4 -- \"0.2 | 0\" --> n3 n4 -- \"0.2 | -5\" --> n7 n4 -- \"0.3 | 0\" --> n3 在 Week 时治疗，有 0.6 概率成功，随后有 0.5 的概率再被攻击，所以是 0.3 的概率回到 Strong。 目标与奖励代理的目标是最大化累积奖励的期望值。 $$G_t \\doteq R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\cdots + \\gamma^{T-t-1} R_T = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}$$ 其中： $G_t$ 是从 $t$ 时刻开始的累积奖励 $R_t$ 是 $t$ 时刻的奖励 任务类型 Episodic Task：上面的 t 是有限的，任务有明确的终止状态，如游戏 Continuing Task：t 是无限的，任务没有明确的终止状态，如生存，股票 折扣回报（Discounted Return）： 由于在持续任务中，回报可能是无限的，难以计算，且在现实世界中，未来的奖励通常不如当前奖励重要，因此要给未来奖励打折，所以引入折扣因子 $0 \\leq \\gamma \\leq 1$，来减少未来奖励的影响。 $\\gamma \\rightarrow 0$：关注短期的奖励 $\\gamma \\rightarrow 1$：关注长期的奖励 由于折扣回报涉及多个时间步，所以可以使用递归形式： $$G_t \\doteq R_{t+1} + \\gamma G_{t+1}$$ 表明当前的回报由 当前奖励 和 未来回报 组成。我们约定 $R_{T+1}$ 代表在 $t$ 时采取动作的奖励。 当 $R_t = 1$ 且 $\\gamma &lt; 1$ 时，有： $$G_t = \\frac{1}{1 - \\gamma}$$ 马尔可夫性质Markov Property 就一句话，下一个状态只依赖于当前状态，与之前的状态无关。 练习：给定 $\\gamma = 0.5$，奖励序列如下： $R_1 = -1$ $R_2 = 2$ $R_3 = 6$ $R_4 = 3$ $R_5 = 2$ 目标是计算从每个时间步 $t$ 开始的折扣回报 $G_t$。 解： 在 MDP 中，终止状态的回报通常为 0，因为不会再有新的状态了，所以有 $$G_5 = 0$$ 我们从最后一步开始，使用折扣回报公式，逐步向前计算： $$G_t = R_{t+1} + \\gamma G_{t+1}$$ t $R_t$ $G_t$ 5 - $G_5 = 0$ 4 $R_5 = 2$ $G_4 = 2 + 0.5 \\times 0 = 2$ 3 $R_4 = 3$ $G_3 = 3 + 0.5 \\times 2 = 4$ 2 $R_3 = 6$ $G_2 = 6 + 0.5 \\times 4 = 8$ 1 $R_2 = 2$ $G_1 = 2 + 0.5 \\times 8 = 6$ 0 $R_1 = -1$ $G_0 = -1 + 0.5 \\times 6 = 2$ 吸收状态有限与无限任务需要一个共同的表示方式，所以我们为 Episodic Task 引入了吸收状态（Absorbing State）。当任务到达 $T$ 时，不再设为终止状态，而是吸收状态，它不会再产生奖励。我们可以重新定义折扣回报： $$G_t \\doteq \\sum_{k=t+1}^{T} \\gamma^{k-t-1} R_k$$ $G_t$ 是从 $t$ 时刻开始的累积奖励 $R_k$ 是 $k$ 时刻的奖励 $T$ 是任务结束的时间步，也可以是无限的 $T = \\infty$ 与 $\\gamma = 1$ 不能同时存在，否则回报无限 策略与价值函数代理用于在环境中做出决定的规则成为策略（Policy）$\\pi$，将状态映射到动作： $$\\pi(a|s) = P(A_t = a | S_t = s)$$ 这表示代理在状态 $s$ 下选择动作 $a$ 的概率。策略可以是确定性（Deterministic）的，即 $\\pi(s) = a$，在某个状态下始终采取同一个动作。也可以是随机性（Stochastic）的，即上述公式。在 RL 中，我们的目标是找到最优策略 $\\pi^*$，使得在任何状态下，都能获得最大的累积奖励。 Value Function 用于衡量 State-Action Pair 的好坏，即代理在该状态下应期望得到多少奖励。 Action-value 函数动作价值函数表示在策略 $\\pi$ 下，从状态 $s$ 开始，选择动作 $a$ 后，未来能够获得的期望折扣回报： $$q_{\\pi}(s, a) \\doteq E_{\\pi}[G_t | S_t = s, A_t = a] = E_{\\pi}[\\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} | S_t = s, A_t = a]$$ 这个函数对于动作选择很重要，它直接告诉我们某个动作的价值。人类难以直观估计 Q 值，因为其涉及长期回报计算。 我们可以用递归（Bellman）的方式表示： $$q_{\\pi}(s, a) = E_{\\pi}[R_{t+1} + \\gamma q_{\\pi}(S_{t+1}, A_{t+1}) | S_t = s, A_t = a]$$ State-value 函数状态价值函数表示在策略 $\\pi$ 下，从状态 $s$ 开始，未来能够获得的期望折扣回报： $$v_{\\pi}(s) \\doteq E_{\\pi}[G_t | S_t = s] = E_{\\pi}[\\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} | S_t = s]$$ 折扣是折扣因子导致的 我们可以用递归（Bellman）的方式表示： $$v_{\\pi}(s) = E_{\\pi}[R_{t+1} + \\gamma v_{\\pi}(S_{t+1}) | S_t = s]$$ $V_{\\pi}(s)$ 是在该状态下所有可能的动作 $Q(s, a)$ 的加权和： $$v_{\\pi}(s) = \\sum_{a} \\pi(a|s) q_{\\pi}(s, a)$$ 这意味着某个状态的价值，是在该状态下按策略选择不同动作的期望值。它衡量的是在该状态下，按照策略平均能得到多少奖励。 例：值迭代 x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 x Action Space: $A = [Up, Down, Left, Right]$ 策略：每个动作选择概率相等 $\\pi(a|s) = 0.25$ 每走一步都会有 $R = -1$ 的奖励，终点设置为 0。 环境为确定性环境，即 $p(s’ | s, a) = 1$ $\\gamma = 1$ 请计算每个状态的价值函数 $V(s)$，进行策略评估。 解： 值迭代使用贝尔曼方程来迭代： $$v_{\\pi}(s) = \\sum_{a} \\pi(a|s) \\sum_{s’, r} p(s’, r | s, a) [r + \\gamma v_{\\pi}(s’)]$$ $k = 0, V_0(s) = 0$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $k = 1$用 $s = 1$ 为例，分析概率： Up: $p(1, -1 | 1, Up) = 1$ Down: $p(5, -1 | 1, Down) = 1$ Left: $p(0, -1 | 1, Left) = 1$ Right: $p(2, -1 | 1, Right) = 1$ 其余情况为 0，如 $p(6, -1 | 1, Down) = 0$ 因为不可能直接从 1 走到 6 所以 $v_{\\pi}(1) = \\sum_{4} 0.25 \\sum_{s’, r} p(s’, r | 1, a) [r + \\gamma v_{\\pi}(s’)] =$$0.25 \\times 1 \\times [-1 + 1 \\times 0] +$$0.25 \\times 1 \\times [-1 + 1 \\times 0] +$$0.25 \\times 1 \\times [-1 + 1 \\times 0] +$$0.25 \\times 1 \\times [-1 + 1 \\times 0] =$$4 \\times 0.25 \\times -1 = -1$ 其他点也是同样的情况，有 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 $k = 2$用 $s = 1$ 为例： $v_{\\pi}(1) = \\sum_{4} 0.25 \\sum_{s’, r} p(s’, r | 1, a) [r + \\gamma v_{\\pi}(s’)] =$$0.25 \\times 1 \\times [-1 + 1 \\times 0] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] =$$3 \\times 0.25 \\times -2 + 1 \\times 0.25 \\times -1 = -1.75$ 其他点也是同样的算法： $v_{\\pi}(6) = \\sum_{4} 0.25 \\sum_{s’, r} p(s’, r | 6, a) [r + \\gamma v_{\\pi}(s’)] =$$0.25 \\times 1 \\times [-1 + 1 \\times -1] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] +$$0.25 \\times 1 \\times [-1 + 1 \\times -1] =$$4 \\times 0.25 \\times -2 = -2$ 得到 0 -1.75 -2 -2 -1.75 -2 -2 -2 -2 -2 -2 -1.75 -2 -2 -1.75 0 然后可以无限向后迭代，直到达到某个收敛值。 最优策略最优策略是能够最大化长期期望回报的策略。在 MDP 中，至少存在一个最优策略。使用 $v_*(s)$ 和 $q_*(s, a)$ 表示最优状态价值函数和最优动作价值函数（其实也就是那俩方程求 max）。 但这基本上是理论上可行，实践困难。在低维度，状态少的时候可以用动态规划或者值迭代，但一旦高维数据会导致计算量爆炸。Curse of Dimensionality 维度灾难就是说明状态空间维度高时，数据稀疏，计算困难的，这时候我们就需要 Function Approximation 函数逼近，如神经网络等。 备份图Backup Diagram 用于可视化值更新过程，每个空心圆代表一个状态，而实心圆代表一个 State-Action Pair。 考虑如下 MDP： State Space: 只有一个决策状态 Action Space: Left, Right Reward: $R_{Left} = 1, R_{Right} = 2$ $\\gamma = 0 / 0.9 / 0.5$ flowchart TD n1[\"Small Circle\"] -- left --> n2[\"Filled Circle\"] n1 -- right --> n3[\"Filled Circle\"] n3 -- 0 --> n4[\"Small Circle\"] n2 -- +1 --> n5[\"Small Circle\"] n5 --> n6[\"Filled Circle\"] n4 --> n7[\"Filled Circle\"] n6 -- 0 --> n1 n7 -- +2 --> n1 n1@{ shape: sm-circ} n2@{ shape: f-circ} n3@{ shape: f-circ} n4@{ shape: sm-circ} n5@{ shape: sm-circ} n6@{ shape: f-circ} n7@{ shape: f-circ} 求不同 $\\gamma$ 下的最优策略。 解： 首先拿出函数： $$v_{\\pi}(s) = E_{\\pi}[R_{t+1} + \\gamma G_{t+1} | S_t = s]$$ $\\gamma = 0$ 时，只考虑当前奖励，所以 $$v_{\\pi = Left}(s) = E_{\\pi}[1 + 0 \\times G_{t+1}] = 1$$ $$v_{\\pi = Right}(s) = E_{\\pi}[0 + 0 \\times G_{t+1}] = 0$$ 完全不考虑未来回报，选择 left 直接获得 1，所以最优策略是 left。 $\\gamma = 0.5$ 时，考虑部分未来回报，所以 $$v_{\\pi = Left}(s) = E_{\\pi}[1 + 0.5 \\times 0] = 1$$ $$v_{\\pi = Right}(s) = E_{\\pi}[0 + 0.5 \\times 2] = 1$$ 选择 left 仍然是 1，后续奖励为 0 所以折扣对其无影响。而选择 right 则后续奖励以 0.5 折扣。结果相同，此时策略无偏好。 $\\gamma = 0.9$ 时，考虑更多未来回报，所以 $$v_{\\pi = Left}(s) = E_{\\pi}[1 + 0.9 \\times 0] = 1$$ $$v_{\\pi = Right}(s) = E_{\\pi}[0 + 0.9 \\times 2] = 1.8$$ 选择 left 仍然是 1，选择 right 后续奖励以 0.9 折扣。right 为最优策略。 由于右侧状态在下一步后无额外奖励，所以第一轮计算就已经能决定最终值函数。而计算未来回报 $G_{t+1}$ 时，需要递归 $v_{\\pi}(s)$，但由于终止状态的奖励为 0，未来回报不影响计算，所以第一轮计算就已经足够。 import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}});","link":"/AI/RL/RL-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/"},{"title":"Turing Machines","text":"自动寄 删除 010创建一个图灵机，它复制二进制输入到输出，并删除所有的 010 States Start End Tape Head Position Start Start Stop A0 0 A B0 0 B Copy Stop 1234567891011121314151617181920212223// 处理 0 开头，转到 A[Start; 0; SP]-&gt;[A; ANY; ANY; &gt;; S]// 处理 1 开头，直接复制[Start; 1; SP]-&gt;[Start; ANY; 1; &gt;; &gt;]// 为空，结束[Start; SP; SP]-&gt;[Stop; ANY; ANY; S; S]// 在 0 1 _ 时，转 B[A; 1; SP]-&gt;[B; ANY; ANY; &gt;; S]// 在 0 0 _ 时，写入 0，转 Start[A; 0; SP]-&gt;[Start; ANY; 0; S; &gt;]// 在 0 0 S 时，写入 0，结束[A; SP; SP]-&gt;[Stop; ANY; 0; S; &gt;]// 在 0 1 0 时，略过，回到 Start[B; 0; SP]-&gt;[Start; ANY; ANY; &gt;; S]// 在 0 1 1 时，将 0 复制，转 Copy 1[B; 1; SP]-&gt;[Copy; ANY; 0; S; &gt;]// 在 0 1 S 时，将 0 复制，转 Copy 1[B; SP; SP]-&gt;[Copy; ANY; 0; S; &gt;]// Copy 1[Copy; ANY; SP]-&gt;[Start; ANY; 1; S; &gt;] 把 00 变成 ##但是不处理超过 2 个 0 的情况 States Start End Tape Head Position Start Start Stop A0 0 Zero1 Zero2 FindOne Trans Trans2 Stop 1234567891011121314151617181920212223242526272829303132// 0 _ 转 Zero1[Start; 0]-&gt;[Zero1; 0; &gt;]// 1 _ 回到开始[Start; 1]-&gt;[Start; 1; &gt;]// 为空，结束[Start; SP]-&gt;[Stop; SP; S]// 0 0 _ 继续计数[Zero1; 0]-&gt;[Zero2; 0; &gt;]// 0 1 _ 回到开始[Zero1; 1]-&gt;[Start; 1; &gt;]// 0 S 结束[Zero1; SP]-&gt;[Stop; SP; S]// 0 0 0 不处理[Zero2; 0]-&gt;[FindOne; 0; &gt;]// 0 0 1 变换前两个为 #[Zero2; 1]-&gt;[Trans; 1; 2*&lt;]// 0 0 S 变换前两个为 #[Zero2; SP]-&gt;[Trans; SP; 2*&lt;]// 第一次写入[Trans; 0]-&gt;[Trans2; #; &gt;]// 第二次写入[Trans2; 0]-&gt;[Start; #; &gt;]// 找到下一个 1[FindOne; 1]-&gt;[Start; 1; &gt;]// 仍然是 0[FindOne; 0]-&gt;[FindOne; 0; &gt;]// 结束[FindOne; SP]-&gt;[Stop; SP; S] 011 变 ABCD States Start End Tape Head Position Start Start Stop A0 0 Zero B0 0 One Copy BCD CD D Stop 1234567891011121314151617181920212223242526272829303132// 0 _ 计数[Start; 0; SP]-&gt;[Zero; 0; SP; &gt;; S]// 1 _ 复制[Start; 1; SP]-&gt;[Start; 1; 1; &gt;; &gt;]// 为空，结束[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 0 1 _ 计数[Zero; 1; SP]-&gt;[One; 1; SP; &gt;; S]// 0 0 _ 复制 0，回到开始[Zero; 0; SP]-&gt;[Start; 0; 0; S; &gt;]// 0 S 复制 0，停止[Zero; SP; SP]-&gt;[Stop; SP; 0; S; &gt;]// 0 1 1 变换，写入 A[One; 1; SP]-&gt;[BCD; 1; A; S; &gt;]// 0 1 0 复制 0，转 Copy 1[One; 0; SP]-&gt;[Copy; 0; 0; &lt;; &gt;]// 0 1 S 复制 0，转 Copy 1[One; SP; SP]-&gt;[Copy; SP; 0; &lt;; &gt;]// 写入 B[BCD; ANY; SP]-&gt;[CD; ANY; B; S; &gt;]// 写入 C[CD; ANY; SP]-&gt;[D; ANY; C; S; &gt;]// 写入 D，回到开始[D; ANY; SP]-&gt;[Start; ANY; D; &gt;; &gt;]// Copy 0[Copy; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// Copy 1[Copy; 1; SP]-&gt;[Start; 1; 1; &gt;; &gt;] 多个 1 变一个 1 States Start End Tape Head Position Start Start Stop A0 0 One B0 0 Stop 12345678910111213// 0 复制[Start; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 复制并计数[Start; 1; SP]-&gt;[One; 1; 1; &gt;; &gt;]// 为空，停止[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 1 0 复制，回到开始[One; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 1 找到下一个 0[One; 1; SP]-&gt;[One; 1; ANY; &gt;; S]// 1 S 停止[One; SP; SP]-&gt;[Stop; SP; SP; S; S] 11 变 112 States Start End Tape Head Position Start Start Stop A0 0 One B0 0 Two Stop 12345678910111213141516// 0 复制[Start; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 复制并计数[Start; 1; SP]-&gt;[One; 1; 1; &gt;; &gt;]// 为空，停止[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 1 1 添加 2[One; 1; SP]-&gt;[Two; 1; 1; S; &gt;]// 1 0 复制并回到开始[One; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 S 停止[One; SP; SP]-&gt;[Stop; SP; SP; S; S]// +2s[Two; ANY; SP]-&gt;[Start; ANY; 2; &gt;; &gt;] 0000… 变 4444… States Start End Tape Head Position Start Start Stop A0 0 One Two Three Trans Stop 1234567891011121314151617181920212223242526272829303132// 0，计数[Start; 0]-&gt;[One; 0; &gt;]// 1，跳过[Start; 1]-&gt;[Start; 1; &gt;]// 为空，停止[Start; SP]-&gt;[Stop; SP; S]// 0 0[One; 0]-&gt;[Two; 0; &gt;]// 0 1 回[One; 1]-&gt;[Start; 1; &gt;]// 0 S 停止[One; SP]-&gt;[Stop; SP; S]// 0 0 0[Two; 0]-&gt;[Three; 0; &gt;]// 0 0 1[Two; 1]-&gt;[Start; 1; &gt;]// 0 0 S 停止[Two; SP]-&gt;[Stop; SP; S]// 0 0 0 0，转换[Three; 0]-&gt;[Trans; 4; 3*&lt;]// 0 0 0 1 回[Three; 1]-&gt;[Start; 1; &gt;]// 0 0 0 S 停止[Three; SP]-&gt;[Stop; SP; S]// 4 0 0 4[Trans; 0]-&gt;[Trans; 4; &gt;]// Stop Trans[Trans; 4]-&gt;[Start; ANY; &gt;] 二进制乘 3 States Start End Tape Head Position Start Start Stop A0 0 X Non Carry Stop 1234567891011121314151617181920212223// 在结果最前加一个 0[Start; 0; SP]-&gt;[X; 0; 0; S; &gt;][Start; 1; SP]-&gt;[X; 1; 0; S; &gt;]// 复制[X; 0; SP]-&gt;[X; 0; 0; &gt;; &gt;][X; 1; SP]-&gt;[X; 1; 1; &gt;; &gt;]// 在输入最后加一个 0[X; SP; SP]-&gt;[Non; 0; SP; S; &lt;]// 不进位[Non; 0; 0]-&gt;[Non; 0; 0; &lt;; &lt;][Non; 0; 1]-&gt;[Non; 0; 1; &lt;; &lt;][Non; 1; 0]-&gt;[Non; 1; 1; &lt;; &lt;][Non; 1; 1]-&gt;[Carry; 1; 0; &lt;; &lt;][Non; SP; SP]-&gt;[Stop; SP; SP; S; S]// 进位[Carry; 0; 0]-&gt;[Non; 0; 1; &lt;; &lt;][Carry; 0; 1]-&gt;[Carry; 0; 0; &lt;; &lt;][Carry; 1; 0]-&gt;[Carry; 1; 0; &lt;; &lt;][Carry; 1; 1]-&gt;[Carry; 1; 1; &lt;; &lt;][Carry; SP; SP]-&gt;[Stop; SP; 1; S; S]","link":"/Algorithm/TM/Turing-Machines/"},{"title":"Stable Marriage Problem","text":"研究生学习开始啦 本文是 Design and Analysis of Algorithms 的一部分 这节课介绍了一些著名的问题解决方案及其典型算法，并且还有它们的实践内容 Problem Description 有 n 个男人和 n 个女人 每个人都有一个 preference list，即对另一性别的人的偏好排序 问题：如何匹配男女，使得每个人都能得到满意的匹配？(稳定) 稳定：不存在一对男女，他们之间相互更喜欢。换言之，不存在一对男人和女人，他们都更喜欢对方而不是他们当前的配偶。 如果存在一对男女，他们不是当前匹配中的伴侣，但相互之间都优先于他们各自的伴侣则称其为 rogue / vogue couple / 阻碍对 (为什么要叫这个名) 存在 rogue couple 的匹配是不稳定的，因为这对男女都有动机离开他们当前的伴侣而彼此匹配 如果我们允许同性恋，那么这个问题就是 Stable Roommates Problem，在这种情况下 没有 稳定匹配 Unisex Case让我们来看一个不可能进行稳定匹配的例子，它需要与第四个人创造一个三角恋 A -&gt; B / D / CB -&gt; D / A / CC -&gt; N/AD -&gt; A / B / C C 的喜好无关紧要，因为 C 是每个人的最后选择 Proof让我们假设存在稳定匹配： 有 [A, D] 那么另一对必然是 [B, C] 但是 A 相比 D 更喜欢 B，B 相比 C 更喜欢 A 所以 [A, B] 应该是一对 那么 [C, D] 就是另一对 但是 B 相比 A 更喜欢 D，D 相比 C 更喜欢 B …… 无限循环 所以不存在稳定匹配 但是在 bipartite graph (二分图) 中，我们一定可以找到稳定匹配 这类问题无法使用 greedy 或者 induction (or recursion) 算法解决，所以我们需要 Gale-Shapley Algorithm也叫 Deferred Acceptance 算法 Steps 每个男人都向他的首选求婚 每个女人都暂时选择她当前最喜欢的求婚者，拒绝其他人 每个被拒绝的男人向他的下一个选择求婚 重复步骤 2 和 3，直到每个女人都接受了一个求婚者 我们将每一轮定义为一天女人在每一轮接受的求婚都是临时的，这就是为什么此算法又叫 Deferred Acceptance 延迟接受 的原因。 Theorem 1: 在 $n^2 + 1$ 天内结束反证让我们来看看算法还未终止时必须发生的一件事情：某个男孩从他的名单上划掉一个女孩 为什么？因为算法如果没有终止，那么某个女孩至少有两位追求者那至少有一个人会被拒绝，则他会把她划掉 因此，如果算法没有在 $n^2 + 1$ 次内终止，那么总共会有 $n^2 + 1$ 次划掉但是，每个人最多只能划掉 n 次，所以最多可以有 $n^2$ 次划掉我们有了矛盾。最后一天只有接受，没有拒绝 $n^2 + 1$ 并不是算法的最坏情况，所以让我们来计算 最坏 $(n - 1)^2 + 1$让我们来举一个最坏的情况：每个男孩都会被拒绝 n - 1 次总不能被拒绝 n 次吧，那不是就没人要了 总求婚数 = 总拒绝数 + 总接受数则$$ 总求婚数_{直到第 n - 1 天} = 男孩的数量 \\times 每个男孩的求婚数 = n \\times (n - 1) $$得到$$ 总求婚数 = n \\times (n - 1) + 1 = n^2 - n + 1 $$ 在第一天，每个男人都会求婚，则进行了 n 次求婚随后的每一天，都只会有 一个 男人求婚（这也是为什么总求婚数可以计算总天数的原因） 所以我们可以据此求出总天数：$$ 总天数 = 总求婚数 - 第一天求婚的次数 + 第一天 = [n^2 - n + 1] - n + 1 = n^2 - 2n + 2 $$ 所以，在最坏的情况下，$\\Omega (n^2)$ 天内中止（算法所需的时间至少与参与者数量的平方成正比） 大 $O$ 记号提供了一个上界，表示运行时间的增长速率不会快于某个特定的函数大 $\\Omega$ 记号提供了一个下界，表示运行时间的增长速率至少是某个特定函数 Lemmas 当男孩结婚时，他已经遍历了所有更喜欢的女孩 如果一个男孩到头来也没结婚，那么他一定遍历过了所有女孩 每个女孩都会嫁给 追求过 她的男孩中最喜欢的那个 如果一个女孩被追求过，那么她一定会结婚 Theorem 2: 在算法中，每个人都会结婚在有以上 Lemmas 后，我们可以反证这个定理 假设一个男孩 B 没有结婚 但是在 L2 中说明了他遍历了所有女孩 但是根据 L4，每个女孩都会结婚 由于男孩的数量等于女孩的数量 因此每个人都会结婚 Theorem 3: 算法总是产生稳定匹配假设算法产生了一个 不稳定匹配 [B, G] B 更喜欢 G 而不是自己的配偶 G1 G 更喜欢 B 而不是自己的配偶 B1 根据规则，男性按照偏好顺序求婚。由于 B 最终匹配到 G1，但 B 更偏爱 G则有 B -&gt; G &gt; G1，但 G 拒绝了 B，所以 G -&gt; B1 &gt; B 根据规则，女性当有更好追求者的时候，会拒绝当前追求者则 G 拒绝 B 的唯一可能，是 G 得到了她认为更好的 B1则有 G -&gt; B1 &gt; B 而 rogue couple 要求 B -&gt; G &gt; G1 和 G -&gt; B &gt; B1这与通过规则得到的结果相矛盾，因此不存在 rogue couple Theorem 4 / 5: 算法会产生 求婚 / 被求婚 方的 最佳 / 悲观 匹配定义： 最佳伴侣是他 / 她从可能的伴侣中最喜欢的 悲观伴侣是他 / 她从可能的伴侣中最不喜欢的 Boy optimal / Girl optimal 男性主动求婚，女性被动选择，持续优化直至男性满足，导致女性最坏结果 Uniqueness：如果两种情况下算法得到相同的匹配结果，那么这个结果就是唯一的稳定匹配 Max Magnitude $\\theta (2^n)$习题证明题Suppose there are $n$ boys and $n$ girls. $m$ boys are tall and the same number of girls are blonde.Boys prefer blonde girls to non-blonde girls.Girls prefer tall boys to non-tall boys. 金发配高个Show that in every stable match, blonde girls are paired with tall boys. 这题是在说有一些高个男生和一些金发女生，男生更喜欢金发女生，女生更喜欢高个男生要证明在每一个稳定匹配中，金发女生都会和高个男生配对 要证明，我们假设矛盾：存在一个稳定组合 $(b, g)$ 有 $b$ 是高个男生, $g$ 不是金发女生 或者 $b$ 不是高个男生, $g$ 是金发女生 1 和 2 是对称的，所以我们分析 1，同理可得 2 令高个的反义为矮个，金发的反义为黑发 既然有 高个配黑发，由于男女人数相同，那么一定有一个 $(b’, g’)$ 是矮个配金发 我们发现 $g’$ 更喜欢 $b$，因为 $g’$ 更喜欢高个所以 $(b, g’)$ 是 rogue couple，这就与题目中的稳定匹配矛盾了 证明思路：假设初始匹配稳定，随后找出 rogue couple，导致违反稳定匹配的条件 相同偏好If all the girls have the same preference list, then there is only one stable pairing. 要证明只存在一种稳定匹配，我们就假设有 A / B 两种稳定匹配 A 有 $(g, b)$，而在 B 中有 $(g, b’)$同一个女生出现在不同的匹配中 由于所有女生偏好相同，则在任何稳定匹配中，将完全由男生的优先级决定，无论 g 与谁匹配，其他女生的相对偏好不变 由于同一个女生出现在了不同的匹配中，这意味着至少在某个匹配中，她得到了相对于另一个匹配更 高 / 低 优先级的男生 因为如果 $g$ 在 B 中能与 $b’$ 匹配，那么在 A 中与 $b$ 匹配的的其他女生将偏好 $b’$这就导致了 rogue couple，违反了稳定匹配的条件 最优解There is no pairing, stable or unstable, in which all the boys are better off than when the Gale-Shapley algorithm is used. 这题意思就是证明 GS 算法是最优解（而且是 boy optimal） 假设存在一个配对，在这个配对中所有的男孩比使用 GS 算法时更满意这意味着每个男孩都与他的偏好列表中更高位的女孩配对了 然而，根据 GS 算法的性质，算法结束时每个男性都无法与他偏好列表中更高位的女性配对因为这样的女性要么与他们自己的偏好列表中更高位的男性配对，要么在追求过程中拒绝了这些男性 因此，如果所有男性在某个配对中都比 GS 算法的结果更满意那么这意味着至少有一个男性与他的偏好列表中的一个女性配对而该女性在 GS 算法中拒绝了他 如果所有男孩在某个配对中都比 GS 算法的结果更满意那么至少会有一对男女是不稳定的，因为至少有一个女孩可以与她更偏好的男孩配对所以不存在这样的匹配，因为它会违反 GS 算法的稳定匹配性质 匹配题 Boy b1 g1 g4 g3 g2 g5 b2 g3 g1 g4 g2 g5 b3 g4 g3 g5 g1 g2 b4 g1 g5 g2 g4 g3 b5 g4 g1 g5 g3 g2 Girl g1 b4 b2 b1 b5 b3 g2 b4 b1 b3 b2 b5 g3 b4 b3 b1 b2 b5 g4 b1 b3 b4 b2 b5 g5 b2 b3 b5 b1 b4 Day g1 g2 g3 g4 g5 1 b1, b4 - b2 b3, b5 - 2 b4, b5 - b2 b3, b1 - 3 b4 - b2, b3 b1 b5 4 b4, b2 - b3 b1 b5 5 b4 - b3 b1, b2 b5 6 b4 b2 b3 b1 b5 (g1, b4), (g2, b2), (g3, b3), (g4, b1), (g5, b5)","link":"/Algorithm/Stable-Marriage-Problem/"},{"title":"分而治之","text":"本文是 Design and Analysis of Algorithms 的一部分 每天大清早是真的起不来床这课的 Kahoot 我是一分也没拿到 Inversion Count定义给定一个数组 $A$，如果 $i &lt; j$ 且 $A[i] &gt; A[j]$，则称 $(i, j)$ 是 $A$ 的一个逆序对 也就是说，某个前面的元素比后面的元素大，这样的对数就是逆序对 如有 arr[] = [8, 4 ,2, 1]则逆序对为 (8, 4), (8, 2), (8, 1), (4, 2), (4, 1), (2, 1)共 6 对 简单解法 遍历数组 对于元素 $A[i]$，遍历 $A[i+1:]$，统计比 $A[i]$ 小的元素个数 累加 123456789101112const arr = [8, 4, 2, 1];let count = 0;for (let i = 0; i &lt; arr.length; i++) { for (let j = i + 1; j &lt; arr.length; j++) { if (arr[i] &gt; arr[j]) { count++; } }}console.log(count); // 6 $O(n^2)$ Merge Sort首先复习一下 归并排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051MergeSortInversion(A, low, high) { if (low &lt; high) { mid := (low + high) / 2 leftCount := MergeSortInversion(A, low, mid) rightCount := MergeSortInversion(A, mid + 1, high) mergeCount := Merge(A, low, mid, high) return leftCount + rightCount + mergeCount }}Merge(A, low, mid, high) { leftIndex := low rightIndex := mid + 1 arrayIndex := low inversionCount := 0 tempArray := [] while (leftIndex &lt;= mid &amp;&amp; rightIndex &lt;= high) { if (A[leftIndex] &lt;= A[rightIndex]) { tempArray[arrayIndex] = A[leftIndex] leftIndex++ } else { tempArray[arrayIndex] = A[rightIndex] rightIndex++ inversionCount += mid - leftIndex + 1 } arrayIndex++ } while (leftIndex &lt;= mid) { tempArray[arrayIndex] = A[leftIndex] leftIndex++ arrayIndex++ } while (rightIndex &lt;= high) { tempArray[arrayIndex] = A[rightIndex] rightIndex++ arrayIndex++ } for (i := low; i &lt;= high; i++) { A[i] = tempArray[i] } return inversionCount} 时间复杂度为 $O(n \\log{n})$ Max Increasing给定一个数组 $A$，找到一对 $(i, j)$ 有 $1 \\leq i \\leq j \\leq n$ 使得 $A[j] - A[i]$ 最大 通常找最大差值的问题使用 $O(n)$ 的算法解决，不过这里要求分治法所以 123456789101112131415FindMaxDiff(A, low = 0, high = len(A) - 1) { if (low &gt;= high) return 0 mid := (low + high) / 2 leftMaxDiff := FindMaxDiff(A, low, mid) rightMaxDiff := FindMaxDiff(A, mid + 1, high) leftMin := FindMin(A, low, mid) rightMax := FindMax(A, mid + 1, high) crossMaxDiff := rightMax - leftMin return Math.max(leftMaxDiff, rightMaxDiff, crossMaxDiff)} 第 $k$ 大Given different real numbers an array A[1:n] and an integer $1 \\leq k \\leq n$.Let’s determine the $k$-th biggest element of the array.The cost of the procedure should be $O(n \\log{n})$. 快速选择其实就是快排中轴值计算的过程，时间复杂度为 $O(n)$ 123456789101112131415161718192021222324252627282930QuickSelect(A, low = 1, high = n, k) { if (low = high) return A[low] pivotIndex := Partition(A, low, high) position := pivotIndex - low + 1 if (k = position) return A[pivotIndex] else if (position &gt; k) return QuickSelect(A, low, pivotIndex - 1, k) else return QuickSelect(A, pivotIndex + 1, high, k - position)}Partition(A, low, high) { pivot := A[high] i := low - 1 for (j := low; j &lt; high; j++) { if (A[j] &lt;= pivot) { i++ Swap(A[i], A[j]) } } Swap(A[i + 1], A[high]) return i + 1} 但其实如果要达到 $\\theta(n \\log{n})$ 的话直接快速排序然后取第 $k$ 个元素就好了","link":"/Algorithm/%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B/"},{"title":"匈牙利留学攻略2024","text":"有个朋友要我帮他做做攻略，现在发出来造福大家，希望对你也能有所帮助。本文以随笔的形式写成，如有错误纰漏请指正。 关于生活去匈牙利留学是一个不错的选择。这个国家有着非常辉煌的过去，很多目前位于匈牙利的学校，以前都位于目前来说的其他国家，因为曾经那些地方都属于匈牙利的领土。生活成本与成都市中心持平，房租较贵，如果住学校学生宿舍或者专门为学生提供的第三方宿舍，则与成都持平，不建议住在郊区，稍微住的远一点可以，但是远一点房租也不会便宜多少。 匈牙利的公共交通系统较为发达，全欧洲第一条地铁就位于布达佩斯，每个大城市都有夜间班车，所以打车是不必要的，而且间隔时间也跟国内差不多，不会出现德国那种在工作时间一辆公交车也得等半小时的情况。火车线路九成都是国营，覆盖了几乎全匈牙利，虽然开得慢，但好在票价不贵，购买匈牙利通票即可无限次乘坐公共交通，骨折价乘坐火车。不要逃票，真的会罚款，查的很严。 欧洲的肉比国内便宜，但是蔬菜很贵，种类很少，去欧洲任意国家留学都要求做饭技能，因为下馆子是国内的两到三倍价格，高档餐厅一份牛排能买到一千人民币。中餐好吃的不多，合口味的不多，贵的倒是一抓一大把还不好吃，但是种类齐全，烧烤火锅炸鸡奶茶之类的全部都有，也有很大的亚洲超市，所以生活质量取决于钱包厚度。 匈牙利人吃的喝的都没有什么奇怪的东西，而且它们也是黄种人，对中国人没有什么偏见，它们是整个欧洲唯一一个和我们一样姓在前，名在后的国家，跟中国与俄罗斯的关系不错，但是它是北约国家，政府在整个欧盟内都属于比较会找茬的。它们也有很多在野党，但是执政党就一个，所以相对来说很稳定，并且匈牙利不收难民，所以在火车上你可以睡觉。 在匈牙利我基本没用过现金，它们用它们自己的货币，福林，欧元并不在匈牙利广泛流通。随身携带银行卡和现金不是必要的，NFC 刷手机几乎都能用，有些小店只收现金，但是你大可以换个地方消费。欧洲的税赋很高，收入乱七八糟加起来基本上交国家一半，匈牙利有电子产品 27%的税，所以在国内买好了电子产品再带去。 在匈牙利生病了，如果有医保或者商业保险基本就不用担心价格问题。但如果没有，如果不是要死的病，往返一趟国内机票也没多少钱。匈牙利有中医，还不少。私立医院较多，服务好但是很贵，有的还不能走国家医保，只能刷商业保险或自费。但是匈牙利的医院并不会出现今年预约 CT 明年才能做上的情况，真有问题的当场就给处理了，但是排队肯定是比国内久的。 让我们来说说学校匈牙利的学校基本都是中小班教学，但是，三分听七分做，老师能教的东西很有限，并且没有辅导员的角色，更没有班级一说，甚至学期都可以很模糊，提前毕业和推迟毕业更是家常便饭，有些专业的老师也不是很在乎你到底来不来上课，作业写不写，因为你毕不毕业跟他们一点关系都没有，你挂科他不扣钱，你考得好他也没奖金，除非你帮他做出什么科研成果，不然老师是不会主动的。 所以，出门在外，全靠自己，无论是生活还是学习。三年本科，两年研究生，后面还有博士等。他人是指望不上的，作弊被发现看老师，老师管的话，根据规定可以直接开除，老师不管的话也就是个重考。课程不难，认真学认真做了都能过。在匈牙利 1 是最差（挂科），5 是最好，重考会影响最终成绩，在国内找工作绩点肯定不能差了，但是在国外，绩点看得过去就行，它们不是很在乎这个。 国外的研究生学习阶段，跟中国的差距非常大。它们的研究生是本科的延续，你一样要上课，它就是一个缩短版的，更有方向性的本科，并不会像国内一样一来就有导师带着你做项目，所有的项目和项目组都需要你自己争取加入。有些项目组会发薪资，但是绝大部分项目都是没有钱的。 博士就跟国内差不多了，这是一份体面的工作，学校会开一个还过得去的薪资，但是所有的博士生都需要去给本科研究生讲课，大部分课程都会分两部分：概念课与实践课。概念课按规定都是教授讲课，所以你的实践课老师大概率是博士生，你的导师也大概率是博士生，因为教授实在不够用。 全匈牙利的学校，申请大都用的是 DreamApply 的系统，学生教务系统全部都是 Neptun，大部分学校都用的微软 O365，面试用 Skype。学生信息统一接入国家教育部门，移民局在你续签居留许可的时候会检查你的学习进度，表现很差的会拒签，三年本科最多读六年。 奖学金对于那些没有在国内上本科，并且本科学校恰好有匈牙利交换项目的学生来说就别想了。更何况匈牙利的平均学费相比于 US / UK 等并没有多少钱，大约 2 万人民币一学期，具体取决于专业。入学以后第一个学期可以申请转为奖学金，但是名额有限，且基本被匈牙利学联包圆了。温馨提示，离学联和其成员尤其是管事的远一点。中国人专坑中国人。 对于语言成绩，匈牙利大部分学校都要求雅思 5.5，或者同等水平的证明，这个因学校而异。高考成绩可有可无，但是高中毕业证和高中成绩单一定要有。申请后一定有面试，但不一定有笔试，取决于专业，我们统称其为入学考试。如果入学考试表现不好的，可能会发配到预科，如果再差一点的，面试官觉得预科都救不了你的，就会直接拒绝。附带预科的录取通知书是四年，但是一年预科读完后你不一定还继续在同一个学校继续读，也可以去其他学校，甚至换一个专业。 QS / THE / USNEWS 排名都没有太多参考意义，很多都是买的，尤其是 QS。建议参考 软科（中国）和 CWUR （沙特阿拉伯）的排名。 让我们来根据 2024 年排名来介绍一下各个学校。 罗兰大学（平均 406 名）https://apply.elte.hu/ CWUR 517 / 软科 501 展示了它不俗的实力。北京交通大学和北京邮电大学今年跟它同一排名。 优势学科：心理学，物理，地球物理，地质，数学，和全部艺术与人文类专业。罗兰大学属于综合类院校，是匈牙利最大，等级最高的学校，出了 5 个诺贝尔奖，最早是皇室直属。现在的校名是以其著名物理学家 Loránd Eötvös 得来。 罗兰大学除了其优势学科以外，其他学科都不一定比得上一些专门学校，但是也不失为一个好的选择。学校每个学院都分布在整个布达佩斯的不同地方，每个校区都离得很远，甚至还有一个 Szombathely 校区，距离布达佩斯 228KM。但是每个专业的学生都不会离开自己的学院，而去其他学院上课，选修课基本也是如此，所以不必担心通勤问题。 罗兰大学的 AI 系有 8 张 A100 40G 显卡专门给学生做项目用的，在普遍穷的叮当响的匈牙利学校中，这算是不错的待遇了。校企合作项目也很多，就看个人争取了。 塞格德大学https://apply.u-szeged.hu/en_GB/ 这个学校很有意思，它有一个非常辉煌的过去，曾经长期跻身于全球 200 名左右。而现在，软科 411，CWUR 709 的巨大偏差，让人无法准确估计这个学校到底是什么水平。它最初是由波兰的国王建立的，在 16 世纪末，是匈牙利唯一的高等教育机构。 它不在首都布达佩斯，而是在匈牙利第三大城市塞格德，邻近塞尔维亚，是一所综合类院校，就目前来说，没有特别出彩的专业，但是也没有特别差的专业，我也较少听到有关它的信息。 塞麦尔维斯大学https://semmelweis.hu/admission/process/ 你别看它软科排名 601 就小瞧它，因为它根本不在乎排名。它的医学是全世界前 200 名的，解剖学与生理学长期位于 100 名左右。THE 常年给它 250 左右的综合排名。这是一所医科大学，只有与医学相关的专业，覆盖了各个方面。Semmelweis 被誉为“母亲们的救星”，这所大学就是以他的名字命名的。 在欧洲，最赚钱的是牙科。匈牙利所有的医学类专业都一定需要预科，其他专业的预科不一定需要语言成绩，但是医学是一定要的，也不高，雅思 5.5 属于医学预科入门门槛，这个成绩其他一些专业都可以直接入学了。预科通过率 50%，本科按时毕业率 20%（可能都还不到）。要背的东西特别多，从预科就要开始背医学词典。 但是如果学成归来，无论哪个医学专业，甚至是兽医，在欧洲找份工作，那也是真的挣。 德布勒森大学https://edu.unideb.hu/programs.php 德布勒森是匈牙利第二大城市。其为综合类大学，学校排名也就是 650 左右，但是它的农业相关专业很不错，其他专业也不差。它还有着匈牙利为数不多的超算，但是需要排队使用。我经常能遇见在德布勒森上学的人。 布达佩斯技术大学https://xplore.bme.hu/available-programmes/ BME 是理工科专业大学，看它的排名意义不大（800），因为实践型的它没有太多科研产出。这个学校三天一小考，五天一大考，直接让你回到高中生活，毕业也比较困难，我见过计算机本科延毕两年然后转校的（看样子是没认真学）。但是研究生有几乎一对一的导师，能省去很多麻烦。就理工科专业来说，罗兰是比不上 BME 的。出来去科技公司之类的也比较好找到工作。 佩奇大学https://apply.pte.hu/ 不是小猪佩奇，英文发音也不一样，所以你说这个事情给外国人，他们是不理解的。为匈牙利第五大城市，但是有机场可以直飞德国慕尼黑。 这是一所综合类大学，排名很低（~1k），很好毕业，性价比是它的代名词，如果家中拮据，不失为一个选择，毕竟，学习靠自己。学院分散于整个佩奇，有的在山上，有的在市中心，有的藏在居民区，不如说整个佩奇城市，都是围绕着这个大学运行的。 但是它的医学院不错，并且是独立运作的，如果塞梅维尔斯去不了，佩奇医学院也不错。并且它还有全匈牙利最好的预科学院，环境好，宿舍好，老师也好。如果一定要预科，可以来这里先读一年，会比较好适应。 考文纽斯大学https://corvinus-university.dreamapply.com/ 这是在布达佩斯的一个商学院，而商学院有个特点就是基本不参与排名。如果看 FT 管理学硕士排名的话，它保持在全球 100 名以内。该大学的主楼是联合国教科文组织遗产的一部分。 这所学校名人没出多少，但是达官显贵很多。匈牙利最大的国有银行行长，Wizz 航空 CEO，特朗普的副助理等人均从这个学校毕业。如果想学管理，从政，搞钱之类的，这是个不错的地方。 关于申请每个学校名字下面的链接就是申请地址，需要注意的是，每个学校每个专业都可能有不同的开放周期，请看好时间，不要错过了提交期限。匈牙利的学校基本都有春季入学和秋季入学两种选择，这也导致它们一年也有两个毕业季，当然，六月和九月是最热闹的。 申请是完全不需要中介帮忙的，因为系统会给你很好的提示，需要什么材料，材料怎么写，应该是什么样的，都比较清楚。对于所有的材料，如果原文是中文的，能想办法开英文版的就开英文版，开不了英文版的，比如高中毕业证，则需要公证处翻译并公正。不要相信任何中介的包过等承诺，匈牙利的学校与中介没有任何合作，如果你真的有钱，可以去捐一栋楼，让学校给你发个荣誉学位，这比中介靠谱多了，并且国内好多中介关于匈牙利的业务都是转包的。 还有一点需要注意的是，不要用 QQ 数字邮箱。网易，Outlook 等都能正常收发学校的消息，而 QQ 邮箱很容易进学校邮件系统的垃圾箱。并且如果要给学校发邮件咨询任何消息，一定要有礼貌，邮件格式网上都有，并且不要轰炸学校邮箱，真的会给你拉黑的，一个事情短期内发一封，学校的人看到了一定会回的。如果是很重要或者很急的事情，那么可以将邮件同时发给多个相关的老师。 你还需要去办一张旅行健康证，这个网上搜一下就有。如果有什么传染性疾病的话，还是治好了再去吧。有些学校要求填写学校自己的健康证明单，这个打印下来给你办健康证的地方的医生，他们知道该怎么填。如果你缺少一些必要的疫苗，这也是一个补种的好机会。 你的个人简历需要使用 Europass 制作，如果你有高中以上的学历，当然可以写进去，但请准备好证明，如成绩单等。不需要写高中以前的内容，也没必要写你是不是团员和党员。请把你的个人经历制作的丰富一些，项目经验，组织工作，个人技能，有什么写什么，让人感觉你是一个能干，优秀的人。如果你实在没有什么东西可以写，也可以马上去考一些证书，Google 等大公司都有网上在线考试，这些完全可以用于丰富你的简历。对于简历到底该怎么写，我的个人意见是在你原有的基础上夸大其词，如遇团队项目把功劳揽过来即可，不要凭空捏造一些你完全没有经历过的事情。最后，多去知乎上看看其他人是怎么写的。 动机信不要照抄，不要全靠 AI，不要把对面当傻子。学校会给你动机信的提示，告诉你应该从哪些方面考虑。我的建议是，你可以先多去看看别人是怎么写的，然后你用中文写好，不要写流水账，然后让几个朋友来帮你看看，然后再翻译到英文。不需要华丽的辞藻，不需要复杂的语法，需要的是清晰易懂的表达和实际的内容，还有不要拼错单词和用错语法，这个事情 AI 很擅长。动机信一页就够，学校会给字符数限制。对于不需要直接在文本框内粘贴动机信的，同样使用 Europass 制作 Cover Letter 的 PDF。 如果你的资料有问题，学校会发邮件告诉你修改或者补充，多交材料没关系，你可以把你认为有用的，英文版本的，都传上去，但是要用英文命好文件名。最后你就可以等面试和笔试（如果有）通知了。对于面试，和国内找工作的远程面试一样的要求，安静地点，干净背景，整洁的你。不需要正装，但不要奇装异服，不需要化妆因为摄像头自带美颜（清晰度低），不要用手机面试。 我在匈牙利的学校只经历过四次面试。一次是我入学预科（我直接报的预科），基本没问什么内容，因为他默认你啥也不会，英语也不好，不然为什么要去预科呢。第二次是预科结束以后的转正面试，会开始问专业问题了，但是不会很深奥，主要是看你反应速度，都是比较简单的问题，如果你还需要想半天的话，那基本上就没戏了。第三次是我转专业的面试，这种情况下，除了专业问题，还会问你的动机。第四次是研究生面试，面试到一半直接开始在线答题，我计算机专业问了一个 python 脚本运行结果的问题，我好像还答错了，它考的是 python 的变量作用域，比较巧妙的问题。 总的来说，面试除了一开始的一分钟自我介绍，剩下的除了专业问题，就是你为什么来匈牙利，为什么选这个学校，为什么是这个专业的基本问题了。学校的面试官给你约面都会提前定时间，如果你的时间恰好不合适，也是完全可以提前一周协调的，当然如果临到头了协调会直接当你缺席。如果是技术问题导致的面试失败或者中断，学校会安排二次面试，但是如果是有人闯入了你的镜头，那就是你自己的问题了，面试中你这边绝对不可以出现第二个人，但是你可以使用辅助软件。面试可比国内找工作的面试简单多了，并且持续时间也就 15 分钟，不需要紧张。 如果一切顺利，你足够优秀，你就能收到录取通知书了，匈牙利的学校都有一个最晚发通知书的期限，你一定能在那之前收到结果。如果你不是很优秀，可能会分配到预科，这也完全没有问题。如果你被某个学校的专业拒绝了，为了避免你没地方去，最好是一次性申请多个学校的多个专业，无非就是多交一点申请费而已。在拿到 offer 后，你最多可以选择推迟一年入学。 关于签证在收到录取通知后，你必须第一时间提交签证申请，在此之前，你可以提前准备好一些必要的材料。护照肯定是必要的，同时你需要向学校支付学费，办理签证需要学校的学费收据。有些学校可以在线银行卡支付，同时请让你的监护人为你办理一张 Visa 或者 Master 的外币附属卡，银联是用不了的。如果学校不接受在线付款，你可以找在欧洲的熟人帮忙转账，实在没有的，找国内的私立银行，如民生银行，它们的转账手续费更低。 匈牙利的签证现在基本都是签证中心在办理，并且网点很多，服务也还行，会清楚的告诉你所有需要的材料。通过签证中心提交的申请不容易被面签，并且签证中心也会预审材料，有问题的会立即要求修改。一旦被要求面签，那就得亲自去匈牙利大使馆了，不过他们也不会问你太复杂的问题，如实回答，不要编造内容，并且不要表露出移民倾向，问就是最后回国。 对于未成年人，还需要监护人的授权同意书，大使馆会告诉你怎么写。所有法定监护人的单位均需要开具英文版的收入证明，注意是所有。如果有困难，收入不要写的太低即可，移民局也无权查证，其他情况就如实填写，不要夸大其词，如果怀疑起来，移民局会要银行流水。你还需要一份旅行保险，这个各个保险公司都有对应的产品，注意一下保额不要太低即可。 你还需要准备一份存款证明，金额不需要太多，在国内银行存个 5 万多人民币的定期就行了，然后让银行出具一份英文证明即可。而且也不用担心锁定之类的问题，毕竟交几块钱就可以解冻，拿出来继续用。这些钱是移民局来确保你不是去匈牙利当难民，而是去学习的，所以不建议存款证明造假（如临时借钱），不然交不起学费被遣返，或者被拒签，是一件对未来很有负面影响的事情。请注意，如果需要解冻，请你拿到签证以后再操作。 你还需要提前找好房子，最好是在拿到通知书后再签订合同（如果时间充足），不要过于相信中介，如果能住宿舍，第一学期最好住宿舍，不要去赌你能远程找到好房子，你可以到了那再立刻开始找自己想住的地方，宿舍是可以中途退出的。申请签证需要正确的租房合同和去匈牙利的机票。 签证的事情就听签证中心和大使馆的，一切顺利你就能拿到签证了。 关于启程你可以购买学生机票，这样你就有两个行李托运额度了。匈牙利是发达国家，不需要带的像去逃难或者去无人区一样，你能想到的东西那边基本都能买得到，只需要带上你的生活必需品和电子产品即可。电子产品一定不要带包装，甚至是发票，否则容易被收税。不要购买任何德国入境欧盟的机票，会被疯狂上税，到匈牙利有直飞的，不贵。 到了匈牙利你行李多的话可以预定接送，但是如果你能处理的了行李，机场接驳公交车非常方便。我自己从始至终就只坐过一次接送专车，省心是省心，贵也是真的贵。注意，你只有在拿到学生证或者临时纸质学生证后才能购买学生票。 最后，学校在开学前会组织多次线上线下的交流答疑会，还是很建议去参加听一下的。选课什么的会在开学前进行，你会收到学校的详细介绍邮件，跟着邮件有什么不懂的礼貌咨询注册处即可。开学前几天到匈牙利，在学校报道以后就可以着手准备领取居留卡和办理学生证等后续事项了，这些学校都会给你邮件指示和一定程度上的帮助，总之在这些事情上，联系学校就是最正确的选择。 后记匈牙利还有很多学校我就不一一介绍了，比如李斯特音乐学院，全球排名第 15 的音乐专业，学费也是贵的吓人。还有什么 Obuda 综合类大学，兽医大学，BGE 金融大学，农业大学等等……要将出国留学这件事情放在一个合适的位置，不要太焦虑，也不要满不在乎，随时做好两手准备才是硬道理。希望这篇攻略能对你有所帮助。","link":"/Memo/%E5%8C%88%E7%89%99%E5%88%A9%E7%95%99%E5%AD%A6%E6%94%BB%E7%95%A52024/"},{"title":"数据库概念入门","text":"所以说我们老师考这些的意义是什么呢 第一周Data -&gt; Database -&gt; Data Warehouse都什么年代了还在用数据仓库 Physical Data 是储存在实体介质上的数据Logical Data 是指数据的逻辑结构有 Add / Modify / Delete / Merging / Breaking 这什么玩意写的乱七八糟的 数据独立性物理独立性 程序与磁盘数据相互独立 程序不需要了解如何储存数据 数据如何储存由 DBMS 管理 物理储存改变，程序无需改变 逻辑独立性 程序与数据库的逻辑结构相互独立 数据逻辑结构改变，程序无需改变 数据独立性的重要性 数据质量 维护成本 安全性 结构化 Implementation (Layers of data) 减少重复 备份 物理层面容易修改，提高性能 合着真就不说人话 三级模式结构Physical Schema内模式（储存模式），对应 物理（内部）级描述了数据在磁盘上的存储方式和物理结构 Conceptual Schema概念模式（逻辑模式），对应 概念（逻辑）级是对数据库中全部数据的逻辑结构和特征的总体描述是全局视图，由 Data Description Language 描述 External Schema外模式（用户模式），对应 用户（视图）级是用户所看到的数据库的数据视图是概念模式的一个子集，包换特定用户使用的那部分数据由 Data Manipulation Language 操作 关系模型突然发现老师的 PPT 内容都是网上抄的 概念 Attribute: Column Table: Relation Tuple: Row Degree: Count(Column) Cardinality: Count(Row) Relation key: 比如主键 Domain: 数据类型，约束等 Relation Schema: 表名 和 其中的列 Relation Instance: 表中的数据 完整性约束Domain Constraints123... ColName INT CHECK(ColName = 3) NOT NULL ...-- AndCREATE TRIGGER SomeName ... Key Constraints主键约束 Referential Integrity Constraints外键约束 优势 简单 结构独立 易用 能够查询 数据独立 可扩展 第二周 RDBMS: Relational Database Management System关系型数据库管理系统 SQLWhy 方便存取数据 有助于描述数据 允许对数据库中的数据进行定义和操作 创建和删除表 创建和使用 函数，View，储存过程 设置权限 这些都是老师说的，我持保留意见 Types DDL: Data Definition Language 定义 CREATE ALTER DROP TRUNCATE DML: Data Manipulation Language 操作 INSERT UPDATE DELETE DCL: Data Control Language 权限 GRANT REVOKE TCL: Transaction Control Language 事务 COMMIT ROLLBACK SAVEPOINT DQL: Data Query Language 查询 SELECT 索引查看索引 1EXEC sp_helpindex 表名 聚集索引Clustered Index 表中行数据的物理顺序与索引的逻辑顺序相同 一个表只能有一个聚集索引 Primary Key 默认 非聚集索引Nonclustered Index 储存的是指向表中行的指针 UNIQUE 默认 索引覆盖Covering Indexes 索引中包含了所有要查询的字段 提高性能 第三周维护Maintenance Repair 重组索引 重建索引 更新统计信息 一致性和完整性检查Consistency and Integrity 修复和清理 Normalization数据库规范化 保护数据 消除冗余 消除不一致的依赖关系 不一致用户在 Customer 表中查找 Address 是合理的但是在这里查找 负责这个客户的 员工的 Salary 就不合理了这应该去 Employee 表中查找 不一致的依赖关系 会使数据难以访问 非规范化表 学生编号 指导教师 咨询室 课程 1 课程 2 课程 3 1022 Jones 412 101-07 143-01 159-02 4123 Smith 216 101-07 143-01 179-04 1NF：消除重复的列 消除单个表中的重复列 为每组相关数据单独创建一个表 使用主键标识每组相关数据 学生编号 指导教师 咨询室 课程 1022 Jones 412 101-07 1022 Jones 412 143-01 1022 Jones 412 159-02 4123 Smith 216 101-07 4123 Smith 216 143-01 4123 Smith 216 179-04 2NF：消除重复的行 为应用于多条记录的值，创建单独的表 用外键连接这些表 Table Student 学生编号 指导教师 咨询室 1022 Jones 412 4123 Smith 216 Table Course 学生编号 课程 1022 101-07 1022 143-01 1022 159-02 4123 101-07 4123 143-01 4123 179-04 3NF：消除与主键无关的数据指导教师和咨询室是与学生编号无关的数据 Table Student 学生编号 指导教师 1022 Jones 4123 Smith Table Teacher 名称 咨询室 Jones 412 Smith 216 主键 不能为空 唯一 几乎不会改变 Composite Key复合主键是指由多个字段组成的主键 外键 可空 不唯一 依赖完整性 ER 图 实体 Entity用矩形表示，也就是表 属性 Attribute用椭圆表示，也就是列 关系 Relationship用菱形表示，也就是表之间的关系 派生属性可以由其他属性计算得出，虚线比如 Age 可以由 Birthday 计算得出 多值属性可以有多个值，双椭圆比如书有多个作者 复合属性由多个属性组成比如名字由姓和名组成 可选属性 复合实体用于多对多联系，矩形内加一个菱形 弱实体必须依赖另一个实体存在比如学生是强实体，成绩单是弱实体必须是一对一或者一对多的关系用双层矩形表示 一对一 一对多 多对多需要复合实体帮助 步骤 Entity Identification找实体 Relationship Identification找关系 Cardinality Identification一对多之类的 Identify Attributes找 Column Create the ER Diagram画图 数据仓库数据仓库，OLAP，使用数据库系统来帮助洞察业务典型的有 Redshift，主要用于数据分析比如，20~30 岁女性用户在过去五年的第一季度化妆品类商品的购买行为与公司进行的促销活动方案之间的关系 数据库是为读写优化的，而数据仓库是为只读优化的 事实表主要特点是含有大量的数据，并且这些数据是可以汇总，并被记录的 维度表分析数据的窗口，包含事实表中事实记录的特性 星形模式 Star一张事实表和多张维度表组成 雪花模式 Snowflake每一个维度表都可以向外连接多个子维度表 星系模式 Galaxy多个事实表版本的星型模型，多张事实表共用模型中的维度表 Data Cube专指那些远大于内存的数据集合，它用来存储和表示多维度数据 钻取 Drill Down从高维度到低维度比如，对第二季度的总销售数据进行钻取可以得到第二季度中每个月的销售数据 上卷 Roll Up从低维度到高维度比如，将 4，5，6 月的销售数据进行上卷可以得到第二季度的销售数据 切片 Slice对特定值进行分析比如，只选择电子产品的销售数据 切块 Dice对特定范围进行分析比如，选择第一季度和第二季度的销售数据 旋转 Rotate交换维度比如，通过旋转实现产品和地域的维度互换 元数据元数据通常包括有关数据仓库中数据的描述信息、数据的属性和结构、以及数据之间的关系等元数据可以帮助人们更好地理解和使用数据仓库中的数据，并且在数据仓库的管理和维护方面也起着重要作用","link":"/Database/Theory/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"title":"数理逻辑2 B卷","text":"Mathematical Logic 完全理解！ CoqideAP ∧ (Q ∧ R), (S ∧ E) ∧ U, E ⇒ W ⊢ (Q ∧ P) ∧ W 123456789101112131415161718192021222324252627Require Import Classical.Parameters P Q R S U E W: Prop.Hypothesis P1: P /\\ (Q /\\ R).Hypothesis P2: (S /\\ E) /\\ U.Hypothesis P3: E -&gt; W.Goal (Q /\\ P) /\\ W.Proof.pose proof(proj1 P1).pose proof(proj2 P1).pose proof(proj1 H0).pose proof(conj H1 H).pose proof(proj1 P2).pose proof(proj2 H3).pose proof(P3 H4).pose proof(conj H1 H).pose proof(conj H6 H5).exact H7.Qed. BQ, Q ⇒ P ∨ R, R ⇒ S ⊢ P ∨ S 12345678910111213141516171819202122Require Import Classical.Parameters P Q R S: Prop.Hypothesis P1: Q.Hypothesis P2: Q -&gt; P \\/ R.Hypothesis P3: R -&gt; S.Goal P \\/ S.Proof.pose proof(P2 P1).destruct H.left.exact H.right.pose proof(P3 H).exact H0.Qed. CS ⇒ P, Q ⇒ E ⊢ (P ⇒ Q) ⇒ (S ⇒ E) 1234567891011121314151617181920Require Import Classical.Parameters P Q E S: Prop.Hypothesis P1: S -&gt; P.Hypothesis P2: Q -&gt; E.Goal (P -&gt; Q) -&gt; (S -&gt; E).Proof.intros H.assert(S -&gt; E).intros H1.apply P2.apply H.apply P1.exact H1.exact H0.Qed. D(P ⇒ Q) ⇒ (P ⇒ R) ⇒ (Q ⇒ R ⇒ W) ⇒ P ⇒ W 1234567891011121314Require Import Classical.Theorem Implies : forall P Q R W : Prop, (P -&gt; Q) -&gt; (P -&gt; R) -&gt; (Q -&gt; R -&gt; W) -&gt; P -&gt; W.Proof.intros P Q R W PQ PR QR PW.apply QR.apply PQ.exact PW.apply PR.exact PW.Qed. Symbolize No superhero is faster than Spiderman. Some evil superheros can climb on the wall. Evil superheros are not faster than Spiderman. If someone is faster than Spiderman, then Spiderman is evil. Everone who is faster than Spiderman is evil and can climb on the wall. There is someone who is faster than anyone who can climb on the wall. Someone who is faster than Spiderman is evil. Only those who are evil can be faster than those who are not faster than Spiderman. Find TruthUD: { Potter, Granger, Weasley }Extension H: { Potter, Weasley }Extension W: { Granger, Weasley }Extension R: { (Potter, Granger), (Granger, Potter), (Weasley, Granger) }Referent a: Potter ∃x(Rxa ∧ Rax) ∀x(Rxa ∨ Rax) ∀x(Hx ⇔ Wx) ∀x(Rxa ⇒ Wx) ∀x[Wx ⇒ (Hx ∧ Wx)] ∃x(Rxx) ∃x∃y(Rxy) ∀x∀y(Rxy) ∀x∀y(Rxy ∨ Ryx) ∀x∀y∀z[(Rxy ∧ Ryz) ⇒ Rxz] IsConsistentP ⇒ Q, Q ∧ (P ∨ P), ¬(Q ∨ R) IsValid R ⇒ (P ∨ Q), R ∧ Q ⊢ R ⇒ P ¬R ⇒ Q, ¬P ∨ ¬Q, ¬(P ⇔ Q) ⊢ ¬(P ∨ Q) Symbolize &amp; IsValidEvery dwarf that saw Snowhite biting into the apple want to save her.Someone (a dwarf) let the stepmother into the house.Those dwarfs that want to save Snowite did not let the stepmother into the house.Therefore: Not every dwaft saw Snowhite biting the apple. Natural Deduction P ∨ Q ⇒ R ⊢ (P ∧ Q) ⇒ R 1234567891011121314151617Require Import Classical.Parameters P Q R: Prop.Hypothesis P1: P \\/ Q -&gt; R.Goal (P /\\ Q) -&gt; R.Proof.intro.destruct H.apply P1.left.exact H.Qed. (R ∧ S) ⇒ (P ∧ ¬Q), E ∧ (E ⇒ S), Q ⊢ R ⇒ P 123456789101112131415161718192021222324Require Import Classical.Parameters P Q R S E: Prop.Hypothesis P1: (R /\\ S) -&gt; (P /\\ ~Q).Hypothesis P2: E /\\ (E -&gt; S).Hypothesis P3: Q.Goal R -&gt; P.Proof.intro.pose proof(proj1 P2).pose proof(proj2 P2).pose proof(H1 H0).pose proof(conj H H2).pose proof(P1 H3).pose proof(proj1 H4).exact H5.Qed. j is a constant, ∀x(¬Mx ∨ Ljx), ∀x(Bx ⇒ Ljx), ∀x(Mx ∨ Bx) ⊢ ∀xLjx ∃x∀yPxy ⊢ ∀y∃xPxy ∀xPx, ∃x(Px ⇒ ∀yQy), ∀x(Qx ⇒ Rx) ⊢ ∃x(Qx ∧ Rx) Argument invalid, Prove∃x(Dx), ∃x(Ex), ∀x(Dx ∨ Ex) ⊢ ∃x(Dx ∧ Ex)","link":"/Math/Logic/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%912-B%E5%8D%B7/"},{"title":"记一次面试题","text":"参加了一次 黑客排名 的技术面试 得到的经验就是别去看那有的没的的题干，很浪费时间，而是要： 看示例输入 看示例输出 找输入输出的关系 写框架代码 找题中的细节要求 完善代码 Test &amp; Debug 我有 70 分钟作答 ，但是吧，这题弱智都做得出来，无非是时间问题 算法题从 List&lt;List&lt;int&gt;&gt; 中找出最大相邻相同数字的方阵长度，比如 输入 1231 1 11 1 01 0 1 输出 2 解本题需要用到 动态规划 的思想 二维数组 dp 来记录以每个元素为右下角的最大相邻相同数字的方阵长度然后遍历输入的矩阵，根据当前元素的值来更新 dp最后，返回 dp 中的最大值作为最大相邻相同数字的方阵长度 12345678910111213141516171819202122232425262728static int FindMaxSquareLength(List&lt;List&lt;int&gt;&gt; matrix) { var rows = matrix.Count; var cols = matrix[0].Count; var maxLength = 0; var dp = new int[rows, cols]; for (var i = 0; i &lt; rows; i++) for (var j = 0; j &lt; cols; j++) { if (i == 0 || j == 0) dp[i, j] = matrix[i][j]; else if (matrix[i][j] == 1) dp[i, j] = Math.Min(dp[i - 1, j - 1], Math.Min(dp[i - 1, j], dp[i, j - 1])) + 1; maxLength = Math.Max(maxLength, dp[i, j]); } return maxLength;}List&lt;List&lt;int&gt;&gt; matrix = new() { new() { 1, 1, 1 }, new() { 1, 1, 0 }, new() { 1, 0, 1 }};var maxLength = FindMaxSquareLength(matrix);Console.WriteLine(&quot;最大相邻相同数字的方阵长度为: &quot; + maxLength); 技能题编写一个 HTTP GET 查询 URL: https://jsonmock.hackerrank.com/api/transactions它不提供除了 ?page=num 以外的查询参数 编写代码以实现 1List&lt;string&gt; maximumTransfer(string name, string city) 其中，找出最大的 credit 为 [0]，最大的 debit 为 [1] 解这个真没啥好说的，单纯考基本功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596static async Task&lt;List&lt;string&gt;&gt; maximumTransfer(string name, string city) { var result = new List&lt;string&gt;(); var allData = await GetAllData(); var maxCredit = decimal.MinValue; var maxDebit = decimal.MinValue; var maxCreditAmount = &quot;&quot;; var maxDebitAmount = &quot;&quot;; foreach (var data in allData.Where(data =&gt; data.userName == name &amp;&amp; data.location.city == city)) switch (data.txnType) { case &quot;credit&quot;: { var creditAmount = ParseAmount(data.amount); if (creditAmount &gt; maxCredit) { maxCredit = creditAmount; maxCreditAmount = data.amount; } break; } case &quot;debit&quot;: { var debitAmount = ParseAmount(data.amount); if (debitAmount &gt; maxDebit) { maxDebit = debitAmount; maxDebitAmount = data.amount; } break; } } result.Add(maxCreditAmount); result.Add(maxDebitAmount); return result;}static async Task&lt;List&lt;Data&gt;&gt; GetAllData() { var allData = new List&lt;Data&gt;(); var currentPage = 1; var totalPages = 1; while (currentPage &lt;= totalPages) { var url = $&quot;https://jsonmock.hackerrank.com/api/transactions?page={currentPage}&quot;; using (var client = new HttpClient()) { var response = await client.GetAsync(url); if (response.IsSuccessStatusCode) { var json = await response.Content.ReadAsStringAsync(); Root root = JsonConvert.DeserializeObject&lt;Root&gt;(json); allData.AddRange(root.data); totalPages = root.total_pages; } else throw new($&quot;Failed to retrieve data from {url}. Status code: {response.StatusCode}&quot;); } currentPage++; } return allData;}static decimal ParseAmount(string amount) { var cleanedAmount = amount.Replace(&quot;$&quot;, &quot;&quot;).Replace(&quot;,&quot;, &quot;&quot;); return decimal.Parse(cleanedAmount);}var maxTransfer = await maximumTransfer(&quot;John Doe&quot;, &quot;New York&quot;);Console.WriteLine(&quot;Max Credit: &quot; + maxTransfer[0]);Console.WriteLine(&quot;Max Debit: &quot; + maxTransfer[1]);internal class Data { public int id { get; set; } public int userId { get; set; } public string userName { get; set; } public object timestamp { get; set; } public string txnType { get; set; } public string amount { get; set; } public Location location { get; set; } public string ip { get; set; }}internal class Location { public int id { get; set; } public string address { get; set; } public string city { get; set; } public int zipCode { get; set; }}internal class Root { public int page { get; set; } public int per_page { get; set; } public int total { get; set; } public int total_pages { get; set; } public List&lt;Data&gt; data { get; set; }} SQL 题写一个 SQL 查询，有表 12customers(id: smallint, name:varchar)warehouses(customer_id, volume: decimal, is_active:smallint) 期望输出 1record(name, warehouses, min_volume, max_volume, total_volume) 只有 active 的仓库才被列出，按 name 排序 解或许 ChatGPT 写的比你更快更好 ，有的时候找找自己原因，好吧，这么多年了工资涨没涨，有没有认真工作，好不，这么多年都是这个代码质量我真的疯掉了。 123456789101112131415SELECT c.name AS name, COUNT(w.customer_id) AS warehouses, MIN(w.volume) AS min_volume, MAX(w.volume) AS max_volume, SUM(w.volume) AS total_volumeFROM customers c INNER JOIN warehouses w ON c.id = w.customer_idWHERE w.is_active = 1GROUP BY c.id, c.nameORDER BY c.name;","link":"/Program/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"论使用WebCodecs对视频进行处理","text":"原文 更新于 2022-02-10，由 Aloento 翻译，具体以原文为准 现代的 Web 技术为视频提供了丰富的处理能力，例如 Media Stream API、Media Recording API、Media Source API, 和 WebRTC API 等，它们提供了丰富的工具以便 录制、传输、回放视频流。这些 API 虽然封装了很多高级功能以便方便的完成既定任务，但它们并不能让你处理视频流的内部细节，如 按帧处理 和 处理未 Muxed 的视频或音频块等。为了实现以上目的，你不得不使用一些类似 WebAssembly 的方式来把浏览器本就自带的编解码器（通常它们都有硬件加速）又一次的引入，这属实是对资源的浪费。 而 WebCodecs API 为程序员提供了使用浏览器自带编解码器的能力，来提高你的工作流效率，具体而言： 音视频的编解码 视频原始帧 图像解码 WebCodecs API 对于需要完全控制媒体内容处理方式的场景是非常有用的，例如视频编辑、视频会议、视频流等。 视频处理工作流帧 是视频处理的基本单位，因此，在 WebCodecs 中，大多数类要么使用帧，要么产生帧。编码器将帧转为编码的 chunks（块），而解码器则做相反的事情。VideoFrame 有一个可以接受 CanvasImageSource 的构造函数来于其他的 Web API 很好的配合。所以它可以被用于 drawImage() 和 texImage2D() 等函数中. 此外，它还可以从 canvases, bitmaps, video elements 和 其他 video frames 中创建。 WebCodecs API 可以用 Insertable Streams API，让 WebCodecs 和 media stream tracks 一起工作。 MediaStreamTrackProcessor 将媒体流分解为单个帧。 MediaStreamTrackGenerator 从帧序列中创建媒体流。 WebCodecs 和 Web Workers按照设计，WebCodecs API 以异步方式在主线程之外完成所有繁重的工作。但是由于帧和 Chunk 的回调经常在一秒之类被调用多次，这可能导致主线程的混乱，导致网页 UI 的缓慢和卡顿，所以我们最好将处理工作放到 Worker 线程中。 而 ReadableStream 有一个简便的方法可以将来自媒体流的帧全部自动转移到 Worker 线程中，例如，从摄像头的来的流通过 MediaStreamTrackProcessor 获取到 ReadableStream 后，就可以在 Worker 线程中被 VideoEncoder 处理。 我们甚至可以通过 HTMLCanvasElement.transferControlToOffscreen 在主线程之外进行渲染。但如果所有的高级接口都不满足你的需求，VideoFrame 本身也是可以在不同的 Worker 中转移的。 WebCodecs 的编解码Encoding / 编码 我们从 VideoFrame 开始，有三种方法来构建视频帧。 从图片源，如 canvas, image bitmap, 或 video element. 1234const canvas = document.createElement(&quot;canvas&quot;);// Draw something on the canvas...const frameFromCanvas = new VideoFrame(canvas, { timestamp: 0 }); 使用 MediaStreamTrackProcessor 从 MediaStreamTrack 中提取帧 1234567891011const stream = await navigator.mediaDevices.getUserMedia({…});const track = stream.getTracks()[0];const trackProcessor = new MediaStreamTrackProcessor(track);const reader = trackProcessor.readable.getReader();while (true) { const result = await reader.read(); if (result.done) break; const frameFromCamera = result.value;} 从 BufferSource 中的原始二进制像素中创建帧 123456789101112131415161718const pixelSize = 4;const init = { timestamp: 0, codedWidth: 320, codedHeight: 200, format: &quot;RGBA&quot;,};const data = new Uint8Array(init.codedWidth * init.codedHeight * pixelSize);for (let x = 0; x &lt; init.codedWidth; x++) { for (let y = 0; y &lt; init.codedHeight; y++) { const offset = (y * init.codedWidth + x) * pixelSize; data[offset] = 0x7f; // Red data[offset + 1] = 0xff; // Green data[offset + 2] = 0xd4; // Blue data[offset + 3] = 0x0ff; // Alpha }}const frame = new VideoFrame(data, init); 无论它们来自哪里，帧都可以用 VideoEncoder 编码为 EncodedVideoChunk。而 VideoEncoder 需要两个参数： 两个函数，用来处理已编码数据块和产生的错误，传入后不可变。 编码器配置，用来配置输出的视频流参数，可以使用 configure() 进行修改。 如果你指定的配置不被浏览器支持，configure() 方法将抛出 NotSupportedError。所以我们建议你调用异步静态方法 VideoEncoder.isConfigSupported() 来预先检查你的配置是否被用户的浏览器支持。 12345678910111213141516171819202122const init = { output: handleChunk, error: (e) =&gt; { console.log(e.message); },};const config = { codec: &quot;vp8&quot;, width: 640, height: 480, bitrate: 2_000_000, // 2 Mbps framerate: 30,};const { supported } = await VideoEncoder.isConfigSupported(config);if (supported) { const encoder = new VideoEncoder(init); encoder.configure(config);} else { // Try another config.} 编码器设置好以后，你就可以通过 encode() 方法来传入帧了。configure() 和 encode() 都不需要等待实际工作结束，它们会立刻返回。编码器允许多个帧同时排队等待编码，encodeQueueSize 表示队列中有多少帧还未处理。 如果你传入的参数或调用方法的顺序不正确，则方法可以立刻抛出错误，也可以通过你设置的 error() 回调函数报告错误。如果编码成功，就会调用你设置的 output() 回调函数。这里需要强调一点，如果你的帧不再使用，你应该调用 close() 来释放资源。 12345678910111213141516171819202122let frameCounter = 0;const track = stream.getVideoTracks()[0];const trackProcessor = new MediaStreamTrackProcessor(track);const reader = trackProcessor.readable.getReader();while (true) { const result = await reader.read(); if (result.done) break; const frame = result.value; if (encoder.encodeQueueSize &gt; 2) { // Too many frames in flight, encoder is overwhelmed // let's drop this frame. frame.close(); } else { frameCounter++; const keyframe = frameCounter % 150 == 0; encoder.encode(frame, { keyFrame }); frame.close(); }} 最后，我们编写一个处理从编码器中得到的 Chunks 的函数，来完成最终的编码。一般来说，这个函数会把 Chunk 发往服务器，或者将 Chunk Muxing 到一个容器中来生成一个视频文件。 1234567891011121314151617181920212223function handleChunk(chunk, metadata) { if (metadata.decoderConfig) { // Decoder needs to be configured (or reconfigured) with new parameters // when metadata has a new decoderConfig. // Usually it happens in the beginning or when the encoder has a new // codec specific binary configuration. (VideoDecoderConfig.description). fetch(&quot;/upload_extra_data&quot;, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/octet-stream&quot; }, body: metadata.decoderConfig.description, }); } // actual bytes of encoded data const chunkData = new Uint8Array(chunk.byteLength); chunk.copyTo(chunkData); fetch(`/upload_chunk?timestamp=${chunk.timestamp}&amp;type=${chunk.type}`, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/octet-stream&quot; }, body: chunkData, });} 如果你需要确保所有的编码请求都已经完成，你可以调用异步函数 flush()。 1await encoder.flush(); Decoding / 解码 设置 VideoDecoder 的方法与设置 VideoEncoder 的类似：在创建解码器的是否传入两个参数，并调用 configure() 修改解码器参数。解码器的参数会因编码器的不同而不同，比如一个 H.264 解码器可能需要一个 AVCC 格式的二进制 blob，除非流是以 Annex B 编码的。(encoderConfig.avc = { format: &quot;annexb&quot; }) 1234567891011121314151617181920const init = { output: handleFrame, error: (e) =&gt; { console.log(e.message); },};const config = { codec: &quot;vp8&quot;, codedWidth: 640, codedHeight: 480,};const { supported } = await VideoDecoder.isConfigSupported(config);if (supported) { const decoder = new VideoDecoder(init); decoder.configure(config);} else { // Try another config.} 在准备好解码器后，你需要给它一个 EncodedVideoChunk。要创建 Chunk，你需要： 一个编码视频数据的 BufferSource Chunk 的开始时间戳，单位是微秒（Chunk 中第一个编码帧的媒体时间） Chunk 的类型： key，如果 Chunk 可以独立于之前的数据块进行解码，则为关键帧类型 delta Chunk 必须在其他块被解码以后才能被解码 编码器产生的所有 Chunk 都是可以用解码器解码的。之前提到的错误报告和方法的异步等事项，对解码器也是如此。 12345678910const responses = await downloadVideoChunksFromServer(timestamp);for (let i = 0; i &lt; responses.length; i++) { const chunk = new EncodedVideoChunk({ timestamp: responses[i].timestamp, type: responses[i].key ? &quot;key&quot; : &quot;delta&quot;, data: new Uint8Array(responses[i].body), }); decoder.decode(chunk);}await decoder.flush(); 现在，我们把解码好的帧展现在页面上。最好确保解码器的输出回调函数(handleFrame())迅速返回。在下面的例子中，它只是将一个帧添加到准备渲染的帧队列中。渲染是独立进行的，由两个步骤组成： 等待合适的时机来展示帧 在 Canvas 上绘制帧 一旦帧不再被使用，就调用 close() 来在 GC 之前释放底层内存，这将减少平均内存使用量。 1234567891011121314151617181920212223242526272829303132333435const canvas = document.getElementById(&quot;canvas&quot;);const ctx = canvas.getContext(&quot;2d&quot;);let pendingFrames = [];let underflow = true;let baseTime = 0;function handleFrame(frame) { pendingFrames.push(frame); if (underflow) setTimeout(renderFrame, 0);}function calculateTimeUntilNextFrame(timestamp) { if (baseTime == 0) baseTime = performance.now(); let mediaTime = performance.now() - baseTime; return Math.max(0, timestamp / 1000 - mediaTime);}async function renderFrame() { underflow = pendingFrames.length == 0; if (underflow) return; const frame = pendingFrames.shift(); // Based on the frame's timestamp calculate how much of real time waiting // is needed before showing the next frame. const timeUntilNextFrame = calculateTimeUntilNextFrame(frame.timestamp); await new Promise((r) =&gt; { setTimeout(r, timeUntilNextFrame); }); ctx.drawImage(frame, 0, 0); frame.close(); // Immediately schedule rendering of the next frame setTimeout(renderFrame, 0);} Dev Tips在 Chrome DevTools 中使用 Media Panel，查看媒体日志和调试 WebCodecs。 Demo下面这个例子展示了 Canvas 上的动画是如何被： 通过 MediaStreamTrackProcessor 以 25fps 的帧率采集到 ReadableStream 中 转发到 Worker 线程 编码成 H.264 的视频 再次解码为帧序列 使用 transferControlToOffscreen() 在另一个 Canvas 上渲染 new-webcodecs-blogpost-demo Other demosAlso check out our other demos: Decoding gifs with ImageDecoder Capture camera input to a file MP4 playback Other samples 使用 WebCodecs API兼容性检查检查对 WebCodecs 的支持: 123if (&quot;VideoEncoder&quot; in window) { // WebCodecs API is supported.} 请注意，WebCodecs API 只在 secure contexts 下运行，所以如果 self.isSecureContext 是 false，则检测会失败。 FeedbackThe Chrome team wants to hear about your experiences with the WebCodecs API. Tell us about the API designIs there something about the API that doesn’t work like you expected? Or arethere missing methods or properties that you need to implement your idea? Have aquestion or comment on the security model? File a spec issue on thecorresponding GitHub repo, or addyour thoughts to an existing issue. Report a problem with the implementationDid you find a bug with Chrome’s implementation? Or is the implementationdifferent from the spec? File a bug at new.crbug.com.Be sure to include as much detail as you can, simple instructions forreproducing, and enter Blink&gt;Media&gt;WebCodecs in the Components box.Glitch works great for sharing quick and easy repros. Show support for the APIAre you planning to use the WebCodecs API? Your public support helps theChrome team to prioritize features and shows other browser vendors how criticalit is to support them. Send emails to media-dev@chromium.org or send a tweetto @ChromiumDev using the hashtag#WebCodecsand let us know where and how you’re using it. Hero image byDenise Janson Unsplash.","link":"/Program/WebCodecs/%E8%AE%BA%E4%BD%BF%E7%94%A8WebCodecs%E5%AF%B9%E8%A7%86%E9%A2%91%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86/"},{"title":"论如何在C++&#x2F;CLI中使用LINQ：记一次奇妙的C++大作业","text":"123456“救我，你一定要救我啊！” 我的同学对我如是说“¿”“C++要考试了！我整不来啊，我感觉挺简单的题”“......”“请你吃顿饭”“彳亍” 然后我就收到了这么两道题目： 准备 生成 20 个可被 2 或 5 整除，介于 1 至 100 之间的无重复随机数 Write a program (in C++) that generates and calculates 20 different random numbers that can be divided by 2 or 5. Random numbers must be generated from 1 to 200,the same number cannot be included in the array! The random number generation should be written in a function, i.e. the return value of the function should be an array! 随机产生 50 个人的工资表，并列出平均、最高低工资 Given a list in which the wages of 50 people are stored (in EUR). Write a program (in C++) that determines what the average wage is, who has the highest wage, who has the lowest wage, and who has the wages below average. 乍一看感觉这题确实就是初学者的题目，不过如果我使用普通的方法完成这题就不能称之为 “奇妙” 的大作业了，所以在犹豫一阵后我决定，使用 C++/CLI 来完成顺带再期待一下老师如果看到一堆 CLI 代码会作何反应（ 什么是 C++/CLIC++/CLI 是 C++ 的扩展，让我们可以同时享受 C# 和 C++ 的特性，是微软的就我个人而言，如果能用 C++/CLI 的话那我绝对不会用传统的 C++而且这玩意据我了解在中国没多少人用，或者说老外也不怎么用因为这玩意不上不下的，说实话 C# 的 unsafe 已经足够了 而且就目前为止，它仍然不能跨平台，Core 以后也无法生成独立程序了 寄 There isn’t currently a template for C++/CLI console or Windows applications that can be used with .NET Core.Instead you must put application entry point outside of the C++/CLI code. 所以作业是用 .NET Framework，不过本文使用 .NET Core所以查个资料，学习起来着实有点费力，以后有空可以专门讲讲 在撰写这篇文章时我目前心目中的优先级：C# &gt; Go &gt; Rust &gt; C++/CLI &gt; TS &gt; Java &gt; Python &gt; JS &gt; C++ &gt; C一天到晚只想用托管类语言的我已经是个废物了 话费不多的请直接跳到文章最后看结果接下来我会一点点讲述我的心路历程 做题 准备项目 用 VS 2022 创建一个新的 C# .NET Core 解决方案 在解决方案中添加一个 C++/CLI .NET Core 类库项目 这里如果使用空白项目的话需要自己配置很多东西而且微软对 C++/CLI 的支持是越来越不好了注意：CLI 项目更改以后需要生成一下才能在 C# 中看到变化 Func: GetRandoms首先我们来实现生成随机数的函数既然两个题目都要求了随机数的产生那么我们就专门做一个函数出来复用 尽可能多的复用我认为是一件非常好的习惯无论是在写代码，还是在生活中 函数定义12345678910using namespace System;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq { public: static List&lt;int&gt;^ GetRandoms(int min, int max, int num) { return nullptr; }}; 这就是我的格式习惯，一股子 Java 味让我们来分析一下这个代码 这是在一个 .h 头文件里面的代码 声明函数的写法就是传统的 C++ namespace 和 using 都和 C# 一样，只不过把 . 变成 :: public 是为了让 C# 可以访问 ref 表明这是一个托管类 static 在我这里是 Helper 的统一写法 List&lt;int&gt;^ 返回一个 托管的 ^ List&lt;int&gt; 类型 托管类型都是从 C# 来的用 C++/CLI 托管的代码可以无缝在 C# 中使用，反之亦然 基本功能1234567891011121314static List&lt;int&gt;^ GetRandoms(int min, int max, int num) { auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res;} Random::Shared 说明了我们现在在使用 .NET Core gcnew 表明了我们要生成一个 托管的 对象 if 语句用来排除重复的随机数，并且确保是 2 和 5 的倍数 i++ 表明我们已经得到了目标，所以我们要让 i 加一，不可以让 for 语句来完成 至此，有一些编程基础的都应该轻松看懂除了一些 CLI 的独特语法以外，其余的和传统 C++ / C# 并无太大区别 数据验证我们写代码的时候还是不要过于相信用户会按照你的想法来使用它毕竟 一个测试工程师走进一家酒吧，啥也没干酒吧就炸了 所以我们简单的加一句： 12if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) throw gcnew ArgumentOutOfRangeException(); 这里我没有写具体的说明，不过正式写代码的时候，报错一定要写清楚原因 完全体123456789101112131415161718192021222324252627#pragma onceusing namespace System;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq sealed { public: static List&lt;int&gt;^ GetRandoms(const int min, const int max, const int num) { if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw gcnew ArgumentOutOfRangeException(); } auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res; } };} Func: GetWagesList我是把两道题一起做的，所以在这个 CLILinq 类里应该还有第二题的方法这个方法用来产生一些随机的 Name:Wages 键值对由于时间关系，我们这里生成的名字就直接按 ASCII 取了 123456789101112static Dictionary&lt;Char, double&gt;^ GetWagesList() { auto random = Random::Shared; auto dictionary = gcnew Dictionary&lt;Char, double&gt;(); Char c = 65; for (auto i = 0; i &lt; 50; i++) { auto wage = random-&gt;NextDouble() * 1000; dictionary-&gt;Add(c++, wage); } return dictionary;} 因为比较简单，所以直接上代码这里不用 char 而是 Char，这样可以直接被 C# 转字符串，方便输出 调用：第一题第一题的调用比较无脑，直接用就行了 123456static void Invoke() { auto randomList = GetRandoms(1, 200, 20); for each (auto num in randomList) { Console::WriteLine(num); }} LINQ：第二题第二题的实际逻辑就在这里也是 LINQ 出场的地方 （原谅我前面瞎扯了那么多） 我们先看实现代码 123456789101112131415161718static void Invoke() { auto wageDic = GetWagesList(); auto v = wageDic-&gt;Values; double sum = 0; for each (auto num in v) { sum += num; } auto avg = sum / 50; auto c = System::Globalization::CultureInfo::CultureInfo::CreateSpecificCulture(&quot;eu-ES&quot;); Console::WriteLine(&quot;Average: &quot; + avg.ToString(&quot;C&quot;, c) + &quot;\\n&quot;); auto ordered = Enumerable::OrderBy(wageDic, gcnew Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;(Select)); for each (auto one in ordered) { Console::WriteLine(one.Key + &quot;: &quot; + one.Value.ToString(&quot;C&quot;, c)); }} for each (auto num in v) 这部分其实就是 Enumerable.Aggregate 的简单实现毕竟要交作业，不能写的那么高级 （其实是嫌麻烦） CultureInfo 就是设置个格式化区域，这里转成欧洲的货币格式avg.ToString(&quot;C&quot;, c) 就是把 avg 转成 Currency LINQ接下来就是 Enumerable.OrderBy 的实现为了搞懂如何传入这个方法需要的参数，我搞了一个多小时到处找资料和 debug… 由于 C++ 11 之前就没有 lambda 表达式，后面有了也非常奇怪所以 LINQ 压根就没有提供类似的调用方式所以我们必须使用 gcnew Func() 的方式传递一个委托 首先，我们必须清楚 Func 的泛型类型到底是什么C++/CLI 在这里 IDE 是完全没有代码提示的，所以我们需要自行分析最好的方式就是在 C# 里面写同样的代码，然后看它们的类型 在这里，Dictionary&lt;Char, double&gt; 的单个元素的类型是 KeyValuePair&lt;Char, double&gt;所以很显然我们需要 Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;现在我们就有了它的类型，然后我们需要实现这个委托 这个委托是一个选择器，它的作用是从类型中选择出一个对象来作为排序的依据在我们这里，就是要从 KeyValuePair 中把 Value 选出来 随后就有了以下代码 123static double Select(KeyValuePair&lt;Char, double&gt; a) { return a.Value;} 非常简单，在特定情况下，你也可以尝试直接内联它之后的事情就非常简单了，该调用调用，该输出输出 实际上先贴一堆代码，可以粗略看看 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697namespace Aloento.SCLILinq;using System.Globalization;public sealed class SCLILinq { public static List&lt;int&gt; GetRandoms(int min, int max, int num) { Random random = null; List&lt;int&gt; list = null; if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw new ArgumentOutOfRangeException(); } random = Random.Shared; list = new List&lt;int&gt;(num); int num2 = 0; while (num2 &lt; num) { int num3 = random.Next(min, max); if (!list.Contains(num3) &amp;&amp; (num3 % 2 == 0 || num3 % 5 == 0)) { num2++; list.Add(num3); } } return list; } public static Dictionary&lt;char, double&gt; GetWagesList() { Random random = null; Dictionary&lt;char, double&gt; dictionary = null; random = Random.Shared; dictionary = new Dictionary&lt;char, double&gt;(); char c = 'A'; for (int i = 0; i &lt; 50; i++) { double value = random.NextDouble() * 1000.0; char key = c; c = (char)(c + 1); dictionary.Add(key, value); } return dictionary; } public static double Select(KeyValuePair&lt;char, double&gt; a) { return a.Value; } public static void Invoke() { List&lt;int&gt; list = null; Dictionary&lt;char, double&gt; dictionary = null; Dictionary&lt;char, double&gt;.ValueCollection valueCollection = null; CultureInfo cultureInfo = null; IOrderedEnumerable&lt;KeyValuePair&lt;char, double&gt;&gt; orderedEnumerable = null; IEnumerator&lt;KeyValuePair&lt;char, double&gt;&gt; enumerator = null; list = GetRandoms(1, 200, 20); List&lt;int&gt;.Enumerator enumerator2 = list.GetEnumerator(); while (enumerator2.MoveNext()) { int current = enumerator2.Current; Console.WriteLine(current); } Console.WriteLine(&quot;\\n-------------------------------\\n&quot;); dictionary = GetWagesList(); valueCollection = dictionary.Values; double num = 0.0; Dictionary&lt;char, double&gt;.ValueCollection.Enumerator enumerator3 = valueCollection.GetEnumerator(); while (enumerator3.MoveNext()) { double current2 = enumerator3.Current; num += current2; } double num2 = num / 50.0; cultureInfo = CultureInfo.CreateSpecificCulture(&quot;eu-ES&quot;); string str = &quot;\\n&quot;; double num3 = num2; string str2 = num3.ToString(&quot;C&quot;, cultureInfo); Console.WriteLine(string.Concat(&quot;Average: &quot; + str2, str)); orderedEnumerable = Enumerable.OrderBy(dictionary, new Func&lt;KeyValuePair&lt;char, double&gt;, double&gt;(Select)); enumerator = orderedEnumerable.GetEnumerator(); try { while (enumerator.MoveNext()) { KeyValuePair&lt;char, double&gt; current3 = enumerator.Current; double value = current3.Value; string format = &quot;C&quot;; string str3 = value.ToString(format, cultureInfo); string arg = &quot;: &quot;; Console.WriteLine(string.Concat(current3.Key + arg, str3)); } } finally { IEnumerator&lt;KeyValuePair&lt;char, double&gt;&gt; enumerator4 = enumerator; if (enumerator4 != null) { enumerator4.Dispose(); long num4 = 0L; } else { long num4 = 0L; } } }} 这是直接对 C++/CLI 生成的库反编译的结果我们可以发现，这就相当于是写了一堆 C# 而已如果带指针之类的，就是 unsafe所以：没必要，别用 C++/CLI 适用范围 如果你想 Wrapper 一个 C / C++ 的库给 C# 用 如果你想让 .NET 与其他语言一起工作 让 C++ 享受 .NET 的生态 如果你闲得慌想找点事情干 在大部分情况下，C++/CLI 的存在都是为了高效的让 C# 与 C / C++ 交互而使用使用它可以让你的 .NET 项目享受到 C++ 全套的生态，反之亦然毕竟 P/Invoke 并不优雅 在托管类语言中，C++/CLI 在一定程度上让 C# 成了最容易与 C / C++ 交互的语言进而让它也更容易与能够和 C / C++ 交互的语言交互 使用它，你需要同时掌握 C# 和 C++而且在很多时候，IDE 不会给你有效的提示所以学习它需要很多时间来尝试 结论12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970using namespace System;using namespace Linq;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq sealed { public: static List&lt;int&gt;^ GetRandoms(const int min, const int max, const int num) { if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw gcnew ArgumentOutOfRangeException(); } auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res; } static Dictionary&lt;Char, double&gt;^ GetWagesList() { auto random = Random::Shared; auto dictionary = gcnew Dictionary&lt;Char, double&gt;(); Char c = 65; for (auto i = 0; i &lt; 50; i++) { auto wage = random-&gt;NextDouble() * 1000; dictionary-&gt;Add(c++, wage); } return dictionary; } static double Select(KeyValuePair&lt;Char, double&gt; a) { return a.Value; } static void Invoke() { auto randomList = GetRandoms(1, 200, 20); for each (auto num in randomList) { Console::WriteLine(num); } Console::WriteLine(&quot;\\n-------------------------------\\n&quot;); auto wageDic = GetWagesList(); auto v = wageDic-&gt;Values; double sum = 0; for each (auto num in v) { sum += num; } auto avg = sum / 50; auto c = System::Globalization::CultureInfo::CultureInfo::CreateSpecificCulture(&quot;eu-ES&quot;); Console::WriteLine(&quot;Average: &quot; + avg.ToString(&quot;C&quot;, c) + &quot;\\n&quot;); auto ordered = Enumerable::OrderBy(wageDic, gcnew Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;(Select)); for each (auto one in ordered) { Console::WriteLine(one.Key + &quot;: &quot; + one.Value.ToString(&quot;C&quot;, c)); } } };}","link":"/Program/C/CLI/%E8%AE%BA%E5%A6%82%E4%BD%95%E5%9C%A8CPPCLI%E4%B8%AD%E4%BD%BF%E7%94%A8LINQ%E4%B9%8B%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%A5%87%E5%A6%99%E7%9A%84CPP%E5%A4%A7%E4%BD%9C%E4%B8%9A/"},{"title":"迷宫寻路","text":"我被困在一个迷宫中 迷宫寻路题目描述你被困在一个 4x4 的迷宫中，迷宫的结构如下所示： 123456789-----------------| M | N | O | P |-----------------| I | J | K | L |-----------------| E | F | G | H |-----------------| A | B | C | D |----------------- 迷宫中存在以下墙壁： M 和 N 之间有墙 N 和 O 之间有墙 J 和 K 之间有墙 F 和 G 之间有墙 I 和 E 之间有墙 E 和 F 之间有墙 K 和 G 之间有墙 P 和 L 之间有墙 你的任务是从起点 P 出发，找到一条通往终点 A 的路径。在寻路过程中，你需要按照 北（N）、西（W）、南（S）、东（E） 的优先级进行移动。 问题 列举当前经过的位置：请按照你的寻路顺序，列出从 P 到 A 所经过的所有位置。 实现目标需要多少步：计算从 P 到 A 所需的总步数。 需要多少个回溯步骤：在寻路过程中，如果遇到死胡同，你需要回溯到上一个分叉点。请计算总共需要回溯多少次。 使用 Java 模拟：编写一个 Java 程序，模拟从 P 到 A 的寻路过程，并输出经过的位置、总步数和回溯次数。具体实现过程由你自由发挥，只需要确保输出结果正确即可。 提示 在移动时，优先尝试向北（N）移动，如果不行则依次尝试西（W）、南（S）、东（E）。 注意墙壁的存在，确保不会穿过墙壁。 回溯步骤是指在遇到死胡同时，需要返回到上一个可以继续探索的位置。 示例假设迷宫中不存在墙壁，从 P 到 A 的路径可能是：P → L → H → D → C → B → A。但在这个迷宫中，由于墙壁的存在，路径会有所不同。 解答要求请详细描述你的寻路过程，并回答上述三个问题。同时，编写一个 Java 程序来模拟寻路过程，并输出结果。 预期输出枚举表应该类似如下内容： No. Curr N W S E Back 1 P Blocked OK 2 O Blocked Blocked OK … … … … … … … 20 A 程序应输出类似以下内容： 123经过的位置: [P, O, N, M, I, J, F, E, A]总步数: 9回溯次数: 2 参考答案 No. Curr N W S E Back 1 P Blocked OK 2 O Blocked Blocked OK 3 K Visited Blocked Blocked OK 4 L Blocked Visited OK 5 H Visited OK 6 G Blocked Blocked OK 7 C Visited OK 8 B OK 9 F OK 10 J OK 11 N Blocked Blocked Visited Blocked Back 12 J Used OK 13 I OK 14 M Blocked Blocked Visited Blocked Back 15 I Used Blocked Blocked Visited Back 16 J Used Used Visited Blocked Back 17 F Used Blocked Visited Blocked Back 18 B Used OK 19 A P &gt; O &gt; K &gt; L &gt; H &gt; G &gt; C &gt; B &gt; A.8 Steps shortest.5 back steps.18 total steps. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import java.util.*;public class Main { private static final char[][] MAZE = { {'M', 'N', 'O', 'P'}, {'I', 'J', 'K', 'L'}, {'E', 'F', 'G', 'H'}, {'A', 'B', 'C', 'D'} }; private static final Map&lt;Character, Set&lt;Character&gt;&gt; WALLS = new HashMap&lt;&gt;(); private static final List&lt;Character&gt; path = new ArrayList&lt;&gt;(); private static int backSteps = 0; private static Set&lt;Character&gt; visited = new HashSet&lt;&gt;(); static { addWall('M', 'N'); addWall('N', 'O'); addWall('J', 'K'); addWall('F', 'G'); addWall('I', 'E'); addWall('E', 'F'); addWall('K', 'G'); addWall('P', 'L'); } private static void addWall(char a, char b) { WALLS.computeIfAbsent(a, k -&gt; new HashSet&lt;&gt;()).add(b); WALLS.computeIfAbsent(b, k -&gt; new HashSet&lt;&gt;()).add(a); } private static boolean hasWall(char from, char to) { return WALLS.getOrDefault(from, Collections.emptySet()).contains(to); } private static List&lt;Character&gt; getNeighbors(char current) { int[] pos = findPosition(current); int row = pos[0], col = pos[1]; List&lt;Character&gt; neighbors = new ArrayList&lt;&gt;(); // North if (row &gt; 0 &amp;&amp; !hasWall(current, MAZE[row-1][col])) neighbors.add(MAZE[row-1][col]); // West if (col &gt; 0 &amp;&amp; !hasWall(current, MAZE[row][col-1])) neighbors.add(MAZE[row][col-1]); // South if (row &lt; 3 &amp;&amp; !hasWall(current, MAZE[row+1][col])) neighbors.add(MAZE[row+1][col]); // East if (col &lt; 3 &amp;&amp; !hasWall(current, MAZE[row][col+1])) neighbors.add(MAZE[row][col+1]); return neighbors; } private static int[] findPosition(char c) { for (int i = 0; i &lt; 4; i++) for (int j = 0; j &lt; 4; j++) if (MAZE[i][j] == c) return new int[]{i, j}; return null; } private static boolean dfs(char current, char target) { path.add(current); visited.add(current); if (current == target) return true; for (char next : getNeighbors(current)) { if (!visited.contains(next)) { if (dfs(next, target)) return true; backSteps++; } } path.remove(path.size() - 1); return false; } public static void main(String[] args) { dfs('P', 'A'); System.out.println(&quot;经过的位置: &quot; + path); System.out.println(&quot;总步数: &quot; + (path.size() - 1)); System.out.println(&quot;回溯次数: &quot; + backSteps); }}","link":"/Algorithm/%E8%BF%B7%E5%AE%AB%E5%AF%BB%E8%B7%AF/"},{"title":"DAA Endterm","text":"交张白卷上去，不愧是我 网格最大成本寻路Suppose that you are given a $n \\times n$ checkerboard and a checker. You must move the checker from the bottom edge of the board to the top edge of the board according to the following rules. At each step you may move the checker to one of three squares: the square immediately above the current square. the square that is one up and one to the left. (but only if the checker is not already in the leftmost column) the square that is one up and one to the right. (but only if the checker is not already in the rightmost column) Each time you move from square $x$ to square $y$, you receive $f(x, y)$ dollars. You are given $f(x, y)$ for all pairs $(x, y)$ for which a move from x to y is legal. Give an $O(n^2)$ dynamic programming algorithm that figures out the set of moves that will move the checker from somewhere along the bottom edge to somewhere along the top edge while gathering as many dollars as possible. Your algorithm is free to pick any square along the top edge as a destination in order to maximize the number of dollars gathered along the way. 解https://github.com/juemura/amli/blob/master/Checkerboard.ipynb 这题说白了就是让你计算一个矩阵，每次只能往上临近的地方走一格，每走一次有一个 f 方程给你计算收益，让你求出最大收益的路径。 这道题没有给出 f 的定义，所以我们自己定个规则：随机给每个格子填一个值，这个值可大可小，可正可负，走到格子上就把格子的值加到最终收益上。 1234567891011121314import { random } from &quot;lodash&quot;;function makeMatrix(dim: number) { const matrix: number[][] = []; for (let i = 0; i &lt; dim; i++) { matrix.push([]); for (let j = 0; j &lt; dim; j++) { matrix[i].push(random(-100, 100)); } } return matrix;} 打印矩阵的代码 123456789101112131415161718192021function printMatrix(matrix: number[][]) { let res = &quot;|X\\\\Y|&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += i + &quot;|&quot;; } res += &quot;\\n|---|&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += &quot;---|&quot;; } res += &quot;\\n&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += `|**${i}**|${matrix[i].join(&quot;|&quot;)}|`; res += &quot;\\n&quot;; } console.log(res);} 随后，我们得到矩阵 X\\Y 0 1 2 3 4 0 -60 51 -24 -4 -66 1 45 12 76 -41 -22 2 -50 19 -79 47 96 3 -74 -12 98 54 1 4 -66 16 91 -87 -20 接下来要做的事情就很明显了：计算局部最优的转移过程的累加收益（说的玄乎，看代码马上就懂了，也就是每次转移都找收益最大的那个来源） 要注意，正向转移是不可能计算的，所以我们每次计算的都是从哪里来的，而不是去哪里。 123456789101112131415161718192021222324252627282930313233343536373839function calcDifference(matrix: number[][]) { const n = matrix.length; // 用来存储每个格子的最大值 const aggregate: number[][] = Array.from({ length: n }, () =&gt; Array(n).fill(0) ); // 用 matrix 填充第一行，因为没有格子可以从上方移动来 for (let col = 0; col &lt; n; col++) { aggregate[0][col] = matrix[0][col]; } // 从第二行开始填充 maxDiff for (let row = 1; row &lt; n; row++) { // 遍历当前行的每一个格子 for (let col = 0; col &lt; n; col++) { let fromLeft = -Infinity; let fromTop = -Infinity; let fromRight = -Infinity; // 如果当前格子不在第一列，那么可以从左上移动来 if (col &gt; 0) { fromLeft = aggregate[row - 1][col - 1] + matrix[row][col]; } // 从正上方移动来 fromTop = aggregate[row - 1][col] + matrix[row][col]; // 如果当前格子不在最后一列，那么可以从右上移动来 if (col &lt; n - 1) { fromRight = aggregate[row - 1][col + 1] + matrix[row][col]; } // 计算当前格子的最大值 aggregate[row][col] = Math.max(fromLeft, fromTop, fromRight); } } return aggregate;} 我们得到 X\\Y 0 1 2 3 4 0 -60 51 -24 -4 -66 1 96 63 127 -45 -26 2 46 146 48 174 70 3 72 134 272 228 175 4 68 288 363 185 208 接下来我们追踪最大值的路径，这里我们只需要找到最后一行的最大值，然后从这个最大值开始往上找，将 DP 值最大的一个作为路径的下一个点，直到找到第一行。 123456789101112131415161718192021222324252627282930313233343536373839404142function traceBack(aggregate: number[][]) { const n = aggregate.length; const path: [number, number][] = []; let stopIndex = 0; aggregate[n - 1].forEach((val, index) =&gt; { if (val &gt; aggregate[n - 1][stopIndex]) { stopIndex = index; } }); path.push([n - 1, stopIndex]); let currentCol = stopIndex; for (let row = n - 2; row &gt;= 0; row--) { let fromLeft = -Infinity; let fromTop = -Infinity; let fromRight = -Infinity; if (currentCol &gt; 0) { fromLeft = aggregate[row][currentCol - 1]; } fromTop = aggregate[row][currentCol]; if (currentCol &lt; n - 1) { fromRight = aggregate[row][currentCol + 1]; } if (fromLeft &gt; fromTop &amp;&amp; fromLeft &gt; fromRight) { currentCol -= 1; } else if (fromRight &gt; fromTop &amp;&amp; fromRight &gt; fromLeft) { currentCol += 1; } path.push([row, currentCol]); } return path;} 我们得到路径 Path (X, Y) 4 2 3 2 2 3 1 2 0 1 最优参数Give the dynamic programming solution to the optimal parameterization problem for them matrix product $A_1, A_2, A_3, A_4, A_5$ where the dimensions of $A_3$ are $4 \\times 2$, the dimensions of $A_4$ are $2 \\times 5$, and the dimensions of $A_5$ are $5 \\times 3$. Show all calculations. 解子序列Run the dynamic programming algorithm to the longest common subsequence problem of sequences $(a, b, b, d, c, d, b, a)$ and $(a, b, d, c, a, b, c, d, a)$. 解背包问题Run the dynamic programming algorithm to the knapsack problem for items: i 1 2 3 4 5 6 7 $w_i$ 2 2 5 4 1 3 1 $v_i$ 10 50 40 80 70 10 20 and knapsack capacity 11. 解最大收益Suppose you are managing a consulting team of expert computer hackers, and each week you have to choose a job for them to undertake. Now, as you can well imagine, the set of possible jobs is divided into those that are low-stress, and those that are high-stress. The basic question, each week, is whether to take on a low-stress job or a high-stress job. If you select a low-stress job for your team in week $i$, then you get a revenue of $l_i &gt; 0$ dollars. If you select a high-stress job, you get a revenue of $h_i &gt; 0$ dollars. The catch, however, is that in order for the team to take on a high-stress job in week $i$, it’s required that they do no job in week $i - 1$. On the other hand, it’s OK for the team to take a low-stress job in week $i$ even if they have done a job in week $i - 1$. So, given a sequence of $n$ weeks, a plan is specified by a choice of low, high, none for each of the $n$ weeks, which the property that if high is chosen for week $i &gt; 1$, the none has to be chose for week $i - 1$. (1st week can be high) The value of the plan is determined in the natural way: for each $i$ you add $(h/l/n)_i$ to the value of you chose high in week $i$. Give an efficient dynamic programming algorithm that take values for $l_1, l_2 \\cdots l_n$ and $h_1, h_2 \\cdots h_n$ and returns a plan of maximum value. Also give the running time of your algorithm. 解","link":"/Algorithm/DAA-Endterm/"}],"tags":[{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"},{"name":"考试","slug":"考试","link":"/tags/%E8%80%83%E8%AF%95/"},{"name":"数据科学","slug":"数据科学","link":"/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"习题","slug":"习题","link":"/tags/%E4%B9%A0%E9%A2%98/"},{"name":"SQLServer","slug":"SQLServer","link":"/tags/SQLServer/"},{"name":"Matplotlib","slug":"Matplotlib","link":"/tags/Matplotlib/"},{"name":"编程","slug":"编程","link":"/tags/%E7%BC%96%E7%A8%8B/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"数值方法","slug":"数值方法","link":"/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"},{"name":"云","slug":"云","link":"/tags/%E4%BA%91/"},{"name":"OpenStack","slug":"OpenStack","link":"/tags/OpenStack/"},{"name":"RL","slug":"RL","link":"/tags/RL/"},{"name":"图灵机","slug":"图灵机","link":"/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"},{"name":"匈牙利","slug":"匈牙利","link":"/tags/%E5%8C%88%E7%89%99%E5%88%A9/"},{"name":"留学","slug":"留学","link":"/tags/%E7%95%99%E5%AD%A6/"},{"name":"攻略","slug":"攻略","link":"/tags/%E6%94%BB%E7%95%A5/"},{"name":"逻辑","slug":"逻辑","link":"/tags/%E9%80%BB%E8%BE%91/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"翻译","slug":"翻译","link":"/tags/%E7%BF%BB%E8%AF%91/"},{"name":"音视频","slug":"音视频","link":"/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"WebCodecs","slug":"WebCodecs","link":"/tags/WebCodecs/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"CLI","slug":"CLI","link":"/tags/CLI/"},{"name":"LINQ","slug":"LINQ","link":"/tags/LINQ/"},{"name":".NET","slug":"NET","link":"/tags/NET/"}],"categories":[{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Data Science","slug":"Data-Science","link":"/categories/Data-Science/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Program","slug":"Program","link":"/categories/Program/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"MSSQL","slug":"Database/MSSQL","link":"/categories/Database/MSSQL/"},{"name":"Python","slug":"Program/Python","link":"/categories/Program/Python/"},{"name":"NLP","slug":"AI/NLP","link":"/categories/AI/NLP/"},{"name":"Math","slug":"Math","link":"/categories/Math/"},{"name":"Cloud","slug":"Cloud","link":"/categories/Cloud/"},{"name":"RL","slug":"AI/RL","link":"/categories/AI/RL/"},{"name":"TM","slug":"Algorithm/TM","link":"/categories/Algorithm/TM/"},{"name":"Memo","slug":"Memo","link":"/categories/Memo/"},{"name":"Theory","slug":"Database/Theory","link":"/categories/Database/Theory/"},{"name":"WebCodecs","slug":"Program/WebCodecs","link":"/categories/Program/WebCodecs/"},{"name":"C++","slug":"Program/C","link":"/categories/Program/C/"},{"name":"Matlab","slug":"Math/Matlab","link":"/categories/Math/Matlab/"},{"name":"OpenStack","slug":"Cloud/OpenStack","link":"/categories/Cloud/OpenStack/"},{"name":"Logic","slug":"Math/Logic","link":"/categories/Math/Logic/"},{"name":"CLI","slug":"Program/C/CLI","link":"/categories/Program/C/CLI/"}],"pages":[]}