{"posts":[{"title":"Basics of Computer Science","text":"我是真没搞明白这老师在干什么所以我按着她的板书，自己搓了一遍她写的那个字，就跟狗爬的一样 Algorithmic problems, modellingtheory of computation, modelling tools, examples What is it good for Create efficient algorithms Programming language research Efficient compiler design and construction 我们为什么要研究算法？ 构建高效算法 编程语言研究 高效编译器设计和构建 Branches of ToCAutomata theory is the study of abstract computational devices formal framework for designing and analyzing computing devices we will discuss Turing Machines. 自动机理论 是对抽象计算机的研究 用于设计和分析计算机的形式框架 我们将讨论图灵机 Computability Theory defines whether a problem is “solvable” by any abstract machines some problems are computable, some are not (e.g. travelling salesman problem) 可计算性理论 定义了一个问题是否可以被任何抽象机器解决 有些问题是可计算的，有些不是（例如旅行推销员问题） Complexity Theory studying the cost of solving problems cost = resources (e.g. time, memory) running time of algorithms varies with inputs and usually grows with the site of inputs we will discuss how to measure complexity 复杂度理论 研究解决问题的成本 成本 = 资源（例如时间，内存） 算法的运行时间随着输入而变化，通常随着输入的增大而增长 我们将讨论如何衡量复杂度 ModllingProblem -&gt; (Model) -&gt; Mathematica Frame -&gt; (Algorithm) -&gt; Solution 问题 -&gt; (模型) -&gt; 数学框架 -&gt; (算法) -&gt; 解决方案 Tools of modelling sets function number systems, coding graphs 集合 函数 数制，编码 图 Graph definitionG=(V,E) where V is finite and not empty set, V = edges, E = vertices G=(V,E) 其中 V 是有限且非空的集合，V = 边，E = 顶点 Graph Representations drawing edge and vertex list adjacency matrix 图形表示法 绘图 边和顶点的列表 邻接矩阵 Examples of graph modelsComplicated intersection traffic lights Translates to graph coloring problem and maximal independent set problem too King Arthur and the knights of the Round TableNoblemen and Noble MaidensTuring Machinesdefinition, construction, properties, transition functions What is a Turing Machine TMS are abstract models for real computers having an infinite memory(in the form of a tape) and a reading head has finite number of internal states has distinguished starting and final states (termination: accept / reject) has transition functions (Tt) (graphs) 图灵机是对真实计算机的抽象模型，它具有无限内存（以磁带的形式）和读写头 具有有限数量的内部状态 具有特殊的起始和终止状态（终止：接受/拒绝） 具有转换函数（Tt）（图） TM accepts the initial content of the tape if it terminates in an acceptingstate. Otherwise TM rejects it. TM terminates, if there is no rule with watching conditionsfor certain state and input symbols. TM is ND (non-deterministic), if such a state and set of input symbolsexist, for which there are multiple rules defined.(= from the same set of starting state and input symbols the TM has multiple outcomes) 如果图灵机终止于接受状态，则它接受磁带的初始内容。否则拒绝。 如果没有匹配的规则，则图灵机终止。 如果存在某个状态和输入符号集，对于该状态和输入符号集，有多个规则，则图灵机是非确定性的（ND）。（=从同一组起始状态和输入符号集，图灵机具有多个结果） NDTM accepts the initial content of the tape if there isa sequence of transition functions that accepts it. Thesis: For All NDTM Exsist equivalent DTM 对于所有的非确定性图灵机，都存在等价的确定性图灵机 Defining a Turing Machine defining the number of tapes &amp; head defining the tape alphabets defining the net of state, initial and terminating states,accepting and rejection terminal states From an already existing machine it is possible to head the followings: number of heads set of states constructed from the states mentioned in the TFS Universal TM: TM, which can simulate All other TM Church - Turing thesis:A function (problem) can be effectively solved &lt;=&gt; it is computable with a TM The same problems can be solved by a TM and modern computers Complexity of algorithmsmeasuring complexity, complexity classes 算法会消耗时间和内存，复杂度就是衡量消耗的指标 时间复杂度时间复杂度主要是循环导致的，我们不必把它想得太复杂下面列出的时间复杂度越来越大，执行的效率越来越低 常数阶 O(1)12let i = 1;i = i + 1; 说白了就是没有循环，即便它有几百万行 对数阶 O(logN)1234let i = 1;while (i &lt; n) { i = i * 2;} 我们可以看到，每次循环都会把 i 乘 2设循环 x 次后，i 大于 n则 2^x &gt; n，即 x &gt; log2(n) 线性阶 O(N)123for (let i = 0; i &lt; n; i++) { console.log(i);} 这个就更好理解了，循环 n 次它的前进速度明显就没有之前乘 2 的那个快了 线性对数阶 O(NlogN)12345for (let i = 1; i &lt; n; i = i * 2) { for (let j = 0; j &lt; n; j++) { console.log(j); }} 名字看的很奇怪，但实际上把 O(logN) 的代码，再循环 N 次那它的时间复杂度就是 n * logn 了 当然你也可以把 O(N) 的代码，再循环 logN 次就像上面的例子一样 平方阶 O(N^2)12345for (let i = 0; i &lt; m; i++) { for (let j = 0; j &lt; n; j++) { console.log(j); }} n * n 不就是 n^2 吗把 O(N) 的代码，再循环 N 次比之前那个还好理解 当然也可以是 m * n那时间复杂度就是 O(MN) 了 其他的还有 K 次方阶 O(N^k) 指数阶 O(2^N)一般是递归算法 O(3^N) etc. 计算T(n) 算法的执行次数T(n) = O(f(n)) 嵌套循环由内向外分析，并相乘 1234567// O(n)for (let i = 0; i &lt; n; i++) { // O(n) for (let j = 0; j &lt; n; j++) { console.log(j); // O(1) }} 时间复杂度为 O(n * n * 1) = O(n^2) 顺序执行你可以把它们的时间复杂度相加在不要求精度的情况下可以直接等于其中最大的时间复杂度 1234567891011// O(n)for (let i = 0; i &lt; n; i++) { console.log(i);}// O(n^2)for (let i = 0; i &lt; n; i++) { for (let j = 0; j &lt; n; j++) { console.log(j); }} 时间复杂度为 O(n + n^2) 或者不要求精度 O(n^2) 条件分支时间复杂度等于所有分支中最大的时间复杂度说人话就是：最麻烦的那个情况 123456789if (n &gt; 10) { // O(n) for (let i = 0; i &lt; n; i++) { console.log(i); }} else { // O(1) console.log(n);} 时间复杂度为 O(n) 空间复杂度很显然，时间复杂度并没有真正计算算法实际的执行时间那么空间复杂度一样也不是真正的占用空间 O(1)12let i = 1;i = i + 1; 代码中的变量所分配的空间，都不随数据量的变化而变化所以空间复杂度为 O(1) O(N)1234let arr = [];for (let i = 0; i &lt; n; i++) { arr.push(i);} 看到数组就表明，空间是随着 n 增大而增大的所以空间复杂度为 O(N) 计算所以说的简单一点 如果 n 增大，程序占用的空间不变，则空间复杂度为 O(1) 如果 n 增大，程序占用的空间成线性增长，那么空间复杂度就是 O(N) 如果 n 增大，程序占用的空间成平方增长，那么空间复杂度就是 O(N^2) 以此类推当然也有 O(N + M), O(logN)等 Sorting algorithms and their complexityselection sort, bubble sort, insertion sort and optimization, their analysis, theorem about maximum complexity case runtime steps 我们按时间复杂度区分，并介绍十大常用的排序算法由于这门课并不教怎么写代码，所以我们只需要了解它是怎么工作的就行了 学计算机不学写代码，行吧，当数学课上 O(N)它们都是非比较算法，不适合大量或大范围数据 计数排序Counting Sort每个桶只存储单一键值O(N + K) 对于给定的输入，统计每个元素出现的次数，然后依次把元素输出 桶排序Bucket Sort 每个桶存储一定范围的数值它需要调用其他的排序算法来完成排序所以它的实际时间复杂度受到其使用的排序算法的影响O(N * K) 基本思路是，把数据分到有限数量的桶里，然后对每个桶内部的数据进行排序最后将各个桶内的数据依次取出，得到结果 让我们看一个例子假设我们有 20 个数据，要分成 5 个桶 12345678910111213141516171819202122232425262728293031323334353637383940function bucketSort(arr: number[], bucketSize: number) { // 创建大小为 bucketSize 的桶数组 const bucket: number[][] = []; // 初始化桶数组 for (let i = 0; i &lt; bucketSize; i++) { bucket[i] = []; } // 获取数组中的最大值和最小值 const max = Math.max(...arr); // 194 const min = Math.min(...arr); // 13 // 计算桶的范围 // (194 - 13 + 1) / 5 = 36.4 const range = (max - min + 1) / bucketSize; // 将数据放入对应的桶中 for (let i = 0; i &lt; arr.length; i++) { // 计算数据应该放入的桶的索引 // 比如 63：floor(63 - 13) / 36.4) = 1 const index = Math.floor((arr[i] - min) / range); bucket[index].push(arr[i]); } // 使用其他算法，对桶内的数据进行排序 for (let i = 0; i &lt; bucketSize; i++) { bucket[i].sort((a, b) =&gt; a - b); } // 将桶内排好序的数据依次取出，得到有序序列 const result: number[] = []; for (let i = 0; i &lt; bucketSize; i++) { for (let j = 0; j &lt; bucketSize; j++) { result.push(bucket[i][j]); } } return result;} 基数排序Radix Sort根据键值的每位数字来分配桶O(d(n+r))，其中 d 是基数，n 是要排序的数据个数，r 是每个关键字的基数 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零然后，从最低位开始，依次进行一次排序这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列 O(NlogN)希尔排序Shell Sort，也称递减增量排序是插入排序的一种更高效的改进版本，它会优先比较距离较远的元素 先将整个序列，分割成若干个子序列，分别进行插入排序待整个序列基本有序时，再对整体进行插入排序 我们有 [7, 6, 9, 3, 1, 5, 2, 4] 需要排序首先我们确定增量为 4，每次缩小一半 所以我们有 4 个子序列 1234[7, 1];[6, 5];[9, 2];[3, 4]; 分别排序它们 1234[1, 7];[5, 6];[2, 9];[3, 4]; 得到 1[1, 5, 2, 3, 7, 6, 9, 4]; 然后缩小增量为 2，再次分割 12[1, 2, 7, 9];[5, 3, 6, 4]; 排序得到 1[1, 2, 3, 4, 5, 6, 7, 9]; 归并排序Merge Sort，是一种分治算法将两个或两个以上的有序表合并成一个新的有序表 把长度为 n 的序列分成两个长度为 n/2 的子序列 对这两个子序列分别采用归并排序（递归） 将两个排序好的子序列合并成一个最终的排序序列 快速排序Quick Sort应该算是在冒泡排序基础上的递归分治法 随便选择一个元素 将比这个元素小的放在左边，比这个元素大的放在右边 对左右两边的元素重复第二步，直到各区间只有一个元素 堆排序Heap Sort 构建一个大顶堆，此时，整个序列的最大值就是堆顶的根节点 将其与末尾元素进行交换，此时末尾就为最大值 然后将剩余的 n-1 个元素重新构建成一个堆，这样会得到 n 个元素的次小值 如此反复执行，便能得到一个有序序列了 O(N^2)冒泡排序Bubble Sort比较相邻的元素，如果第一个比第二个大，就交换他们两个，一直向上冒泡 选择排序Selection Sort也就是每次找到最小的元素，放到前面，重复 优化可以在找到最小元素时记录下它的位置，并在最后交换元素的时候使用该位置。这样可以避免每次都将最小元素与已排序序列的最后一个元素交换，减少了不必要的操作 例如，对于序列[5, 3, 8, 1, 9]，优化的过程如下： 第一次遍历，找到最小元素 1，然后将 1 与 5 交换[1, 3, 8, 5, 9] 第三次遍历，在剩下的序列 [5, 8, 9] 中找到最小的元素 5，然后将 5 与 8 交换[1, 3, 5, 8, 9] 插入排序Insertion Sort像打扑克时整理手牌一样，将每张牌插入到合适的位置 Basic graph algorithmsgraph searches (BFS, DFS, Dijsktra), tree traversals, longest path problems 深度优先搜索 广度优先搜索 遍历前序遍历：根结点 —&gt; 左子树 —&gt; 右子树是从最上层往下走 中序遍历：左子树 —&gt; 根结点 —&gt; 右子树是从最左边往右走 后序遍历：左子树 —&gt; 右子树 —&gt; 根结点是从最下层往上走 层次遍历：只需按层遍历即可 Dijsktra123456789 5A ----- B| || |4 6| || |C ----- D 5 首先，我们将 A 设为原点，并初始化每个顶点到原点的距离为无穷大 1234567891011121314/** * 每个顶点到原点的距离 */let dist: Record&lt;string, number&gt; = { A: 0, B: Infinity, C: Infinity, D: Infinity,};/** * 获取两个顶点之间的权重 */declare function weight(node1: string, node2: string): number; 接下来，我们要不断迭代更新每个顶点到原点的最短距离，直到所有顶点的最短距离，都被更新为最终值。 在每次迭代中，我们首先找到所有未被更新的顶点中，距离原点最近的顶点，然后更新它到原点的最短距离，并根据新的距离，更新其他顶点，到原点的距离。 从 A 向外扩散 1234dist.B = Math.min(dist.B, dist.A + weight(&quot;A&quot;, &quot;B&quot;)) = Math.min(Infinity, 0 + 5) = 5; 1234dist.C = Math.min(dist.C, dist.A + weight(&quot;A&quot;, &quot;C&quot;)) = Math.min(Infinity, 0 + 4) = 4; 从 B 向外扩散 1234dist.D = Math.min(dist.D, dist.B + weight(&quot;B&quot;, &quot;D&quot;)) = Math.min(Infinity, 5 + 6) = 11; 从 C 向外扩散 1dist.D = Math.min(dist.D, dist.C + weight(&quot;C&quot;, &quot;D&quot;)) = Math.min(11, 4 + 5) = 9; 得到结果 123456dist = { A: 0, B: 5, C: 4, D: 9,}; 所以，从 A 到 D 的最短距离为 9 Graph diagnosticsGraph diagnostic problems are graph problems that can be answered with Y/N. Connectivity A graph G is connected, if for any two nodes there exists a walk between them. 连通性是指图中任意两个顶点之间是否存在一条路径，使得两个顶点可以互相到达。如果一个图中的任意两个顶点都可以互相到达，那么这个图就被称为连通图。 要判断一个图是否连通，可以使用搜索算法，如广度优先搜索或深度优先搜索。搜索时，从图中的任意一个顶点开始，并尝试访问该顶点的所有邻接点。如果能够访问到图中所有的顶点，那么这个图就是连通图。 Absolute winner绝对赢家指的是一个结点，它在一个博弈论游戏中总是能够获胜。这意味着，不论对手采取什么策略，该结点都有某种优势，使它能够获胜。例如，如果一个结点具有更多的邻居，那么它就可能是一个绝对赢家，因为它可以通过与其他结点交换信息来获得更多的有利条件。 绝对赢家与相对赢家有所不同。相对赢家指的是在某些情况下，某个结点比其他结点更有优势，从而使它有可能获胜。但是，如果对手采取了特定的策略，那么这个结点可能就不再是赢家了。而绝对赢家则不存在这种情况，它总是能够获能，不管对手采取什么策略。 Complete node, logical formulas完全节点是指，这个节点与其他任何节点都至少存在一条边 至于 logical formulas，指的是 FDNF disjunctive normal form它与 DNF 不同点似乎是每个出现的变量都会出现在每个子句中 Graph coloringVertex顶点着色的规则是，任意两个相邻的顶点不能有相同的颜色。并且我们使用尽可能少的颜色来着色。 我们从图中的一个顶点开始，为它分配一种颜色。然后，我们按照顶点的顺序遍历图中的其他顶点，为每个顶点分配一种与相邻顶点不同的颜色 Brooks theorem描述了图的着色数与图中最大度数的关系，提供了图着色数的一个上界 如果一个无向图 G 满足以下条件，那么它可以用 Δ(G) 或更少的颜色染色： G 是一个连通图（即它不包含任何脱离的部分） G 不包含任何奇环（即它不包含任何长度为奇数的环） Δ(G) 指的是图 G 中最大的度数。 Degree度数指的是一个顶点与其相邻顶点之间的边的数量度数可以用来衡量一个顶点与其他顶点的连通性。通常情况下，一个顶点的度数越大，它与其他顶点的连通性就越强 Four color theorem如果一个平面图 G 不包含任何环，那么它可以用不超过 4 种颜色染色，使得相邻的两个区域拥有不同的颜色。 Subgraph在原图中选择一些节点和边，并从原图中删除其他的节点和边。这样得到的图就是原图的一个子图。如果一个节点的度数为 2，那么我们可以删除该节点，并将它与其他两个节点之间的两条边”合并”成一条边。 Edge给图中的边分配颜色，使得图中相邻的边拥有不同的颜色 Chromatic index 是图的最小着色度，指需要多少种不同的颜色 Vising theorem 指 对于任意一个无向图，它的染色度（chromatic number）不会超过其度数（degree）的上限 Bipartite graphs 是一种二分图，它由两个部分组成，每个部分内部的点互不相邻，而两个部分之间的点才会相互相邻。 Planar graphs 则是一种平面图，它是指图中任意两条边都不会相交，也就是说，图中的边可以在平面上放置而不会交叉。 Scheduling problems 例如，在一个工厂生产线上，有许多不同的机器和工人，他们需要按照特定的顺序来完成各种任务。为了让生产流程顺利进行，我们可以使用 edge coloring 算法来给每个任务分配一种颜色，并确保相邻的任务颜色不同。这样，工人和机器就可以按照颜色顺序来执行任务，从而保证生产流程的顺利进行。 Packing and CoveringGeneralizationGeneral, “everyday” problems, which have suboptimal solutions: Put in objects into one container!Some pairs are incompatible, those cannot be put into the container together.Question: how to put the maximal number of objects into the container? n people at a meeting.Find the largest subgroup of them, in which everybody knows everybody! Trucker delivering goods with no going backQuestion: how can they deliver the maximum number of goods? Big piece of leather, cutting out small shapes.Question: how to cut out the largest amount of smaller shapes? Common property of these problems: representable with a graph similarly.Is there any connection between their solutions? Let’s look at the problems solutions, starting with the “easiest”: 一般来说，“日常” 问题，它们有着次优解： 把物品放入一个容器中有些物品是不兼容的，它们不能放在同一个容器中问题：如何把最多的物品放入容器中？ n 个人在会议中找到其中最大的一个子集，其中每个人都认识 卡车司机送货，不允许回头 大块皮革，切割成小块。问题：如何切割出最多的小块？ 这些问题的共同特点：它们可以用图来表示 Disjoint Interval Search Trucker delivering goods with no going backQuestion: how can they deliver the maximum number of goods? Disjoint Interval Search (DIS)This problem is also called interval packing. 绎演丁真，鉴定为史 如果一个卡车司机要把货物送到多个不同的地方，而且一旦离开一个地方就不能再回去，那么他应该怎样才能把尽可能多的货物送到目的地呢？ 我寻思着这问题应该用 TSP 来解才对总之先看看什么是 DIS DIS 是一种用于处理区间数据的算法。区间数据是指一组由起始和结束点表示的区间，例如：[1, 5]、[10, 15] 等。它能够快速检索出与给定的区间不相交的区间。 将区间数据存储在能够快速查找和插入的数据结构中，例如红黑树、平衡树或 B 树 查找与给定区间不相交的区间检查区间数据中的每一个区间，并判断它们是否与给定区间不相交如果一个区间与给定区间不相交，则将其加入结果集。 返回结果集 Cliquen people at a meeting.Find the largest subgroup of them, in which everybody knows everybody! Can we find three people like that?Can we find four people like that?Can we find five people like that? Why not?Clique search 衣掩丁真，鉴定为衣驼使 这是一个分团问题Clique search 是一种用于寻找图中的完全子图（即“clique”）的算法完全子图是指一个子图中所有节点都相互连通算法需要枚举所有可能的完全子图，并确定哪些子图满足给定的条件 Maximal Independent SetPut in objects into one container!Some pairs are incompatible, those cannot be put into the container together.Question: how to put the maximal number of objects into the container? Edges code incompatibility.We are searching for independent node subsets.Maximal Independent Set (MIS) We found a maximal empty subgraph. Connection with the previous problem?If we create the complimenting graph from this (where we had an edge, now we don’t have one, and vice versa), and consider the same chosen nodes, then that is a clique. So we can convert this problem into the previous one: MIS → Clique search These problems are basically the same, only their representation is different. In this sense, even problem no.3 is the same as no.1 and no.2. Converting problem no. 3 to the present form: Intervals are going to turn into vertices of a graph.If two intervals are incompatible, we draw an edge between the corresponding nodes. We converted DIS into MIS. Maximal Independent Set 是指一个图中没有一个节点与其他节点相邻，并且该集合不能再增加任何节点而保持这种性质的节点集合 一个独立集（也称为稳定集）是一个图中一些两两不相邻的顶点所形成的集合，如果两个点没有公共边，那么这两个点可以被放到一个独立集中 对于三个点组成的完全图而言，每个点自身是一个独立集（且是最大独立集）对四个点构成的四边形图而言，对角的两个点组成一个独立集（且是最大独立集） 如果往图 G 的独立集 S 中添加任一个顶点都会使独立性丧失（亦即造成某两点间有边），那么称 S 是极大独立集。 如果 S 是图中所有独立集之中基数最大的，那么称 S 是最大独立集，且将该基数称为 G 的独立数，记为 α(G)。一般来讲，图 G 中可能存在多个极大独立集和最大独立集。 根据定义，最大独立集一定是极大独立集，但反之未必。 CutBig piece of leather, cutting out small shapes.Question: how to cut out the largest amount of smaller shapes? 大块的皮革，切出小的形状。问：如何切出最多的小形状？ We can rotate the sample, but we still have to fit into the big piece of leather. 我们可以旋转样本，但我们仍然要贴合大块皮革。 This is the most difficult problem out of the four, because the main “philosophical” difference between them is that the first three were obvious finite problems (finite number of people, objects, intervals), whereas this problem cannot produce obvious finite number of nodes. 这是四个问题中最困难的一个，因为它们之间的主要“哲学”区别在于前三个是显然的有限问题（人数、物品数、区间数都是有限的），而这个问题不能产生显然的有限节点数。 So we make a grid on the big leather, place a node on the shape, and say that the shape can only be cut out of that node fits on one of the grid points. 因此，我们在大皮革上做一个网格，在形状上放一个节点，并说形状只能在该节点适合网格点之一时被切出来。 The grid points create a finite set. But since we can still rotate the shape around the grid point, our choices are infinite again. Solution: we only consider a few angles. So now we can only cut out the shape if the node is ou a grid point, and the line on the sample can only parallel to one of our predefined angle lines. 网格点创建了一个有限集。但是，由于我们仍然可以围绕网格点旋转形状，所以我们的选择又是无限的。解决方案：我们只考虑几个角度。因此，现在我们只能在节点在网格点上并且样本上的线只能与我们预定义的角度线平行时切出形状。 So to make an infinite problem finite we need to add restrictions. 因此，要使无限问题变为有限，我们需要增加限制。 We can code the placement with the number of the grid point and the number of the angle.Eg: (5; 6) and (14; 6). 我们可以用网格点的编号和角度的编号来编码放置位置。例如：（5；6）和（14；6）。 However, these two overlap, so they cannot be cut out together. This incompatibility can be represented in a graph by adding an edge between these two number pains. 然而，这两个重叠了，因此它们不能一起切出来。这种不兼容可以通过在这两个数字之间添加一条边来表示在图中。 This way we can create a graph, and the maximum number of cutouts on the leather is reduced to finding the maximal number of independent nodes in the corresponding graph. 这样我们就可以创建一个图，皮革上的最大切割次数就被减少到在相应图中找到最大的独立节点数。 What is the problem with this method?The restrictions can cause a result with less cutouts, than if we could freely place the shape. 这种方法有什么问题？限制可能导致切割次数比我们可以自由放置形状时少的结果。 Solution: let’s use a denser grid and consider none rotational angles! 解决方案：让我们使用更密集的网格并考虑非旋转角度！ Problem with the solution: as we have more gridpoints and angles, the graph becomes larger, so finding the MI5 is more complicated. 解决方案的问题：随着我们有更多的网格点和角度，图变得更大，因此找到 MI5 变得更复杂。 So this method is a digitalization, which has a resolution. The bigger the resolution is, the closer to the optimal solution we are. 因此，这种方法是一种数字化，它具有分辨率。分辨率越大，我们越接近最优解。 总结Ater examining these four problems, we have a general framework: 在经过对这四个问题的检查后，我们得出了一个总体框架： Given is a graph. Find the maximal number of nodes such that those are never connected to each other. &lt;=&gt; We want to find the maximal independent set of nodes. → MIS problem. 给定一张图。找到一个节点的最大数量，这些节点从不相互连接。&lt;=&gt;我们想找到节点的最大独立集合。→MIS 问题。 This can be solved in exponential time. 这可以在指数时间内解决。 The trivial algorithm for finding MIS: 找到 MIS 的简单算法： We want to find MIS of { 1, 2, 3, 4, 5, 6 }. We try to find an independent subset of size 2. Start with 41,2}. Is this independent? No! So try { 1, 3 }. This is good! But then can we find an independent subset of nite 3? We need to check all site 3 subsets. 我们想找到 {1,2,3,4,5,6} 的 MIS。我们试图找到大小为 2 的独立子集。从 {1,2} 开始。这是独立的吗？不是！所以尝试 {1,3}。这很好！但是然后我们能找到大小为 3 的独立子集吗？我们需要检查所有大小为 3 的子集。 In the worst case we need to investigate all subsets of { 1, 2, 3, 4, 5, 6 } 在最坏的情况下，我们需要调查 {1,2,3,4,5,6} 的所有子集 Theorem: If |x| = n, then |p(x)| = 2^n. (p(x) = { y | y &lt;= x } -&gt; power set = set of all subsets) In our example n = 6, so we have 2^6 = 64 subsets. How to code subsets? { 1, 2, 3, 4, 5, 6 } 1 0 1 0 0 0 1 1 0 0 0 1 -&gt; this will code { 1; 3 }-&gt; this will code { 1; 2; 6 } Since it is a one-to-one correspondence between subsets and outshines,then |p(x)| = |{ binary string of length 8 }| 因为子集和出现之间是一一对应的，所以 |p(x)| = |{长度为 8 的二进制字符串}| because a choice codes 1 On 0 = yes or no 因为选择编码 1 On 0 = yes or no In terms of our MIS - finding problem: if we count checking a binary string for independence, then this trivial algorithm has an exponential runtime, exactly 2^n. 就我们的 MIS 查找问题而言：如果我们算出检查一个二进制字符串是否独立的次数，那么这个简单算法的运行时间是指数级别的，精确地说是 2^n。 A more refined algorithm for the same problem:Find a method, where we only check already independent sets. 同一问题的一种更优秀的算法：找到一种方法，只检查已经独立的集合。 Example: The independent set is called S.We always ask the nodes whether they are an element of S. → “yes” branches and “no” branches. Next question is based on already existing elements. 独立集合称为 S。我们总是问节点是否是 S 的元素。→“是”和“否”分支。下一个问题是基于已存在的元素。 This is a labelled and rooted binary thee.Can be done faster, if we are only considering paths that have a chance to have enough nodes on them.“if it’s not there, don’t even look” 这是一棵带标签和根的二叉树。如果我们只考虑可能有足够节点的路径，可以更快地完成。“如果它不在那里，甚至都不用看”。 Interval packing, dominating setsA little help for the next algorithm: the Pidgeon-hole principle. 下一算法的一点帮助：鸽巢原理。 Question: when the pigeons go to their pigeon-holes, what can we state for sure?Whichever houses they choose, there is going to be at least one hole with two pigeons in it. 问题：当鸽子去它们的鸽巢时，我们能肯定什么？无论它们选择哪所房子，至少会有一个洞有两只鸽子。 So the pigeon-hole principle says that if there are more pigeons than houses, then there will be at least one hole with at least two pigeons in it. 因此，鸽巢原理说，如果有比房子更多的鸽子，那么至少会有一个洞至少有两只鸽子。 If this weren’t true, and all houses tould contain one pigeon at worst, then there would be only as many pigeons as houses. Whereas we had more pigeons. 如果这不是真的，并且所有的房子里最多只有一只鸽子，那么只会有和房子一样多的鸽子。但我们有更多的鸽子。 If we use our previous example 3, we can apply the pigeon-hole principle to the problem: 如果我们用之前的例子 3，我们可以将鸽巢原理应用于问题： The algorithm: choose closest destination, if starting point is still ahead=&gt; maximal number of =&gt; independent intervals =&gt; Interval packing algorithm 算法：如果起点仍然在前面，则选择最近的目的地=&gt;最大数量的=&gt;独立区间=&gt;区间打包算法 If we only consider the destinations as pink dots, then we can choose any interval, there will always be a pink dot on it - at least one dot.=&gt; the set of pink dots is a dominating set. 如果我们只考虑目的地作为粉红色点，那么我们可以选择任何区间，它上面总会有一个粉点——至少有一个点。=&gt;粉点集是一个支配集。 A set X is a dominating set, if for every you find at least one element of the set on that interval. 一个集合 X 是支配集，如果对于每个区间都能找到集合中的至少一个元素。 Femina: X is a dominating set, 4 is an independent set of intervals.Then |x| &gt;= |y|. X 是支配集，4 是区间的独立集。 The chosen intervals corresponding to the transportation is an independent set with three intervals. There are also three pink dots as the dominant set. So based on the lemma, there can be no more independent intervals. 选择的区间对应于运输是具有三个区间的独立集。还有三个粉红色的点作为支配集。因此，根据引理，不能有更多的独立区间。 Proof: Indirectly. New statement: |x|birds &lt; |y|houses. Let’s have one more independent interval. But according to the pigeon-hole principle, there is at least one pint dominating dot on every interval. In order to dominate the all intervals, we would need at 1 different pink dots. 让我们再来一个独立区间。但根据鸽巢原理，每个区间都至少有一个主要点。为了控制所有区间，我们需要至少 1 个不同的粉点。 =&gt; There must be at least two intervals with the same pink dot,but then they’re not independent. =&gt; 必须有至少两个区间有相同的粉点，但这样它们就不是独立的了。 Even though there is no general quick (polynomial) solution forfinding MIS, the Interval pairing algorithm is fast. How fast? 尽管没有求解 MIS 的通用快速（多项式）解决方案，但 Interval pairing 算法是快速的。它有多快？ We shone all starting and destination point somehow - e.g. by numbers.So we only have to order them, and find the “smallest” endpoint first. 我们用某种方式给所有起点和终点标号——例如，用数字。所以我们只需要按顺序排序，找到“最小”的终点。 ~n steps needed to find the closest destinationwe need to repeat it at worst a times =&gt; polynomial algorithm 找到最近目的地需要 ~n 步最坏情况下，我们需要重复 a 次，所以这是一个多项式算法 How can it be that MI5 can’t be solved quickly, but this algorithm has quadratic runtime?! 为什么 MI5 无法快速解决，但这个算法的运行时间是二次的呢？ The intervals are represented as nodes and overlaps as edges in the graph.So did we just solve MI5 in quadratic time?! 区间在图中表示为节点，重叠部分表示为边。所以我们刚刚在二次时间内解决了 MI5 吗？ No! Because not all graphs can be processed by this method. (Not all graphs with a nodes occur this way.) so we only solved MI5 for a subset of graphs having a nodes. 不是的！因为并不是所有图都可以用这种方法处理。（不是所有带有 n 个节点的图都是这样出现的。）所以我们只为一个带有 n 个节点的图子集解决了 MI5。 So for a subset of cases we have a solution, but not for the general case.(e.g. 5th degree polynomials) 所以对于一个子集的情况，我们有一个解决方案，但不是通用情况。（例如，五次多项式） 区间打包，用于找到最多可以放在一个容器内的不相交区间的最大数量。是指把一系列区间尽可能多地放到一个集合中，使得它们都不重叠。 支配集指在一张图中，存在一组节点，每个节点都与它相邻的节点相连，或者至少有一个节点在该组中。其中的元素可以覆盖整个集合，即每个元素都与至少一个其他元素有交集。 Suboptimal algorithms次优算法 what is the basic problem?→ polynomial algorithms are “quick”→ exponential algorithms are “very slow” 基本问题是什么？→ 多项式算法“快”→ 指数算法“非常慢” There is a set of problems for which there is no quick algorithm. 有一类问题没有快速算法。 Their runtime is proportionate to f(a) =2^n. To put this in perspective, there are no more than 2^350 atoms in the whole universe. 它们的运行时间与 f(a) = 2^n 成比例。为了更好地理解这一点，整个宇宙中没有超过 2^350 种原子。 Therefore we can just use this disadvantage to our advantage by using these kind of problems for coding protocols, as decoding them would tale over a million years. 因此，我们可以利用这个缺点，通过使用这类问题来编写编码协议，因为解码它们需要超过一百万年。 Good example for this is finding a Hamiltonian cycle in a graph. Creating is easy, but then we can obfuscate it. 寻找图中的汉密尔顿回路是一个很好的例子。创建容易，但是我们可以混淆它。 Problem is, that there are a lot of real-life situations that can only be converted into these kinds of problems, where the solution is exponential, or even worse. 问题是，有很多现实生活中的情况只能转换为这类问题，其解是指数级的，甚至更糟。 Good example is the traveling agent problem. This is understood on weighed graphs, and the point is to touch all the nodes with a minimal sum of edge weights. (Hamiltonian path problem). 一个很好的例子是旅行代理问题。这在加权图上是可以理解的，其目的是以最小的边权和触摸所有节点。（汉密尔顿路径问题） In this case we can imagine a package delivery service, in which case we need the shortest possible combination / permutation of the packages in order to make the least amount of kilometers. Though, this is a hard problem, meaning, there exists not a quick algorithm for this. 在这种情况下，我们可以想象一个包裹配送服务，在这种情况下，我们需要包裹的最短可能组合/排列，以便减少尽可能多的公里数。尽管这是一个难题，即不存在一个快速的算法来解决这个问题。 =&gt; suboptimal algorithms-&gt; We don’t want to (= can’t) find the best solution, but something that is pretty close this best solution. =&gt; 次优算法-&gt; 我们不想（也不能）找到最优解，而是找到一个非常接近最优解的解决方案。 So in case of the traveling agent, we don’t want to find the optimal route, but we want a route such that it is sure that it uses at more Klia as many kilometers as the optimal one. It would be a 2-optimal algorithm. 所以在旅行代理的情况下，我们不想找到最优路线，而是想找到一条路线，使得它确保它使用的公里数至少与最优路线相同。这将是一个 2-optimal 算法。 So the suboptimality of algorithms has nothing to do with running time. 因此，算法的次优性与运行时间无关。 In the traveling agent situation a 3-optimal algorithm would find a solution that is at most three times worse than the optimal one, meaning, it would find a permutation of the target adnesses such that if the driver follows that order, than at most three times as many kilometers are used as in case of the optimal solution. 在旅行代理的情况下，3-optimal 算法将找到一个至多比最优解差三倍的解决方案，这意味着它会找到目标地址的一个排列，如果司机遵循这种顺序，那么至多会使用三倍于最优解情况下的公里数。 An algorithm is called k-optimal (k ≥ 1) if its output is at most b-times worse than the best output would be. 如果其输出最多比最佳输出差 b 倍，则称该算法为 k-optimal（k ≥ 1）。 Bin packing problem Objects with volumes:V1, V2, V3 … Vn. Vi &lt;= (i = 1, …, n) Problem: use the least amount of containers to store all objects. 问题：使用最少的容器来存储所有物品。 (The sum of the volumes of objects in one container can’t exceed volume of the container.) （一个容器中物品的总体积不能超过容器的体积。） This is a hard problem. But there exists a 2-optimal algorithm for that. 这是一个难题。但是存在一个 2-optimal 算法。 First Fit Algorithm: Choose the first container in which the object fits. (This is greedy.) 首次适应算法：选择第一个容器，其中的物品适合。（这是贪婪的。） 降序首次适应算法First Fit Decreasing 将物品按照价值从大到小排序 找到一个能放下物品的背包，放入物品 重复 2，直到所有物品都放入 简而言之，FFD 按照大小降序排列项目，然后放入第一合适的背包 Algebraic algorithmsDivisibility, Euclidean algorithmFaster multiplication and division of large numbers","link":"/Algorithm/Basics-of-Computer-Science/"},{"title":"DAA Endterm","text":"交张白卷上去，不愧是我 网格最大成本寻路Suppose that you are given a $n \\times n$ checkerboard and a checker. You must move the checker from the bottom edge of the board to the top edge of the board according to the following rules. At each step you may move the checker to one of three squares: the square immediately above the current square. the square that is one up and one to the left. (but only if the checker is not already in the leftmost column) the square that is one up and one to the right. (but only if the checker is not already in the rightmost column) Each time you move from square $x$ to square $y$, you receive $f(x, y)$ dollars. You are given $f(x, y)$ for all pairs $(x, y)$ for which a move from x to y is legal. Give an $O(n^2)$ dynamic programming algorithm that figures out the set of moves that will move the checker from somewhere along the bottom edge to somewhere along the top edge while gathering as many dollars as possible. Your algorithm is free to pick any square along the top edge as a destination in order to maximize the number of dollars gathered along the way. 解https://github.com/juemura/amli/blob/master/Checkerboard.ipynb 这题说白了就是让你计算一个矩阵，每次只能往上临近的地方走一格，每走一次有一个 f 方程给你计算收益，让你求出最大收益的路径。 这道题没有给出 f 的定义，所以我们自己定个规则：随机给每个格子填一个值，这个值可大可小，可正可负，走到格子上就把格子的值加到最终收益上。 1234567891011121314import { random } from &quot;lodash&quot;;function makeMatrix(dim: number) { const matrix: number[][] = []; for (let i = 0; i &lt; dim; i++) { matrix.push([]); for (let j = 0; j &lt; dim; j++) { matrix[i].push(random(-100, 100)); } } return matrix;} 打印矩阵的代码 123456789101112131415161718192021function printMatrix(matrix: number[][]) { let res = &quot;|X\\\\Y|&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += i + &quot;|&quot;; } res += &quot;\\n|---|&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += &quot;---|&quot;; } res += &quot;\\n&quot;; for (let i = 0; i &lt; matrix.length; i++) { res += `|**${i}**|${matrix[i].join(&quot;|&quot;)}|`; res += &quot;\\n&quot;; } console.log(res);} 随后，我们得到矩阵 X\\Y 0 1 2 3 4 0 -60 51 -24 -4 -66 1 45 12 76 -41 -22 2 -50 19 -79 47 96 3 -74 -12 98 54 1 4 -66 16 91 -87 -20 接下来要做的事情就很明显了：计算局部最优的转移过程的累加收益（说的玄乎，看代码马上就懂了，也就是每次转移都找收益最大的那个来源） 要注意，正向转移是不可能计算的，所以我们每次计算的都是从哪里来的，而不是去哪里。 123456789101112131415161718192021222324252627282930313233343536373839function calcDifference(matrix: number[][]) { const n = matrix.length; // 用来存储每个格子的最大值 const aggregate: number[][] = Array.from({ length: n }, () =&gt; Array(n).fill(0) ); // 用 matrix 填充第一行，因为没有格子可以从上方移动来 for (let col = 0; col &lt; n; col++) { aggregate[0][col] = matrix[0][col]; } // 从第二行开始填充 maxDiff for (let row = 1; row &lt; n; row++) { // 遍历当前行的每一个格子 for (let col = 0; col &lt; n; col++) { let fromLeft = -Infinity; let fromTop = -Infinity; let fromRight = -Infinity; // 如果当前格子不在第一列，那么可以从左上移动来 if (col &gt; 0) { fromLeft = aggregate[row - 1][col - 1] + matrix[row][col]; } // 从正上方移动来 fromTop = aggregate[row - 1][col] + matrix[row][col]; // 如果当前格子不在最后一列，那么可以从右上移动来 if (col &lt; n - 1) { fromRight = aggregate[row - 1][col + 1] + matrix[row][col]; } // 计算当前格子的最大值 aggregate[row][col] = Math.max(fromLeft, fromTop, fromRight); } } return aggregate;} 我们得到 X\\Y 0 1 2 3 4 0 -60 51 -24 -4 -66 1 96 63 127 -45 -26 2 46 146 48 174 70 3 72 134 272 228 175 4 68 288 363 185 208 接下来我们追踪最大值的路径，这里我们只需要找到最后一行的最大值，然后从这个最大值开始往上找，将 DP 值最大的一个作为路径的下一个点，直到找到第一行。 123456789101112131415161718192021222324252627282930313233343536373839404142function traceBack(aggregate: number[][]) { const n = aggregate.length; const path: [number, number][] = []; let stopIndex = 0; aggregate[n - 1].forEach((val, index) =&gt; { if (val &gt; aggregate[n - 1][stopIndex]) { stopIndex = index; } }); path.push([n - 1, stopIndex]); let currentCol = stopIndex; for (let row = n - 2; row &gt;= 0; row--) { let fromLeft = -Infinity; let fromTop = -Infinity; let fromRight = -Infinity; if (currentCol &gt; 0) { fromLeft = aggregate[row][currentCol - 1]; } fromTop = aggregate[row][currentCol]; if (currentCol &lt; n - 1) { fromRight = aggregate[row][currentCol + 1]; } if (fromLeft &gt; fromTop &amp;&amp; fromLeft &gt; fromRight) { currentCol -= 1; } else if (fromRight &gt; fromTop &amp;&amp; fromRight &gt; fromLeft) { currentCol += 1; } path.push([row, currentCol]); } return path;} 我们得到路径 Path (X, Y) 4 2 3 2 2 3 1 2 0 1 最优参数Give the dynamic programming solution to the optimal parameterization problem for them matrix product $A_1, A_2, A_3, A_4, A_5$ where the dimensions of $A_3$ are $4 \\times 2$, the dimensions of $A_4$ are $2 \\times 5$, and the dimensions of $A_5$ are $5 \\times 3$. Show all calculations. 解子序列Run the dynamic programming algorithm to the longest common subsequence problem of sequences $(a, b, b, d, c, d, b, a)$ and $(a, b, d, c, a, b, c, d, a)$. 解背包问题Run the dynamic programming algorithm to the knapsack problem for items: i 1 2 3 4 5 6 7 $w_i$ 2 2 5 4 1 3 1 $v_i$ 10 50 40 80 70 10 20 and knapsack capacity 11. 解最大收益Suppose you are managing a consulting team of expert computer hackers, and each week you have to choose a job for them to undertake. Now, as you can well imagine, the set of possible jobs is divided into those that are low-stress, and those that are high-stress. The basic question, each week, is whether to take on a low-stress job or a high-stress job. If you select a low-stress job for your team in week $i$, then you get a revenue of $l_i &gt; 0$ dollars. If you select a high-stress job, you get a revenue of $h_i &gt; 0$ dollars. The catch, however, is that in order for the team to take on a high-stress job in week $i$, it’s required that they do no job in week $i - 1$. On the other hand, it’s OK for the team to take a low-stress job in week $i$ even if they have done a job in week $i - 1$. So, given a sequence of $n$ weeks, a plan is specified by a choice of low, high, none for each of the $n$ weeks, which the property that if high is chosen for week $i &gt; 1$, the none has to be chose for week $i - 1$. (1st week can be high) The value of the plan is determined in the natural way: for each $i$ you add $(h/l/n)_i$ to the value of you chose high in week $i$. Give an efficient dynamic programming algorithm that take values for $l_1, l_2 \\cdots l_n$ and $h_1, h_2 \\cdots h_n$ and returns a plan of maximum value. Also give the running time of your algorithm. 解","link":"/Algorithm/DAA-Endterm/"},{"title":"DAA Midterm Exam","text":"The Midterm Exam for Design and Analysis of Algorithms直接一套连招被送走，我真的是命苦 Gale-Shapley Boys b1 g2 g4 g3 g1 g5 b2 g3 g2 g1 g5 g4 b3 g2 g1 g3 g5 g3 b4 g4 g3 g4 g1 g2 b5 g2 g4 g3 g1 g5 Girl g1 b2 b5 b1 b3 b4 g2 b2 b3 b1 b4 b5 g3 b4 b2 b5 b1 b3 g4 b3 b1 b5 b2 b4 g5 b5 b3 b4 b1 b2 Solution Day g1 g2 g3 g4 g5 1 - b1, b3, b5 b2 b4 - 2 - b3 b2 b4, b1, b5 - 3 - b3 b2, b4, b5 b1 - 4 b5 b3, b2 b4 b1 - 5 b5, b3 b2 b4 b1 - 6,7 b5 b2 b4 b1 b3 (g1, b5), (g2, b2), (g3, b4), (g4, b1), (g5, b3) Stable MarriageIf it is true, give a short explanation. Otherwise, give a counterexample. ExistenceIn every instance of the Stable Marriage Problem, there is a suitable matching containing a pair $(b, g)$ such that $b$ is ranked first on the preference list of $g$ and $g$ is ranked first on the preference list of $b$. SolutionFalse, consider the following case: Boys b1 g1 g2 b2 g1 g2 Girl g1 b2 b1 g2 b1 b2 (b1, g2), (b2, g1) is the only stable matching. b2 and g1 are both first on each other’s preference list.But we cannot find a pair where b1 and b2 are each other’s first preference.So it’s not true for every instance. BelongingConsider an instance of the Stable Marriage Problem in which there exists a boy $b$ and a girl $g$ such that $b$ is ranked first on the preference list of $g$ and $g$ is ranked first on the preference list of $b$. Then every stable marriage $M$ for this instance, the pair $(b, g)$ belongs to $M$. SolutionTrue. If $b$ and $g$ rank each other first, then any pairing where they are not matched would be unstable. Because if either $b$ or $g$ where matched with someone else, they would both prefer to be matched with each other, leading to an unstable pairing. So, in any stable pairing $M$, $b$ and $g$ must be matched. Master Method$T(n) = 4T(n/2) + n$$a = 4, b = 2, f(n) = n, n^{\\log_{b} a} = n^2$ $T(n) = 6T(n/3) + n^2$$a = 6, b = 3, f(n) = n^2, n^{\\log_{b} a} = n^{\\log_{3} 6} \\approx n^{1.63} &lt; n^2$ $af(n/b) = 6(n/3)^2 = \\frac{2}{3}n^2$ $c = \\frac{2}{3} &lt; 1$ $T(n) = n^2$ $T(n) = 8T(n/2) + n^3$$a = 8, b = 2, f(n) = n^3, n^{\\log_{b} a} = n^3 = f(n)$ $T(n) = n^3 \\log n$ Significant InversionRecall the problem of finding the number of inversions: we are given a sequence of n numbers $a_1, a_2, \\cdots, a_n$, which we assume are all distinct, and we define an inversion to be a pair $i &lt; j$ such that $a_i &gt; a_j$. We motivated the problem of counting inversions as a good measure of how different two orderings are. However, one might feel that this measure is too sensitive. Let’s call a pair a significant inversion if $i &lt; j$ and $a_i &gt; 2a_j$. Give an $O(n \\log n)$ divide and conquer algorithm to count the number of significant inversions in a sequence of n pairwise distinct numbers $a_1, a_2, \\cdots, a_n$. Solution123456789101112131415161718192021222324function mergeAndCount(left: number[], right: number[]): [number[], number] { let i = 0, j = 0, inversions = 0; const sorted: number[] = []; while (i &lt; left.length &amp;&amp; j &lt; right.length) { if (left[i] &lt;= 2 * right[j]) { sorted.push(left[i]); i++; } else { // Since left[i] &gt; 2 * right[j], all remaining elements in left are also inversions. inversions += left.length - i; sorted.push(right[j]); j++; } } // Append any remaining elements (no further inversions can be found here) while (i &lt; left.length) sorted.push(left[i++]); while (j &lt; right.length) sorted.push(right[j++]); return [sorted, inversions];} Largest Contiguous SumGive a $O(n \\log n)$ time divide and conquer algorithm to find a contiguous subarray within a one-dimensional array $A[1 : n]$ of real numbers which has the largest sum, i.e., find indices $1 \\leq i \\leq j \\leq n$ such that$$ A[i] + A[i+1] + \\cdots + A[j] $$is as large as possible. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162function findMaxCrossingSubarray( A: number[], low: number, mid: number, high: number): [number, number, number] { let leftSum = -Infinity; let sum = 0; let maxLeft = mid; for (let i = mid; i &gt;= low; i--) { sum += A[i]; if (sum &gt; leftSum) { leftSum = sum; maxLeft = i; } } let rightSum = -Infinity; sum = 0; let maxRight = mid; for (let j = mid + 1; j &lt;= high; j++) { sum += A[j]; if (sum &gt; rightSum) { rightSum = sum; maxRight = j; } } return [maxLeft, maxRight, leftSum + rightSum];}function findMaximumSubarray( A: number[], low: number, high: number): [number, number, number] { if (high === low) { return [low, high, A[low]]; // Base case: only one element } else { const mid = Math.floor((low + high) / 2); const [leftLow, leftHigh, leftSum] = findMaximumSubarray(A, low, mid); const [rightLow, rightHigh, rightSum] = findMaximumSubarray( A, mid + 1, high ); const [crossLow, crossHigh, crossSum] = findMaxCrossingSubarray( A, low, mid, high ); if (leftSum &gt;= rightSum &amp;&amp; leftSum &gt;= crossSum) { return [leftLow, leftHigh, leftSum]; } else if (rightSum &gt;= leftSum &amp;&amp; rightSum &gt;= crossSum) { return [rightLow, rightHigh, rightSum]; } else { return [crossLow, crossHigh, crossSum]; } }}","link":"/Algorithm/DAA-Midterm-Exam/"},{"title":"ITDS Midterm","text":"学不动了 DS &amp; MLWhat are the main differences between DS and ML, and how do their goals and functionalities differ even though they are closely linked? DS 和 ML 之间的主要区别是什么？尽管两者密切相关，但它们的目标和功能有何不同？ DS 是涵盖数据处理、分析、可视化的广泛领域，目的是从数据中提取信息。ML 是 DS 的子领域，专注算法和模型，使计算机能基于数据学习并作出预测。DS 注重数据处理流程，而 ML 专注于算法模型。 LifecycleEnumerate the steps involved in the DS lifecycle. Highlight the key tasks and considerations at each stage? 列举 DS 周期中涉及的步骤。在每个阶段突出关键任务和考虑因素是什么？ 需求：明确目标 数据采集：公共，私有，第三方 数据处理：清洗，整理 数据分析：统计，可视化 建模：使用 ML 部署：持续监控，优化 HammingConsider two objects represented by binary strings:A = 110010, B = 101011.Define and calculate the Hamming distance between A and B.Can we use the Hamming distance if A and B have different lengths and why? 考虑由二进制字符串表示的两个对象：A = 110010，B = 101011。定义并计算 A 和 B 之间的汉明距离。如果 A 和 B 长度不同，我们可以使用汉明距离吗？为什么？ 汉明指两个等长字符串对应位置上不同字符的数量。 12A = 110010;B = 101011; 观察得到有三个位不同，所以汉明距离为 3。如果 A 和 B 长度不同，汉明距离无法计算，无法确保每个位置都有对应的字符进行比较。 MetricUnder which conditions is a distance measure a metric?Demonstrate that the Hamming distance is a metric.Provide explanations and calculations to support each part of the proof. 在什么条件下，一个距离测量是一个度量？证明汉明距离是一个度量。提供解释和计算来支持证明的每个部分。 Non-Negative：$d(x, y) \\geq 0$ Symmetry：$d(x, y) = d(y, x)$ Identity：$d(x, y) = 0 \\Leftrightarrow x = y$ Triangle Inequality：$d(x, y) + d(y, z) \\geq d(x, z)$ 汉明距离是非负的，最小为 0 基于位置的比较导致顺序无关 如果距离为 0 ，则两个字符串相同 设有 A B C 等长字符串。若 A 和 C 在 x 位置上相同，则 $d(A, C)_x = 0$。若 A 和 B and/or B 和 C 在 x 位置上不同，最多会使 $d(A, C)$ 增加 1。但 $d(A, B) + d(B, C)$ 至少为 1，因此满足三角不等式。 K-MeansWhat are the hyper-parameters of K-means clustering and how do we set them? K-means 聚类的超参数有哪些，我们应该如何设置它们？ Cluster Number $k$：聚类数量，使用 Elbow Method 或 Silhouette Score Initial Centroids：初始质心，使用随机选择或 KMeans++ Maximum Iterations：最大迭代次数，一般为 300 Convergence Tolerance：收敛容差，当质心变化小于阈值时停止迭代，一般为 $10^{-4}$ AgglomerativeIn hierarchical agglomerative clustering, how would you determine the optimal number of clusters without relying on pre-defined stopping criteria? 在层次聚类中，如何在不依赖预定义停止条件的情况下确定最优的聚类数量？ 一般使用 Dendrogram 来帮助确定最优聚类数量。 生成树状图 寻找最大的 Merge Distance 增量 在这个点 Cut 树状图 切割点以上的分支数量即为最优数 DBSCANIf you set a large value for $\\epsilon$ in DBSCAN, what would be the potential consequences on the clustering results? 如果在 DBSCAN 中设置一个较大的 $\\epsilon$ 值，这对聚类结果可能有什么影响？ $\\epsilon$ 表示 Eps-neighborhood，即邻域半径 导致本应分开的不同簇被合并 噪声点可能被错误地分配到簇中 边界结构 Blurred Overfitting RegressionDiscuss the difference between simple linear regression and multiple linear regression. 讨论简单线性回归和多元线性回归之间的区别。 简单线性只涉及一个 feature，多元线性涉及多个 feature。都是使误差平方和最小化，但多元线性可以更全面地分析多个因素对结果变量的综合影响 GradientDescribe the process by which gradient descent is employed to refine the parameters of a linear regression model. 描述梯度下降如何被用来优化线性回归模型参数的过程。 线性回归模型参数随机初始化 通常使用 MSE 计算 Loss 为 Loss 的每个参数计算 partial derivative 将参数减去 学习率 * gradient 重复 2-4 直到收敛 RegularizationHow does regularization help overcome the challenges associated with using polynomial regression models?Particularly in mitigating overfitting and controlling model complexity? 正则化如何帮助克服使用多项式回归模型所面临的挑战？特别是在减少过拟合和控制模型复杂度方面？ Overfitting：向 Loss 增加额外的 Penalty，通常是 L1 或 L2，使得模型不能 fit 小波动 Complexity：惩罚大的 coefficient，削弱其影响，降低复杂度，提高 generalization ability","link":"/Data-Science/ITDS-Midterm/"},{"title":"Introduction to Data Science","text":"这年头真的是什么臭鱼烂虾都敢出来教课了你们这帮人除了会照着代码念以外还会干什么 本文是这门课的 Lecture 部分，各个 Practice 会独立成文 Introduction什么是 DS它的目标是：从数据中提取有用的信息 我们将 机器学习的算法应用于各种数据，以训练 AI 来完成通常需要人类进行的任务这些 AI 会产生一些见解，以供用户将其转化为业务价值 关系 DS 与 ML 密切相关 DS 研究如何从原始数据中提取信息 ML 是 DS 的一种技术，使机器能够自动从过去的数据中学习 AI 使用指导思想，即让机器模仿人类的思维方式 DL 是 ML 的子集，它使用多层神经网络计算 生命周期让我们来看看 DS 的生命周期 商业需求 数据采集 数据处理 数据分析 建模，使用 ML 部署和优化模型 数据我们称数据表的 Columns 为 Features，Rows 为 Samples / Examples / Instances 数据的类型： Categorical无序集合，如 City.{Viena, Paris} Numerical有序集合，如 Age.{0, 1, 2, 3, …} 我们偏向于把 Categorical 转化为 Numerical 例如 Age City 20 Viena 30 Paris 转化为 Age City_Viena City_Paris 20 1 0 30 0 1 这样我们就可以将 instance 表达为空间中的一个点，如 (20, 1, 0) 随后我们可以： 把所有数据映射到空间中，称之为 Feature Space 使用 Euclidean Distance 来计算两个点之间的距离 用来查找相似内容… 质量ML 算法需要干净的数据 原始数据有可能： NoiseModicitation of original values Outliers (异常 / 离群)与大部分数据有截然不同的特征 Missing Values Duplicates如同一个人使用不同 ID 数据缺失可能是由于 未收集（拒绝回答），或不适用（未成年人的收入）导致的可以使用以下方法处理： 删除 估计 Estimation 忽略 对于数据量，一般是越多越好，有一个流行的说法是 十倍于特征数量，但是要保证质量 有效分析与可视化一般流程 提出问题 目标是什么 如何处理数据 想预测或者估计什么 数据收集 如何抽样 哪些数据是相关的 隐私问题 探索数据 绘图 检查异常 寻找规律 建模 构建 拟合 验证 展示可视化结果 学到了什么 结果的意义 见解 Anscombe’s Quartet 用来说明在分析数据前先绘制图表的重要性，以及离群值对统计的影响之大 左上：线性 右上：二次 左下：线性，但有离群值，降低了相关性 右下：非线，但有离群值，使相关性升高 可视化的目的 沟通与解释 展示数据和想法 解释 提供支撑 说服 分析与探索 浏览数据 评估 决定如何处理 决定下一步 EDA 工作流Exploratory Data Analysis 从数据构建 DataFrame，所有数据都在其中 清理数据 每一列都描述一个属性 列偏好于数值 列无法进一步拆分（原子性） 探索 Global 属性 Histogram 直方图 Scatter Plot 散点图 Aggregation 聚合 探索 Group 属性 Groupby 分组 Pivot Table 透视表 Box Plot 箱线图 Small Multiples 小多图 来比较数据的子集 可视化原则 图形完整性 避免 Scale Distortion Be Proportional 对比性 包括所有的不确定情况 包含所有的数据 简单 避免 3D 选择合适的图表 有效感知，用数据表明观点，比如 A 比 B 大 10% 合理的颜色 考虑到色盲 相似与测距基本概念距离描述两个数据对象之间的差异性，当两个对象相同时，距离为 0 相似性：1 - 距离 Metric 度量 d 或 距离函数 有以下四个性质： 非负性 同一性（Identity） $d(x, y) = 0 \\Leftrightarrow x = y$ 对称性（Symmetry）：$d(x, y) = d(y, x)$ 三角不等式（Triangle Inequality）：$d(x, y) + d(y, z) \\geq d(x, z)$通过第三个对象间接计算的距离不会小于直接计算的距离 度量空间 Metric Space 是一个集合，其中定义了一个度量函数 三维欧几里得空间是一个常见的度量空间，其中的距离可以用欧几里得距离度量来计算 $L_p$ 范数是一种距离度量，用于衡量向量的大小 $$ Lp (x, y) = \\left ( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{\\frac{1}{p}} $$ p = 1 时，称为曼哈顿距离p = 2 时，称为欧几里得距离p = $\\infty$ 时，称为切比雪夫距离 欧几里得距离：$L_2 (x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$","link":"/Data-Science/Introduction-to-Data-Science/"},{"title":"MSSQL 练习题","text":"最近因为学校的原因，不得不学习 MS SQL 相关内容遂记录一些练习题 首先我们 1234DROP DATABASE IF EXISTS Learn;CREATE DATABASE Learn;USE Learn; Check创建一个 Student 表，有 ID, Name, Semester, City 字段。写一个 SQL，只允许插入第三学期的学生。这意味着用户不能插入第一、第二或第四学期的学生。 Create one Student table where is ID, Name, Semester, City colums.Find the solution that we can insert just the 3rd semester students.This mean that the user connot inser Student who are in 1, 2, or 4th semester. 12345678DROP TABLE IF EXISTS Student;CREATE TABLE Student ( ID INT PRIMARY KEY IDENTITY(1, 1), Semester TINYINT CHECK(Semester = 3) NOT NULL, NAME TEXT NOT NULL, City TEXT NOT NULL,); 去重创建一个方法，对同一 record 进行过滤，并只返回一次。例如，如果我们有 3 个价格为 450 的比萨饼，如果我们 Select，那么结果将是只有 1 个比萨，而不是 3 个比萨。 Create one method, what filtering the same record and give back just once.For example, if we have 3 pizza with 450 price, if we take a Select,then results will be just 1 pizza, not 3 pizza. 1234567891011121314151617181920DROP TABLE IF EXISTS Food;CREATE TABLE Food ( ID INT PRIMARY KEY IDENTITY(1, 1), Name VARCHAR(50) NOT NULL, Price DECIMAL CHECK(Price &gt;= 0) NOT NULL,);INSERT INTO Food Values ('Pizza', 450), ('Pizza', 450), ('Pizza', 450);-- Type 1SELECT MIN(Id), Min(Name), Min(Price) FROM Food GROUP BY Name;-- Type 2SELECT DISTINCT Name, Price FROM Food; 函数创建一个阻止 18 岁以下用户的 function。 Create one function what block the user who are younger as 18 years old. 1234567DROP TABLE IF EXISTS TUser;CREATE TABLE TUser ( ID INT PRIMARY KEY IDENTITY(1, 1), Name VARCHAR(50) UNIQUE NOT NULL, Age TINYINT CHECK(Age &gt;= 0),); 123456789101112131415CREATE OR ALTER FUNCTION IsAdult(@Name VARCHAR(50))RETURNS BITASBEGIN IF EXISTS( SELECT * FROM TUser WHERE Name = @Name And Age &gt;= 18 ) RETURN 1 RETURN 0END 12345INSERT INTO TUser Values('Some', 18)DECLARE @ret BITEXEC @ret = IsAdult 'Some'SELECT @ret 层次化索引 Create one hierarchy index. 12345678910DROP TABLE IF EXISTS HIndex;CREATE TABLE HIndex ( IdPath HIERARCHYID PRIMARY KEY, Sth TEXT)INSERT INTO HIndex VALUES ('/1/', 'Something'), ('/1/1/', 'Somebody') Trigger创建一个触发器，如果产品数量在 10 个以下，则更新价格（+20%）。 Create one trigger what is update the price(+20%)if the products quantity is under 10 pirces. 123456789101112DROP TABLE IF EXISTS Product;CREATE TABLE Product( Id INT PRIMARY KEY IDENTITY, Name VARCHAR(50), Price MONEY, Quantity INT CHECK(Quantity &gt;= 0));INSERT INTO Product VALUES ('Pizza', 1000, 15), ('Bun', 100, 12); 1234567CREATE OR ALTER TRIGGER IncreasePriceOn Product FOR UPDATE ASBEGIN UPDATE Product SET Price = Price * 1.2 WHERE Quantity &lt; 10END; 12UPDATE ProductSET Quantity = 8; 复合主键不是很能理解他到底在说什么，但是答案是复合主键相关 How can we kill the nested loops operator?How can we kill the double I/O problems? 1234567DROP TABLE IF EXISTS Composite;CREATE TABLE Composite( Id INT NOT NULL, Comp INT NOT NULL, CONSTRAINT PK_Composite_Id_Comp PRIMARY KEY (Id, Comp)); 脏读 Create one select what is dirty read. 1234567891011DROP TABLE IF EXISTS Bank;CREATE TABLE Bank( Id INT PRIMARY KEY IDENTITY(1, 1), AccountNum VARCHAR(50), Name VARCHAR(50), Balance MONEY)INSERT INTO Bank VALUES ('SomeAccountNum', 'SomeName', '80'); 123456789BEGIN TRAN; UPDATE Bank SET Balance = Balance - 45 WHERE AccountNum = 'SomeAccountNum'; WAITFOR DELAY '00:00:10';ROLLBACK TRAN;SELECT * FROM BankWHERE AccountNum = 'SomeAccountNum'; 123456-- Dirty ReadSET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;BEGIN TRAN; SELECT * FROM Bank WHERE AccountNum = 'SomeAccountNum';COMMIT TRAN; 或者 12Select Count(*)FROM Bank WITH (NOLOCK) While两个产品。咖啡是 245，披萨是 475。(硬币：20，10，5）如果我们想买这些产品，请计算需要多少硬币。 You have 2 products. The coffee is 245, the pizza is 475. (Coins: 20, 10, 5)Please count how many coins need it if we would like to buy this products. 12345678910111213141516171819202122232425262728293031CREATE OR ALTER PROCEDURE CountCoins(@Price INT)ASBEGINDECLARE @C20 INT, @C10 INT, @C5 INT;SET @C20 = 0;SET @C10 = 0;SET @C5 = 0; WHILE @Price &gt;= 20 SET @Price = @Price - 20 SET @C20 = @C20 + 1 WHILE @Price &gt;= 10 SET @Price = @Price - 10 SET @C10 = @C10 + 1 WHILE @Price &gt;= 5 SET @Price = @Price - 5 SET @C5 = @C5 + 1 PRINT 'It can be paid with ' + TRIM(CAST(@C20 as VARCHAR(50))) + ' 20Coin, ' + TRIM(CAST(@C10 as VARCHAR(50))) + ' 10Coin, ' + TRIM(CAST(@C10 as VARCHAR(50))) + ' 5Coin.'END 聚集索引 Create two cluster index on your table, on the same table but different columns. 123456789DROP TABLE IF EXISTS TTest;CREATE TABLE TTest( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));CREATE CLUSTERED INDEX IX_TTest_Col1 ON TTest (Col1, Col2); XML导出表到 XML。 Create XML code from your table. 12345678910111213DROP TABLE IF EXISTS TXML;CREATE TABLE TXML( Col1 INT PRIMARY KEY IDENTITY, Col2 VARCHAR(10), Col3 VARCHAR(50));INSERT INTO TXML VALUES ('Some', 'Thing'), ('Body', 'Any');SELECT * FROM TXML FOR XML AUTO; 事务用事务填充表。 Create one table with 900 records. 123456789101112131415161718DROP TABLE IF EXISTS Fill;CREATE TABLE Fill( Id INT PRIMARY KEY IDENTITY, Increse INT);BEGIN TRANDECLARE @index INTSET @index = 0WHILE @index &lt; 900BEGIN INSERT INTO Fill VALUES (@index) SET @index = @index + 1ENDCOMMIT TRAN 用户账户创建新用户并授予其权限。 Create a new account, which log in via system administrator with data reader persmission. 123CREATE LOGIN [DGYY] WITH PASSWORD=N'123', DEFAULT_DATABASE=[master]ALTER SERVER ROLE [sysadmin] ADD MEMBER [DGYY]ALTER ROLE [db_datareader] ADD MEMBER [DGYY] UNION合并多个 SELECT 语句的结果集 How can we use the data of set? 123SELECT NULL FROM SomeTableUNIONSELECT NULL FROM OtherTable; CASE WHEN用 CASE 写一个判断 Create one new table for cars(Id, type, color). After this,select one car from the table and compare this car color onthe next logical statement the car is Black (True, False) Or White. 1234567891011121314151617181920DROP TABLE IF EXISTS Car;CREATE TABLE Car( Id INT PRIMARY KEY IDENTITY, Type VARCHAR(50), Color VARCHAR(50));INSERT INTO Car VALUES ('Audi', 'Black'), ('BMW', 'Red'), ('Suzuki', 'Grey'), ('Aston', 'White');SELECT TOP(1) CASE WHEN Car.Color = 'White' Then 'White' WHEN Car.Color = 'Black' THEN 'True' ELSE 'False' ENDFROM Car OFFSET How can we use the data offset? 123456789101112131415161718192021DROP TABLE IF EXISTS Offset;CREATE TABLE Offset( Id INT PRIMARY KEY IDENTITY, Sth INT);DECLARE @index INTSET @index = 0WHILE @index &lt; 5BEGIN INSERT INTO Offset VALUES(RAND() * 10) SET @index = @index + 1ENDSELECT *FROM OffsetORDER BY IdOFFSET 2 ROWSFETCH NEXT 3 ROWS ONLY; BETWEEN12ALTER TABLE TableNameADD CONSTRAINT CK_Between CHECK (LEN(ColomnName) BETWEEN 1 AND 10) THROW Create one trigger what give for us an error messageif we cannot insert data in the table. 123456789CREATE TRIGGER ErrorTrigger-- 类似 BEFOREON TTest INSTEAD OF INSERT ASBEGIN IF 1 = 1 THROW 60000, 'Error Message!', 1 ;END 表变量12345678910111213DECLARE @TTest TABLE( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));INSERT INTO @TTest VALUES (1, 2, 'Some'), (3, 4, 'Thing');SELECT * FROM @TTest;DROP TABLE @TTest; 临时表12345678910111213CREATE TABLE #TTest( Col1 INT NOT NULL, Col2 INT NOT NULL, Col3 VARCHAR(50));INSERT INTO #TTest VALUES (5, 6, 'Body'), (7, 8, 'Any');SELECT * FROM #TTest;DROP TABLE #TTest;","link":"/Database/MSSQL/MSSQL-%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"title":"Master Method","text":"本文是 Design and Analysis of Algorithms 的一部分 本节课一上来就给我搞了一个新概念让我措手不及，完全听不懂 前置知识在学习可以手搓魔法阵的大师方法之前，我们需要一些前置知识 时间复杂度在 很久之前 我就写过关于时间复杂度的内容 我们做复杂度分析的时候，考虑的因变量只有问题规模，而不是具体输入无论哪种记法，默认是取最坏情况来分析 大 O 与 渐进分析用 大 O 表示的复杂度，就叫渐进复杂度我们常说的分析复杂度，其实就是分析渐进复杂度 它忽略了复杂度的常数倍差别，更关心 “算法所需要的资源，随问题规模增长而增长的速度” 且 O 表达的是低阶于，即算法的复杂度不会超过这个值比如，对于一个 O(1) 的算法，你要说它是 O(n) 也没错，只不过你的上限不够紧致 所以，$O$ 是上限，$\\Omega$ 是下限，$\\Theta$ 是上下限相同（即确定就在这一阶） 递归分治算法一个典型的例子就是 Merge Sort 让我们来快速复习一下： 把序列一分为二 分别对两个子序列进行归并排序 合并两个有序序列 Master Method如果我们想快速计算归并，或者存在递归的分治算法的时间复杂度，我们可以使用主定理 定义有递归关系式 $$ T(n) = aT(\\frac{n}{b}) + f(n), 其中 a \\geq 1, b &gt; 1$$ n 是问题规模，a 是递归子问题数量，b 是问题规模的缩小比例$\\frac{n}{b}$ 是子问题规模，$f(n)$ 为递归以外的操作（如分治） 那么我们存在三种情况 1. 递归主导存在常数 $\\epsilon &gt; 0$，使得 $$ f(n) = O(n^{\\log_b(a) - \\epsilon}) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)}) $$ 2. 一样耗时存在常数 $\\epsilon \\geq 0$，使得 $$ f(n) = \\Theta(n^{\\log_b(a)} \\log^\\epsilon n) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)} \\log^{1+\\epsilon} n) $$ 另可写为$$ f(n) = \\Theta(n^{\\log_b(a)}) $$ 则 $$ T(n) = \\Theta(n^{\\log_b(a)} \\log n) $$ 3. 分治主导存在常数 $\\epsilon &gt; 0$，使得 $$ f(n) = \\Omega(n^{\\log_b(a) + \\epsilon}) $$ 且存在常数 $c &lt; 1， n \\to \\infty$ 时，有 $$ af(\\frac{n}{b}) \\leq cf(n) $$ 则 $$ T(n) = \\Theta(f(n)) $$ 理解汗流浃背了吧 以 $T(n) = 2T(\\frac{n}{2}) + n$ 为例 12345678 f(n) / \\ f(n/b) f(n/b) / \\ / \\f(n/b^2) f(n/b^2) f(n/b^2) f(n/b^2) / \\ / \\ / \\ / \\ ......（很多次递归以后）Θ(1) Θ(1) ... Θ(1) Θ(1) Θ(1) Θ(1) ... 递归树被分为两个部分：$f(n)$ 与 $\\Theta(1)$ 本质它其实在对比这两个部分的时间复杂度： 是 $\\sum f(n)$ 耗时，还是 $\\sum \\Theta(1)$ 耗时 所以我们可以将其描述为 $$ T(n) = g \\cdot f(n) + k \\cdot \\Theta(1)$$ 由于 $g$ 增长较慢，所以我们可以认为 g 是常数，则有 $$ g \\cdot f(n) \\to O (f(n)) $$ 所以问题来了，$k$ 是多少 推导我们可以发现这个树每一层分叉都是 $a$ 每次问题规模缩小为 $\\frac{n}{b}$，且 $n = b^{\\log_b (n)}$所以这棵树的高度是 $\\log_b n$这样我们就有 $a^{\\log_b (n)}$ 个叶子节点 所以，有 $\\sum \\Theta(1) = \\Theta(a^{\\log_b (n)})$使用换底公式，$\\Theta(n^{\\log_b (a)})$ 眼熟吗？ 将 $k$ 代入，得到 $T(n) = g \\cdot f(n) + n^{\\log_b (a)}$ 对比接下来我们就只需要对比 $f(n)$ 与 $n^{\\log_b (a)}$ 到底谁随着 n 增长的速度更快了 1. $\\sum \\Theta(1) &gt;$$k$ 的增长大于 $f(n)$ 的增长表示最终处理问题的最小任务占主导 则 $T(n) = \\Theta(n^{\\log_b (a)})$引入 $\\epsilon$，仅为了说明增长速度快 2. $=$表示最小子任务与分割任务的时间复杂度一样此时 $f(n) = \\Theta(n^{\\log_b (a)})$因此需要把两个的时间复杂度都算上有 $T(n) = \\Theta(n^{\\log_b (a)} \\log n)$ 3. $\\sum f(n) &gt;$分治过程占主导，为什么有额外要求呢？ $$c &lt; 1, af(\\frac{n}{b}) \\leq cf(n), n \\to \\infty$$ 因为不可以让子问题的耗时增长速率大于其本身，但其实是在限制 $g$ 限制 $g$我们前文提到，$g$ 被限制速率不可超过 $O(f(n))$，所以认为 $g$ 是常数这在 1 / 2 情况中默认不可能超过 $k$，而 3 中我们需要额外限制 $g$ 的计算让我们把 $f(n)$ 加起来 $$\\sum_{j=0}^{\\log_b (n) - 1} a^j f(\\frac{n}{b^j})$$ 随后我们用变形的 等比数列求和公式 得到 $$\\sum_{i=0}^{k} r^i = \\frac{r^{k+1} - 1}{r - 1}$$ 递归树有 $\\log_b (n)$ 层，去掉最后一层是 $k = \\log_b (n) - 1$，变形公式正好抵消 1 我们发现第三条的规定，就是在限制 $r$ 足够小 细节我也看不明白，希望大佬指点 例题让我们来画点魔法阵 情况一$T(n) = 9T(\\frac{n}{3}) + n$ $a = 9, b = 3, f(n) = n$ $T(n) = n^{\\log_{3} (9)} = n^2 &gt; f(n)$ 情况二$T(n) = T(\\frac{2n}{3}) + 1$ $a = 1, b = \\frac{3}{2}, f(n) = 1$ $n^{\\log_b (a)} = n^{\\log_{\\frac{3}{2}} (1)} = n^0 = 1 = f(n)$ $T(n) = 1 \\times \\log n = \\log n$ 情况三$T(n) = 3T(\\frac{n}{4}) + n \\log n$ $a = 3, b = 4, f(n) = n \\log n, n \\to \\infty$ $n^{\\log_4 (3)} = n^{0.792} &lt; n &lt; n \\log n$ 由此判定为情况三，则 $af(\\frac{n}{b}) = 3 \\frac{n}{4} \\log \\frac{n}{4} &lt; \\frac{3}{4} n \\log n = cf(n)$ 取 $c = \\frac{3}{4}$ 即可 $T(n) = n \\log n$ 不适用$T(n) = 2T(\\frac{n}{2}) + n \\log n$ $a = 2, b = 2, f(n) = n \\log n, n \\to \\infty$ $n^{\\log_2 (2)} = n &lt; f(n)$ 由此判定为情况三，我们尝试验证 $af(\\frac{n}{b}) \\leq cf(n)$ $af(\\frac{n}{b}) = 2 \\frac{n}{2} \\log \\frac{n}{2} = n \\log \\frac{n}{2} = n \\log n - n = n(\\log n - 1) \\leq c \\times n \\log n = cf(n)$ 则等价于 $\\log n - 1 \\leq c \\log n$ 我们尝试求解 $\\log n - 1 \\geq c \\log n$ 重写为 $(1 - c) \\log n \\geq 1 \\to \\log n \\geq \\frac{1}{1 - c} $ 得到 $n \\geq 2^{\\frac{1}{1 - c}}$ 这说明对于任何 $c &lt; 1$，都存在一个 $n \\geq 2^{\\frac{-1}{c - 1}}$，使得 $af(\\frac{n}{b}) \\geq cf(n)$ 所以存在一个 $n$ 的界限，超过后 $g$ 的增长速度将超过 $k$ 的增长速度 导致不能使用主定理 注：根据对数法则，$\\log \\frac{n}{2} = \\log n - \\log 2$由于本题讨论计算机领域，默认以二为底，有 $\\log = \\log_2$则 $\\log 2 = 1$，所以 $\\log \\frac{n}{2} = \\log n - 1$ 习题1.$T(n) = 7 T(\\frac{n}{2}) + n^2$ $a = 7, b = 2, f(n) = n^2$ $T(n) = n^{\\log_{2} (7)} = n^{2.8\\dots} &gt; f(n)$ 2.$T(n) = 7 T(\\frac{n}{3}) + n^2$ $a = 7, b = 3, f(n) = n^2$ $n^{\\log_{3} (7)} = n^{1.77\\dots} &lt; f(n)$ $af(\\frac{n}{b}) = 7 (\\frac{n}{3})^2 = \\frac{7}{9} n^2 = cf(n)$ $c = \\frac{7}{9} &lt; 1$ $T(n) = n^2$ 3.$T(n) = 16 T(\\frac{n}{4}) + n^2$ $a = 16, b = 4, f(n) = n^2$ $n^{\\log_{4} (16)} = n^2 = f(n)$ $T(n) = n^2 \\log n$","link":"/Algorithm/Master-Method/"},{"title":"Matplotlib 入门","text":"本文是 Introduction to Data Science 的一部分 你们就照着文档念吧，谁照着念能念的过你们啊，活爹 快速开始实际上这玩意就是一个 Python 版的 Matlab 绘图库对于有 Matlab 经验的人来说基本就是换个地方写一样的东西 接下来的每一个代码块都默认附加在上一个代码块的后面 导入12345678# 启用 Jupyter 嵌入绘制的魔术命令%matplotlib inlineimport matplotlib as mpl# 真要用的也就只有 pltimport matplotlib.pyplot as plt# 怎么能少了数据源呢import numpy as np 其中，inline 会嵌入静态图片，notebook 会嵌入交互式图片 尝试1234567# 生成数据x = np.linspace(0, 10, 200)# 绘制图形plt.plot(x, np.sin(x))plt.plot(x, np.cos(x))# 显示图形plt.show() 保存12345678# 生成一个空白图形并将其赋给 fig 对象fig = plt.figure()# 绘制实线plt.plot(x, np.sin(x), '-')# 保存矢量图fig.savefig('my_figure.svg')# 查看所有支持的格式fig.canvas.get_supported_filetypes() 两种绘图方式MATLAB 风格对于一般的绘图来说，这种方式更加直观简单 12345678910# 创建一个图形plt.figure()# 创建一个子图plt.subplot(2, 1, 1)# 绘制第一个子图plt.plot(x, np.sin(x))# 创建第二个子图plt.subplot(2, 1, 2)# 绘制第二个子图plt.plot(x, np.cos(x)) 创建子图：subplot(rows: 子图行数, columns: 子图列数, subplot_number: 子图序号) 绘制图形：plot(x: x 轴数据, y: y 轴数据, …) 面向对象风格对于复杂的绘图来说，这种方式更加灵活 123456# 创建一个图像网格fig, ax = plt.subplots(2)# 绘制第一个子图ax[0].plot(x, np.sin(x))# 绘制第二个子图ax[1].plot(x, np.cos(x)) subplots 会返回一个包含所有子图的数组 基本图形线图1234# 使用 rangeplt.plot(range(1, 10))# 使用 numpyplt.plot(range(10, 1, -1), np.arange(1, 10)) plot(y: y 轴数据, …)x 会自动使用 0 到 len(y) - 1 的整数 使用 OOP12345678910# 创建图像fig = plt.figure()# 创建坐标轴ax = plt.axes()# 创建等长数据序列x = np.linspace(0, 5, 20)# 绘制 sinax.plot(x, np.sin(x))# 绘制 cosax.plot(x, np.cos(x)) linspace(start: 起始值, stop: 结束值, num: 生成的数据个数)该函数会返回一个包含 num 个元素的等差数列 多次调用 plot 会在同一张图上绘制多个图形 plot123456789101112plot( x: x 轴数据, y: y 轴数据, linestyle: 线条风格, linewidth: 线宽, color: 颜色, marker: 为线图添加散点，指定点的形状, markersize: 点大小, markeredgecolor: 点边框颜色, label: 图例标签, alpha: 透明度) 颜色plot 会自动循环使用颜色，但是也可以手动指定 12345678910# 短颜色编码（rgbcmyk）plt.plot(x, 2*x+1, color = &quot;g&quot;)# 灰度，从0到1plt.plot(x, 2*x+2, color = &quot;0.6&quot;)# HEXplt.plot(x, 2*x+3, color = &quot;#FFEE22&quot;)# RGB元组，从0到1plt.plot(x, 2*x+4, color = (0.8, 0.7, 0.1))# CSS 颜色名plt.plot(x, 2*x+5, color = &quot;chartreuse&quot;) 线条风格plot(…, linestyle: 线条风格) 使用名称12345678# 实线plt.plot(x, 2*x, linestyle = &quot;solid&quot;)# 虚线plt.plot(x, 2*x+1, linestyle = &quot;dashed&quot;)# 点线plt.plot(x, 2*x+2, linestyle = &quot;dotted&quot;)# 点划线plt.plot(x, 2*x+3, linestyle = &quot;dashdot&quot;) 使用符号12345678# 实线plt.plot(x, 2*x, linestyle = &quot;-&quot;)# 虚线plt.plot(x, 2*x+1, linestyle = &quot;--&quot;)# 点线plt.plot(x, 2*x+2, linestyle = &quot;:&quot;)# 点划线plt.plot(x, 2*x+3, linestyle = &quot;-.&quot;) 我们还可以把颜色和线条风格合并在一起 1234# 绿色虚线plt.plot(x, 2*x, &quot;g--&quot;)# 蓝色点线plt.plot(x, 2*x+1, &quot;:b&quot;) 图例虽然 plot 提供了 label 参数，但需要 legend() 才能显示 12345678910111213141516171819202122232425262728293031323334x = range(0, 10)y = np.cos(x)# 蓝线plt.plot( x, y, linestyle = '-.', linewidth = 1, color = 'blue', marker = 'o', markersize = 10, markeredgecolor = 'r', label = 'Cos', alpha = 0.5)y2 = np.sin(x)# 红线plt.plot( x, y2, linestyle = '--', linewidth = 1, color = 'red', marker = 'x', markersize = 10, markeredgecolor = 'b', label = 'Sin', alpha = 0.5)plt.legend() 标题标签123456x = np.linspace(0, 10, 200)plt.plot(np.sin(x))plt.title('Sine Curve')plt.xlabel('Radian')plt.ylabel('Magnitude') 范围123456plt.plot(np.sin(x))# X 设置在 50 到 175plt.xlim(50, 175)# Y 设置在 -0.5 到 1plt.ylim(-0.5, 1) 如果将参数反转，可以实现坐标轴的翻转 123456plt.plot(np.sin(x))# X 设置在 175 到 50plt.xlim(175, 50)# Y 设置在 1 到 -0.5plt.ylim(1, -0.5) axis我们还可以通过 axis: [xmin, xmax, ymin, ymax] 函数一次性设置 12345plt.plot(np.sin(x))# X 设置在 175 到 50# Y 设置在 -0.5 到 1plt.axis([175, 50, -0.5, 1]) 它还支持自动调整 axis('tight') 会自动调整到数据的最小范围 axis('equal') 会使 x 和 y 与屏幕宽高比一致 axis('scaled') 会使 x 和 y 的单位长度相等，不会调整到数据的最小范围 axis('square') 会使 x 和 y 的单位长度相等，并且调整到数据的最小范围 axis('off') 会关闭坐标轴 可以使用 plt.axis? 查看更多信息 散点图今天做 quiz 的时候居然在一个非常简单的问题上选错了，不能再摆了 散点图在观察数据分布的时候非常有用 123x = range(1, 11)# 传入 &quot;o&quot; 以便绘制散点图plt.plot(x, x, &quot;o&quot;) 还可以使用 scatter 函数，其提供了更多可以自定义的特性 1plt.scatter(x, x) 形状Matplotlib 支持很多点的形状 12345678910# 随机数生成器rand = np.random.RandomState(42)# 绘制随机点for marker in ['o', '.', ',', 'x', '+', 'v', '^', '&lt;', '&gt;', 's', 'd']: plt.plot(rand.rand(5), rand.rand(5), marker, label = &quot;marker = '{}'&quot;.format(marker))plt.legend()# 避免图例与数据重叠plt.xlim(0, 1.8) 透明度点太多会重叠，不便于观察 12345x = rand.rand(200)y = rand.rand(200)# 绘制散点图plt.scatter(x, y, alpha = 0.5) 颜色与大小12345678910x = rand.rand(100)y = rand.rand(100)colors = rand.rand(100)sizes = 1000 * rand.rand(100)# 绘制散点图plt.scatter(x, y, c = colors, s = sizes, alpha = 0.5)# 添加颜色条plt.colorbar() 条形图PPT 专用图形 1234x = range(1, 6)y = [1, 4, 6, 8, 4]plt.bar(x, y) 还可以是水平的 1plt.barh(x, y) 分组123456789101112131415161718192021222324member = ['A', 'B', 'C', 'D']jan = [30, 40, 50, 60]feb = [35, 45, 55, 65]mar = [40, 50, 60, 70]# 设置每个柱状图的宽度width = 0.2# 绘制柱状图plt.bar(range(4), jan, width = width, label = 'Jan')plt.bar(np.arange(4) + width, feb, width = width, label = 'Feb')plt.bar(np.arange(4) + width * 2, mar, width = width, label = 'Mar')# 添加图例plt.legend()# 设置刻度plt.xticks(np.arange(4) + width, member)# 设置 y 轴标签plt.ylabel('Revenue')# 显示网格plt.grid()# 显示图形plt.show() 堆叠1234567891011121314151617# 绘制堆叠柱状图plt.bar(np.arange(4), jan, label = 'Jan')plt.bar(np.arange(4), feb, bottom = jan, label = 'Feb')plt.bar(np.arange(4), mar, bottom = np.array(jan) + np.array(feb), label = 'Mar')# 添加图例plt.legend()# 设置刻度plt.xticks(np.arange(4), member)# 设置 y 轴标签plt.ylabel('Revenue')# 显示网格plt.grid()# 显示图形plt.show() bottom 让数据在上一个数据的基础上偏移np.array 便于元素级别（向量化）运算 直方图123456789x1 = np.random.normal(0, 0.4, 1000)x2 = np.random.normal(-3, 1, 1000)x3 = np.random.normal(2, 2, 1000)kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=40)plt.hist(x1, **kwargs)plt.hist(x2, **kwargs)plt.hist(x3, **kwargs) 参数1234567891011121314151617plt.hist( x: 数据, bins: 柱数, range: 上下边界, density: 频数转换成频率, weights: 每个数据的权重, cumulative: 计算累计频数或频率, bottom: 基准线, histtype: 柱状图类型 _bar_ / barstacked / step / stepfilled, align: 边界对齐方式 left / _mid_ / right, orientation: 方向 _vertical_ / horizontal, rwidth: 柱宽, log: 是否对 y 轴取对数, color: 颜色, label: 图例标签, stacked: 有多个数据时是否堆叠 默认水平) 二维数据二维直方图在两个维度进行切分，来查看数据的分布 12345x = np.random.randn(1000)y = np.random.randn(1000)plt.hist2d(x, y, bins=30, cmap='Blues')plt.colorbar() 饼图","link":"/Program/Python/Matplotlib-%E5%85%A5%E9%97%A8/"},{"title":"Morgan Stanley 的面试题","text":"TMD，跟资本拼了 卷入资本的大潮踩在浪尖上的就是巅峰踩不上的就卷到大海里走上人生巅峰了属于是 摩根士丹利在我们学校招聘，提供了一些公开的习题，我也来做做看 JavaFilter12345678910111213import hava.util.stream.Stream;class Main { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of( &quot;Morgan&quot;, &quot;Stanley&quot;, &quot;Investment&quot;, &quot;Managment&quot; ); stream.filter( str -&gt; &quot;AEIOU&quot;.indexOf(Character.toUpperCase(str.charAt(0))) != -1) .forEach(System.out::println); }} OOP12345678910111213141516171819202122232425262728abstract class Animal { public void sound() { System.out.println(&quot;sound &quot;); }}class Dog extends Animal { public void sound() { super.sound(); }}class SleepingDog extends Dog { public void sound() { System.out.println(&quot;silence &quot;); }}class Main { public static void main(String[] args) { Animal rex = new Dog(); Animal spike = new SleepingDog(); rex.sound(); System.out.println(&quot;of &quot;); spike.sound(); }} Recursive1234567891011121314151617181920212223242526272829public class Main extends Thread { public static int result = 1; private int n; Main(int x) { n = x; } public void fac() { if (n &lt;= 1) { result *= 1; return; } result *= n; Main thread = new Main(n - 1); thread.start(); } public void run() { fac(); } public static void main(String[] args) throws InterruptedException { Main thread = new Main(5); thread.fac(); System.out.println(result); }} Concept You can define static functions outside classes. There are 4 different access modifiers in Java. A Java class can extend multiple classes. A Java interface can extend multiple interfaces. Type Size byte 1 bit boolean 1 bit char 2 bit int 4 bit double 8 bit PythonSyntax [] * 42 [_ for _ in range(66) if not _] [[i for i in range(2)] if i is 1] ['Why?' for why in ['Yes', 'Indeed', 'Sure']] For12345678for i in range(1, 3): if not i % 3: print(&quot;Found: &quot;, i, end=', ') break else: passelse: print(&quot;Invalid&quot;, end=', ') Equality123str1 = &quot;equality in Python&quot;.upper()str2 = &quot;EQUALITY IN PYTHON&quot;print(str1 == str2, str1.__eq__(str2), str1 is str2) OOP123456789101112class A: def a(self): return 'a' def b(self): return 'b'd = dir(A())for fun in d: if not fun.startswith('__'): result = getattr(A(), fun)() print(result, end='') Numpy123import numpy as npa = np.array([[1, 2], [3, 4]])print(int(np.linalg.det(a))) C++SizeHow many bits in a C++ byte? 4 / 8 / 8+ / depends on system FlushWhich of the following will flush the output buffer? std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; '\\n'; std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Please flush!&quot; &lt;&lt; std::flush; printf(&quot;Please flush!&quot;); Pointer123int arr[3] = {1, 2, 3};int *p = arr;std::cout &lt;&lt; *p++ &lt;&lt; &quot; &quot; &lt;&lt; * p &lt;&lt; std::endl; Virtual The member function to call is resolved at compile time based on the type of the pointer or reference to the object. The member function to call is resolved at runtime time based on the type of the pointer or reference to the the object. The member function to call is resolved at runtime time based on the type of object(not the pointer or reference to the object), by checking the v-table realted to the object instance. The member function to call is resolved at runtime time based on the type of object(not the pointer or reference to the object), by checking the v-table associated with the object class.","link":"/Program/Morgan-Stanley-%E7%9A%84%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"NLP-Alignments","text":"对齐 AI alignment in generalAI系统的 对齐 是确保其操作符合 人类（用户、操作员等）的预期目标和偏好 一般的伦理原则 （ethical） 基于机器学习的AI系统的行为受到其开发者的多种方式影响。最重要的是，他们选择/开发了 用于训练数据驱动模型的数据集 如果模型使用强化学习进行训练，则是奖励函数（reward） 一般来说，在训练期间通过使用的参数优化方法（例如梯度下降）最小化或最大化的损失或目标函数 不对齐（misalignment 缺乏对齐）的实例有时分为两种（不一定容易区分）的类型： 外部不对齐：开发者指定的系统目标或奖励与预期的人类目标之间的偏差 内部不对齐：显式指定的训练目标与系统实际追求的目标（所谓的涌现目标 emergent）之间的偏差 指令跟随大型语言模型中的涌现少样本能力Emergent few-shot abilities 正如GPT-3所展示的那样，使用标准MLE目标训练的LLM在许多任务上表现出显著的 0-shot、1-shot和少样本性能： 在许多情况下，MLE训练的LLM只需要一个包含任务简单描述的提示，并且可选地提供几个示例即可表现良好： 据报道，MLE训练的GPT-3在没有任务特定微调的情况下，在以下任务上表现良好： 翻译 问答 阅读理解 SAT风格的类比 检测句子之间的逻辑关系 简单算术 单词拼写和操作（如字谜、单词反转等） 根据给定的标题和风格写诗 指令跟随模型这些观察自然引出了基于LLM的通用 指令跟随助手 的想法，这些助手可以根据描述执行广泛的、开放式的任务。 从这种预期用途的角度来看，对这种模型的期望包括： 有帮助的：它应该真正尝试执行所描述的任务 诚实的：它应该提供准确的信息，包括在适当情况下表达不确定性 无害的：它不应该具有攻击性、歧视性，也不应该推荐或帮助危险或不道德的行为 指令跟随中的不对齐关于这些人类目标和期望（它们应该作为 有帮助的助手）来说，GPT-3类的LLM在以下情况下训练 （主要）在未经筛选的网络抓取数据上 使用基于标准MLE的语言建模目标 将会 不对齐：根据收到的提示，它们 可以轻易生成 有害的（危险的、歧视性的等）内容 产生听起来合理但不真实、误导性的陈述（“幻觉” hallucinations） 可能无法（尝试）真正执行所描述的任务 关于仅使用MLE训练的LLM正确执行任务的重要类型的不对齐是对小的和（对用户来说）看似无关紧要的 提示差异 过于 敏感。在任务描述、示例选择和示例顺序上的微小变化被报告为导致了巨大的性能差异。 一个说明性示例：实验提示模板对 他们发现左边的0-shot模板在GPT-3版本上比右边的1-shot甚至10-shot实例表现更好。（在WMT’14 Fr-En数据集上的BLEU得分为1-shot的18.0，10-shot的24.1，但0-shot提示的26.5。） 对齐与不对齐是相对使用案例的MLE训练的语言模型仍然可以（并且确实）与其他合法的使用案例 良好对齐，例如，用于 OCR 或 语音识别 的语言建模，其中任务只是评估在某种上下文中由人类产生的一段文本或语音的概率。 与指令跟随的对齐监督微调提高指令执行的低和/或不一致性能的最明显方法是创建一个包含大量不同任务的 监督数据集，其中包含 $$(\\mathrm{task \\space instruction}, \\mathrm{correct \\space response})$$ 对，并在其上对MLE预训练的LLM进行 微调。 给定一个好的指令数据集，监督微调本身不需要特殊技术，例如，对于一个transformer-decoder类型的语言模型 $(\\mathrm{instruction}, \\mathrm{response})$ 对被转换为单个序列，中间有一个固定的分隔符（例如，Flan在它们之间使用一个“特殊的EOS标记”） 训练损失是通常的 交叉熵损失（使用教师强制），它可以包括指令中标记的损失，但可能权重较低 指令数据集更严峻的挑战是创建高质量的指令数据集 （instruction）。创建数据点的主要策略是 手动创建：正确的响应由人工注释者编写，指令要么从用户与LLM的交互中收集，要么也是手动创建 数据整合：使用手动创建的模板将现有的监督NLP任务数据集转换为自然语言的 $(\\mathrm{instruction}, \\mathrm{response})$ 对 基于LLM的合成生成：响应由LLM生成（但可能由人类过滤），而指令要么 从用户提示中收集 也由LLM基于手动创建的种子提示生成 数据整合：Flan从2020年开始，发布了几个指令微调数据集，其中基于大量NLP任务数据集的Flan具有高度影响力： Flan为每个数据集使用10个手动创建的转换模板来转换数据点： 合成生成像 Self-Instruct [S-I] 这样的激进合成(Synthetic)生成方法使用 一个小的手动创建的初始池 种子任务指令（S-I 使用 175 个）和具体示例（S-I 每个任务使用 1 个示例） 随机抽取池中的内容来 提示 LLM 生成更多的指令和示例 生成的新指令和示例使用启发式规则进行 过滤，高质量的内容被添加到池中。采样、生成、过滤和池扩展步骤可以 递归重复，直到达到所需的数据集大小。 即使生成器模型是一个普通的 MLE 训练的 LLM，Self-Instruct 风格的合成生成数据集在指令微调中也可以非常有用。报告显示，在 SuperNatural Instructions 数据集上使用 ROUGE-L 评分测量性能， 普通 GPT-3 在自生成的 Self-Instruct 数据集上微调后性能提高了 33% 它非常接近 InstructGPT 的性能（39.9 对 40.8%） 由于其多样性，它们也可以作为手动创建的指令数据集的有用补充。 基于人类反馈的强化学习也许最有影响力的方法是 OpenAI 对 GPT-3 微调的方法： 起点是一个 MLE 预训练的 GPT-3 和一个 监督数据集，该数据集包含指令提示（从 API 调用中收集）和 手动创建的首选输出示例 预训练模型在此数据集上进行 MLE 微调 微调模型和标注者的监督信号用于训练一个回归 奖励模型，该模型为提示-响应对分配标量奖励 最后，使用奖励模型提供的信号，通过 强化学习 进一步微调模型 将文本生成视为强化学习问题 状态 是要继续的标记序列——可能只包含一个 $\\langle start \\rangle$ 标记 动作 是从词汇表中添加一个新标记到序列中，因此 $|\\textrm{Actions}|=|\\textrm{Vocabulary}|$ 状态转换 是 确定性 的（添加一个标记确定性地产生扩展序列） 策略 基本上是“预测下一个”类型的语言模型，通常是随机的，因为通常有几种替代的续集 奖励 通常是稀疏的，即基于整个完成的序列 奖励模型 奖励模型（RM）的起点是一个相对较小的（6B）MLE预训练的GPT版本，该版本也在监督数据集上进行了指令微调 初始奖励模型只是这个语言模型，将其解嵌层替换为回归头 奖励模型在一个手动创建的质量比较数据集上进行训练，该数据集包含监督数据集中提示的替代模型输出对（由MLE微调的大型GPT-3生成） 奖励模型在 $(x, y_{better}, y_{worse})$ 三元组上的损失，其中 $x$ 是从提示数据集中采样的指令，$y_{better}, y_{worse}$ 是两个排序的替代模型输出，是 $$-\\log(\\sigma(RM_{\\Theta}(x, y_{better})-RM_{\\Theta}(x, y_{worse})))$$ 引导模型为给定的指令提示提供更高的奖励给“更好”的输出。 强化学习训练最后一步是使用奖励模型通过 强化学习 进一步微调语言模型 使用的算法通常是 近端策略优化（Proximal Policy Optimization PPO），这是一种策略梯度变体，通过将更新剪辑到一定范围来避免进行过大的策略更改 强化学习训练的目标是 最大化 奖励模型对（指令，模型响应）对的预期奖励，但也要 最小化（缩放版本的）策略预测的条件分布与用于初始化的指令语言模型之间的 KL散度 直接偏好优化（Direct Preference Optimization DPO）RLHF需要训练一个单独的奖励模型和一个人类反馈循环，这两者都很昂贵。 直接偏好优化 将RL优化问题转化为监督（机器学习）任务。 重新参数化RL优化问题，以__策略__而不是奖励模型$RM$为基础 为策略 $\\pi_\\theta$ 制定最大似然目标 在原始用户判断上通过监督学习优化策略 DPO… 表现类似于PPO，有时甚至更好 需要的计算量比PPO少5-8倍，内存需求减半 对采样温度不太敏感 助手聊天机器人作为对话系统的指令微调语言模型近年来，指令数据集生成和微调方法的成功导致了一系列指令微调的大型语言模型的发展：Google的FLAN、OpenAI的InstructGPT、Stanford的Alpaca等。 作为对话系统，这些模型支持的对话具有以下特点： 用户发起 由正好 两轮 组成 其 目标 是 执行描述的任务 与传统的任务导向系统相比，没有预定义的领域和任务列表，范围是真正 开放的 Assistant chatbots指令微调模型最明显的限制是它们不支持 多轮对话，而对齐的大型语言模型的下一个开发周期的主要目标是消除这一限制。 主要解决方案是保持用于指令微调的框架： 从一个 MLE预训练的大型语言模型 开始 收集一个$D$ 条件文本生成数据集，包含$(x, y)$输入-输出对 在$D$上对预训练的大型语言模型进行 微调，使用监督训练和可选的基于RLHF的训练（后者需要额外的数据和奖励模型的训练） 主要区别在于，条件文本生成的输入不是单个指令，而是一个复杂的 助手对话上下文的表示，包括其 历史： 表示对话历史最简单的表示当然是完整的 $$[u_1, s_1, u_2, \\dots, s_{N-1}, u_N]$$ 从开始到结束交替出现的用户和系统话语列表，但在非常长的对话情况下，这可能会超过模型的最大输入大小，因此通常会被 截断。 更复杂的解决方案不仅仅是简单地删除对话的早期部分，而是用某种压缩表示来替换它，例如 摘要。 挑战尽管取得了不可否认的进展，当前基于LLM的开放域辅助聊天机器人仍然可能 提供不准确或误导的信息（“幻觉”） 产生__冒犯或危险__的输出 未能真正尝试执行任务 因此，在 诚实、无害 和 有帮助 方面的进一步对齐仍然是一个活跃的研究领域。","link":"/AI/NLP/NLP-Alignments/"},{"title":"NLP-Classification-SequenceTagging","text":"分类和序列标注 文本分类文本分类任务文本分类任务是从给定的 $C={c_1,\\dots,c_n}$ 类别/分类标签集中为 $d$ 文本/文档 分配适当的标签。 代表性的例子包括 情感分析：根据文档表达的情感进行分类。标签集示例： { positive, negative, ambigous } { admiration, amusement, annoyance, approval, …, sadness, surprise } 垃圾邮件检测：SPAM，二分类决定消息是否为未经请求的邮件 作者身份检测：从指定的作者集中确定谁写了文本 作者特征检测：作者是男性还是女性，他们的年龄等 主题/话题检测：文档属于预定义列表中的哪个 主题/话题，例如，在国会图书馆分类系统中 { 医学, 农业, 科学, 美术, … } 体裁检测：Genre，确定文本的体裁，例如，从集合 { 科幻, 冒险, 爱情故事, 悬疑, 历史, 西部 } 中分配标签 方法 手工设计的基于规则的系统：例如，使用精心设计的与类别正相关或负相关的词列表。 这些系统可以达到良好的性能，但需要大量的手工工作，并且难以维护和适应。 机器学习方法：在包含标记文档的监督数据集上学习的模型：${\\langle d_i, c_i \\rangle}_{i\\in {1, \\dots, N}}$ 方法范围从线性机器学习方法如逻辑回归（logistic regression）到深度神经网络。 词袋表示法Bag of words 许多基于机器学习的分类方法需要将输入表示为固定长度的数值向量。对于长度不一的文本，一个常见的方法是使用词袋表示法： 使用词汇表 $V={w_1,\\dots,w_N}$ 对输入文本进行分词 并将它们表示为 $|V|=N$ 维的词频向量，即，对于一个文档 $d$，$BOW_V(d)=\\langle c_{1,d}, \\dots, c_{N,d}\\rangle$，其中每个 $c_{i,d}$ 是 $w_i$ 在 $d$ 中的出现次数 一个简单的例子： 词袋表示法的改进基本的 BOW 表示法可以通过几种方式进行改进，可能最重要的三种是： 从 BOW 向量中省略stopword（非信息词）的计数。什么算作停用词取决于任务和领域，但通常会考虑（某些）功能词，例如限定词作为停用词 向 BOW 表示中添加一些词序列计数，例如，bigram或三元组计数 根据词的信息量对词进行加权：最广泛使用的方法是根据词频和逆文档频率（term frequency-inverse document frequency）进行加权 TF-IDF 方案TF-IDF 加权方案的基本假设是，出现在大部分训练文档中的词不如只出现在少数文档中的词信息量大。因此，TF-IDF 向量相应地通过文档频率来折扣 word counts（term frequencies）。一个简单但广泛使用的变体： $$TF{\\text -}IDF(d)=\\langle tf_{1,d}\\cdot idf_1, \\dots, tf_{N,d}\\cdot idf_N\\rangle$$ 其中 $tf_{i,d}$ 只是 $w_i$ 在 $d$ 中的出现次数，而 $$idf_i = \\log\\frac{\\mathrm{\\# of \\space all \\space documents}}{\\mathrm{\\# of \\space documents \\space containing} \\space w_i }$$ 二进制词袋表示法词袋表示法的一种有趣的简化是仅指示单词的存在或不存在： $$BOW_{bin}(d)=\\mathop{\\mathrm{sign}}(BOW(d))$$ 其中 $\\mathop{\\mathrm{sign}}$ 函数的应用是逐元素的，即， $$BOW_{bin}(d)=\\langle \\mathop{\\mathrm{sign}}(c_{1,d}), \\dots, \\mathop{\\mathrm{sign}}(c_{N,d})\\rangle$$ 事实证明，在许多情况下，这些更简单且占用内存更少的表示法可以代替正常的 BOW 向量使用，而不会有明显的性能差异。 朴素贝叶斯与词袋表示法Naive Bayes classifier with BOW 在其最简单的形式中，朴素贝叶斯（NB）分类器是一种生成模型，建模 $\\mathbf{x}$ 观测特征向量和它们的 $c$ 类别标签的联合分布为 $$P(\\mathbf{x}, c) = P(c)\\prod_{i=1}^D P(x_i \\space \\vert \\space c)$$ 该模型被称为“朴素”，因为它基于条件独立假设（conditionalindependence assumption），即在给定类别标签的情况下，所有观测特征彼此独立。 NB 模型可以通过指定以下内容来精确描述： 类别标签的分类分布 $P(c)$，以及 每个 $x_i$ 观测特征和 $c_j$ 标签的 $P(x_i \\space \\vert \\space c_j)$ 分布 $P(c)$ 始终是一个分类（伯努利或“多项”）分布，而 $P(x_i \\space \\vert \\space c_j)$ 分布的选择取决于 $x_i$ 的类型；对于连续的 $x_i$，它可以是任何连续分布，高斯分布是一个常见的选择。 NB 模型可以通过将 NB 假设应用于单个标记来适应文本分类：假设每个标记是根据分类条件分布 $P(w \\space | \\space c)$ 独立选择的。如果 $\\mathbf{x}$ 是一个词袋向量，$c$ 是一个类别标签，这意味着 $$P(\\mathbf{x}, c) = P(c) \\prod_{i=1}^{|V|}P(w_i \\space \\vert \\space c)^{x_i}$$ 为了数值稳定性，对两边取对数： $$\\log P(\\mathbf{x}, c) = \\log P(c) + \\sum_{i=1}^{|V|}x_i \\log P(w_i \\space \\vert \\space c)$$ 这意味着，给定一个 $\\mathbf{x}$ 词袋向量和一个向量 $$\\theta_c=\\langle \\log P(w_1 \\space \\vert \\space c),\\dots,\\log P(w_{|V|} \\space \\vert \\space c) \\rangle$$ 表示类别 $c$ 的条件对数概率， $$\\log P(\\mathbf{x}, c) = \\log P(c) + \\theta_c \\cdot \\mathbf{x}$$ 即 $(\\mathbf{x}, c)$ 的对数概率对于每个 $c_i$ 是一个简单的线性函数。对于一个文档 $d$，预测最可能的类别也非常简单： $$\\hat c = \\mathop{\\mathrm{argmax}}_{c\\in C}(\\log P(c) + \\theta_{c} \\cdot BOW(d))$$ 模型参数的最大似然估计可以基于简单的计数： $$P(c) \\approx \\frac{\\# \\mathrm{of} \\space c \\space \\mathrm{documents}}{ \\# \\mathrm{of \\space all \\space documents }}$$ $$P(w \\space | \\space c) \\approx \\frac{\\# w \\space \\mathrm{occurrences \\space in} \\space c \\space \\mathrm{documents}}{\\# of \\space \\mathrm{words \\space in} \\space c \\space \\mathrm{documents}}$$ 由于我们基本上在处理每个类别的（unigram）语言模型，数据稀疏性再次带来了问题。 最极端的情况是，如果一个词 $w\\in V$ 在任何 $c$ 类别的文档中都没有出现，那么基于语料库的最大似然估计 $P(w \\space | \\space c)=0$，因此，对于任何包含 $w$ 的非零计数的 $\\mathbf{x}$ 词袋向量的文档， $$P(\\mathbf{x}, c) = P(c) \\prod_{i=1}^{|V|}P(w_i \\space \\vert \\space c)^{x_i}=0$$ 无论它们包含任何其他词。 解决方案是使用适当的平滑方法，例如，加一平滑。 朴素贝叶斯的局限性尽管基于 BOW 的 NB 模型相对简单，可以用于估计和预测，并且表现尚可，但也存在一些缺点： NB 条件独立假设相当不现实，并且在基本 BOW 模型中会导致误导性的概率预测 NB 假设使得使用 $N$-gram 基于 BOW 的特征向量比使用 unigram 更加值得怀疑 对于判别任务使用完整的生成模型通常会带来一些性能损失 判别线性方法在经典学习算法领域中，最重要的替代方法是使用 BOW 向量的判别方法之一： 感知器变体 perceptron variant 逻辑回归 支持向量机（SVM）， 基于决策树的集成方法，如随机森林或梯度提升树 这些模型不假设条件独立，并且在使用改进的（例如基于 $N$-gram 的）BOW 表示作为输入时没有问题。 有些出乎意料的是，在某些应用中，在朴素贝叶斯文本分类器中使用重叠(overlapping)的 $N$-gram 实际上对性能有益处，例如，character $N$-gram 经常用于语言识别的 NB 模型中。 序列标注序列标注任务通常是将给定有限标签集 $T$ 中的一个标签分配给可变长度输入序列的每个元素。在 NLP 中，输入序列通常是 $\\langle w_1,\\dots,w_n \\rangle$ 的标记序列。因此，序列标注任务也被称为 标记分类。 在传统的 NLP 流水线中，有些任务是明确的序列标注任务，例如词性标注（POS-tagging）和形态标注（morphological tagging）。其他任务，如名词短语分块（NP-chunking）、命名实体识别（NER）或关键词识别，可以通过简单的技巧转化为序列标注任务。 IOB 标注Inside-Outside-Beginning 这些任务表面上是跨度查找和跨度标注任务：目标是找到属于某些类别的标记跨度。 例如，在（最小）名词短语（NP）分块的情况下： IOB 技巧是将 跨度识别/标注 （span identification） 任务重新表述为序列标注任务。如果有 $T_1,\\dots,T_N$ 个要识别的跨度类型，那么我们引入三种类型的标记级别标签： 对于所有跨度类型的 $B$（开始）标签：$BT_1,\\dots,BT_N$ 表示给定类型的跨度的第一个标记 对于所有跨度类型的 $I$（内部）标签：$IT_1,\\dots,IT_N$ 表示一个标记在跨度内（作为第二个或更晚的元素），最后 对于不属于任何要找到的跨度类型的标记，使用唯一的 $O$ 标签 使用这些标签，跨度识别任务变成了序列标注任务。 除了 IOB（BIO）之外，还有其他方案，最流行的是 BIOES，它引入了 $ET_i$ 结束标签，以及用于单标记跨度的 $ST_i$ 标签。 序列标注的挑战序列标注的主要挑战是元素标签与其他元素的特征（包括它们的标签）之间的复杂相互依赖性：在大多数 NLP 标注任务中，标签是 强烈依赖上下文 的。 另一个重要问题是特征工程：哪些序列元素的特征与标注相关？如果要正确处理词汇表外的单词，那么至少有些特征可能应该基于单词的表面形式，例如其大写、后缀等。 序列标注的监督方法这些方法假设有一个监督数据集 $$D={\\langle \\mathbf{x_1},\\mathbf{y_1} \\rangle,\\dots, \\langle \\mathbf{x_N},\\mathbf{y_N} \\rangle}$$ 其中每对 $\\langle \\mathbf{x}_i, \\mathbf{y}_i \\rangle$ 包含一个要标注的序列 $\\langle x_1^i,\\dots,x_{n_i}^i\\rangle$ 和对应的正确标签序列 $\\langle y_1^i,\\dots,y_{n_i}^i\\rangle$。 我们将讨论的方法都是概率方法（probabilistic）：它们要么建模 $P(\\mathbf{X}, \\mathbf{Y})$ 联合分布（generative model），要么建模 $P(\\mathbf{Y} \\space | \\space \\mathbf{X})$ 条件分布（判别模型，discriminative model）。 隐马尔可夫模型(Hidden Markov models) HMMs 是基于假设可观察序列 $\\mathbf{x}$ 的元素实际上依赖于位置上对应的隐藏序列 $\\mathbf{y}$ 的元素的 $P(\\mathbf{X}, \\mathbf{Y})$ 分布的生成模型，而这些隐藏元素又根据马尔可夫模型分布。条件独立假设共同遵循以下图形模型： 由于关于 $Y$ 的马尔可夫模型假设，有一个 $A$ 矩阵指定所有标签的转移概率，因此对于任何适当的 $k, i, j$， $$P(Y_k=y_j \\space | \\space Y_{k-1}=y_i) = a_{i j}$$ HMMs 还假设 $P(X \\space | \\space Y)$ 发射概率与位置无关：因此也有一个 $B$ 矩阵，对于任何 $k, i, j$， $$P(X_k= x_j \\space | \\space Y_{k}= y_i) = b_{i j}$$ 假设最终有一个包含每个可能 $y_i$ 标签的起始概率的 $\\Pi$ 向量： $$P(Y_1 = y_i) = \\pi_i,$$ 具体的 $\\langle \\mathbf{x}, \\mathbf{y} \\rangle =\\langle \\langle x_{l_1},\\dots,x_{l_n} \\rangle, \\langle y_{m_1},\\dots,y_{m_n} \\rangle \\rangle$ 对的概率可以计算为 $$P(\\mathbf{x}, \\mathbf{y}) = \\pi_{m_1} b_{m_1 l_1} \\prod_{i=2}^na_{m_{i-1} m_i}b_{m_i l_i}.$$ $A, B$ 和 $\\Pi$ 中概率的最大似然估计 (MLE) 可以通过简单计数来计算。如果训练数据集包含 $N$ 个序列，那么 $$ \\begin{equation} \\begin{gathered} \\pi_i = \\frac{C(\\mathrm{first~~element~~is~~} y_i)}{N}\\\\ \\nonumber a_{ij} = \\frac{C(\\langle y_i,y_j\\rangle)}{\\sum_kC(\\langle y_i,y_k\\rangle)}\\\\ \\nonumber b_{ij} = \\frac{C(y_i \\mathrm{~~emits~~} x_j)}{C(y_i)} \\nonumber \\end{gathered} \\end{equation} $$ 与其他基于计数的 MLE 方法类似，在数据稀疏（sparse）的情况下可能需要平滑处理。 维特比算法Viterbi algorithm 给定一个训练好的 HMM 及其 $\\pi, A, B$ 参数，以及一个长度为 $n$ 的输入序列 $\\mathbf{x}$，我们希望确定最可能的对应标签序列 $\\mathbf{y}$，即找到 $$\\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^n} P(\\mathbf{y} | \\mathbf{x}, \\Pi, A, B)$$ 这等价于 $$\\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^n} P(\\mathbf{x}, \\mathbf{y} | \\Pi, A, B)$$ 穷举搜索是不可行的，因为有 $|Y|^n$ 种可能的标签序列。 动机：最小和算法我们如何根据如下图所示的图表找到 A 和 B 之间的最低成本路径？ 与时间复杂度可能是 A 和 B 之间最短路径长度的指数级的暴力（brute）解决方案不同，我们可以使用一个简单的 消息传递 方法。 从 A 开始，每个节点 接收来自其前驱节点（predecessors）的关于它们从 A 的最小和距离的消息 基于这些消息，计算自己的最小和距离和入边，并 将其最小和距离发送给所有后继节点 最终，消息到达 B，B 能够计算出 A-B 的最小和距离，并且可以重建 A 和 B 之间的最小和路径。 Min-Sum 算法可以适应解决我们的问题，因为它可以在不进行任何显著更改的情况下用于最大化节点之间路径上的乘积（max-product），并且 HMM 的 transition/emission 概率具有所需的有向无环图结构： The Viterbi algorithm更正式地说，HMM 的 conditional independence assumptions 有以下结果：如果我们知道，对于所有 $y_i\\in Y$，值 $$ \\mathbf{y}^{n-1}_i = \\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in Y^{n-1}~\\wedge~\\mathbf{y}[n-1] = y_i} P(\\mathbf{x}[1:n-1], \\mathbf{y} ~|~ \\Pi, A, B) $$ （即以 $y_i$ 结尾的最可能的 $n-1$ 长度标签序列），那么最可能的 $\\mathbf{y}$ 可以通过仅比较 $|Y|^2$ 个延续来计算： $$ \\mathbf{y} = \\mathop{\\mathrm{argmax}}_{\\mathbf{y}\\in \\{\\langle \\mathbf{y}_i^{n-1},~y \\rangle ~|~ i \\in 1\\dots |Y|~\\wedge~ y \\in Y\\}} P(\\mathbf{x}, \\mathbf{y} ~|~ \\Pi, A, B) $$ 这就提出了以下算法： 算法通常通过逐步填充一个 $|Y| \\times \\mathrm{length}(\\mathbf{x})$ 表来实现。在前向传递中，它 计算 $y_i^t$ 的概率，并 维护到最可能的 $\\mathbf{y}^{t-1}$ 的反向引用 在后向传递中，选择最可能的 $y_i^n$ 并通过跟随反向引用恢复 $\\mathbf{y}$。 维特比是一种 动态规划 算法，与穷举搜索形成鲜明对比，其时间复杂度为 $\\mathcal O(\\mathrm{length}(\\mathbf{x})|Y|^2)$ 跟踪部分 $\\mathbf{y}_i^t$ 序列元素及其概率的表仅占用 $\\mathcal{O}(\\mathrm{length}(\\mathbf{x})|Y|)$ 空间。 直接计算要比较的概率需要乘以非常接近于零的数字，因此通常使用对数概率的和来进行计算。 注意：正如我们所见，维特比算法也被称为 最小和 或 最大积 算法的应用。 判别序列标注方法Discriminative methods 与朴素贝叶斯序列分类器类似，HMM 是生成模型，建模输入和标签的概率，这在我们的设置中是不必要的。我们可以通过“反转”输入和标签之间的箭头并对 $\\mathbf{X}$ 进行条件化来构建类似结构但判别的模型： 最大熵马尔可夫模型Maximum entropy Markov models (MEMMs) 根据前面的图形模型假设， $$ P(\\mathbf{Y}~|~\\mathbf{X}) = P(Y_1~|~ \\mathbf{X})\\prod_{m=2}^n P(Y_m|Y_{m-1}, \\mathbf{X}) $$ MEMMs 通过使 $Y_m$ 仅在当前观测 $O_m$ 上条件依赖来形式化这个通用模型： $$ P(\\mathbf{Y}~|~\\mathbf{X}) = P(Y_1~|~O_1)\\prod_{m=2}^n P(Y_m|Y_{m-1},O_m) $$ 那么 $Y_m$ 如何依赖于 $\\mathbf{X}$ 呢？诀窍在于如何定义 $O_m$。 特征函数$Y_{m-1},O_m$ 对被定义为 $\\mathbf{f}(y_k,\\mathbf{x}, m)$，其中 $f(\\cdot)$ 是一个基于 $Y_{m-1}=y_k$ 和 $x$ 在 $m$ 处生成 feature vector 的函数。 在 NLP 中，我们仅在要标注元素周围的上下文窗口内对local features进行条件化。由语言学家设计的一些用于词性标注的示例特征： 上下文窗口中 $x_m$ 周围的元素，例如 $\\langle x_{m-1}, x_{m}, x_{m+1} \\rangle$ 上下文窗口元素的后缀（固定长度） 上下文窗口元素的前缀（固定长度） 上下文窗口元素的大小写信息 前一个元素的词性标注 $y_k$ MEMMs个别的 $P(Y_m|Y_{m-1},X_m)$ 概率类似于使用 softmax 函数的multinomial logistic regression进行建模： $$ P(Y_m = y_i|Y_{m-1}=y_k,\\mathbf{x})=\\frac{\\exp (\\mathbf{w}_i \\cdot \\mathbf{f}(y_k, \\mathbf{x}, m))}{\\sum_{j=1}^{|Y|}\\exp (\\mathbf{w}_j \\cdot \\mathbf{f}(y_k, \\mathbf{x}, m))} $$ 其中每个 $\\mathbf{w}_i$ 是 $y_i\\in Y$ 标签的权重向量。 MEMM 这个名称来源于在 NLP 中，多项逻辑回归更常被称为maximum entropy。 标签偏置尽管 MEMMs 比 HMMs 更灵活（例如，标签可以依赖于上下文的其他特征而不仅仅是前一个标签），但它们也有重要的局限性。 也许最重要的是标签概率是局部归一化的：$\\sum_{y\\in Y}P(y~|y_{m-1}, \\mathbf{x}, m)=1$，无论模型对上下文有多“熟悉”，因此模型无法表达对给定上下文中的标签的一般低置信度。 这导致了所谓的Label bias问题：模型无法轻易从在低置信度情况下做出的过去标注错误中恢复。 示例一个词性标注器将句子 “cat sat” 标注为 ARTICLE VERB，因为 标注器无法从 &lt;S&gt; 处 cat 的偏斜后验分布（skewed posterior distribution）中恢复，使用局部归一化（图1）。 未归一化的 $\\mathbf{w}_i \\cdot \\mathbf{f}(\\cdot)$ 观测值（图2）显示 标注器对”cat“ 开始一个句子没有信心 全局 NOUN VERB 具有更高的分数（对数和沿边缘相加） 条件随机场线性链条件随机场（Linear chain Conditional Random Fields）是判别模型，旨在避免标签偏置。它们假设以下 undirected 结构： 根据这些假设， $$P(\\mathbf{Y}~|~\\mathbf{X}) = \\frac{1}{Z(\\mathbf{X})}\\prod_{m=1}^{n-1} \\phi_{m}(Y_m, Y_{m+1}, \\mathbf{X})$$ 与 MEMMs 有些类似，$\\phi_m(\\cdot)$ 势函数 （potential）通过特征函数和相应的权重向量线性建模。它们基本上是 softmax 的分子： $$\\phi_m(y_m, y_{m+1},\\mathbf{x})={\\exp (\\mathbf{w} \\cdot \\mathbf{f}(y_m,y_{m+1}, \\mathbf{x}, m))}$$ 关键区别在于归一化是全局的： $$P(\\mathbf{y}~|~\\mathbf{x}) = \\frac{\\exp(\\sum_{m=1}^{n-1}\\mathbf{w}\\cdot\\mathbf{f}(y_m,y_{m+1}, \\mathbf{x}, m))} {\\sum_{\\mathbf{y}'\\in Y^n}\\exp(\\sum_{m=1}^{n-1}\\mathbf{w}\\cdot\\mathbf{f}(y'_m,y'_{m+1}, \\mathbf{x}, m))}$$ 优化和推理MEMMs 和线性链 CRFs 都可以使用标准的凸优化技术进行优化，例如梯度下降，并且在训练模型后，可以使用维特比算法的变体有效地找到给定输入的最可能标签序列。","link":"/AI/NLP/NLP-Classification-SequenceTagging/"},{"title":"NLP-DependencyParsing","text":"依赖关系解析 依存解析任务句法解析（复习）Syntactic theories 旨在描述 “支配单词如何组合成短语、形成良构单词序列的规则或原则。” 在这种情况下，最重要的“良构序列”是句子：给定语言的句法理论的核心目标是找到 characterize/delineate 该语言良构句子的结构规则或原则。 如果一个句子具有满足所讨论理论的句法约束的结构描述或句法解析，那么它就是良构的。句法上的良构性并不保证连贯性或有意义。引用乔姆斯基的著名例子： Colorless green ideas sleep furiously. 在句法上是良构的但无意义，而 Furiously sleep ideas green colorless. 甚至不是良构的。 依存语法（复习）Dependency grammars 将单词之间的依存关系视为基本关系。 具体标准因理论而异，但通常在一个句子中，如果一个 $d$ 单词依赖于一个 $h$ 单词（等价地，$h$ 支配 $d$），则 $d$ 修饰 $h$ 的意义，使其更具体，例如 eats $\\Rightarrow$ eats bread, eats slowly 等 并且它们之间存在不对称的可省略关系：可以从句子中省略 $d$ 而保留 $h$，反之则不行 依存语法对一个良构句子中的依存关系施加了重要的全局约束，例如， 恰好有一个独立的单词（句子的根）。 所有其他单词直接依赖于一个单词。 由于这些约束的结果，句子的直接依存图是一个树。 大多数依存语法使用typed direct dependencies：存在有限的直接依存类型列表，并对它们何时可以成立施加特定约束。 投射性依存解析树的一个重要（但并非总是满足）要求是projectivity： 如果一个 $w$ 单词直接依赖于 $h$，并且一个 $w’$ 单词在句子的词序中位于它们之间，那么这个 $w’$ 的支配词要么是 $w$，要么是 $h$，或者是位于它们之间的另一个单词。 更不正式地说，投射性条件表明依存关系是嵌套的，单词之间不能有交叉依存关系。 依存语法的优势依存语法已成为 NLP 中使用的主要句法理论，因为 依存树在许多方面比短语结构解析树更简单的结构（例如，每个单词只有一个节点）； 依存图提供的句子谓词-论元分析是事件或框架导向语义分析的一个很好的起点。 Universal Dependencies (UD) 框架已被创建，以促进不同语言之间的一致 annotation。 语义表示的可用性比较事件语义方面 依存解析给定一个句法理论（syntactic theory），解析任务是为输入句子分配满足该理论 constraints/conditions 的句法结构。对于依存语法，这意味着分配一个依存结构： 识别句子中单词之间的直接依存关系 以这样的方式使它们共同构成一个满足所有理论约束的依存树 在现代 NLP 实践中，解析任务所依据的依存语法通常是隐式指定的，使用所谓的树库，即由带有解析树注释的句子组成的数据集。 这使得解析成为一个结构化的监督学习任务：给定一个由大量 $\\langle \\mathrm{sentence}, \\mathrm{parse} \\space \\mathrm{tree} \\rangle$ 对组成的训练集，学习预测未见句子的解析树。 性能指标对于依存语法解析器，最常用的评估指标是 UAS：Unlabeled Attachment Score（无标签依存准确率）正确依附于正确支配词的单词百分比 LAS：Labeled Attachment Score（有标签依存准确率）正确依附于正确支配词并具有正确依存标签的单词百分比 解析算法像大多数序列标注方法一样，依存解析算法使用将预测任务分解为结构元素的单个决策的策略。在这种情况下， 单个决策是关于单词之间的个体依存关系 主要问题是确保这些单个决策能形成一个连贯的依存树 依存解析器通常使用 transition-based，或 graph-based的方法 基于转换的解析该算法基于一个解析过程的形式模型，该模型从左到右移动要解析的句子，并在每一步选择以下操作之一： 将当前单词分配为某个先前看到的单词的中心词（head） 将某个先前看到的单词分配为当前单词的中心词 或者推迟对当前单词的任何处理，将其添加到存储中以供以后处理 该过程的形式模型由以下组件组成： 一个缓冲区，其中包含未处理的输入标记 一个堆栈，包含当前操作的标记并存储推迟的元素 一个依存图，用于为输入句子构建 模型配置在过程的每一步，模型处于某种配置中： 初始配置解析过程从特殊的初始配置开始，其中 缓冲区包含输入的所有单词 堆栈包含依存图的单个根节点 并且依存图是空的（不包含任何依存边） 解析过程在每一步，都会执行一个允许的配置操作（配置转换）。允许的操作有所不同；在所谓的 arc standard 方法中使用了一组非常简单的操作： 带标签 $l$ 的左弧：将边 $s_2\\xleftarrow{l} s_1$ 添加到图中并移除 $s_2$（$s_2$ 不能是根元素） 带标签 $l$ 的右弧：将边 $s_2\\xrightarrow{l} s_1$ 添加到图中并移除 $s_1$（$s_1$ 不能是根元素） 移位：从缓冲区中移除第一个单词 $w_1$ 并将其放在堆栈顶部 当达到一个无法执行任何操作的配置时，过程结束。 该过程保证在有限步数后结束，在此配置中，缓冲区为空，并且创建的依存图是整个输入的良构依存树： 它会结束，因为在每一步中我们都会减少依存图的 “collective token distance” $$ 2 \\cdot \\#(\\mathrm{缓冲区中的tokens}) + \\#(\\mathrm{堆栈中的tokens}) $$ 缓冲区必须为空，因为否则移位操作将可用，并且堆栈只能包含根元素，原因类似 每个输入标记在图中恰好有一个中心词 图中不能有circle 选择正确的操作解析器如何决定选择哪个操作？模型必须充当一个 可能配置的分类器：如果有 $n$ 个标签，那么将会有 $2n+1$ 个 actions/classes。 为了为这个分类器提供训练数据，依存树库注释必须转换为包含 $$ \\langle \\mathrm{parser~~configuration}, \\mathrm{correct~~action} \\rangle $$ 对的监督数据集，即，treebanks 必须转换为关于“parsing oracle”动作的数据集，解析神谕总是选择正确的操作。 将解析树“转换为神谕操作”给定正确的解析树，可以使用一个简单的算法重建oracle的配置和操作： （显然）从堆栈中仅包含根和包含完整输入的缓冲区开始 如果选择左弧操作会导致正确的边，则选择该操作并附上正确的标签 否则，如果选择右弧操作会（i）导致正确的边（ii）所有以 $s_1$ 为中心词的依存关系已经添加到依存图中，则选择该操作并附上正确的标签 否则选择移位操作 替代操作/转换集Arc-standard 并不是基于转换的解析器所使用的唯一转换系统 — 一个重要的替代方案是 arc-eager，它可以显著简化某些推导。Arc-eager 有以下操作： 右弧: 添加边 $s_1\\xrightarrow{l} w_1$ 并将 $w_1$ 移动到堆栈顶部 左弧: 添加边 $s_1\\xleftarrow{l} w_1$ 并从缓冲区中移除 $w_1$。前提条件：$s_1$ 尚未有中心词 Shift: 将 $w_1$ 移动到堆栈顶部 Reduce: 从堆栈中移除 $s_1$。前提条件：$s_1$ 已经有中心词 非投射性问题Arc-standard 和 arc-eager 转换只能生成投射树，但大多数树库包含相当数量的非投射句子： 非投射性：解决方案 使用可以创建（一定数量的）非投射边的转换系统 伪投射解析： 找到一个 $\\varphi$ 映射，将所有相关的（投射和非投射）树映射到投射树 对于训练，使用 $\\varphi$ 对训练集进行“投射化”，并在转换后的数据集上训练解析器 对于预测/推理，应用 $\\varphi^{-1}$ 到解析器的输出，以获得最终的（可能是非投射的）结果 分类器特征从配置中提取适当的特征对于性能至关重要。传统的（例如基于感知器的）解决方案使用复杂的、专家设计的特征模板，例如， 与其他领域一样，手动特征工程和数据稀疏性的问题导致了深度学习解决方案的发展，这些解决方案依赖于embeddings进行分类。Stanford 神经依存解析器是一个简单但具有代表性的例子： 架构所使用的模型架构是 NLP 中典型的分类架构： 在出现基于深度学习的解析器之前，主要使用线性模型（使用 weighted perceptron 或 SVM 作为学习算法），但也存在基于 k-NN 的解决方案 在深度学习中，在出现基于 transformer 的解决方案之前，CNN 和 LSTM 模型占主导地位，这些解决方案在很大程度上依赖于预训练的上下文嵌入，如 BERT 基于图的解析两种对解析树进行评分的对比方法： 基于转换的方法 将对依存图的评分问题转化为对一个稍微复杂的图构建过程步骤的评分 基于图的解析器，相反，直接对图本身进行评分，并尝试找到得分最高的依存图： $$\\hat g =\\underset{g\\in G}{\\operatorname{argmax}}~S(g)$$ 一种简单但表现出色的方法是： 创建一个由所有可能的依存边组成的完全连接、有权重、有向图（如果有 $n$ 个标记和 $l$ 个标签，则有 $n(n-1)l$ 条边） 单独对边进行评分，然后 找到总得分最高的（方向正确的）树 假设是 $$S(g) = \\sum_{e\\in g} S(e)$$ 这种对图进行评分的方法称为edge-或arc-factored方法。 寻找得分最高的树显然，对所有可能的图进行暴力搜索是不可行的。幸运的是，有一些相对快速的算法可以找到得分最高的树（所谓的maximum spanning tree）。 一个常用的算法是 Chu-Liu-Edmonds 算法，其时间复杂度为 $\\mathcal O( n^3 l)$，其中 $n$ 是输入标记的数量，$l$ 是可能的标签数量。通过将边缘得分存储在一种特殊的数据结构中，即所谓的斐波那契堆，可以将其减少到 $\\mathcal O(n^2l)$。 边缘评分特征基于图的依存解析器是regressors：它们必须为输入标记之间的可能边缘生成得分。所使用的特征模板类似于基于转换的解析器： 依存词及其词缀（affixes）、词性（POS）等 中心词及其词缀、词性等 边缘标签 句子中中心词和依存词之间的关系，例如它们之间的距离 对于神经架构，节点和边缘标签的嵌入 Architectures与基于转换的情况类似，多年来已经开发了经典的机器学习和神经网络的基于图的解析器，性能最高的解析器使用自注意力层。 一些最近架构的一个重要方面是由 @dozat2016deep 的论文引入的，即它们对同一单词的中心词和依存词表示使用不同的嵌入集。 vs这两种方法之间存在重要的权衡。 时间复杂度: 解析 $n$ 个标记并有 $l$ 个可能的边缘标签的时间复杂度为 对于基于转换的解析器通常是 $\\mathcal O (n)$，而 基于图的解析器预先计算所有可能边缘的分数，因此它们从 $\\mathcal O(n^2 l)$ 操作开始，并且还要加上找到最大生成树的时间。即使我们将找到标签视为一个单独的任务，$\\mathcal O(n^2)$ 的复杂性也是不可避免的 非投射性: 如我们所见，非投射性是最广泛使用的转换系统的一个严重问题，需要特殊处理。基于图的方法没有这个问题。 性能: 基于转换的系统往往在处理长距离依存关系时存在问题，而基于图的模型没有这个性能问题。因此，依存解析器的排行榜通常由基于图的系统主导。","link":"/AI/NLP/NLP-DependencyParsing/"},{"title":"NLP-DatasetsBenchmarks","text":"数据集，基准测试，引导 介绍众所周知，LLM 需要庞大的文本语料库进行（预）训练。实际上，我们使用几种类型的数据集来训练和/或评估 LLM： 预训练语料库 微调数据集 指令微调数据集 基准测试 在本讲座中，我们将详细讨论这些类型，并了解每种类型的最流行示例。 预训练LLM（顾名思义）总是通过某种形式的语言建模目标进行训练： 因果（自回归）语言建模 掩码语言建模（MLM） 等等 这种类型的预训练只能在庞大的文本语料库上进行（取决于模型大小）。LLM 需要比 人类儿童/年轻人 遇到的文本数据多得多。另一方面， LLM 没有多感官输入（有些在某种程度上有） 我们之前看到一次性标签会减慢收敛速度 预训练语料库大小 来源预训练语料库通常来自多种来源的混合： 网络文本 书籍和娱乐 学术存储库 程序代码 对话数据 杂项 the Pile 的组成：一个 800GB 的英语语料库用于 LLM 预训练。它由 22 个数据集创建，组成如下： 网络文本通常是任何预训练语料库中最大的组成部分。 优点： 易于获取，通常以网络抓取格式存在 数据量大 缺点： 质量参差不齐，通常低于其他来源 即使是好的页面也包含非内容元素（例如广告） 文本重复 偏见、有害、极端内容 AI 生成/自动翻译的内容 网络文本语料库Corpora Common Crawl (CC): 一个免费的、开放的网络抓取数据存储库，以 WARC 格式提供 大约每月一次新的抓取 数据量达到 PB 级；2023 年 9/10 月的抓取数据为 100TB 构成了大多数用于预训练的网络文本语料库的基础 Web ARChive 格式 EnglishC4: 从 2019 年 4 月的 CC 转储创建；750GB 用于预训练 T5 过滤包含不良词汇的文档（减少 $3\\times$） WebText: GPT-2 的预训练语料库 800 万文档，40GB 从“策划”的文档中创建：Reddit 上至少有 3 个 karma 的外部链接 不包括 Wikipedia，以避免 GPT-2 的测试集与训练集重叠 专有 OpenWebText: WebText 的开源重新实现 MultilingualOSCAR: 一个巨大的多语言语料库，由单个每月 CC 抓取创建 Ungoliant 数据管道 标记数量： 英语：3770 亿 匈牙利语：46 亿 约鲁巴语：1 千 ROOTS: 一个 1.6TB 的语料库 由 BigScience 编译 国际研究人员合作 Hugging Face 支持 用于预训练 BLOOM ROOTS 中的语言ROOTS 的语言分布。此外，与其他语料库（例如 OSCAR）相比，英语被高度下采样。 mC4: C4 的多语言版本 (Hugging Face HUB) 基于整个 CC 语料库（截至 2021 年），因此有足够的数据用于中等规模的语言，如匈牙利语（390 亿标记） 并未真正清理过，因此标记数量有些乐观 llm-datasets 数据集和脚本的 GitHub 仓库 包含 Common Crawl 以外的语料库 如何预处理 Common Crawl基于 Common Crawl 创建特定语言的网络文本语料库看似简单，但实际上是一个多步骤的过程，存在许多陷阱。这里我们回顾一下 cc_corpus 所采取的步骤，这是用于创建 Webcorpus 2 的管道。 要求：下载所有（多个）每月转储，因为只有英语在一个转储中有足够的标记。 下载索引 CC 索引是按域名而不是按语言划分的 例如，对于匈牙利语，我们下载 .hu 顶级域名 根据 OSCAR 统计，包含许多匈牙利语页面的其他域名 在每月索引转储之间去重 URL 下载数据 CC 不应被 DDoS WARC 文件需要大量空间 去除样板 去除网页的非内容部分（导航、广告、图片、表格等） 我们使用 jusText 和自定义代码去除 JS / cookie 警告 需要处理各种文件类型（HTML、RSS、文本等） 过滤 语言过滤 基于质量的过滤： 文档长度 还可以使用例如样板比例、某些 HTML 标签的长度等 去重 文档级去重以保持文本完整性 MinHash–LSH 设置 需要大量内存，否则会非常慢 可选：按域名去重频繁段落（基于内容的样板去除） 硬件设置： 在单个服务器上运行；多服务器通信正在进行中 所有类似映射的步骤都是高度并行的，以充分利用 多核/CPU 服务器 一台具有 768GB 内存的服务器用于去重 特殊网络文本数据集Wikipedia: 非常优质的编辑资源，大多真实 大小取决于语言，例如英语是匈牙利语的 10 倍 预处理并不简单，因为标记格式： wikiextractor 尝试解决这个问题 zim_to_corpus 从 Kiwix 的预处理 .zim 存档中提取文本 Stack Overflow, Reddit: 策划的数据集（points / karma） 可用于问答、编程等 编辑文本编辑文本是高质量文本的重要来源。不幸的是，与网络文本相比，数量上要难得多。 编辑文本通常有两种格式： 数字原生：从一开始就为数字消费准备的文本。通常可以直接使用，但 可能需要去除样板：表格、图形、页眉/页脚 编码问题确实会发生，尤其是 PDF 扫描：原本在纸上的数字化文档。版面分析 和 光学字符识别 (OCR) 的质量可能从可接受到非常糟糕不等。 编辑文本 / Prose自 BERT 以来，常规散文（如书籍）一直是 LLM 训练方案的一部分。文本的水平因体裁而异，导致训练语料库多样化。 BookCorpus 一个由 7,185 本自出版书籍创建的 985M 字语料库 用于训练 GPT 和 BERT，但后来被撤回，不公开提供 BookCorpus2 (the Pile)：BookCorpus 的扩展，大约 17k 本书 已出版书籍语料库： Books1-2 (GPT-3)：67B 标记 Books3，Project Gutenberg (the Pile)：分别约 187k 和 27k 本书 匈牙利电子图书馆 (MEK)：32,830 本书，800M 标记 OpenSubtitles： 从电影和电视字幕创建了 1689 个双语文本 可以从中提取大约 300M 字的语料库 语料库主要由对话组成 书籍等是预训练语料库的重要且非常有用的部分。然而，它们并非完全安全： 可能存在有问题的内容（色情、有害等） 在模型中使用它们可能导致 版权侵犯 编辑文本 / Professional通常是非常高质量的专业文本，具有自己的术语。 学术存储库： 非常高水平的文本 许多表格、图形等，打断文本流 通常需要大学访问权限（和爬虫）来下载论文 议会记录： 国家 / 欧盟 / 等等 有些可能提供 REST API，有些需要爬取 法律、裁决、法规等 新闻： 大量且重要的来源，但也可能有偏见和有害内容 极端重复 通常在付费墙后面 私人数据： 公司规则和公司内部通信 知识等 杂项数据对话 对于聊天机器人非常重要 对于通用对话：电影、书籍等 最重要的来源：互联网论坛、实际客户服务互动 编程 来自 CVS 服务（GitHub、SourceForge 等）的开源项目 版权和许可证违规是一个可能带来法律后果的问题 指令指令获取我们在前一讲中讨论了指令微调数据集的编译方式： 手动 / 众包努力 从用户收集数据 将 NLP 任务转换为指令 自我指令 我们已经看到 FLAN 如何将 NLP 任务转换为指令，但我们跳过了第一类。 Manual Instructions手动创建指令数据集需要众包（crowdsourcing）。两个例子： Databricks 的 **Dolly**： 包含 15,000 对提示/响应对 由 5,000 多名 Databricks 员工创建 **ShareGPT**： 用户分享他们与 ChatGPT 的对话 质量非常好，但由于 OpenAI 的许可证存在问题 被用于训练 Vicuna LAION 的 Open-Assistant 由志愿者编译 英语和西班牙语代表性很好，但其他语言代表性不足 Self-instruct两个自我指令数据集的例子： Alpaca： 使用 OpenAI 的 text-davinci-003 创建的最著名的自我指令数据集 页面包含有关如何使用 GPT3 进行指令生成的良好建议 由于 GPT3 许可证，不能用于商业目的 WizardLM： 使用 Evol-Instruct 从 Alpaca 创建 微调微调数据集已经证明，具有分类器头的 LLM 可以在 NLP 数据集上进行微调，以达到最先进的结果。这包括 传统的 NLP 任务（NP 分块、NER、依存解析等） NLU 任务（问答、自然语言推理等） 各种分类数据集（情感分析、主题分类等）这些通常在树库上进行训练 微调数据集具有训练-开发-测试拆分，因此它们也作为基准数据集。 传统数据集 任务 英语 命名实体识别 CONLL 2003 其他数据集 NP 分块 CONLL 2003 依存关系 Universal Dependencies 解析 Penn TreeBank 其他资源 可以在 NLP-progress page 上跟踪 NLP 任务的进展 有各种 NLP 数据集列表： Awesome NLP / Datasets nlp-datasets Awesome Hungarian NLP / Datasets NLU 数据集这些数据集包括传统 NLP 可以（和不能）解决的任务，但 LLM 可以。因此，这些数据集是 LLM 的便捷基准。 **GLUE**： 一个包含 9 个任务的 NLU 基准（句子相似性、释义、QA 等） 测试集不共享；在线排行榜 **SuperGLUE**： 8 个精心策划的任务（开放、困难、宽松许可等） **SQuAD2.0**： 由众包工人编译 10 万个问题加上 5 万个对抗性、无法回答的问题 **MMLU**： 一个仅用于测试的基准，包含 57 个主题中的 15,687 个选择题 对抗性基准测试问题：基准测试被越来越好的模型“快速”清除。我们能否创建更难的基准，使其持续时间更长？ 模型脆弱性：证据表明 自然语言推理（NLI）数据集由于（注释者）偏见而表现出虚假的统计模式 模型实际上学习了这些模式，而不是推理 因此，它们是脆弱的，可以被非专家注释者打破 想法：人类与模型循环启用训练（HAMLET）。 对抗性 NLI对抗性 NLI (Adversarial) 通过在注释者和模型之间引入“军备竞赛”编译而成。 这导致 一个良好的训练集，可以很好地转移到其他 NLI 基准 一个非常难的训练集 测试工具LLM 测试越来越多地通过 测试工具 自动化： Google 的 BIG-bench EleutherAI 的 lm-evaluation-harness 两者都包含 200 多个任务，并提供 新任务的轻松集成； 使用所有任务评估模型。 可重复的测试使得竞争成为可能，例如 **Open LLM Leaderboard**。 Bootstrapping什么是引导？引导 是一种使用现有资源创建新资源的方法。 在我们的例子中，我们将使用现有的预训练模型来创建新的数据集以训练新模型。我们通常使用现有的最大、性能最好的模型。在 2023 年底，这些模型是私有的 GPT-4 和开源的 LLaMa2-70B。 引导是： 成本效益高 快速 易于实施 能够生成高复杂度数据 有风险（许可证问题、质量问题） 使用现有模型生成数据“自我”指令在这里，我们使用现有模型为我们自己的模型生成数据。在这种情况下，另一个模型是教师，我们的模型是学生。 重要区别：与蒸馏相反，我们不使用教师在向量级别的预测，而是使用教师在数据集中的标记级别输出。这样就不需要直接访问教师模型。 斯坦福 Alpaca 声称，这种方式的指令微调具有成本效益且快速。它可以在几百美元内完成。 零样本链式思维可靠的链式思维（chain-of-thought）提示需要一些示例才能工作。通过使用 CoT 提示，我们可以为给定主题生成大量的 CoT 完成数据集。 WizardLM 通过使用 Evol-Instruct 逐步演变给定任务的指令，采用了一种更抽象的指令生成方法。这样生成的指令将覆盖任务空间的更广范围，并具有更复杂的提示。 我们提示我们的 LLM 生成指令的修改版本，然后使用这些版本生成数据集。这些修改步骤可以链接在一起。 Evol-Instruct任务演变的示例（对于基本任务“1+1=？”）： 深化：在什么情况下 1+1 不等于 2？ 增加推理：如果 x^3 + 2x + 3 = 7，x 的值是多少？ 具体化：如果你有一个苹果，有人给你另一个香蕉，你有多少水果？ 添加约束：如何在哥德巴赫猜想中证明 1 + 1 = 2？ 复杂输入：1/(sqrt(2) + 4^2) = ？ 广度演变（变异）：真空中光速是多少？ 增加演变推理（上述）：光在真空中比声音快多少倍？ 演变步骤 移除演变当以下情况发生时，消除中间结果： 演变后的指令相比原始指令没有提供任何信息增益。使用 ChatGPT 来做出这个决定 演变后的指令使得 LLM 难以生成响应。如果生成的响应包含“对不起”且长度相对较短（即少于 80 个单词），通常表明 LLM 难以响应演变后的指令 LLM 生成的响应仅包含标点符号和停用词 演变后的指令明显复制了一些来自演变提示的词语，例如“给定提示”、“重写提示”、“#重写提示#”等 EvolInstruct 的效果EvolInstruct 微调能够提高高复杂度任务的性能，如下图所示。 OrcaEvolInstruct 在指令生成方面引入了多样性。与此相反，Orca 深入研究了响应生成方面，特别是推理和解释生成。在原始论文中，他们为 LLM 定义了各种系统提示，以指导响应生成风格。 一些示例包括： 你是一个 AI 助手。提供详细的答案，使用户不需要在外部搜索来理解答案 你应该描述任务并解释你的答案。在回答选择题时，首先输出正确答案。然后解释为什么其他答案是错误的。想象你在回答一个五岁孩子的问题 解释调优的优势小模型通过解释调优可以轻松解决困难和专业任务。 小模型通过解释调优可以轻松解决困难和专业任务。 模型评估评估复杂模型很难，因为没有明确的方法来评估开放域性能。常见的方法包括人工和 LLM 评审。 人工评审昂贵且缓慢，但可以通过众包来加速和稳定这一过程，例如 Chatbot Arena。Chatbot Arena 是一个评估聊天机器人的平台，用户可以与多个机器人聊天并表示他们的偏好。 LLM 评审更快且更便宜，但偏见更大。利用方法包括：两个答案的成对比较、单个答案评分（分数分配）、参考引导评分（分数分配）。 模型偏见根据 LLM 的评审，评审员倾向于第一个答案以及较长的答案。值得使用对称评估。“重命名”提示表明某些模型（如 Claude-v1）也对名称（如助手 A、助手 B 等）存在偏见。 评审员 提示 一致性 偏向第一个 偏向第二个 错误 Claude-v1 默认 23.8% 75.0% 0.0% 1.2% Claude-v1 重命名 56.2% 11.2% 28.7% 3.8% GPT-3.5 默认 46.2% 50.0% 1.2% 2.5% GPT-3.5 重命名 51.2% 38.8% 6.2% 3.8% GPT-4 默认 65.0% 30.0% 5.0% 0.0% GPT-4 重命名 66.2% 28.7% 5.0% 0.0%","link":"/AI/NLP/NLP-DatasetsBenchmarks/"},{"title":"NLP-DialogSystems","text":"Chatbot 介绍对话系统 它们通过进行对话与用户交流 对话的形式可以是 口语 书面（文本） 混合：除了语音和/或文本对话外，还可以包含带有按钮的对话框等GUI元素 典型的环境包括 消息平台（例如，Slack和Facebook Messenger） 智能手机助手（Siri，Cortana等） 智能音箱（例如，Alexa） 汽车（例如，Google Android Auto） 对话系统的类型通常区分 任务导向 （task-oriented）和 开放域 （open domain）对话系统（后者也称为 聊天机器人）。 任务导向对话系统：目标是在预定义的任务集中完成一个或多个任务，例如，订购某物、打电话、转账、获取路线等 开放域对话系统： 目标是开放式和非结构化的扩展对话 没有预定的任务（或任务集）作为目标 在许多情况下，主要结果只是“娱乐” 可以作为主要任务导向系统的附加组件 另一种重要的分类是根据谁发起和控制对话。对话可以是 用户发起：例如，手机助手。对话通常非常简短，例如，用户问题和系统回答使用手机助手 系统控制：变体包括 系统发起并控制，例如通过警告或提醒用户某事 用户通过请求指示发起，从那里系统指示而无需用户的基本输入 用户通过请求服务发起，从那里系统通过提问帮助用户“填写问卷” 混合主动性：有几个回合，系统和用户都可以主动（initiative） — 这些通常是开放域对话系统 一般对话需求系统需要能够再现人类之间对话的重要特征，包括但不限于： 语境建立Grounding，通过说话者不断确认理解对方所说内容，建立一个不断演变的 共同语境（common ground）。 说话者 引入 新的信息 确认 添加的信息（通过手势或口头确认） 如果需要，请求澄清 邻接对Adjacency pairs，话语类型与响应期望相关联： 问题 $\\Rightarrow$ 答案 提议 $\\Rightarrow$ 接受 赞美 $\\Rightarrow$ 降低 等 question $\\Rightarrow$ answer proposal $\\Rightarrow$ acceptance compliment $\\Rightarrow$ downplayer etc. 语用推理Pragmatic inferences，我们通过假设话语（utterances）是 相关的 信息丰富的 真实的 清晰简洁的（或者至少说话者的目标是这样）来推断说话者的意思 开放域对话系统方法 基于规则 传统上，基于规则的“模式匹配和替换”类型系统被使用，著名的有 Eliza (1966)，模拟罗杰斯心理学家 PARRY (1971)，用于研究精神分裂症 基于语料库 更现代的替代方法当然是构建一个基于语料库（Corpus）的系统，该系统在包含大量对话的数据集上进行训练。 基于语料库的方法 检索（retrieval）响应：使用数据集中 与最后一轮最相似的发言 是与最后一轮最相似的发言的响应的发言 相似性可以是完全预训练的，或基于 训练/微调 的嵌入 生成响应：在数据集上训练一个生成模型，典型的架构包括： 基于RNN或Transformer的编码器-解码器 一个微调的“预测下一个”语言模型，例如GPT类架构。我们将在下一讲中讨论这种替代方法 任务导向对话系统Task-oriented dialog systems 框架大多数任务导向对话系统（TODs）基于（某种变体的）框架，即用户意图的结构化表示，包含可以用 值 填充的 slots。槽值可以是另一个框架。 基于框架的TOD系统会提出问题，帮助填充框架槽，直到填满当前目标任务所需的所有槽，然后执行任务。 早期基于框架的架构早期基于框架的任务导向对话系统（TODs）具有以下组件： 控制结构：一个生产规则系统，控制如何操作槽值以及根据实际状态和用户输入提出哪些问题 自然语言理解（NLU）：一个基于规则的NLP模块，确定话语的domain（一般主题）、意图（intent，具体目标）和槽 和 填充值 自然语言生成（NLG）模块：一个基于模板的系统，用于生成适当的系统问题给用户 可选的自动语音识别（ASR）模块，通常基于任务特定的词汇和 语法/语言 模型 Natural language generation Natural language understandingNLU 任务是确定每个用户话语的领域、意图和槽填充。例如，对于 Show me morning flights from Boston to San Francisco on Tuesday 我们希望得到如下分析： DOMAIN AIR-TRAVEL INTENT SHOW-FLIGHTS ORIGIN-CITY Boston ORIGIN-DATE Tuesday ORIGIN-TIME morning DEST-CITY San Francisco 对话状态系统现代、更复杂的基于框架的TODs方法的化身是 Dialog-state systems 架构。 与早期系统相比，主要区别在于 将 控制 分解为两个独立的模块： 对话状态跟踪器（也称为 belief state tracker），根据对话历史计算当前更新的对话状态（用户目标，即填充的槽值等） 对话策略，根据实际状态确定下一个系统动作 在所有模块中广泛使用 机器学习方法，而不是早期系统的基于规则的方法 基于语音的系统的完整架构： 实现NLU组件识别用户话语中的领域、意图和槽值/实体可以通过分类器和序列标注模型来实现： 对话状态跟踪基于NLU的（N-best）输出 和/或 对话历史，跟踪器确定发生的对话行为，以及当前（更新的）对话状态。这可以通过生成一组候选状态并对其进行评分来实现： 评分器可以基于像BERT这样的预训练编码器： 除了对完整的对话状态进行评分，还可以单独对（槽，值）对进行评分： NLU 如前两个示例中所示，现代对话状态跟踪器经常直接使用用户话语作为输入，而不需要在对话架构中独立的NLU组件 基于机器学习的NLU和对话状态跟踪模块的对话系统通常通过首先开发一个基于规则的系统来启动，并使用它来生成一个“银”标注的数据集（当然，验证数据集仍然是完全手动标注的。） 对话策略Dialog policy 决定系统接下来应该采取的行动，基于对话状态和可能的对话历史的其他元素。最重要的行动类型是 系统对话行为（例如，提问、确认请求等）、查询数据库 和外部 API 调用。 对话策略通常可以实现为一个分类器，因为通常有一个有限（且通常较小）的可能行动集合可供选择。策略模块可以实现为 基于规则 的系统 使用 监督学习 的机器学习模型 使用 强化学习 优化的机器学习模型（可能在监督预训练之后） NLG最后，当所需的行动是一种系统话语时，NLG 组件根据具体的行动、对话状态和（可选的）对话历史生成实际的句子。 NLG 任务通常分解为 话语规划：规划话语的内容（应提到哪些槽/值，可能还有它们的顺序和分组） 话语实现：实际生成计划内容的自然语言表达 简化生成任务和缓解数据稀疏性的一种广泛使用的策略是生成 去词化模板，其中包含槽值的占位符，然后用所需的槽值替换它们。 话语或其模板的生成可以实现为基于规则的系统或机器学习模型；最近的实现通常使用 序列到序列模型： 简化的架构和模型广泛使用的seq2seq模型用于实现独立的对话状态系统模块，以及在单独训练的模块之间的错误传播，导致了提出训练一个（基于预训练语言模型的）单一多任务seq2seq模型，SimpleTOD，同时用于 对话（信念）状态跟踪 对话策略 自然语言生成（NLG） 当然，类似SimpleTOD的方法仍然需要一个带有对话动作和对话状态标注的数据集进行训练，并且需要关于领域意图和 实体类型/槽 的通用信息。因此，为具体任务或任务训练的模型不能用于其他任务，除非重新训练。 一个有趣的研究领域是训练完全通用的任务导向对话模型，这些模型明确地以任务导向对话描述为条件，即所谓的 对话模式图 （dialog schema graphs）。 对话模式图 基于模式的任务导向对话数据集有几个基于模式的任务导向对话数据集可用，这些数据集除了包含注释对话外，还包含模式图： STAR 数据集包含 13 个领域中的 5,820 个任务导向对话，共 127,833 个话语 SGD Schema-Guided Dialog 数据集包含 20,000 个对话 SGD-X 数据集“通过为每个模式扩展 5 个众包变体来扩展 SGD 数据集，这些变体在语义上相似但风格上多样” 评估评估开放域对话系统基于某种类型的距离与预定义的正确行为的度量不起作用，因为在任何给定回合中正确响应的集合太大。相反，人类 参与者 （participants）或 观察者 （observers）根据各种质量方面评估系统产生的对话行为，例如： 对话有多 吸引人 话语是否 像人类 响应在上下文中是否 有意义 是否 流畅 是否避免 重复 评估任务导向对话系统一个核心指标是 绝对任务成功率：根据用户的意图，多少百分比的对话导致任务成功执行。 对于基于槽的系统，还可以测量 槽错误率：系统正确填充的槽的百分比。 除了这些与成功相关的指标外，用户评估中的 用户满意度 和 总体对话质量 也非常有用。（细粒度指标可以测量类似于开放域系统的方面。）","link":"/AI/NLP/NLP-DialogSystems/"},{"title":"NLP-Inference","text":"推理，生成，水印 介绍随着语言模型变得越来越大，关于如何有效地使用它们、如何使它们的答案更加多样化（“创造性”），以及如何防止它们生成有害内容的问题也随之而来。我们将讨论以下主题： 标准LLM推理方法和参数 “边缘”和服务器推理 辅助推理和推测 引导文本生成 推理时模型“适应” 水印 标准LLM推理回顾：采样 贪婪解码：总是选择最可能的标记 $w_t = \\arg\\max_{w} P(w|w_{t-c}, \\ldots, w_{t-1})$ 随机采样：从分布 $P(w|w_{t-c}, \\ldots, w_{t-1})$ 中采样 束搜索：在每一步保留 $b$ 个最可能的序列 随机束搜索：从 $b$ 个最可能的序列中采样 概率分布Softmax 用于将模型的 logits 转换为概率分布。为了从最可能的标记中提取概率质量（从而使模型更加“创造性”和不那么重复），我们可以使用温度缩放： $$P(w|w_{t-c}, \\ldots, w_{t-1}) = \\frac{\\exp(\\textit{logits}(w) / T)}{\\sum_{w’} \\exp(\\textit{logits}(w’) / T)}$$ 其中 $T$ 是温度参数。 Top-k 采样计算整个词汇表的 softmax 是昂贵的，低评分的标记通常不有趣，因此在每一步几乎限制词汇表到前 $k$ 个标记是可行的。这称为 top-$k$ 采样。 Top-p 采样核采样，或 top-$p$ 采样，以不同的方式限制词汇表：它保留最可能标记的最小集合，其组合概率质量达到（并超过）阈值 $p$。 给定以下标记和概率集： 苹果 (0.3), 香蕉 (0.2), 樱桃 (0.15), 枣 (0.1), 接骨木 (0.1), 无花果 (0.1), 葡萄 (0.05) 一个 top-$p$ 采样，$p=0.6$ 将保留 苹果、香蕉 和 樱桃。 Logit 偏置我们还可以对模型的 logits 进行偏置，以偏向某些标记。这可以用来防止模型生成有害内容，或者使其生成更符合某种风格的内容。例如，意图分类将受益于对类别标签标记添加较大的正偏置，同时抑制其他标记的概率。 更复杂的情况包括“存在”和“频率”惩罚，其中前者对当前文本中出现的标记施加固定惩罚，而后者随着出现次数的增加逐步减少偏置。 应用的公式因实现而异，但惩罚通常使用指数形式。 Beam 大小，最佳 N束大小 $b$ 是束搜索的一个超参数。它是每一步保留的序列数量。较大的束大小将导致更多样化的输出，但也会显著减慢推理速度。束根据其累积概率对序列进行排序，并且可以在推理结束时选择最佳的 N 个序列。 更激进的方法包括完全重启，其中推理从头开始重复 N 次，并选择最佳序列。 高效和边缘推理CPU 推理在 CPU 上进行推理通常速度较慢且内存有限。为了克服这些限制，当前的边缘计算库将模型的权重量化为 4-bit 整数（从 32 位浮点数）。这显著提高了速度并减少了内存占用。 llama.cpp 是一个流行的在 $C^{++}$ 上运行的 LLM CPU 推理库（也有 Rust 变体）。它优化了使用基于 CPU 的高级向量操作。显著成就包括在桌面 CPU、树莓派模型、Apple Silicon、安卓手机上运行 7B GPT 模型，并且还支持桌面混合 CPU-GPU 推理。 最新版本使用 mmap 兼容的内存映射来按需从磁盘加载和卸载权重。 高效 GPU 推理使用 GPU 进行推理时，除了内存容量外，限制因素是内存带宽，因为逐个生成标记需要大量的内存访问操作。 为了克服这一点，可以进行缓存，我们将先前计算的键和值对保存在内存中，并在下一个标记生成时重用它们 这样，每个批次中的查询大小通常为 $1$，由于内存限制，批次大小通常较低（低于 GPU 中的处理单元数量）–&gt; 低 GPU 利用率 Flash 解码 将 $QK$ 乘积计算并行化到序列长度上，softmax 和输出在并行处理完成后计算 Flash 解码 vs 仅缓存关于两者区别的： Softmax 问题计算注意力分数中的 softmax 也可能成为瓶颈。LLM 通常使用“最大值”技巧来防止指数溢出（$\\exp{x_i}\\rightarrow\\exp{x_i - \\max{x}}$），但这包括一个最大值计算，这很难并行化。 Flashdecoding++ 使用了一个经验技巧。它使用基于 activation statistics 的 fixed global constant 来防止溢出，因此 softmax 的元素可以并行计算。如果方法遇到溢出，它将使用实际最大值重新计算 softmax，但这种情况的发生概率应小于 1%。 Flashdecoding++ 还通过双缓冲升级了通用矩阵乘法（General Matrix Multiplication，GEMM），以解决低批次大小下的内存延迟问题，并根据给定的 LLM 和批次大小启发式地选择最佳实现。 最大注意力值 处理并发请求给定一个集中式推理服务器，我们通常期望尽可能少的延迟并行处理大量请求。高性能推理包括两个阶段： 预填充：处理用户提示，计算并缓存 K 和 V。这可以在单次传递中完成，并且可能比生成的输出序列更长。这还包括生成第一个输出标记 解码：这是生成下一个标记并计算下一个 K 和 V 的迭代过程。这不能并行化，但可以重用缓存中的 K 和 V。我们只需要为每次传递计算一个 Q Flashdecoding++ 并发请求的问题 Monolithic KV 缓存：长序列的 KV 缓存可能导致内存碎片化，从而减慢推理速度并导致内存使用效率低下 短序列：短序列无法利用变压器的输入大小，因此传统上填充它们是一种解决方案，但在内存和计算方面是浪费的 不同的预填充和解码时间：我们可以估计给定请求的预填充时间，但解码时间难以预测。这可能导致处理队列中的阻塞和气泡效应 次优的 GPU 利用率：使用正确的批次与序列长度比率对于高效的 GPU 利用率至关重要。我们无法控制传入请求的长度 解决缓存问题缓存分页是一种高效的方法，受虚拟内存管理的启发，解决了各种缓存问题，例如内存碎片化、未知的解码长度、共享序列前缀。 Pages（小的固定大小内存块）用于存储 KV 缓存，以使逻辑上连续的序列存储在非连续的物理内存中。然后利用 PagedAttention，这是一种基于页面的间接部分注意力（可以以类似于 flashdecoding++ 的方式并行化）。vLLM 是一个实现此方法的框架。 内存问题 vLLM 虚拟化 逻辑 vs 物理内存 Solving cache problems这种方法允许动态内存分配和解码长度变化的释放，以及在序列之间共享缓存，并消除具有相同提示或束搜索输入的重复项。 共享前缀在聊天模型中非常常见（通常每个用户与相同的系统提示交互）。Hydragen 提出了进一步的优化，不仅用于缓存，还用于 QK 乘积计算。通过分别计算前缀和序列其余部分的 QK 乘积（可能在单独的传递中），节省了计算，并且前缀在 GPU 工作内存中从页面中读取一次。 Hydragen Piggybacking 和连续批处理可以将小的输入序列组合在一起，形成一个较长的序列，并使用掩码等方法在多个分区上计算注意力。这样，我们可以在一次传递中计算多个解码标记。这称为 continuous batching 或 piggybacking。 混合预填充和解码批处理也是可能的，其中一部分用于计算 KV 缓存，而另一部分用于生成标记。这对于消除解码期间的气泡效应非常有用（长序列处理必须完成后才能开始下一个任务，从而导致 GPU 利用率低下）。 Microbatching将长序列拆分为较小的部分并并行处理，同时将尽可能多的解码任务填充到连续批处理中（解码最大化微批处理）是解决不同序列长度引起的气泡问题的好方法。然而，不同请求的解码时间以及预填充和解码处理时间的总体差异可能会导致微批处理无法解决的气泡。 DeepSpeed-FastGen 还测量了最佳 GPU 吞吐量曲线，并使用此启发式方法找到适合给定 LLM、批处理大小和 GPU 的上下文长度。这通常只有几百个标记。 Sarathi 解决的气泡效应 GPU 利用率 混合预填充和解码每个任务还有不同的限制特征： 预填充是计算受限的 解码是内存受限且延迟关键的 对它们进行联合优化通常会导致干扰（你不能同时优化内存访问和计算）。解决方案：将它们解耦，通过另一个抽象层将逻辑预填充和解码请求映射到不同的物理资源（GPU）。 根据当前负载和预期的解码长度，将 GPU 分配给预填充或解码任务（像这样的解决方案开发了一个长度预测模型来实现这一点）。 解耦(Decoupled)预填充和解码 辅助推理和推测Assisted inference辅助推理或推测推理是一种方法，其中我们的大型自回归模型由一个较小的“草稿”或“助手”模型引导。其思路是自回归地运行助手模型并生成几个标记的序列，然后运行原始模型进行单步推理。这样，原始模型在单次传递中评估助手的整个“推测”（我们检查每个新添加标记的输出，而不仅仅是最后一个）。可能的结果是： 助手模型第一个标记错误 $\\rightarrow$ 原始模型将纠正该标记 助手模型某些标记正确 $\\rightarrow$ 原始模型接受这些标记并纠正第一个错误标记 助手模型所有标记正确 $\\rightarrow$ 原始模型接受整个序列并生成下一个标记 视频资源 预测多少个标记？ 给定 speculate 标记的数量 $\\gamma$ 助手模型在给定序列上的标记接受率 $\\beta$ 模型的一般预期接受率 $\\alpha = \\mathbb{E}[\\beta]$ 单次运行的成本系数 $\\frac{T_{\\text{assistant}}}{T_{\\text{original}}}$ 模型总是生成 $1$ 到 $\\gamma+1$ 个标记。平均接受的标记数量为 $\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha}$。生成一个标记的预期成本为 $(c\\gamma + 1)T_{\\text{original}}\\cdot\\frac{1-\\alpha}{1-\\alpha^{\\gamma+1}}$。总改进为 $\\frac{1-\\alpha^{\\gamma+1}}{(c\\gamma + 1)(1-\\alpha)}$。 在有足够内存进行预测且 $\\alpha &gt; c$ 的情况下，我们选择最大化改进的整数 $\\gamma$。 预测解码结果给定一个标准 LLM，例如 Chincilla(70B) 和一个 4B 的助手模型，使用 $\\gamma=3$ 且 $c=0.13$ 时，预期接受率约为 $\\alpha=0.7$。这种方式的改进约为 $1.82$（推理速度提高 1.82 倍）。 T5 模型也可以通过这种方法改进，例如在英语到德语翻译中，XXL (11B) 模型可以由小型 (60M) 模型辅助。这里的预期接受率约为 $\\alpha=0.75$，改进约为 $3.4$，使用 $\\gamma=7$。 采样通常会降低接受率，但改进仍然显著。 进一步方向 分块解码和验证：先前的研究表明，通过小规模的微调，可以为模型附加多个输出头，不仅预测下一个标记，还预测接下来的 $k$ 个标记。然后我们可以假设这些 $k$ 个标记是由助手模型生成的，并使用原始输出作为验证器。算法类似于上面描述的，但使用具有多个输出的单个模型 重用：辅助可以来自先前生成的标记，例如提示本身、缓存的历史记录、其他用户的会话等。然后由原始模型进行验证 分块解码头 重用标记 引导文本生成Logit 偏置值可以根据辅助评分函数动态设置。这可以用来引导模型生成更符合特定用例的文本，或限制模型的输出风格。 这还可以包括有限状态机，其中模型的输出词典根据机器的当前状态受到限制。如果我们根据例如给定的正则表达式构建 FSM，我们可以保证模型生成的文本与正则表达式一致。 基于 FSM 的引导 分类器引导分类器也是可行的引导工具，其中输出 logits 被偏向所需的类别，使用辅助分类器。这被证明在避免有害文本方面是有用的。对所有词汇元素进行此操作是不可行的，因此选择了一组得分最高的标记进行重新评分。 小型专家语言模型和专家+反专家对也可以用来输出一个 logit 分布，然后用于引导。在专家+反专家对的情况下，我们取两个模型 logits 的差值，并将其用作引导信号。 专家引导 推理时模型“适应”代理微调是一种有前途的方法，它利用专家和反专家模型，其中专家是一个小型微调模型，反专家是代理的原始未调版本。通过这种方式，可以进行指令微调和各种对齐方法（过滤有害响应等），以及提高模型在下游任务中的性能。代理微调在“沟通风格”类任务中表现出色，同时在事实性和连贯性方面也有所改善。 代理微调的突出特点是它是模型无关的（仅限于词汇表）、便携且可重用的、硬件高效的（无需对大型模型进行微调，这将非常昂贵），并且可组合的，因为可以同时使用多个专家和反专家。 Proxy-tuning 代理微调结果 水印为什么需要水印？随着大型语言模型（LLM）的性能不断提高，对模型输出的可追溯性和可检测性的需求也在增加。水印是一种在模型输出中嵌入独特模式的方法，其特点是： 对模型性能影响微乎其微（人类无法察觉） 验证简单且快速 无需了解模型参数即可验证 在相对较小的标记集上工作 不易移除（部分移除或修改仍可检测） 无需重新训练模型 硬性红名单策略红绿名单策略是一种简单的水印方法。在推理的每一步中，我们选择一组不允许生成的红名单标记（其余为绿名单标记）。这样，我们可以通过以下步骤在模型输出中嵌入独特模式： 取最后一个标记 $t-1$，并使用哈希函数生成随机种子 使用该种子生成随机数，将词汇表分为红绿两半 使用 LLM 的 logits 从绿名单中采样一个标记 检测硬性红名单水印一种基线检测方法是从以下事实出发：在不知道红名单标记的情况下，生成长度为 $T$ 的序列而不违反红名单的概率是 $\\left(\\frac{1}{2}\\right)^T$。即使是短序列，这个概率也非常低。 一种更复杂的方法是对以下零假设使用 z 检验：文本序列是在不知道红名单规则的情况下生成的。 假设绿名单标记的数量为 $G$，其期望值为 $0.5T$，方差为 $0.25T$，我们可以计算 z 分数为： $$z = 2(G-0.5T)/\\sqrt{T}$$ 如果 $z$ 超过给定阈值，我们就拒绝零假设。作者建议使用 $z&gt;4$ 作为拒绝标准，因为在这种情况下，误报率为 $3\\cdot10^{-5}$，并且我们可以检测到所有包含 $16$ 个或更多标记的水印。 考虑到对手的标记翻转会在最坏情况下导致 $t$ 和 $t+1$ 处的违规，因为哈希函数依赖于前一个标记。 这意味着对于 $T=1000$ 的标记，修改 $200$ 个标记最多会导致 $400$ 次违规，对于这种情况，$z$ 分数仍然约为 $6.3$。 通常，移除水印需要修改至少 $25%$ 的标记。 低熵序列从硬性水印的角度来看，Low entropy 序列（模型输出高度可预测的地方）是有问题的。 首先，人类也很有可能生成相同的序列（例如在 Barack 之后跟随 Obama）。对这些序列进行水印是适得其反的。 其次，硬性水印通常会破坏这些序列，因为高概率的标记可能会落入红名单。 软性水印解决低熵序列水印问题的一种方法是软性水印，其中绿名单标记仅相对于红名单标记获得小的（而不是完全的）优势。 我们在应用 softmax 之前在绿名单的 logits 上加上一个小的 $\\delta$。这样，当熵高时，绿名单标记获得相对较高的优势，但在熵低的情况下，即使是红名单中的单个最佳标记（$p\\sim1$）也不会有劣势。 作为另一种扩展，我们可以选择词汇表的一部分 $\\gamma$ 作为绿名单标记。这是一个通常保持在 $0.5$ 的超参数。 检测软性水印检测软性水印比检测硬性水印更困难。z 检验仍然适用： $$z = (G-\\gamma T)/\\sqrt{T\\gamma(1-\\gamma)}$$ 误报率仍然很低，但对于低熵序列，检测率会下降。 在给定标记生成时，最大偏离分布的最坏情况困惑度增加为 $(1+(e^\\delta-1)\\gamma)P_{\\text{original}}$（对于 $\\delta=2$ 和 $\\gamma=0.5$ 约为 $4$）。 软性水印侵蚀 erosion当 logit 分布集中在少数几个标记上时，水印较弱。 对于平均熵序列，水印在 $T=200$ 个标记中仍然有 $98.4%$ 的检测率，$\\gamma=0.5$ 和 $\\delta=2$。 对于低熵序列，检测率会下降。这种情况发生在重复的特定文本和记忆的序列中，模型基本上再现了它之前见过的完全相同的文本。 可以通过在 z 检验中仅包括 n-gram 的第一次出现，或使用更多的先前标记来计算哈希函数来解决重复文本的问题（因此红名单对于所有较短的 n-gram 不会相同）。 私有水印从检测器的决策中推断水印方法是可能的，通过提交 $|V|^h$ 个标记到检测器，其中 $h$ 是哈希函数中使用的标记数量。为了对抗解密，我们可以使用更大的 $h$，但这也会引入检测困难，因为翻转一个标记可能会影响接下来的 $h$ 个标记，并平均破坏 $0.5h$ 个标记。 使用更复杂的方法也是可行的，这些方法依赖于当前标记和前 $h$ 个标记中的一个，其中错误率降低到 $1/h$。 使用具有秘密密钥的加密哈希函数（如 AES 或 SHA3）也可以实现私有水印。这样，攻击者在不知道密钥的情况下无法检测到水印。","link":"/AI/NLP/NLP-Inference/"},{"title":"NLP-Introduction","text":"本章主要讲述了 NLP 的基本概念，和关键主题 接下来我将把 PPT 和整理过后的笔记穿插在一起成文 什么是自然语言处理？自然语言处理（NLP） 是一个跨学科领域，旨在使自然语言对计算机可访问。 自然语言 在此上下文中指的是人类用于交流的普通语言，如英语、中文、西班牙语等。 能够访问自然语言涵盖了广泛的能力，重要领域包括： 自然语言是普通人类使用的语言。C++ 就不是自然语言。海军陆战队使用的语言来传递操作代码，这是一种非自然语言。微分方程或其符号表示也可以被视为非自然语言。 交流：接受输入和生成自然语言输出的能力； 理解：能够访问和利用信息和情感内容； 语言协助：帮助人类在语言表达上的能力。 “理解”和“语义内容”这些概念仍然有些模糊，难以明确定义。我们已经在使用一些语言辅助工具，如 Grammarly 和 Google Translate，这些工具是 NLP 的实际应用。 相关领域计算语言学使用计算方法对语言进行科学研究。 也许是最接近 NLP 的领域，但重点不同：NLP 并不关心自然语言的理论见解，而只关注对计算语言处理有用的方法的设计和分析。 它通常不是直接实现理论思想，而是为 NLP 系统提供架构灵感。 NLP 是一种应用导向的构建，旨在实现实际功能，而计算语言学则是使用计算方法研究语言的理论学科。NLP 从计算语言学的理论中获得灵感，但通常不会直接实现这些理论。一个著名的例子是 Transformer 架构 人工智能 (AI)显然，NLP 目标与 AI 构建智能系统的目标有很大的重叠： 语言使用与成为智能所需的概念、表示和推理能力密切相关， 实际上，如果没有从自然语言输入中提取信息的能力，大规模知识获取也是不可能的。 上述特征使得 AI 子领域 知识表示 和 推理 对 NLP 尤为重要。 AI 是一个更广泛的概念，而 GPT、NLP 和 ML 都是 AI 的子领域或应用。人类与其他动物的主要区别在于人类使用抽象语言的能力。这种能力被认为是人类智能的一个关键特征。 机器学习现代 NLP 在很大程度上依赖于机器学习技术，事实上，近年来通用 ML 方法的语言学应用主导了该领域。 主要使用监督或半监督方法，但强化学习的使用也在增加。 文本是离散符号的序列，因此需要能够处理这种类型输入（以及生成时的输出）的 ML 模型。 强化学习在 NLP 中的应用变得非常重要文本基本上是离散符号的序列即使是非深度学习的统计模型也在 NLP 中广泛使用。虽然可以将其归结为普通的统计模型，但这些模型在机器学习中仍然很重要。逻辑回归不是深度学习方法。它不使用神经网络，而是依赖统计建模和优化。提到一个名为 Aliza 的聊天机器人，它被认为是第一个通过图灵测试的聊天机器人。Aliza 是一个基于规则的系统，而不是基于机器学习的系统。使用机器学习是因为手动编写成千上万的规则既繁琐又不够灵活。 语音处理语音信号的处理和生成传统上不被认为是 NLP 的一部分，NLP 主要关注文本，但显然与其密切相关： 语音转文本为 NLP 应用提供输入， NLP 应用为语音合成提供输入； 处理和合成语音都需要语言学知识，这对于 NLP 也很重要：尤其是语言建模在这两个领域中都起着核心作用。 应用应用示例 机器翻译， 文档检索：检索与用户查询匹配的自由文本文档， 问答系统，例如，智能手机助手回答问题的能力， 文本分类，例如检测电子邮件垃圾邮件， 聊天机器人，例如，用于购买火车票的聊天机器人， 拼写检查和语法检查， 自由文本输入的自动补全， 文档摘要， 从结构化数据生成文本（从股票交易新闻到错误消息）。 中心主题管道与端到端架构一种有影响力的 NLP 观点认为其核心任务是提供一个模块管道，该管道依次生成通用的语言分析，每个模块基于前一个模块的输出构建： 然后，专门的 NLP 应用程序作为这个通用管道元素之上的相对简单的附加组件构建。 相反的观点集中在构建 NLP 应用程序作为端到端机器学习模型，这些模型学习将原始输入转换为所需的输出，而无需专门的语言分析模块。 最先进的 NLP 应用程序通常介于这两个极端之间：它们使用一些通用的分析模块，例如用于分词或词干提取，并且还依赖于跳过某些传统管道步骤的机器学习模型来生成所需的输出。 流水线（或称为过滤器和管道）通常由不同的处理单元组成。每个处理单元的输入是前一个单元的输出，这种因果关系在流水线中保持不变。但是，NLP 中的流水线可能会出现循环（loops），这会导致一些架构问题。由于流水线方法的局限性（如递归处理问题），人们开始考虑端到端（end-to-end）架构。端到端架构直接从原始输入生成所需输出，中间没有任何分析器。有时，端到端模型中也会包含一些预处理或后处理的管道元素。端到端模型在某些情况下可能不够通用，无法适应所有任务。 迁移学习一个有趣且相对较新的发展是出现了在非常大的文本集合上进行无监督任务预训练的端到端神经模型，这些模型可以替代传统的处理管道： 可以通过在架构中添加一些非常浅层的层来构建专门的模型，同时保留预训练的权重，可能只需进行一些微调。 似乎传统管道的某些组件在这些模型中有神经类比：某些层似乎学习（更多）形态学，其他层则学习语义等。 基础模型（Foundation Models，FM）这些基础模型通常是端到端预训练的，并且大多数情况下是无监督或半监督的。通过迁移学习，可以对这些预训练模型进行微调，创建专门的模型。迁移学习包括改变一些权重、调整它们、添加新权重，甚至可能是组合权重层。神经网络中的神经激活可以视为一种软流水线元素。基础模型旨在自动化特征工程的过程，从而减少对人工特征工程的依赖。 学习与搜索我们将遇到的大量监督 NLP 任务可以表述为形式为 $$\\hat y = \\mathop{\\mathrm{argmax}}_{y\\in Y(x)}\\Psi_\\theta(x, y)$$ 的优化问题，其中 $x\\in X$ 和 $Y(x)$ 是任务的输入和潜在输出， $\\Psi_\\theta: X\\times Y \\rightarrow \\mathbb R$ 是一个评分函数或模型，它为输入-输出对 $\\langle x, y \\rangle$ 分配分数，并由向量 $\\theta$ 参数化， $\\hat y$ 是预测输出。 特征工程的目的是减少数据的维度。通过特征生成模型（即基础模型）来实现这一点。基础模型需要足够大才能发挥作用。小模型通常不被称为基础模型。基础模型生成的向量空间需要足够大。提到如果 P 等于 NP，那么模型可能不需要太大。 例如， $X$ 可以包含电影评论，$Y$ 可以包含情感标签 Positive、Negative 和 Neutral，$\\Psi_\\theta$ 可以是一个函数，为评论的可能情感标注分配概率。 同样，$X$ 可以是德语文本集，$Y$ 可以是其潜在的英语翻译，$\\Psi_\\theta$ 为候选翻译分配翻译质量分数。这种表述使得可以将问题分解为两个由两个不同模块解决的优化子问题： 学习：找到最优的 $\\theta$ 参数。这通常通过在一个大型监督数据集 ${\\langle x_i, y_i \\rangle}_{i=1}^N$ 上优化 $\\theta$ 来完成，使用数值优化方法。 搜索：为特定的 $x$ 找到得分最高的 $y$，即计算公式中的 $\\mathop{\\mathrm{argmax}}$ 的值。由于搜索空间 $Y(x)$ 通常很大，因为潜在的 $y$ 具有复杂的结构（例如，考虑解析树），这个问题经常需要组合优化。 目标是将问题形式化为一个优化问题，并寻找一个好的解决方案。通过最大化某个函数来实现这一点，这个过程称为推理。通过预测输出和实际测量值之间的差异来进行优化。目标是最大化这个误差的逆，这就是所谓的学习。是否有不使用梯度的学习算法，提到零阶优化算法作为一个例子。提到消除排序（elimination-based sorting）和消除搜索（elimination-based searching）作为学习算法的配对。这种方法与修剪神经网络（pruning neural networks）相关联。 语义视角：关系考虑以下话语 我叔叔买了一只猫。它可能是我见过的最讨厌的动物。 我们如何知道“动物”是指提到的那只猫？一个因素是我们知道猫是动物的一个子类别：它们通过 is_a 关系连接。 计算机需要某种形式的知识来理解语义。这种知识通常以关系的形式存在，例如“猫是动物”。 关系视角 关注表达的意义之间的这些语义/概念链接，它们共同构成语义网络： 词汇语义本体如WordNet和FrameNet试图枚举大量词义之间的语义关系。 关系信息通常以三元组的形式表示，包括源、目标和它们之间的谓词（关系）。通过关系数据库和语义网络来表示语义信息。如果你想使用已经形式化的本体论（如 WordNet），那么 WordNet 有一套封闭的关系集可以使用。过去的语言模型构建原则（如基于规则的翻译模型或对话系统）已经不再是主流。现代语言模型更注重表示底层信息，而不是依赖于预定义的规则。 语义视角：组合性关系视角将词义视为网络中的原子节点。相反，组合视角根据表达式的内部组成来分析其意义。 例如，分解 $$un\\vert bear \\vert able \\vert s$$ 使我们能够看到unbearables的意义是由其部分un与bear、able和s的意义组成的。 分解视角，即分析语言中不同符号的内部组成，这种方法关注语言的内部结构和组成部分。 组合性原则： 复杂表达式的意义由其组成表达式的意义和用于组合它们的规则决定。 该原则可以应用于比单词更大的语言单位：句子甚至段落等。 一种（传统的）方法是用逻辑公式表示意义，并将语法组合规则与语义/逻辑规则关联起来： 1234567891011John visits Julie (S)├── John (NP)└── visits Julie (VP) ├── visits (VT) └── Julie (NP)visits(john, julie)├── john└── λx.visits(x, julie) ├── λy.λx.visits(x, y) └── julie 如果你了解有限自动机，你会发现组合性原理在数学公式中也有类似的应用。如果能将一个句子转化为一阶逻辑（first order logic），那就是一种组合语义表示。即使有很好的表示方法来反映单词之间的联系，仍然存在一个问题：这些表示与文本内容之间的关系是什么。可以使用 GPT 模型生成摘要，然后将摘要表示为向量。 语义视角：分布式“bardiwac”是什么意思？ 他递给她一杯bardiwac。 牛肉菜肴是为了搭配bardiwacs而制作的。 饮料很美味：血红色的bardiwac以及清淡甜美的莱茵酒。 奈杰尔的脸因为喝了太多bardiwac而变红。 马尔贝克是较不知名的bardiwac葡萄之一。 我吃了面包、奶酪和这款极好的bardiwac。 $\\Rightarrow$ Bardiwac 是一种由葡萄制成的浓烈红色酒精饮料。 即使我们不知道“bardiwac”在语义网络中的位置，也不知道其部分的含义，但它出现的上下文提供了大量关于其含义的信息。 分布假设： “你将通过它所处的环境了解一个词。” “具有相似分布的语言项目具有相似的含义。” 分布式方法在实际应用中的一个重要优势是，它使得可以从大型但未标注的文本集合中自动学习单词的语义，而不需要专家知识和注释。 当然，这种方法也不是没有局限性： 对于罕见词汇存在问题；以及 学习相似性而不提供任何解释为什么这些分布是相似的。 由于缺乏分布式学习材料，这些罕见词语无法被模型有效地表示。提到“Bank”这个词，过去在语言模型中难以区分“河岸”（riverbank）和“金融机构”（monetary institution）的不同含义。如果模型只能访问分布数据而没有其他信息来源（如上下文或其他模态），那么它将无法正确理解罕见词语的含义。","link":"/AI/NLP/NLP-Introduction/"},{"title":"NLP-LexicalSemantics","text":"词汇语义学 介绍词义正如我们在第一讲中所见，根据 组合原则， 复杂表达式的意义由其组成表达式的意义和用于组合它们的规则决定。 尽管这一原则并非没有问题，它表明要了解较大文本单元（句子、段落等）的意义，有必要了解组成它们的 词的意义。 直观地说，几个词有不止一个含义，例如，mouse 在以下句子中有不同的含义： 一只 mouse 吃了奶酪。 和 用 mouse 点击关闭按钮。 mouse 可以表示 一种小型啮齿动物 或 一种电子指点设备。识别和描述这些词义或 词义 的任务是 词汇语义学。 词典中的词义一种描述词义的方法是通过传统的词典。例如，在线版的牛津高阶英汉双解词典 描述了这些词义，如下所示： 这些词义描述的显著特点是： 词义有精确的标识符：表面形式 mouse，词性标签 noun 和词义编号共同明确地标识了这些词义； 每个词义都有一个文本定义，虽然不是形式化的，但 使用相对较小的定义词汇 遵循某些惯例，例如，以一个更一般的词加上特征属性开始（小动物，小设备） 有几个例句，展示了该词义使用的典型模式。 关系语义学词汇关系词典可能包含有关词义之间的词汇关系的信息，特别是关于 同义关系：synonymy，两个词义是否（几乎）相同 反义关系：antonimy，两个词义是否彼此相反 其他重要的词汇关系包括分类关系（taxonomical）： 如果词义 $s_1$ 更具体，则 $s_1$ 是 $s_2$ 的下位词（hyponym），例如，$mouse_1$ 是 $animal_1$ 的下位词 相反，如果 $s_2$ 比 $s_1$ 更具体，则 $s_1$ 是 $s_2$ 的上位词（hypernym） 最后，部分-整体关系，即部分关系（meronymy）：例如，finger 是 hand 的部分关系。 总体而言，词义及其词汇关系构成了一个网络，其中 节点是同义词集，且 边是词汇关系。 由于下位词关系（也称为 is_a）是传递的，因此在网络中仅保留直接下位词边是有意义的，即仅当不存在节点 $s_3$ 使得 $s_1 \\xrightarrow{is_a} s_3$ 且 $s_3 \\xrightarrow{is_a} s_2$ 时，才有 $s_1 \\xrightarrow{is_a} s_2$ 边。 WordNet为了在 NLP 中可用，词汇语义信息必须作为具有明确查询 API 的计算资源可访问，并且从 1980 年代中期开始，许多项目开发了此类资源。 最重要的是WordNet 英语词汇数据库，它包含大量带有定义、示例和词汇关系的同义词集。在其成功之后，许多其他语言也开发了 WordNet，现在已有超过 200 个 WordNet 可用。 英语 WordNet 网络的一部分： 知识库作为词汇资源除了专门的词汇数据库外，知识库 也可以作为有用的词汇语义资源，因为它们包含有关 实体 和 概念 的信息，这些信息可以链接到词汇中的单词。重要的例子包括： 维基，最重要的是英文维基百科，这里各种类型的链接和引用在条目之间提供了关系信息 形式本体：这些以形式逻辑语言描述概念之间的关系 注意：词典编纂者区分词汇、概念和百科知识；后者不被认为是单词语义的一部分。 词义消歧为了使用这些词汇资源提供的词义信息，NLP 应用程序必须能够确定输入中使用的单词的意义，即执行 词义消歧 (word sense disambiguation)。WSD 任务的细节取决于它基于哪个词汇资源以及如何使用该资源。给定一个包含词义的资源， 监督 WSD 使用在标注了正确词义的训练数据上的机器学习方法；而 基于知识的 WSD 利用词汇资源中的信息，例如 WordNet 中的词汇关系和定义 潜在语义分析Latent Semantic Analysis 基于向量的词汇语义学我们迄今为止看到的词汇语义学方法具有某些特征，使得它难以实现大范围覆盖并适应新的语言或领域： 词汇数据库是由高素质专家手工组装的 高性能的词义消歧模块的开发通常需要大量专家标注的训练数据 这些问题导致了对替代方法的研究，这些方法以无监督的方式分配有用的词义表示，简单地从文本语料库中学习它们。 尽管曾尝试从文本语料库中学习语义网络，但第一个成功的无监督词汇语义方法是从文本语料库中学习词向量，即形式为 $$E: V \\rightarrow \\mathbb{R}^d$$ 的嵌入函数，它将 $V$ 词汇表中的每个词分配到 $d$ 维（$d\\in \\mathbb N$）向量。当然，并非任何这样的函数都可以：显而易见的要求是，学习到的向量必须传达关于它们所分配词的意义的有用信息。 确保这种联系的一种方法是利用分布假设（distributional hypothesis）： “通过一个词的同伴，你将了解这个词。” “具有相似分布的语言项目具有相似的意义。” 这表明，如果词向量反映了它们所分配词的分布，那么它们也将反映这些词的意义。 共现矩阵获取反映语料库中单词分布的词向量的最直接方法是考虑共现（Co-occurrence）矩阵。如果语料库中有 $D$ 个文档，$V$ 是语料库词汇表，那么 term-document 矩阵是 $|V|\\times D$ 维矩阵，其中每一行是一个词向量，其第 $i$ 个元素是该词在第 $i$ 个文档中的出现次数，而 词-词 矩阵是 $|V|\\times |V|$ 维矩阵，其中每一行是一个词向量，其第 $i$ 个元素是该词与第 $i$ 个其他词的共现次数。 直接使用这些向量的一个重要问题是它们的巨大维度和稀疏性。为了解决这个问题，潜在语义分析 方法应用降维矩阵分解方法，通常是截断奇异值分解（truncated singular value decomposition），以找到原始 $C$ 共现矩阵的低秩近似（low-rank approximation）。使用 SVD 的分解是 $$C \\approx USV^\\intercal$$ 其中 $U,V$ 是正交矩阵（orthonormal），$S$ 是对角矩阵（diagonal）。在截断 SVD 的情况下，$U$ 矩阵的行可以用作基于共现的原始词向量的低维近似表示。","link":"/AI/NLP/NLP-LexicalSemantics/"},{"title":"NLP-MixtureModels","text":"混合模型 介绍集成方法集成机器学习方法是一组使用多个估计器并结合其结果以生成最终输出的方法。常见的方法包括袋装法、提升法、堆叠法等。这些方法背后的思想是，多个估计器的组合比单个估计器更准确。 流行的集成方法包括随机森林和梯度提升等方法。 袋装法（Bootstrap Aggregating）使用训练数据的不同子集来训练多个模型，然后结合它们的结果 提升法（Boosting）顺序地使用多个模型，每个模型都被训练来纠正前一个模型的错误 堆叠法（Stacking）使用多个模型生成预测，然后使用另一个模型来结合前几个模型的预测 专家混合（Mixture of Experts）区分不同类型的输入，使用不同的模型来处理它们，然后结合所选模型的结果 专家混合（MoE）MoE 概述在1991年引入了专家混合（MoE）模型。该模型是混合模型的推广，其中输入用于选择用于生成输出的模型。该模型被训练来为每个输入选择最佳模型。 在原始论文中，该模型由多个前馈神经网络作为专家组成，还有一个决定每个专家被选择概率的门控网络。门控网络也是一个具有softmax激活的前馈神经网络。这里每个专家具有相同的输入，输出维度对于所有专家都是相同的，只是权重不同。 MoE 部件MoE 模型的主要部件包括： 数据集划分（每个专家的输入是什么） 专家（每个专家的架构是什么） 门控网络（如何加权专家输出） 聚合（如何结合加权输出） 路由（不使用权重为零/低的专家） 稀疏性（如何分离专家的知识） 在深度学习模型中，稀疏性和路由可以替代数据集划分。 现代 MoE 稀疏门控引入了一种噪声-Top-K 稀疏门控程序，其中输出是专家的门控和。在使用 $n$ 个专家 ($E(.)$) 和 $G_i(.)$ 门控网络的 $x$ 输入上，输出为： $$O(x)=\\sum\\limits_{i=1}^n G_i(x)E_i(x)$$ 这种架构使用以下方法代替基于 softmax 的门控程序： $$G(x)=Softmax(KeepTopK(H(x),k))$$ KeepTopK 让前 $k$ 个值的原始值通过，并将其余的值在 softmax 之前设置为 $-\\infty$。 这里，$H(x)$ 是一个噪声门控值： $$H_i(x) = (x\\cdot W_g)_i + z_i \\cdot Softplus((x\\cdot W_N)_i)$$ 其中 $z_i \\sim \\mathcal{N}(0,1)$ 是一个随机变量，$W_g$ 和 $W_N$ 是可调权重，softplus 是 ReLU 函数的平滑近似。 这确保了网络在每个输入时激活少量专家。问题是，如果一个专家被频繁激活，它会更频繁地被训练，因此表现会更好，从而会更频繁地被激活。这可能导致大多数输入只使用少量专家。 平衡专家利用率为了解决专家过度使用的问题，我们可以引入一个额外的重要性损失项。这个重要性损失试图最小化每个训练批次中专家重要性的变化。 $$I_{batch}(X) = \\sum\\limits_{x\\in X} G(x)$$ $I_{batch}(X)$ 是批次 $X$ 中输入的专家重要性之和的向量。损失与专家重要性变异（coefficient）系数成正比： $\\mathcal{L}{importance} = w{importance} \\cdot CV(X)$ 其中 $w_{importance}$ 是一个超参数，$CV(X) = \\frac{\\sigma(I_{batch}(X))}{\\mu(I_{batch}(X))}$ 是变异系数。 优化和负载均衡除了专家的均匀利用外，一些解决方案还为每个批次的负载不均衡定义了损失（负载是指分配给每个专家的输入数量）。均衡负载有利于模型的并行化。 由于大批次更有利于平衡，多GPU数据和模型并行性被使用。标准层和门控以数据并行方式复制，而专家是模型并行分片，在整个系统中每个专家子集只有一个副本。不同的子集存储在不同的GPU上，信息根据门控在GPU之间传递。 分层 MoE还引入了一种用于语言建模的分层 MoE 模型，其中第一个路由器/门控网络激活专家集，然后该专家集像传统的 MoE 块一样工作。 快速前馈层是具有对数复杂度树状门控程序的分层 MoE 块。该树中的每一层是一个 $[dim_{in}, dim_{node_{hidden}}, 1]$ 层维度的门控网络，具有 sigmoid 激活。输出表示输入应路由到哪个子节点。叶节点是正常的、更大的前馈专家。 参数效率 + MoE最近引入了许多使用 MoE 架构来改进适配器、前缀调优或 LoRA 的模型，以提供高效且性能优越的适应性。通常，这些 MoE 风格的适配器比密集对应物效果更好。 最近提交给 ICLR 2024 的一篇论文还引入了 MoE 层，其中每个专家都是一个 LoRA。这为使用新添加的专家扩展 MoE 模型并动态激活或停用专家提供了可能性。 为什么它们效果很好？ 仅文本 MoESwitch TransformerSwitch Transformer 基于稀疏 MoE 的思想，但不是将每个输入路由到单个专家，而是将输入拆分并独立地将每个 token 路由到单个专家。 为了指导负载平衡，在重要性和负载损失（它们融合在一起）之上，引入了专家容量（$tokens_{batch}/num_{experts}\\cdot capacity_factor$），这是每个专家可以处理的 token 数量的硬限制。如果发生溢出，本应路由到专家的 token 将不被处理（但其原始值通过残差连接传递）。 Switch Transformer 用 switch MoE 块替换 transformer 模块中的前馈层。Switch Transformer 相比传统的 MoE 和 T5 模型实现了最先进的结果。 作者还指出，特殊的权重初始化、32 位门控精度和 dropout（包括专家和其他部分）是有益的。Q、K、V 权重也可以被 MoE 模型替换，但在 16 位计算时观察到训练不稳定，详情请参阅相关文献。 在相同性能下，Switch Transformer 的训练速度比完整的 T5 模型快 2-3 倍。 UltraFastBERT介绍了 UltraFastBERT，它是使用快速前馈层实现的 BERT。将编码器逐点前馈层中的中间层替换为单神经元专家，并在 11 层二进制决策后使用 GELU 激活函数，据报道可以达到原始 BERT 性能的 96% 以上。 训练时间也显著减少，但推理时间呈指数级加快。作者报告在朴素 GPU 实现上加速了 80 倍，在 CPU 上加速了 250 倍。 多模态 MoEsBeiT在多模态网络中，选择输入数据的“子集”是显而易见的，因为可以根据输入模态选择专家。BeiT-3 以及之前的两个模型，在相同的掩码建模任务中处理图像和文本输入。该模型通过一组视觉、语言和视觉-语言组合专家进行增强。每个输入 token 都有相应的模态信息。根据模态信息从相应的池中为每个 token 选择一个专家。 该模型在发布时在检索任务、目标检测、分割和图像分类方面达到了顶级性能。 BeiT 架构 BeiT 用例","link":"/AI/NLP/NLP-MixtureModels/"},{"title":"NLP-NGram-LM","text":"基于 N-gram 的语言模型 语言模型什么是语言模型？回想一下，在形式语言理论中，语言 $\\mathcal L$ 只是某个字母表 $\\Sigma$ 的子集 $\\Sigma^*$。 相反，统计语言模型切换到语言生成的概率视图，并为来自词汇 $V$ 的任意序列 $\\langle w_1,\\dots, w_n\\rangle \\in V^*$ 分配一个概率 $$P(\\langle w_1,\\dots, w_n\\rangle)$$ 使得 $$\\sum_{\\mathbf{w}\\in V^*} P(\\mathbf{w}) = 1$$ 词汇表传统上，语言模型的词汇表由完整的单词组成，例如， $V$ = {the, be, to, of, $\\dots$} 但最近基于子词和字符的语言模型也被广泛使用，词汇表如{ _don’, t, _un, related, $\\dots$} 或 {a, b, c, d, e, f, $\\dots$} 本章讨论基于单词的语言建模技术 — 字符和子词级别建模技术将是第 9 和第 11 讲的主题。 为什么语言模型有用？概率语言模型对于大量的自然语言处理应用非常重要，其目标是生成合理的词序列作为输出，其中包括 拼写和语法检查 预测输入 语音转文字 聊天机器人 机器翻译 摘要生成 使用连续概率建模使用链式法则，令token序列 $\\mathbf{w} = \\langle w_1,\\dots, w_n\\rangle$ 的概率可以重写为 $$P(\\mathbf w)= P(w_1)\\cdot P(w_2 \\vert w_1 )\\dots \\cdot P(w_n\\vert w_1,\\dots, w_{n-1})$$ 也就是说，对于一个完整的语言模型，只需指定 对于任何 $w\\in V$ 单词，概率 $P(w)$ 表示它将是序列中的第一个单词，以及 对于任何 $w\\in V$ 和 $\\langle w_1,\\dots,w_n\\rangle$ 部分序列，单词 $w$ 的连续概率，即$$P(w ~\\vert ~ w_1,\\dots,w_n)$$ 起始和结束符号基于链式法则的序列概率公式 需要一个单独的、无条件的子句来表示起始概率，并且 没有解决在某个点结束序列的概率。 这两个问题都可以通过在词汇表中添加显式的 $\\langle start \\rangle$ 和 $\\langle end \\rangle$ 符号来解决，并假设语言的所有序列都以这些符号 开始/结束。通过这个技巧，起始/结束 概率可以重写为条件形式 $P(w \\vert \\langle start \\rangle)$ 和 $P(\\langle end \\rangle \\vert \\mathbf{w})$ 语言模型树结构使用 起始/结束 符号，语言模型分配的词序列及其连续概率可以排列成树结构： 文本生成使用语言模型，可以基于模型的生成概率分布生成新的文本。 在前一张幻灯片所示的树结构中，我们寻找权重（对数概率）之和较大的分支。穷举搜索是不可行的，众所周知的策略包括 贪婪搜索 集束（beam）搜索 随机集束搜索 一个简单的集束搜索示例，$K=5$： 评估语言模型的评估可以是 外在的: extrinsic，模型在拼写检查、语音转文字系统等组件中的表现如何，或者 内在的: intrinsic，分配的概率与测试语料库中的文本对应得有多好？ 最广泛使用的内在评估指标是语料库的 困惑度。语言模型 $\\mathcal M$ 在序列 $\\mathbf w = \\langle w_1,\\dots, w_n\\rangle$ 上的困惑度为 $$\\mathbf{PP}_{\\mathcal M}(\\mathbf w) = \\sqrt[n]{\\frac{1}{P_{\\mathcal M}(\\mathbf w)}}$$ 使用链式法则，困惑度可以重写为 $${\\sqrt[n]{\\frac{1}{P_{\\mathcal M}(w_1)}\\cdot \\frac{1}{P_{\\mathcal M}(w_2 \\vert w_1 )}\\dots\\cdot \\frac{1}{P_{\\mathcal M}(w_n\\vert w_1,\\dots, w_{n-1})}}}$$ 这正是语料库中所有单词条件概率倒数的几何平均值。 换句话说，困惑度衡量的是，对于语言模型来说，语料库中的单词（续词）平均而言有多“出乎意料”。 取困惑度的对数，通过一些简单的代数运算可以得到结果 $$-\\frac{1}{n} \\left(\\log P_{\\mathcal M}(w_1) + \\sum_{i=2}^n\\log P_{\\mathcal M}(w_i \\vert w_1,\\dots, w_{i-1})\\right)$$ 这就是每个单词的平均交叉熵和负对数似然。 一个简单的推论是：通过最小化平均交叉熵（cross-entropy）或最大化平均对数似然（log-likelihood），也可以最小化模型在训练数据上的困惑度（perplexity）。 基于 N-gram 的建模概率估计我们如何从文本语料库中估计所需的 $P(\\mathbf{w})$ 概率？我们可以尝试使用出现次数来获得最大似然估计： $$P(\\mathbf{w}) \\approx \\frac{C(\\mathbf{w})}{C(\\mathrm{all \\space texts \\space in \\space corpus})}$$ 但在任何现实的语料库中，大多数文本只出现一次，许多可能的文本根本没有出现。一个选项是切换到连续概率： $$P(w_{i} \\vert w_1,\\dots,w_{i-1})$$ 使用基于计数的估计，我们可以得到 $$P(w_{i} \\vert w_1,\\dots,w_{i-1}) \\approx \\frac{C(\\langle w_1,\\dots,w_{i} \\rangle)}{C(\\langle w_1,\\dots,w_{i-1} \\rangle)}$$ 但同样会遇到数据稀疏性问题。缓解这一问题的一种方法是使用 $$P(w_{i} \\vert w_1,\\dots,w_{i-1}) \\approx P(w_{i} \\vert w_{i-k},\\dots,w_{i-1})$$ 的近似，对于某个 $k$，假设续词概率（近似）由序列中前 $k$ 个 token 决定。 N-gram 语言模型使用这种近似，$\\langle w_1,\\dots,w_n \\rangle$ 序列的概率可以计算为 $$P(w_1) \\prod_{i=2}^k P(w_{i} \\vert w_{1},\\dots,w_{i-1}) \\prod_{i=k+1}^n P(w_{i} \\vert w_{i-k},\\dots,w_{i-1})$$ 其主要优点是 $$P(w_{i} \\vert w_{i-k},\\dots,w_{i-1}) \\approx\\frac{C(\\langle w_{i-k},\\dots,w_{i}\\rangle)}{C(\\langle w_{i-k},\\dots,w_{i-1} \\rangle)}$$ 的估计可以仅基于语料库中最长为 $k+1$ 的子序列计数，即所谓的 N-gram $(N=1, 2, 3,\\dots)$ 一元模型最简单的 $N$-gram 语言模型是一元（Unigram）模型，它为序列 $\\langle w_1,\\dots,w_n \\rangle$ 分配概率 $$P(w_1)\\cdot P(w_2)\\cdot \\dots \\cdot P(w_{n-1})\\cdot P(w_n)$$ 其中单词概率可以简单地估计为 $$P(w) \\approx \\frac{C(w)}{\\sum_{w’ \\in V}C(w’)}$$ 一元模型忽略了单词的顺序，最可能的序列只是完全由最频繁的单词组成的序列。 二元模型自然地，基于更长子序列的 $N$-gram 模型更加细致，甚至所谓的二元（Bigram）模型（$N=2$）计算序列概率简单为 $$P(\\langle w_1,\\dots,w_n \\rangle) = P(w_1)\\prod_{i=2}^n P(w_i \\vert w_{i-1})$$ 其中 $$P(w_2 \\vert w_1) \\approx \\frac{C(\\langle w_1,w_2\\rangle)}{C(w_1)}$$ 马尔可夫语言模型$N$-gram 模型实际上是用概率有限状态机（Markov）来建模语言，其中状态对应于 $N-1$-gram。 例如，在 $\\mathcal M$ 二元模型的情况下，状态对应于词汇表加上一个开始和结束状态，状态 $w_1$ 和 $w_2$ 之间的转移概率只是 $P(w_2 \\vert w_1)$ 的续词概率。 很容易看出，token 序列 $\\mathbf{w}=\\langle w_1,\\dots,w_n \\rangle$ 的 $P_\\mathcal{M}(\\mathbf{w})$ 概率正是马尔可夫模型经过状态 $\\langle start \\rangle,w_1,\\dots,w_n,\\langle end \\rangle$ 的概率。 一个简单的马尔可夫语言模型： 增加 N 值由于实际上人类语言过于复杂，无法满足低阶马尔可夫假设，因此具有更高 N 值（如 N=3,4 甚至 5）的 N-gram 模型通常具有更好的内在和外在性能。不幸的是，随着 N 的增加，语言学上可能的 N-gram 数量急剧增加。例如，在谷歌的 1,024,908,267,229 token 的 N-gram 语料库 中，N-gram 计数为： 一元模型：13,588,391 二元模型：314,843,401 三元模型：977,069,902 四元模型：1,313,818,354 五元模型：1,176,470,663 对于较高 $N$ 值，语言学上可能的 $N$-gram 数量极高，这带来了两个重要问题： 数据稀疏性: 即使在大型文本语料库中，许多可能的组合也不会出现，或者只会很少出现，因此很难估计它们的概率； 模型大小: 即使估计是正确的，模型的大小也会非常庞大。 平滑加法平滑Additive smoothing。我们如何解决在语料库中从未或很少出现的 $N$-gram 的问题？一个简单的解决方案是通过某个数值过度计数每个 $N$-gram，并使用 $$P(w_{i} \\vert w_{i-k},\\dots,w_{i-1}) \\approx \\frac{C(\\langle w_{i-k},\\dots,w_{i}\\rangle)+\\delta}{C(\\langle w_{i-k},\\dots,w_{i-1} \\rangle) + \\delta|V|}$$ $|V|$ 乘数来自于这样一个事实：对于每个 $N-1$-gram，恰好有 $|V|$ 个 $N$-gram 是它的延续。 $\\delta$ 的一个广泛选择是 1。 一个重要的问题是： 如果 $C(\\langle w_1,w_2\\rangle)=0$ 和 $C(\\langle w_1,w_3\\rangle)=0$，那么在加法平滑下我们有 $$p(w_1,w_2)=p(w_1,w_3)$$ 假设现在 $w_2$ 比 $w_3$ 常见得多。那么，直观上，我们应该有 $$p(w_1,w_2)&gt;p(w_1,w_3)$$ 而不是上述的相等关系，因此加法平滑的结果似乎是错误的—我们应该以某种方式在一元和二元计数之间进行插值。 插值Interpolation，在二元模型的情况下，我们通过一定的权重添加来自一元模型频率的概率： $$P(w_2 \\vert w_1) \\approx \\lambda_1\\frac{C(\\langle w_1, w_2 \\rangle)}{C(w_1)} + (1 - \\lambda_1)\\frac{C(w_2)}{\\sum_{w\\in V}C(w)}$$ 对于任意 $k$ 的递归解决方案： $$P(w_{k+1} \\vert w_1.. w_k) \\approx \\lambda_k\\frac{c(\\langle w_1 .. w_{k+1} \\rangle)}{c(\\langle w_1 .. w_k\\rangle)} + (1-\\lambda_k)P(w_{k+1} \\vert w_2 .. w_{k})$$ $\\lambda_k$ 是基于语料库经验设置的，通常使用期望最大化（Expectation Maximization）方法。","link":"/AI/NLP/NLP-NGram-LM/"},{"title":"NLP-Pipeline","text":"本章主要讲述了 NLP 的语言结构和传统管道 语言结构表示层次自然语言是非常复杂的符号系统，其符号（单词、短语、句子等）比普通符号具有更多的内部结构。语言学家通常在语言符号中至少区分以下四个表示层次： 音位结构: 个别声音的层次，或在书面语言中，书写符号、字母； 形态结构: 词素的层次，即最小的有意义的语言单位，以及它们组织成单词； 句法结构: 单词组织成语法正确的句子的层次； 语义结构: 意义的层次，即语言符号所指的内容。 列出的表示层次并未涵盖语言符号的所有重要方面： 语义学，至少传统上，不处理非字面、依赖上下文的意义元素，这些元素属于语用学的范畴，而 对大于句子的单位（段落、整个对话等）内部关系的研究是话语分析的主题。 语法依靠语言符号（简称 l. 符号）的概念，我们可以定义更多重要的概念： 语言 是一组 l. 符号。 语法 是一个由以下两部分组成的对偶： 一组 l. 符号，即语言的 词汇，以及 一组有限的操作，这些操作将一个或多个 l. 符号映射到一个 l. 符号。 当且仅当 $\\mathcal G$ 语法生成 $\\mathcal L$ 语言时，$\\mathcal L$ 包含正好那些在 $\\mathcal G$ 的词汇中或通过有限次应用 $\\mathcal G$ 的操作从 $\\mathcal G$ 的词汇中产生的 l. 符号。 换句话说，语言 $\\mathcal L$ 中的所有符号要么直接在语法 $\\mathcal G$ 的词汇表中找到，要么可以通过语法 $\\mathcal G$ 的规则和操作从词汇表中的符号生成。 语法操作通常分解为同时工作的音韵、形态、句法和语义操作。 例如，对于一个作用于语言符号的二元语法操作 $f$，存在相应的音韵、形态等操作，使得 对于 $f$ 的所有可能参数： $$ f \\begin{pmatrix} \\begin{bmatrix} ph_1 \\\\ mor_1 \\\\ syn_1 \\\\ sem_1 \\end{bmatrix}, \\begin{bmatrix} ph_2 \\\\ mor_2 \\\\ syn_2 \\\\ sem_2 \\end{bmatrix} \\end{pmatrix} = \\begin{bmatrix} f_{\\mathrm{ph}}(ph_1, ph_2)\\\\ f_{\\mathrm{mor}}(mor_1, mor_2)\\\\ f_{\\mathrm{syn}}(syn_1, syn_2)\\\\ f_{\\mathrm{sem}}(sem_1, sem_2) \\end{bmatrix} $$ 根据我们的定义，语法不仅涵盖语言的句法，还包括音韵、形态和语义。 在文献中也经常使用一种更有限的语法概念，它仅限于形态和句法，或者仅限于句法。 此外，语言通常被更狭义地定义为仅包含由语法生成的句子（作为声音或书面符号序列）的集合，而不包括它们的形态、句法和语义结构。 描述语法语言学的一个核心目标是描述生成自然语言（或其片段）的语法：英语语法、西班牙语语法等。 语法通常通过以下两种方式描述： 显式地，通过描述词汇并定义从中生成语言元素的操作，或 隐式地，通过提供由语法生成的语言的代表性示例，即带有形态、句法等分析的语音或文本样本。 解析和生成一些与语法相关的任务在 NLP 中尤为重要： 解析 决定一串书面符号是否属于由给定语法生成的语言：它是否由该语言的单词组成，是否在句法上是正确的，以及是否有意义。 确定由给定语法生成的语言中的一串书面符号相对应的形态、句法和语义结构。 生成 无条件生成: 生成语法语言的元素。 条件生成: 生成满足特定条件的语法语言的元素。这些条件通常是语义上的，即生成语义结构（意义）满足特定条件的语言元素。 解析和传统的 NLP 管道解析任务在传统 NLP 中占据了核心地位，因为人们认为大多数 NLP 任务可以通过以下方式解决： 解析文本输入，并根据特定语法生成其表示结构， 使用生成的分析结果作为进一步处理的特征。 因此，传统的 NLP 管道是一个针对一种或多种语法的解析管道，其中每个组件生成输入表示结构的一部分。 传统管道中的处理任务 形态和句法 分词 句子切分 形态分析 词性标注 （浅层或深层）句法解析 语义 命名实体识别 词义消歧 共指消解 / 实体链接 语义角色标注（浅层语义解析） （深层）语义解析 管道任务分词该任务是将输入字符序列分割成称为tokens的小的有意义的单位，通常是单词和标点符号： ‘This is a sentence.’ $\\Rightarrow$ [‘This’, ‘is’, ‘a’, ‘sentence’, ‘.’] 使用 tokens 而不是单词有两个重要的优点： 允许更多的灵活性：标点符号、表情符号等虽然不是单词，但仍然是有用的分割单位； 暗示这些片段是某些类型的实例，这些类型共同构成一个词汇表。 什么应该算作一个 token？答案取决于任务和模型：例如，对于某些目的，标点符号是无关紧要的，而对于其他目的，句子边界和标点符号是重要的。 尽管如此，一些有影响力的分词风格已经达到了“准标准”状态。对于英语来说，“Penn Treebank 规则”是最常见的，具有以下关键特征： 标点符号与单词分开并作为独立的 token 处理， 动词缩写（如“she’s”中的“’s”）和附加成分（如“don’t”中的“n’t”）被分开。 类型分配和标准化分词还可以涉及确定 tokens 属于哪种类型。例如，如果 ‘apple’ 和 ‘Apple’ 是同一类型的实例，那么我们的分词器会将这些标准化或规范化为一个共同的类型，不考虑大小写。典型的规范化实践包括 “纠正”拼写变体和拼写错误，将所有变体分词为同一类型的实例， 标准化数字或日期类型的表达 以及标点符号（例如，将“!!”视为“!”）。 更激进的策略包括将所有数字表达式或所有不在预定义词汇表中的单词分配给单一类型。 分词挑战分词的挑战取决于任务和方法，还取决于输入的 书写/字母系统（例如，没有空格的书写系统！）， 语言， 领域， 噪音量（例如，拼写错误的数量）。 对于欧洲语言和书写系统，特别的挑战包括 缩写（通常以句号结尾）， 数字表达式（可能包含空格、逗号和句号）， “多词表达”（MWEs），如“New York”。 句子切分该任务是将（通常是预先分词的）输入字符序列分割成句子： [‘John’, ‘entered’, ‘the’, ‘room’, ‘.’, ‘It’, ‘was’, ‘empty’, ‘.’]$\\Rightarrow$ [[‘John’, ‘entered’, ‘the’, ‘room’, ‘.’], [‘It’, ‘was’, ‘empty’, ‘.’]] 主要挑战是 句子和 token 切分的相互依赖性，例如分割形式为 ‘xxx yyy. Zzzz’ 的片段（’yyy.’ 是句子结尾还是缩写？）； 标点符号不正确或缺失。 形态学词素 (Morphemes) 是语言中最小的有意义单位。单词可以由几个词素组成，例如 unbearables = un + bear + able + s 词素之间的有用区分： 黏着词素 (Bound) vs 自由词素: 自由词素（例如 bear）可以单独作为独立的单词存在，而黏着词素（例如 -un, -s）只能与其他词素一起构成单词。 词缀 vs 词根: 词根 (roots) 是单词的主要部分，具有最具体的语义内容（例子中的 bear），其他词素，即词缀，可以围绕词根放置。大多数词根是自由的。 词缀类型词缀 (Affixes) 可以根据它们与其他词素的（通常是位置上的）关系进一步分类： 词缀类型 关系 示例 prefix 前缀 前置 un-，anti- suffix 后缀 后置 -s 和 -ing infix 中缀 中间 Singabloodypore circumfix 环缀 环绕 德语中的 ge...t（例如 gespielt） stem 词干变化 变化 阿拉伯语 kitaab（’书’）$\\rightarrow$ kutub（’书籍’） 这远不是完整的列表，其他词缀类型还包括重复、音调/音高变化等。 一个关键的区别是屈折词缀和派生词缀： 屈折词缀 inflectional，创建同一个词的不同形式，可以表示语法方面如人称、时态等。英语中的例子包括复数 -(e)s 和进行时 -ing。 派生词缀 derivational，则形成新词，例如，bearable 中的 -able 将动词变为形容词。 词干和词元 一个词的 词干 (stem) 由词的基本部分组成，这部分在所有屈折形式中都是共同的。因此，词干通常不是一个有意义的词，例如，produced 的词干是 produc（因为有 producing 等形式）。 词元 (lemma) 与此相反，总是一个完整的词，即屈折形式的未屈折基本形式。继续上面的例子，produced 的词元是 produce。 形态分析任务Morphological 决定一个字符串是否是一个格式正确的单词。 词干提取: 确定一个单词的词干。 词元化: 确定一个单词的词元。 形态标注: 根据词形变化等表达的语法信息标注输入单词。 形态分割: 将输入单词分割 (segmentation) 成词素。 完整的形态分析: 将单词分割成词素，并根据类型和它们传达的语法信息对每个词素进行分类。通常也包括词元化。 形态分析挑战 歧义 / 依赖上下文: 许多单词有多种分析，只有根据上下文才能消除歧义 (Ambiguity) ，例如 chairs 中的 -s。参见： The president chairs the meeting.There were hundreds of chairs in the room. 复合词: 许多语言有由两个或更多简单词组成的复合词 (Compounds)：例如，德语中的 Schadenfreude (幸灾乐祸) 由 Schaden（“损害”）和 Freude（“快乐”）组成。 形态丰富的语言: 英语的形态相对简单。其他语言，例如匈牙利语和土耳其语则复杂得多…… 词性标注词性（Part-of-speech）类别对应于单词在句子中可以扮演的基本句法角色。例如，在句子 Peter ate the apple. 中，Peter 和 apple 是名词，ate 是动词，the 是限定词。词性标注任务是确定已分词（并可能已句子切分）的输入文本中每个单词的词性类别，例如： [‘Peter’, ‘ate’, ‘the’, ‘apple’, ‘.’] $\\Rightarrow$[ (‘Peter’, [‘名词’]), (‘ate’, [‘动词’]), (‘the’, [‘限定词’]), (‘apple’, [‘名词’]), (‘.’, [‘标点’])] 同样地，词性的类别也是依赖于上下文的。例如，比较以下句子： John hit the ball.His first song was a huge hit in Europe. 具体的词性类别列表及其划分也取决于所使用的语言和特定的语法理论，尽管有些类别是相当普遍的，例如，[名词]、[动词]、[形容词] 和 [副词] 几乎总是存在。 开放 vs. 封闭词性类别 封闭词性类别，例如英语中的限定词，由相对较小的词集组成，这些词集不会轻易改变：添加一个新的限定词到一种语言中是一个罕见的现象。 开放词性类别，例如英语动词，包含大量的词，并且每天都会添加新成员。 一个相关的区别是功能词和内容词之间的区别。属于开放词性类别的词通常是内容词：它们自身具有明确的语义内容。封闭词性类别包含的功能词则没有太多独立的内容。 词性标记集在 NLP 中，词性类别通常用简写编码，称为词性标记。即使是英语，也有几种标记集在使用；一个非常重要的、与语言无关的标记集是为 Universal Dependencies 项目 开发的： 开放类标记 标记 描述 示例 [adj] 形容词 big, old, green, African, first [adv] 副词 very, well, exactly, tomorrow [intj] 感叹词 psst, ouch, bravo, hello [noun] 名词 girl, cat, tree, air [propn] 专有名词 Mary, John, London, NATO [verb] 动词 run, eat, runs, ate 封闭类标记 标记 描述 示例 [adp] 介词 in, to, during [aux] 助动词 has, is, should, was, must [cconj] 并列连词 and, or, but [det] 限定词 a, an, the, this, which, any, no [num] 数词 0, 1, 2, one, two [part] 小品词 not, ‘s (as in “Andrew’s table”) [pron] 代词 I, myself, who [sconj] 从属连词 that, if 其他标记 标记 描述 示例 [punct] 标点符号 . , ; [sym] 符号 $, ¶, © [y] 其他 用于无法分析的元素 句法解析句法理论旨在描述“支配单词如何组合成短语、形成良构 (well formed) 词序列的规则或原则集。” 在这个背景下，最重要的“良构词序列”是句子：句法理论的核心目标是为特定语言找到描述/划定该语言中良构句子的结构规则或原则。 一个句子是良构的，如果它具有结构描述或句法解析，并且满足所讨论理论的句法约束。句法上的良构性并不保证连贯性或有意义性。引用乔姆斯基的著名例子： Colorless green ideas sleep furiously. 在句法上是良构的，但毫无意义，而 Furiously sleep ideas green colorless. 甚至不是良构的。 成分句法（也称为短语结构）和依存句法理论对 NLP 尤为重要。 成分 (constituent) 是单个单词或一组连续单词，形成一个“自然单位”。例如，短语 a nice little city： 可以放入各种句子框架中，如 *I wanted to visit ...，Budapest is ...*； 可以作为问题的答案：*What did you visit?*； 可以用代词替换：I have visited a nice little city. $\\Rightarrow$ I have visited it. 基于成分的句法基于成分的句法理论 对成分进行分类，并且 制定规则，根据这些规则可以将成分组合在一起构建更大的成分，最终构建一个完整的句子。 一个良构句子的句法结构就是它的成分结构，例如，对于句子 The students love their professors： $$[ [ The_\\mathrm{D} \\space students_\\mathrm{N} ]_\\mathrm{NP} \\space [ love_\\mathrm{Vt} \\space [ their_\\mathrm{D} \\space professors_\\mathrm{N} ] _\\mathrm{NP} ] _\\mathrm{VP}] _\\mathrm{S}$$ 在更透明的成分树形式中： 123456789S├── NP│ ├── Det: the│ └── Noun: students└── VP ├── Vt: love └── NP ├── Det: their └── Noun: professors 这是基于成分的解析器输出的结构。 基于依存的句法与此相反，依存语法将单词之间的依存关系 (dependency) 视为基本关系。 具体标准因理论而异，但通常在一个句子中，如果一个 $d$ 单词依赖于一个 $h$ 单词（等价于 $h$ 支配 $d$），则 $d$ 修饰 $h$ 的意义，使其更具体，例如 eats $\\Rightarrow$ eats bread，eats slowly 等； 并且它们之间存在不对称的可省略关系：可以从句子中省略 $d$ 而保留 $h$，但反之则不行。 依存语法对一个良构句子中的依存关系施加了重要的全局约束，例如： 恰好有一个独立的词（句子的根）。 所有其他词直接依赖于一个词。 由于这些约束，句子的直接依存图是一个树。 大多数依存语法使用类型化的直接依存关系：存在有限的直接依存关系类型列表，并对它们何时可以成立施加特定的约束。 一个依存解析树的例子： 与成分树相比，它包含更少的节点（每个单词一个），但边缘标有相应的依存类型。 命名实体识别命名实体识别 (Named entity recognition) 是在输入文本中找到命名实体的表达并将其标记为相应实体类型的任务： 通常使用的实体类型有人名、组织和地点，但许多 NER 模型涵盖了其他类型，如日期、事件、艺术作品、法律等。 共指消解NER 确定名称所指实体的类型，但不决定它们是指相同还是不同的实体。相反，共指消解 (Coreference resolution) 任务是定位输入中的更广泛的指称表达，包括普通名词和代词，并将它们聚类到指向同一实体的组中： 实体链接与共指消解类似，实体链接也关注引用的身份，但在两个重要方面与之不同： 像命名实体识别一样，它仅限于类似名称的表达， 它通过将名称连接到外部知识库中的实体记录来确定实体的身份，例如： 词义消歧词义消歧 (disambiguation) 也将表达与外部词汇表中的意义/词义连接起来，但 它关注普通名词和其他类型的内容词：动词、形容词和副词； 词义集合通常是专门构建的词汇资源——准标准是使用 WordNet 词汇数据库。 例如，一个基于 WordNet 的词义消歧系统应该将句子 The scroll wheel in my mouse has stopped working. 中的 mouse 名词消歧为 WordNet 词义 [Mouse]#4: ‘一种手动操作的电子设备，用于控制光标的坐标 [...]‘。 WordNet 中的其他可能性： [Mouse]#1: ‘任何数量众多的小型啮齿动物 [...]‘ [Mouse]#2: ‘一个肿胀的瘀伤 [...]‘ [Mouse]#3: ‘一个安静或胆小的人 [...]‘ 语义角色标注语义角色标注 (Semantic role labeling) 是识别输入文本中的谓词 (predicate) 和论元 (argument) 表达，确定哪个论元属于哪个谓词，以及它们之间关系的任务。在这个背景下， 谓词 是指代事件/情况的表达（例如，指代动作的动词）， 论元 则指这些事件/情况的参与者， 而任务中的角色标注部分是确定与论元对应的参与者在谓词所指的情况中扮演的角色类型。 一个相对简单的例子，使用宾夕法尼亚大学认知计算组的SLR 演示。 语义解析这是完整或深层语义解析的任务，它不仅涵盖共指消解、词义消歧和谓词-论元结构，还旨在提供一个完整的形式语义表示，其特点是： 表示输入文本的意义的形式结构， 表示字面意义， 尽可能消歧， 在某种程度上是规范的，即一个文本意义有一个唯一的表示， 有高效的算法来确定它们与其他语义和知识表示的逻辑和语义关系。 句子 Thetis loves a mortal 的基于一阶逻辑的语义表示：","link":"/AI/NLP/NLP-Pipeline/"},{"title":"NLP-PreExamA","text":"期中考试，人已死 A1 语言结构和语法Linguistic structure and grammars (Linguistic structure, representation levels, grammars, parsing task, generation task, relation to NLP pipelines) 语言结构表示层次phonological 也就是类似于字母表，音素音标的最小单元，通常本身没有意义 随后它们可以构成 morphological，也就是词根，词缀，词尾等，这些构成了词，是有意义的最小单位 词可以构成句子，这就是 syntactic，但是光满足语法要求不能说明句子有意义 所以我们有 semantic，去解释句子的意义和指代的对象等 语法grammar 指导你如何构建句子，如何解析句子 同时也包括 phonological，也就是发音的规则，声调，哪些音可以拼在一起等 当然也包括 morphological，比如进行时过去时之类的 解析任务基本上来说就是判断一个句子是否符合语法规则 然后再分析它们的结构，找出句子表达的意义 生成任务有两种，一种是很傻的无条件生成，也就是不管句子是否有意义，直接按语法规则生成 另一种是有条件生成，生成满足一定需求的句子，也就是有意义的句子 与 NLP 管道的关系在那时我们还没有 transformer 和端到端模型，所以我们需要一步一步的去拆解和分析句子 也就是我们在管道中执行人为设计的算法，帮助计算机理解句子 A2 传统 NLP 管道中的元素和任务Elements and tasks in the traditional NLP pipeline (Structure/order of the pipeline, tokenization, sentence splitting, morphology, POS tagging, syntactic parsing, NER, coreference resolution, entity linking, WSD, semantic role labeling, semantic parsing) 管道的结构/顺序实际上 PPT 中有一个重要的内容没有提到，那就是管道的第一步：预处理 预处理基本就是删除特殊字符，然后统一大小写，去除停用词 the a an 等 随后遵循以下步骤： 先分词，然后拆句子，标词性（POS），解析句法，找命名实体，合并相同指代，链接实体，消除歧义，标语义角色，最后解析语义 分词简而言之就是将句子拆成一个个词，具体怎么拆看需求，同时还可以有规范化的过程 对于如何处理缩写，数字，特殊表达，还有多个词组成的词等，都有不同的处理方式 更进一步的细节看下面专门的章节 句子切分有的时候我们的输入是一大段话，所以我们需要将其拆成一个个句子 这个过程也不是那么简单，比如句号后面的 Mr. Mrs. Dr. 等不应该拆开 形态学分析其实也就是把词再拆开，比如动词的时态，名词的复数等 我们可以通过这个方式确定一个词的格式是否正确 然后我们就能进行时态标注一类的任务了 stem 通常不完整，而 lemma 是完整的，比如 produc 和 produce 词性标注Part-of-speech tagging，简称 POS，就是给每个词标标记角色 none (名词)，verb (动词)，adj (形容词), adv (副词), pron (代词), prep (介词), conj (连词), interj (感叹词), det (限定词), num (数词), art (冠词), aux (助动词), modal (情态动词), cop (系动词), part (分词), punct (标点符号), sym (符号) 句法解析其实也就是通常意义上的语法了，基于 constituent 的解析就是找出句子中谁是 NP(noun phrase)，VP(verb phease)，VT (transitive verb 及物动词)等 更重要的是 dependency parsing，找出句子中的依赖关系，比如主谓宾关系 具体的后面会有专门的章节 命名实体识别就是找出句子中的专有名词，比如人名，地名，机构名等，还有时间，日期等 指代消解就是把指向相同对象的指代词标记出来 比如，我的姐姐，她…，这里的她就是指代消解的对象 实体链接就是把命名实体链接到知识库中的实体，比如把北京这个词指向百科中的北京 词义消歧就是找出一个词在句子中的具体含义，比如 bank 是银行还是河岸 语义角色标注也就是谁做了什么，对谁做了什么，在哪里，什么时候 句法解析主要关注语法，而角色标注关注的是含义 语义解析这就是一个合并任务了，把前面的步骤整合起来，找出句子的含义 A3 经典（全词）分词Classical (whole-word) tokenization (Tokenization task definition, whitespace splitting, regular expressions, and regex cascades, lexers) 分词任务定义前面也说到，把文本切分成合适的小块，这个小块就是 token 空白分割这还用说吗，就是按空格分 这种粗暴的方式问题很多，比如中文，或者缩写就分不了 正则表达式和级联regex 其实是一个 regular language 的 finite acceptor 这里就需要提到形式语言，正则语言，上下文无关，上下文有关，递归可枚举 级联就是多个正则表达式串联起来，比如先找出数字，再找出字母 在执行替换前，把有问题的部分先替换掉 词法分析器也就是用正则表达式来匹配文本，找出 token 的工具 SpaCy 其实就跟 flex 一样 A4 编辑距离和子词分词Edit distance and subword tokenization (Edit distance, subword tokenization, Byte Pair Encoding, WordPiece, SentencePiece) 编辑距离就跟汉明距离很像，Levenshtein 就是在计算要把一个字符串变成另一个字符串需要多少步，然后每个操作还可以有权重 子词分词一种可以无需人工预分词的，基于大数据的办法，文本会分割为最常见的组合 字节对编码先把单词拆散成字符，然后根据常出现的组合合并字符，比如 th 是一个常见的组合 贪婪的它只关心当前最常见的组合，然后合并，直到达到预设的词表大小，可能会生成不常见的组合 优化可以用 dropout，也可以使用 unigram WordPiece更智能的 BPE，从最高频的子词开始合并，尝试用更少的子词表示一个单词 但是它会考虑到生成的子词组合的概率，也就是尽可能增大召回率，更注重质量，生成的子词更有意义 SentencePiece对不需要空格分隔的语言，直接对整段文本进行分词，甚至包含标点符号 它将文本视为连续的序列，然后利用类似于 BPE 等的方法来构建词表 A5 一般语言建模Language modeling in general (Language model, continuation probabilities, role of start and end symbols, text generation, LM evaluation) 语言模型定义就是有一个 L，还有一堆 w 属于 L，然后 sum(P(w)) = 1 连续概率P(Wn | W1, …, Wn-1)，我下一个词的概率只跟我前面的词有关 起始和结束符号的作用因为链式法则需要一个确定的开始和结束符号才能计算概率 文本生成使用概率模型来生成文本，可以有贪婪搜索，也可以是 beam 搜索，去找一个置信度最高的组合 语言模型评估外部评估也就是看拼写，语法之类的 而内部评估是把每个词的概率相乘，然后变换来看整体置信度，或者 Perplexity A6 基于 N-gram 的语言建模N-gram-based language modeling (Estimating sequence and word probabilities, N-gram models, markov models, Smoothing) 序列和词概率估计我们想估计某个单词在语料库中出现的概率，我们可以直接计数 但是对于句子（序列），我们不光要考虑词的独立概率，还要考虑每个单词跟前面的词一起出现的概率 也就是上面说的连续概率，但是有可能我们的语料库中没有这个序列，直接用的话会导致数据 sparse 那为了解决 0 概率问题，我们可以采取 n-gram 模型 N-gram 模型其实就是把连续改成离散，比如 bigram 就是只考虑前一个词，trigram 就是考虑前两个词 马尔可夫模型就是一个有限状态自动机，二元以上才能马尔可夫 平滑但是就算 N-gram 也会有数据稀疏的问题 所以我们给每个词的计数都加一，但是加完了以后可能会导致一个情况 如果说 W1, W2 的计数是 0，那么 P(W1, W2) = 0 W1, W3 的计数是 0，那么 P(W1, W3) = 0 但是 W2 比 W3 常见，那应该有 P(W1, W2) &gt; P(W1, W3) 这就和我们之前得到的结果不符合，所以我们需要插值 比如在二元模型下，把一元模型的频率加进去 A7 使用经典方法进行文本分类Text classification with classical methods (Classification tasks, bag of words, TF-IDF, naive Bayes, discriminative methods) 分类任务跟图像分类差不多，判断是不是垃圾邮件之类的 词袋模型就是把文本中的词拿出来记录词频，然后用这个向量来表示文本 通常可以省略 stopword，也可以用 TF-IDF 来加权 TF-IDF也就是 (全部文档 / 包含 w 的文档)，然后再取对数 本质上是假设一个词出现的频率越低，它的重要性越高 朴素贝叶斯NB 的假设和 unigram 一样，就是每个词都是独立的 那就很适合 BOW，因为它不关心词的顺序，纯粹看词频 我们本质上在推测文本属于不同 c 的概率，然后取最大的那个 也就是 P(x, c)，然后由于我们是连续概率，所以会有个累乘 判别方法Logistic Regression，Random Forest 和 Gradient Boosting，它们都是用于分类任务的算法 A8 使用经典方法进行序列标注Sequence tagging with classical methods (Sequence tagging tasks, IOB tagging, supervised methods, HMM, Viterbi algorithm, MEMM, CRF, optimization and inference, generative and discriminative models) 序列标注任务就是给句子中的每个词打标签，比如词性标注，命名实体识别等 IOB 标注名词短语不是有多个词么，整个标记为 NP，然后用 IOB 把这个 NP 拆开 某个实体的开头标 B，里面的标 I，不属于任何实体的标 O 然后我们就能明确的区分实体边界，处理连续或者重叠的实体时就不会混乱 监督方法无非就是生成模型（P(X,Y) 联合）和判别模型（P(Y|X) 条件） 隐马尔可夫模型本质上就是有一个不可见状态 Y 集，那可见状态 X 就是每个 token，不可见状态就是词性 Y 指向 X，一一对应 Y 是连续的，然后我们就可以预测下一个词的词性 它还假设生成（发射）概率跟位置无关，随后通过最大似然估计来学习概率 转移概率就是词性转移的概率，发射概率在已知词性的情况下，生成某个词的概率 维特比算法HMM 通过 Viterbi 来对新的输入进行标注 它的目标是在给定观测序列 O 的情况下，找到最可能的隐藏序列 Q max = argmax P(Q|O) Q 是隐藏序列 实际就是一个动态规划，每一步都留存了上一步的距离 在一个节点同时接到多个来源的时候，只留最小（大）的那个 然后我们可以通过反向引用来恢复路径 最大熵马尔可夫模型之前那玩意是个生成模型，但是在只需要打标签的时候，生成模型就显得有点多余 那我们就可以让整个 X 指向每一个 Y，一对多 随后 MEMM 就不用转移和发射概率了，而是使用最大熵 给定前一个状态 Y，来观测 X，预计下一个 Y’ 的条件概率为 P(Y’|Y, X) 然后由于我们是连续的 Y，按顺序一个一个判断，所以需要累乘一下 它有 label bias 问题，也就是它会陷入局部最优解 条件随机场那么我们就需要 CRF，直接根据整个句子来判断，考虑上下文 变成无向图，然后我们再用一个 potential 特征函数来建模 关键区别是它的归一化因子会保证 P(Y|X) 的合为 1 优化和推理比如梯度下降，然后用 Viterbi 来推理 生成模型和判别模型A9 依存句法解析Dependency parsing (Dependency grammar, projectivity, transition-based parser, graph-based parsers, non-projective parsing) 依存语法前面提到过，找出谁依赖谁，谁支配谁，并且修饰词可以省略 依存语法对句子有个类似于 AST 一样的约束，也就是有一个根 投射性但是很显然人类的语言不可能随时满足 AST，所以我们需要判断 projectivity 比如，我喜欢吃苹果，有 我 -&gt; 喜欢 &lt;- 吃 &lt;- 苹果 的线性关系，这就是投射的 但是：苹果，我喜欢吃。这句话就会导致 苹果 -&gt; 吃 与 ROOT -&gt; 喜欢 的关系线交叉，这就是非投射的 注意，一定有一个 ROOT 节点去指向句子的动词 基于转换的解析器 操作 Stack Buffer Arcs INIT [ROOT] [I, like, apples] [] SHIFT [ROOT, I] [like, apples] [] SHIFT [ROOT, I, like] [apples] [] LEFT-ARC [ROOT, like] [apples] [(like, I)] SHIFT [ROOT, like, apples] [] [(like, I)] RIGHT-ARC [ROOT, like] [] [(like, I), (like, apples)] RIGHT-ARC [ROOT] [] [(ROOT, like), (like, I), (like, apples)] 非投射性解析转换解析器只能生成投射树，这肯定是不够高的 那我们可以使用 pseudo-projective parsing，它将非投射关系进行变形 比如重新标注，插入额外标记等，等解析完成后，再将预处理的部分还原 基于图的解析器1234567graph LR ROOT --&gt; I ROOT --&gt; like ROOT --&gt; apples like &lt;--&gt; I like &lt;--&gt; apples I &lt;--&gt; apples 使用 ChuLiu 等评分算法对每一条边打分 然后通过 maximum spanning tree 来找出最可能的依存关系 A10 基于词汇资源和潜在语义分析的词汇语义学Lexical semantics based on lexical resources and LSA (Word senses and dictionaries, lexical relations, word vectors, latent semantic analysis) 词义和词典从词典中找出一个词的含义，查字典哥们 词汇关系synonymy 和 antonimy 同义词反义词 还有动物（上）和老鼠（下）的关系，hypo-hypernymy 还有 finger 和 hand 的 meronymy 可以使用 WordNet 来查找这些关系并进行消歧 词向量WN 是手动标注的，这不好，我们可以从语料库中学习词向量 也就是根据词的上下文，和相似分布，来猜测词的含义 使用共现矩阵 词-文档 文档 1 文档 2 词 1 1 0 词 2 0 1 是统计词在文档中出现的次数 和 词-词 词 1 词 2 词 1 1 词 2 1 是统计词在同一个文档中一起出现的次数 潜在语义分析然后我们使用 SVD 来降维，找出词的潜在语义 LSA C = USV，U 和 V 是 orthonormal，S 是 diagonal U：词矩阵，V：文档矩阵，S：不同维度的重要性 A11 Word2vec 和 GloVeWord2vec and GloVe (CBOW and Skipgram tasks, neural embeddings, training architectures, negative sampling, GloVe algorithm) CBOW 和 Skipgram 任务首先，Word2vec 只能生成静态词向量，也就是说即使一个词有不同的含义，它的词向量仍然是一样的 所以不好处理多义词，比如 bank Skipgram 通过中心词来预测它周围的词，它是 n-gram 的扩展，但可以跳过一些非中心词 反过来，Continuous BOW 通过上下文来预测中心词，输入是 One-hot 编码的上下文 神经嵌入嵌入指的是把高维的数据映射到低维的空间，比如把词映射到一个向量 而神经嵌入就是通过神经网络来学习这个映射 训练架构对于 Skipgram，假设我们有单词序列 W，那么给定中心词 Wt，模型最大化 P(W(t-i), W(t-i+1), …, W(t+i) | Wt), i 是窗口大小 那其实也就是当有 Wt 的时候，把窗口大小内的词的概率最大化 对于 CBOW，给定上下文 W(t-i), W(t-i+1), …, W(t+i)，模型最大化 P(Wt | W(t-i), W(t-i+1), …, W(t+i)) 当有上下文的时候，最大化中心词的概率 传统的 softmax 需要计算词汇表中所有单词的概率，这不好 我们将词汇表变成一颗 Huffman 树，然后使用 hierarchical softmax 来计算 简单来说，我们将单词预测变成二叉决策 负采样实际上，语料库中的大部分词都是不应该和目标词一起出现的，与其把所有词都计算一遍，不如只计算一部分 这种随机抽取一些不应该一起出现的词来配对的方法就是负采样，随后每次模型只会更新一小部分参数 而正样本，就是上下文中出现的词 GloVe 算法Word2Vec 主要基于局部上下文窗口进行训练，而 GloVe 则是基于全局的共现矩阵 它更好的保留了词之间的语义关系 A12 评估词嵌入和基于内部词结构的嵌入Evaluating word embeddings and embeddings based on internal word structure (Intrinsic evaluations, extrinsic evaluations, subword [fastText] embeddings) 内在评估我们可以通过词类比 Analogy，词相似度，词类别等 对于词类比，我们可以测试类似于 Wking - Wman + Wwoman = Wqueen 的概率，概率越大，表现越好 而对于词相似度，我们可以比作看词联想游戏 比如看到猫，可以想到狗，我们使用余弦相似度来衡量 在合理的模型中，sim(猫, 狗) &gt; sim(猫, 汽车) 外在评估可以使用 NER 等实际任务来评估词向量的性能 子词[fastText]嵌入传统方法对没见过的词无能为力，但是 fastText 可以通过子词来生成词向量，类似于 n-gram 它跟 W2V 很像，只不过用了子词 A13 使用 RNN 进行语言建模和序列处理Language modeling and sequence processing with RNNs (Four types of sequence processing, sequence tagging, bidirectional RNNs, sequence encoding, sequence generation, seq2seq tasks, LSTM architecture) 四种类型的序列处理 单输入单输出，如图像分类 单输入多输出，如图像描述 多输入单输出，如情感分析 多输入多输出，如机器翻译 序列标注之前就提到过，比如 POS NER 等，可以使用一组 embedding -&gt; LSTM -&gt; softmax 来实现 双向 RNN也就是用两个 RNN，一个正向一个反向，然后把结果合并，这样能更好的捕捉上下文 序列编码首先我们要知道 Seq2Vec 是把序列编码成一个固定维度的向量 那我们就可以使用 LSTM 的最后一层输出来表示整个序列 双向 RNN 的话就用最大池化 RNN 就是 h_t = tanh(W_hx * x_t + W_hh * h_t-1 + b_h) h_t 输出，W_hx 输入到隐藏权重，x_t 输入 W_hh 隐藏到隐藏权重，h_t-1 前一刻的隐藏状态 ，b_h 隐藏偏置 序列生成Seq2Vec 或其他模型，比如ConvNN，可以生成一个向量，然后交给 LSTM 来生成序列 那么 Vec2Seq 公式为 y_t = softmax(W_hy * h_t + b_y) y_t 输出，W_hy 隐藏到输出权重，h_t 隐藏状态，b_y 输出偏置 seq2seq 任务把 Seq2Vec 和 Vec2Seq 结合起来，就叫 seq2seq 任务 我们可以使用 教师强制 来训练，它是把真实的输出作为下一时刻的输入 这样可以帮助模型更快的收敛，但是会导致推理时的性能下降 LSTM 架构是 RNN 的一种增强，它有三个门，Input Forget Output 它可以更好的处理长期依赖，避免梯度 vanishing 和 exploding 流程如下 遗忘门决定丢弃多少信息 输入门决定添加多少信息 将遗忘门的输出与记忆单元相乘，然后加上输入门的输出 输出门决定输出多少信息，然后生成新的隐藏状态","link":"/AI/NLP/NLP-PreExamA/"},{"title":"NLP-Prompt","text":"提示词 预训练、提示和预测描述 GPT-3 的论文介绍了一种使用预训练语言模型进行下游任务的新范式：只需适当地提示模型，并将输出映射到任务的输出域，而无需任何微调。他们区分了三种场景： 一般提示规则 指令应尽可能 详细、具体 和 精确 指定输出的 预期受众（如果适用）通常是有用的 复杂的提示还可以包括 人物描述 上下文示例 约束（例如，预期输出格式的模板） 解决方案所需的步骤 – 这引出了“链式思维提示”的概念 Pretrain, prompt and predict提示范式的一个重要特征是任务性能对提示的细节非常敏感： 示例选择 示例排序 任务表述 都可能产生巨大影响，因为模型具有各种偏差，其中包括： 多数标签 (majority)（imbalance 不平衡）偏差 新近性 (recency) 偏差（后面的标签更有影响力） 常见标记 偏差（更常见的标记更可能被预测） 提示工程列出的偏差（以及其他偏差）使得 优化 用于基于大型语言模型的零样本或少样本任务解决方案的提示变得至关重要，即使用适当的 提示工程 方法。 任务表述formulation 提示挖掘mining 给定一个监督数据集 ${\\langle x_i, y_i \\rangle}_{i=1}^{N}$，可以取一个语料库（例如，维基百科）并 搜索连接 $x$ 和相应 $y$ 的词或句法结构。变体： 中间词提示Barack Obama was born in Hawaii $\\Rightarrow$ [x] was born in [y] 基于依存关系的提示取包含 $x$ 和 $y$ 之间最短依存路径的最小跨度： France $\\xleftarrow{pobj}$ of $\\xleftarrow{prep}$ capital $\\xleftarrow{nsubj}$ is $\\xrightarrow{attr}$ Paris $\\Rightarrow$ capital of [x] is [y] 提示释义从一个 种子提示 开始，通过 释义 生成候选提示（例如，通过翻译和回译）。 示例种子: [x] shares a border with [y] $\\Rightarrow$ [x] has a common border with [y] $\\vdots$ [x] adjoins [y] [示例] 然后可以通过选择在目标任务的训练数据上表现最好的候选提示来选择最佳提示。 基于梯度的搜索构建一个由触发词组成的提示模板，例如 AutoPrompt 算法： 这些词由与坐标下降相关的算法找到： 初始化一个长度为 $L$ 的起始列表，填充掩码标记 对于每个 $i \\in 1 \\dots L$ 的标记位置 计算位置中标记嵌入的训练数据对数似然的 $\\mathbf{g}$ 梯度 对于每个词汇条目，使用梯度近似在该位置使用该词会带来的对数似然变化，并选择前 $k$ 个词 从中选择对数似然值最大的一个词，并用它替换当前位置的标记 这显然假设梯度是可访问的，尽管不需要更改参数。 提示生成可以将提示生成视为条件文本生成问题，并使用标准的 seq2seq 模型来解决。例如，使用预训练的 T5 生成在数据集上具有 高对数似然 的提示候选（使用束搜索）： 一种更激进的方法是提示大型语言模型生成指令： 提示评分最后，基于 BERT 的常识知识提取器，基于一组手工设计的提示模板，但对于任何具体的数据点，选择根据第二个预训练的单向语言模型（测量“连贯性”）具有最高概率的模板实例。 示例选择嵌入空间中的相似示例从训练数据中选择相似和随机的示例用于少样本预测： 对比学习依靠对比学习找到最有用的示例。提出的方法是： 使用（通常较小的）评分 $LM$ 在训练数据中找到正面和负面 $(e, x)$ 对，其中评分只是 $P_{LM}(y | e, x)$ 使用对比学习训练一个度量嵌入模型，该模型可用于为任何（示例，$x$）对分配分数 对于任何 $x$，检索包含根据模型评分最高和最低的 $k$ 个示例的正面和负面示例，并在少样本提示中使用这些示例 连续（“软”）策略前缀微调学习任务特定的嵌入向量序列，以作为实际输入（以及编码器-解码器的输出）嵌入的前缀： 这些向量仅使用训练集上的对数似然目标进行微调 作者实验了仅将前缀的 输入 嵌入作为可学习参数与在 所有层 中前缀嵌入的处理方式，后者方法带来了显著更好的结果 该方法的表现与完全微调相似 前缀微调变体连续前缀微调主题的变体： 离散初始化：优化可以从为任务自动或手动创建的离散提示开始，而不是随机初始化 离散-连续 混合微调：也可以固定提示的一些离散部分（使用“锚定标记”），并仅将前缀的其余部分作为可学习参数 辅助网络 (Auxiliary)：建模前缀嵌入之间的交互使用（相对）简单的网络，例如 LSTM，结果非常有用 答案工程LM 输出到下游任务输出域的映射也可以进行优化。 根据架构和任务，输出可以是 标记：这是分类任务的常见选择 Span：包含几个标记，通常用于“填空提示 cloze prompts” 句子：语言生成任务的自然选择 对于某些任务，直接使用 LM 输出是可行的，例如文本生成，但当 $\\mathcal{Y}$ 输出空间不同或受限时，需要进行映射，例如分类或命名实体识别（NER）任务。 一个简单的映射示例：$v(\\cdot)$ “口头化”函数将下游主题分类任务的类标签映射到答案标记。（输入是一个“填空问题”，模型预测其中的内容。） 找到每个 $y\\in \\mathcal{Y}$ 对应的合适答案集的方法包括 答案释义手动设计的种子答案集通过释义扩展。 修剪后搜索创建一个初始集合，例如通过释义，然后在该集合中搜索 $y$ 的最佳答案，例如通过选择在训练数据集上具有最大对数似然的替代答案。 组合提示提示集成类似于模型集成，将多个未回答提示的 LM 答案组合到相同的 $x$ 输入可以带来更好或更稳定的性能。组合方法可以是 均匀平均 uniform：将组合提示的答案概率分布简单平均 加权平均 weighted：最终分布是答案分布的加权平均——权重可以来自提示在训练数据集上的表现 简单的多数投票 majority 也可以用于分类 对于文本生成，组合提示并不那么简单，但一种方法是在每个生成时间步使用所有下一个词概率分布的平均值来生成下一个词。 基于推理结构的提示连锁思维提示对于涉及复杂推理的任务，例如数学问题解决或规划，提供逐步演示可以显著提高性能。例如， 问题：Tom 和 Elizabeth 进行了一场爬山比赛。Elizabeth 爬山用了 30 分钟。Tom 爬山的时间是 Elizabeth 的四倍。Tom 爬山需要多少小时？ 答案：Tom 爬山需要 30*4 = 120 分钟。Tom 爬山需要 120/60 = 2 小时。所以答案是 2。 问题：Jack 是一名足球运动员。他需要买两双袜子和一双足球鞋。每双袜子 9.50 美元，鞋子 92 美元。Jack 有 40 美元。Jack 还需要多少钱？ 答案：两双袜子的总成本是 9.50 x 2 = 19。袜子和鞋子的总成本是 19 + 92 = 111。Jack 需要 111 - 40 = 71 美元。所以答案是 71。 问题：Marty 有 100 厘米的丝带，他必须将其切成 4 等份。每个切割部分必须再分成 5 等份。每个最终切割部分有多长？ 答案： 更令人惊讶的是，“零样本连锁思维”在没有示例的情况下也有效： 问题：Marty 有 100 厘米的丝带，他必须将其切成 4 等份。每个切割部分必须再分成 5 等份。每个最终切割部分有多长？ 答案：让我们一步一步地思考。 自洽采样用于连锁思维提示Self-consistency sampling for COT，通过采样多个答案，即多个推理路径，而不是单一的贪婪解码，并将结果集成，例如通过多数投票，可以经常改善结果： 自问自答Self-ask 提示模型明确提出并回答后续问题也是一种有用的策略： 知识生成对于常识推理任务，提示大型语言模型生成相关知识也可能是有益的。（具体的表述和示例取决于任务。）生成的知识片段用于回答问题： 通过采样生成多个知识提示的答案，并使用它们生成问题的答案。可以通过多数投票选择最佳答案： 更复杂的思维结构关于连锁思维提示的一个常见观察是它假设了一条直接通向答案的顺序链（sequentialchain），但复杂的人类推理经常涉及 探索从共同起点分支的替代思维序列 丢弃一些思维分支 并回溯 直到找到最终结论。 思维树提示框架支持使用适当的提示执行这种类型的推理步骤。 思维树提示 主要组件是： 明确定义当前任务的 单元思维（unit thought） 是什么（一个段落、一个公式等） 为一个分支生成 延续思维（continuation thoughts，例如，通过采样） 评估 思维 决定下一个扩展节点的 搜索策略（例如，广度优先搜索） 有尝试通过单一提示引出类似思维树的推理，例如，@tree-of-thought-prompting 使用以下示例提示： 123456想象三个不同的专家在回答这个问题。所有专家将写下他们思考的第1步，然后与小组分享。然后所有专家将继续进行下一步，等等。如果任何专家在任何时候意识到他们错了，他们就会离开。问题是... 图思维提示树思维理念的自然扩展是添加思维路径的聚合。这导致将 T-o-t 提示推广到支持任意有向无环图拓扑的Graph-of-thoughts框架： 当然，增加的复杂性需要更复杂的架构，例如，使用以下模块（适应实际任务）： Prompter 用于准备编码图结构的提示 Parser 从输出中提取思维状态并更新动态的图推理状态结构 Scorer 和 Validator 用于评估思维 Controller 用于控制图构建过程的步骤 程序辅助的连锁思维推理连锁思维提示的一个有趣研究方向是提示 LLM 进行形式推理或计算步骤（例如，Python 语句），并通过外部解释器或推理器执行这些步骤生成最终答案。 漏洞除了与 LLM 相关的常见问题（可能的幻觉、危险或有害内容等），将外部输入纳入 LLM 提示的方法可能容易受到各种类型的对抗性提示（adversarial）的攻击，并且必须加以防范： 提示注入 影响 LLM 的行为，使其忽略原始指令做一些意想不到的事情 提示泄漏 注入内容，使 LLM 泄露其提示的细节，这些提示可能包含敏感信息 尾声：元提示 LLM 作为提示优化器Metaprompted LLM 作为优化器使用（元 meta）提示的 LLM 作为通用优化器： \\dots LLM 生成目标函数的新解，然后将新解及其得分添加到元提示中以进行下一步优化。 LLM 作为优化器：在提示中的应用 LLM 作为优化器：在提示中的应用 I LLM 作为优化器：在提示中的应用 II发现元提示优化器方法在 GSM8K 数学问题数据集上表现优于众所周知的手动提示工程方法，如“积极思考”和“链式思维”： 意想不到的最佳提示此外，最佳提示通常是令人惊讶和古怪的：","link":"/AI/NLP/NLP-Prompt/"},{"title":"NLP-RNNs","text":"递归神经网络 介绍使用神经网络进行语言建模正如我们所见，使用学习到的词嵌入的前馈神经网络语言模型已经比传统的 $n$-gram 模型表现得更好： 与最好的 $n$-gram 模型相比，困惑度提高了24%。 但这些模型仍然与$n$-gram模型共享一个重要的限制：续接（continuation）预测基于固定大小的上下文窗口，没有任何关于早期历史的信息： $$ \\hat P(w_{t}~|~w_0,\\dots,w_{t-1}) = \\phi(w_{t-k},\\dots, w_{t-1}) $$ 其中 $\\phi(\\cdot)$ 是由前馈神经网络计算的函数。 循环神经网络 (RNNs)Recurrent Neural Networks与此不同，它们不受限于固定长度的输入序列，并且至少在理论上可以形成有用的任意长历史的内部表示。它们可以逐步处理顺序输入，并在每一步更新内部状态： RNNs 可以非常简单，例如曾经广泛使用的 Elman 网络具有以下结构： $$h_t = a_h(U x_t + W h_{t-1} + b_h )$$ $$o_t = a_o(Vh_{t} + b_o )$$ 反向传播通过时间RNNs 的标准优化方法是backpropagation through time (BPTT)，这是应用于时间展开网络的反向传播： 由于展开的 RNN 的深度随着展开的时间步数线性增长，通常无法对所有时间步进行反向传播。 在这些情况下，展开和误差的反向传播仅在一定数量的时间步内进行 - 反向传播是截断的（backpropagation is truncated）。实际上，大多数神经网络框架实现了截断反向传播。 RNN 训练挑战训练 RNNs 存在显著的挑战： 一个展开了多个时间步的 RNN 在反向传播方面表现得像一个深度前馈网络，因此梯度消失（vanishing）和梯度爆炸（exploding gradients）都可能成为问题，尤其是因为完全相同的层被重复使用。 特别是梯度消失，意味着 RNN 无法学习长期依赖（long-term dependencies），而这在理论上应该是它的强项。 长短期记忆网络Long Short-Term Memory (LSTM)一种复杂的门控拓扑（gated topology）结构，使 RNNs 具有长期记忆，并解决了 梯度消失/爆炸 问题。 Cell stateLSTM 的单元状态充当“信息传送带”（conveyor belt），信息可以在时间步之间传递。 Forget gate遗忘门计算一个 $f_t\\in (0,1)^d$ 掩码，用于从单元状态中移除信息： $$f_t=\\sigma(W_f[h_{t-1}, x_t] + b_f)$$ Input gate and update vector计算输入掩码 $i_t$ 和更新向量 $\\tilde C_t$： $$i_t=\\sigma(W_i[h_{t-1}, x_t] + b_i)$$ $$\\tilde C_t = \\tanh(W_C[h_{t-1}, x_t] + b_C)$$ 计算新的单元状态使用 $f_t, i_t$ 和 $\\tilde C_t$ 计算新的单元状态： $$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde C_t$$ 输出最后，生成输出 $h_t$： $$o_t = \\sigma(W_o[h_{t-1}, x_t] + b_o)$$ $$h_t = o_t \\odot \\tanh(C_t)$$ LSTM 优势门控 LSTM 架构通过确保梯度可以流向远处的时间步，解决了梯度消失/爆炸的问题。 更新是加性（additive）的，这意味着梯度不会像 Elman 网络那样被相乘，并且门控可以在训练期间获得权重，使网络能够在输入和输出值之间表现出长距离依赖关系。 LSTM 变体：窥视孔连接Peephole connections 通过允许门控访问实际的单元状态来扩展 LSTM 架构： LSTM 变体：门控循环单元Gated Recurrent Unit (GRU) 是一种简化的 LSTM 变体，它去除了单独的单元状态，并合并了遗忘门和输入门： 使用 RNNs 进行语言建模 该模型最显著的特点是： 之前的词（“left context”）逐步处理，每次一个词 第一层是静态词嵌入 $h_t$ RNN 的直接输出（隐藏状态）通过仿射（affine）变换和 $\\mathop{\\mathrm{softmax}}$ 非线性变换，转化为词汇表上的续接概率分布 序列元素虽然传统的 RNN 语言模型是基于词的，即序列元素是词，但有两个重要的替代方案： 字符级 语言模型将character视为序列元素，并根据之前的字符预测下一个字符 子词级 语言模型基于subword分词（例如 BPE），并预测词汇表中的下一个子词 这两种类型的模型都可以利用相应的字符和子词嵌入。 训练基于 RNN 的语言模型与所有参数化语言模型一样，使用通常的负对数似然损失进行训练：如果训练序列是 $\\langle w_1,\\dots, w_n \\rangle$，并且 $\\hat P_i$ 是模型对第 $i$ 个续接概率的输出分布，那么损失是 $$- \\sum_{i=1}^n \\log \\hat P_i(w_i)$$ 但是在训练期间，每个时间步 RNN 的输入应该是什么？应该来自训练数据，还是来自 RNN 之前的预测？ RNN 语言模型通常使用训练数据作为输入进行训练。这称为teacher forcing。 Exposure bias尽管教师强制是目前最常用的训练方法，但它有一个主要问题，即所谓的 曝光偏差 现象： 使用教师强制训练的语言模型仅暴露于其输入完全来自训练语料库的情况 相比之下，在推理期间，它们必须为不在训练数据中的文本生成续接，最重要的是，在文本生成期间，它们必须继续自己的输出 解决方案 计划采样：在每个时间步随机选择使用训练数据作为输入还是从模型的预测中采样。选择从训练集中的概率从 1.0 开始，并在训练期间逐渐减少 可微采样：在原始 Scheduled sampling 中，误差不会通过使用的采样操作进行反向传播，因为它是不可微的。对此，开发了 Differentiable 的替代采样解决方案，最重要的是使用所谓的 Gumbel softmax 重参数化（reparametrization） 多层 RNN现代基于 RNN 的架构经常将多个 RNN 单元堆叠在一起作为层，类似于多层前馈网络： 性能在 transformer 出现之前，基于 LSTM 的语言模型在性能上始终优于其他架构，即使在现在也非常具有竞争力。 在 NLP-progress 跟踪的 9 个语言建模数据集中，有 5 个数据集上基于 LSTM 变体的模型（所谓的 Mogrifier LSTM）表现最好，而在剩下的 4 个数据集中，基于 LSTM 的模型非常接近（transformer 产生的）最先进水平。","link":"/AI/NLP/NLP-RNNs/"},{"title":"NLP-Seq2Seq","text":"RNN 序列模型和注意力 基于 RNN 的序列处理根据输入、输出和 hidden/cell 状态的处理方式，RNN 可用于各种序列转换和处理任务： 也许最基本的是将 $\\langle \\mathbf{x}_1,\\dots,\\mathbf{x}_n \\rangle$ 输入序列转换为 $\\langle \\mathbf{y}_1,\\dots,\\mathbf{y}_n\\rangle$ 序列的对应输出。 这种类型的架构可以用于序列标注，当输出是标签的分布时。例如，语言建模可以被视为序列标注的一个特例，当文本中每个单词的正确“标签”只是下一个单词： $$\\mathbf{x} = \\langle w_1,\\dots,w_{n-1}\\rangle$$ $$\\mathbf{y} = \\langle w_2,\\dots,w_{n}\\rangle$$ 序列标注一个简单的标注示例：基于 LSTM 的词性标注器，具有词嵌入输入和 softmax 输出层。 双向 RNN作为序列标注任务的语言建模有一个非常特殊的属性：模型不能访问要标注元素之后的元素信息。 对于其他序列标注任务，这种情况并不成立：元素之后的上下文是输入的重要组成部分。但 RNN 单元本质上是单向的：隐藏状态只能包含关于较早时间步输入的信息。一种广泛使用的方法是使用双向 RNN 并在每个元素处连接它们的隐藏状态。这就是所谓的 Bidirectional RNN 层。 自然地，双向 RNN 层可以像普通的单向 RNN 一样堆叠： Seq2vec: 序列编码有许多任务需要将可变长度的输入序列映射到固定长度的输出，例如情感分类等序列分类任务。 如何使用一个或多个堆叠的 RNN 将输入序列映射到一个有用的表示整个输入的向量？关键在于 RNN 的 隐藏状态（加上 LSTM 的 cell 状态）可以表示到给定时间步的整个输入序列。 对于单向 RNN，显而易见的解决方案是使用最后的隐藏状态（在 LSTM 的情况下可能还包括 cell 状态）来表示整个输入序列。例如，对于分类任务： 相比之下，双向 RNN 的隐藏状态在每个时间步都包含关于整个输入的信息，因此更有意义的是聚合所有隐藏状态，例如，使用平均或最大池化。 Vec2seq: 序列生成基于固定大小向量的序列生成类似于使用语言模型的语言生成，但在这种情况下，生成是有条件的：我们希望建模序列概率 $$P(\\langle y_1,\\dots, y_n\\rangle ~|~ \\mathbf{x})$$ 其中 $\\mathbf{x}$ 是一个固定长度的向量。类似于基于 RNN 的无条件语言模型，我们可以将问题简化为使用 RNN 建模个体 $$P( y_n|~ \\langle y_1,\\dots,y_{n-1} \\rangle, \\mathbf{x})$$ 续接概率。 标准的基于 RNN 的语言模型架构可以通过一个简单的修改来重用：RNN 的隐藏状态也依赖于条件向量 $\\mathbf{x}$。模型具有以下条件独立结构： 在神经网络架构层面，可以通过多种方式将 RNN 的隐藏状态依赖于 $\\mathbf{x}$： 使用 $\\mathbf{x}$（直接或经过转换）作为 RNN 的初始隐藏状态（对于 LSTM 也作为初始 cell 状态） 使用 $\\mathbf{x}$（直接或转换后）作为第一个时间步的输入 使用 $\\mathbf{x}$（直接或转换后）作为每个时间步的输入（除了已经生成的序列元素之外） 最常用的两种解决方案，例如，以下图像字幕模型使用图像的特征向量作为第一个 LSTM 输入： Vec2seq 模型的训练同样类似于无条件语言模型的训练： 主流策略是 教师强制：训练数据集的序列用作 RNN 输入，预测的续接概率仅用于计算损失（负对数似然）。 与无条件情况一样，教师强制会导致 暴露偏差（训练和推理设置之间的不健康差距），因此也使用诸如计划采样等替代训练策略。 基于 RNN 的 Seq2seq通过将 RNN Seq2vec 与 RNN Vec2seq 模块结合，我们可以构建一个 Seq2seq 模型，该模型通过首先将输入编码为固定大小的向量表示，然后将该向量解码为另一个序列，从而将可变长度的输入序列转换为另一个未对齐（unaligned）的序列。组合模型的概率结构如下： 历史上，基于 RNN 的 Seq2seq 模型是 RNN（更具体地说，是 LSTM 变体）最成功的应用之一。应用包括： 机器翻译（LSTM Seq2seq 模型是第一个与传统短语翻译解决方案竞争并后来优于它们的神经机器翻译模型） 摘要生成 问答系统 对话系统 在架构上，这些模型通常是： 基于嵌入的 在编码器和解码器中使用多个 LSTM 层 使用编码器的（最后或聚合的）隐藏状态和 cell 状态初始化解码器的隐藏状态和 cell 状态 像往常一样，通过教师强制和负对数似然损失进行训练 虽然解码器不能包含反向 RNN（显而易见的原因），但编码器通常包含双向 RNN 层。 这个模型展示了如何将一个输入序列翻译成另一个语言的输出序列。编码器将输入序列编码成一个固定长度的向量，解码器则根据这个向量生成目标语言的序列。该模型通常使用注意力机制来提高翻译质量。 注意力机制在基本的 RNN Seq2seq 模型中，如我们所见，解码器只能以编码器生成的固定大小向量表示形式访问编码的输入序列。 显著的是，这个固定大小的“摘要”并不依赖于解码器在解码过程中的位置，尽管我们知道对于典型的 Seq2seq 任务，例如翻译，输入的不同部分在不同的解码阶段是相关的。 即使固定大小的向量是通过对整个编码器隐藏状态序列进行池化生成的，解码器的上下文对池化没有影响。 注意力机制通过在每个解码时间步提供对编码器隐藏状态的动态池化版本的访问来解决这个问题，基于编码器的上下文，即 $h_{t-1}^d$ 隐藏状态： 具体来说，注意力机制基于 $h^d_{t-1}$ 解码器上下文使用 $s(\\cdot, \\cdot)$ 评分函数对 $\\mathbf{h}^e=\\langle h_1^e\\dots,h_n^e \\rangle$ 编码器隐藏状态进行评分，并使用得分的 softmax 产生加权和： $$\\mathbf{s}(\\mathbf{h}^e, h_{t-1}^d ) =\\langle s({h}^e_1, h_{t-1}^d),\\dots, s({h}^e_n, h_{t-1}^d) \\rangle$$ $$\\mathcal A(\\mathbf{h}^e, h_{t-1}^d) = \\mathop{\\mathrm{softmax}}(\\mathbf{s}(\\mathbf{h}^e, h_{t-1}^d )) \\cdot \\mathbf{h}^e$$ 注意力机制：评分函数根据评分函数的类型，注意力机制主要有两种类型： 加性 或 MLP 或 Bahdanau 注意力：评分通过一个简单的具有一个隐藏层的前馈网络计算： $$s_{add}(\\mathbf{a}, \\mathbf{b}) = \\mathbf{v^\\intercal}\\tanh(\\mathbf{W_1\\mathbf{a} + \\mathbf{W_2} \\mathbf{b}})$$ 其中 $\\mathbf{v}$、$\\mathbf{W}_1$ 和 $\\mathbf{W}_2$ 是学习到的参数。 乘性 或 Luong 注意力：评分计算为 $$s_{mult}(\\mathbf{a}, \\mathbf{b}) = \\mathbf{a}^{\\intercal} \\mathbf{W} \\mathbf{b}$$ 其中 $\\mathbf{W}$ 同样是学习到的参数。 点积注意力Dot product 评分是一种重要的、简单的乘性评分变体，其中 $\\mathbf{W}$ 是单位矩阵，即， $$s_{dot}(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\sqrt d}$$ 其中 $d$ 是 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的维度，除以 $\\sqrt d$ 确保如果 $\\mathbf{a}$ 和 $\\mathbf{b}$ 输入具有 0 均值和 1 方差，则得分也具有 0 均值和 1 方差。 注意力机制带来的性能提升将注意力机制添加到 RNN Seq2seq 架构通常会带来显著的性能提升，在翻译任务中困惑度降低了 11%，BLEU 分数提高了 20%。 因此，最先进的 RNN Seq2seq 模型几乎总是包含某种类型的注意力机制。 注意力权重可视化显示了它们如何反映对解码步骤的相关性： 前言：卷积神经网络（CNNs）尽管我们的讨论集中在 RNN 上，但卷积网络在许多 NLP 任务中也相当有竞争力。它们使用一维卷积： …以及一维（通常是最大或平均）池化层。事实上，表现出色的 fastText 分类模型使用了没有卷积的池化：","link":"/AI/NLP/NLP-Seq2Seq/"},{"title":"NLP-StaticNeuralEmbeddings","text":"静态嵌入式神经网络 词向量和神经网络LSI 和 LSA 的成功表明，基于分布的词向量表示对于 NLP 任务非常有用。在神经网络 NLP 模型中，连续的、密集的词表示尤其重要，因为它们 可以用作信息丰富且经济的表示，而不是简单地对词进行独热编码 可以帮助减少模型参数的数量 可以通过神经网络从文本语料库中以自监督的方式学习 一个由神经网络学习到的词向量的最早实例之一可以在语言模型中找到： $C$ 是一个嵌入层，将词汇索引映射到实数向量： $$C: [0, |V|-1] \\rightarrow \\mathbb R^d$$ （静态）词嵌入的维度通常在 50 到 600 之间。 从技术上讲，嵌入层可以通过多种方式实现，例如，作为一个以独热编码词索引为输入的密集层（在这种情况下，词向量表示为层的权重矩阵），或者作为一个表示为数组的查找表等。 关于嵌入层的重要经验教训： 嵌入是静态的：相同类型的标记在不同上下文中具有相同的嵌入 使用端到端训练的词嵌入层的模型比传统的 n-gram 语言模型表现更好 使用词共现频率矩阵的前几个主成分作为词特征向量，而不是训练的嵌入，没有同样的性能优势 使用神经网络学习词嵌入是一种扩展训练语料库的可行方法 Word2vec区别特征Word2vec，也是一个神经网络家族，从语料库中学习有用的分布式词表示，但具有几个新颖的特征： 它是一个专用架构：表示学习 （representation learning）是其唯一目标 它基于一种新的基于语料库的自监督预测任务 架构被故意保持非常简单，以便能够在具有大词汇量的巨大语料库上进行训练 SkipgramsWord2vec 基于 skipgrams，它是 $n$-grams 的推广：虽然 $n$-gram 是文本的连续、长度为 $n$ 的子序列，但 skipgrams 可以包含一定数量的“jumps”：如果基本序列是 $\\langle w_1, \\dots ,w_N \\rangle$，那么具有最多 $k$ 跳距的 $n$ 长度 skipgrams 集合是 $${\\langle w_{i_1} ,\\dots ,w_{i_n}\\rangle | i_1&lt;\\dots&lt;i_n\\in[1, N],i_n - i_1 \\leq n -1 + k }$$ 可以有额外的限制，例如对单个跳跃的数量和长度的限制。 Word2vec 任务Word2vec 任务具体基于长度为 $2c$ 的 skipgrams，在中心有一个单词跳跃。有两种任务变体及其相关的模型架构： CBOW: Continuous Bag of Words 预测 skipgram 中心的缺失词 SkipGram: 给定 缺失/跳过 的词，预测 skipgram 的元素。与 CBOW 任务不同，每个 skipgram 对应一个分类示例，SkipGram 任务为每个 skipgram 生成多个 $\\langle$ 中心词，skipgram 中的词 $\\rangle$ 示例 skipgram 任务的简单示例： 架构 虽然 SkipGram（右）只是将 $E(\\cdot)$ 嵌入映射应用于其一个词输入，CBOW（左）嵌入输入 skipgram 中的所有词并计算它们的和。 在将输入投影到词嵌入空间后，这两种架构都仅使用一个带权重矩阵 $W \\in \\mathbb R^{|V|\\times d}$ 的线性投影和一个最终的 softmax 层来生成词汇表中所有词的预测概率： $$CBOW(\\langle w_{t-c},\\dots ,w_{t+c} \\rangle) = \\mathop{\\mathrm{softmax}}(W\\sum_{i}E(w_i))$$ $$SkipGram(w_t) = \\mathop{\\mathrm{softmax}}(W_{}E(w_t))$$ 这两种模型都使用标准的负对数似然损失和 SGD 进行训练，但在示例采样方面有一些有趣的差异。 值得注意的是，投影矩阵 $W \\in \\mathbb R^{|V|\\times d}$ 也可以看作是词汇表在相同 $R^d$ 空间中的 $E’(\\cdot)$ 嵌入。使用这种表示法，两个模型对于特定单词 $w_j$ 的 logits（线性输出）可以简单地写成： $$CBOW_{linear}[\\langle w_{t-c}, \\dots ,w_{t+c} \\rangle](w_j) = \\sum_{i}E(w_i) \\cdot E'(w_j),$$ $$SkipGram_{linear}[w_t](w_j) = E(w_t) \\cdot E'(w_j)$$ 如这种表示法所示，最小化负对数似然训练目标是一种增加输入嵌入和正确预测嵌入的点积的方法。 由于这种表示法所显示的对称性，可以选择绑定两层的权重，使得对所有 $w\\in V$ 都有 $E(w) = E’(w)$。 尽管这种方法经常被采用，但通常也会保持它们的不同，并且仅使用输入嵌入 $E(\\cdot)$ 的向量作为最终结果，或者将它们结合起来，例如取它们的平均值。 数据点生成和采样对于 CBOW 变体，我们只需将 $c$ 半径的上下文窗口滑动通过语料库，并在每一步生成一个 $$\\langle \\langle w_{t-c}, \\dots ,w_{t-1}, w_{t+1}, \\dots ,w_{t+c} \\rangle, w_t \\rangle$$ $\\langle$ 输入，正确输出 $\\rangle$ 数据点。 对于 SkipGram，过程更为复杂，因为在每一步中，实际使用的上下文窗口半径 $r$ 是从 $[1, c]$ 区间内随机选择的，并且为每个 $w_i\\in \\langle w_{t-r}, \\dots ,w_{t-1}, w_{t+1}, \\dots ,w_{t+r}\\rangle$单词生成一个 $\\langle w_t, w_i\\rangle$ 数据点。其效果是离目标词越近的词被采样的概率越高。 避免 full softmax由于对一个 $|V|$ 长度的向量计算全 softmax 对于大 $V$ 来说是昂贵的，Word2vec 实现通常使用更便宜的输出层替代方案。 一种解决方案是 hierarchical softmax，它基于一个二叉树，其叶子是词汇表中的单词。网络的线性输出对应于内部节点，分配给一个单词 $w$ 的概率可以通过仅计算路径上 $o$ 输出的 $\\sigma(o)$ 值来计算。使用平衡树，这个技巧将训练期间 softmax 计算的复杂度从 $\\mathcal O(|V|)$ 降低到 $\\mathcal O({\\log |V|})$，并且通过巧妙的树结构可以进一步减少。 Hierarchical softmax 说明：如果路径上的线性输出是 $o(w_2, 1), o(w_2, 2), o(w_2, 3)$，那么分配给 $w_2$ 的概率可以计算为 $(1-\\sigma(o(w_2,1)))(1-\\sigma(o(w_2,2)))\\sigma(o(w_2,3))= \\sigma(-o(w_2,1))\\sigma(-o(w_2,2))\\sigma(o(w_2,3))$。 负采样另一种替代方案是 Negative sampling。这涉及将 SkipGram 任务重新表述为一个二元分类问题。 我们将语料库中的早期 SkipGram $\\langle$ 中心词，背景词 $\\rangle$ 数据点视为正例 并且通过从代表整个语料库的噪声分布中采样，为每个中心词生成一定数量的负例“假背景词” 负采样技巧使得简化网络架构成为可能，达到 $$SGNS(w_{t}, w_{c}) = \\sigma(E_t(w_t)\\cdot E_c(w_c))$$ 其中 $E_t(\\cdot)$ 是目标（中心）词嵌入，而 $E_c(\\cdot)$ 是背景词嵌入。对于从 $P_n$ 噪声分布中采样的 $k$ 个负样本，每个真实 $\\langle w_t, w_c\\rangle$ 数据点的负对数似然损失将是 $$- [ \\log SGNS(w_{t}, w_{c}) + \\sum_{\\substack{i=1 \\ w_i \\sim P_n}}^k \\log(1 - SGNS(w_{t}, {w_i}))]$$ Word2vec 作为矩阵分解在 Word2Vec 成功之后，许多研究调查了它与基于计数的矩阵分解方法的关系，结果发现它们密切相关：SGNS 目标等价于分解基于词共现的 $M$ 矩阵，其元素为 $$m_{ij} = \\max(0, PMI(w_i, w_j )- \\log k)$$ 其中 $PMI(w_i,w_j)$ 是 $w_i$ 和 $w_j$ 的 $\\log\\left(\\frac{P(w_i, w_j)}{P(w_i)P(w_j)}\\right)$ 点互信息，$k$ 是负样本的数量。 Pointwise Mutual InformationPMI 衡量单词在彼此上下文中出现的频率与它们独立出现的频率相比的差异。上下界由 $w_i$ 和 $w_j$ 从不 ($P(w_i, w_j) = 0$) 或总是 ($P(w_i, w_j) = P(w_i)$ 或 $P(w_i, w_j) = P(w_j)$) 共现的情况提供： $$-\\infty \\leq PMI(w_i, w_j) \\leq \\min(-\\log(p(w_i)), -\\log(p(w_j)))$$ PMI 公式中的 $\\frac{P(w_i, w_j)}{P(w_i)P(w_j)}$ 比例可以基于目标词-上下文词共现计数估计为 $$\\frac{C(w_i, w_j)C(\\mathrm{\\langle target~word, context~word\\rangle~pairs~in~corpus})}{C(w_i)C(w_j)}$$ 在一个大型维基百科片段中，PMI 分数最高和最低的三组二元组： 单词 1 单词 2 PMI puerto rico 10.03 hong kong 9.72 los angeles 9.56 $\\cdots$ $\\cdots$ $\\cdots$ to and -3.08 to in -3.12 of and -3.70 GloVeGloVe [Global Vectors] 是另一种从非常大的语料库中学习静态词嵌入的算法。它不是一种神经方法，但在这里讨论是因为它在 Word2vec 之后（一年）发表，作为对其的反应，并且是其最重要的替代方案之一。 与 LSA 方法类似，GloVe 明确基于固定大小上下文窗口中词共现的矩阵的低秩分解，但矩阵元素实际上是词共现的对数。 关注共现的对数是基于以下观察的动机：共现概率的比率在语义上非常有信息量： 该表显示了比率在区分与词对冰、蒸汽相关的词（即固体和气体）与噪声词方面做得很好。 直接分解共现对数概率矩阵需要对于任何 $w_i$, $w_j$ 词对满足 $$ E_w(w_i)\\cdot E_c(w_j)\\approx \\log (P(w_j~|~ w_i)) \\approx \\log (C(w_i, w_j)) - \\log (C(w_i)) $$ 其中 $E_w(\\cdot)$ 词嵌入和 $E_c(\\cdot)$ 上下文嵌入满足这个要求，$\\log(P(w_k \\space | \\space w_i)/P(w_k \\space | \\space w_j))$ 对数概率比可以简单地表示为 $(E_w(w_i) - E_w(w_j))\\cdot E_c(w_k)$，即语义上信息丰富的共现关系对应于嵌入之间的简单几何关系。 GloVe 不尝试最小化 $E_w(w_i) \\cdot E_c(w_j) + \\log (C(w_i)) - \\log (C(w_i, w_j))$ 的差异对于 $w_1,w_2\\in V$，而是最小化密切相关的 $$\\sum\\limits_{i, j=1}^{|V|} f(C(w_i,w_j)) (E_w(w_i)\\cdot E_c({w}_j) + b_w(w_i) + {b_c}(w_j) - \\text{log} C(w_i, w_j))^2$$ 目标。差异在于 $f(\\cdot)$ 加权函数对稀有共现进行降权， 为每个词学习的 $b_w$ 和 $b_c$ 偏差，提供了 $\\log(C(w_i))$ 的对称替代。 GloVe 训练与通过滑动上下文窗口训练的 Word2vec 不同，GloVe 的训练分为两个步骤： 组装全局共现计数矩阵 通过随机梯度下降（SGD）优化上述目标中的 $E_w, E_c, b_w, b_c$ 参数，随机采样共现矩阵的元素 与 Word2vec 相比，GloVe 由于处理共现矩阵（尽管是稀疏的）可能需要更大的内存，但这可以通过在之后对非零矩阵元素进行优化来补偿，其数量通常在语料库长度上是次线性的。 评估评估类型如何衡量词嵌入的质量？作为学习到的表示，词向量可以通过以下方式进行评估： 内在地，intrinsically 根据它们与人类对词语语义和形态特征的判断的对应程度 外在地，extrinsically 根据它们在下游 NLP 任务解决方案中的有用程度 从内在的角度来看，使用适当调整参数并在大型高质量语料库上训练的 Word2vec 可以生成几何特性与人类相似性判断惊人接近的嵌入。 内在评估评估词嵌入质量的两种最常用的内在方法是测试它们在两个词汇语义任务中与人类判断的相关性： 词相似度 Word similarity 类比 Analogy 相似度相似的词应该有相似的向量。 语义：dog - hound 语法：dogs - pears 两个词的相似度通过它们表示的余弦相似度来衡量：$\\frac{E(w_1)\\cdot E(w_2)}{|E(w_1)|\\times |E(w_2)|}$。 注意：归一化很重要，因为向量的长度大致与词频的对数成正比。 相似度可以通过使用降维技术（例如 t-SNE 或 UMAP）进行可视化，例如： 类比Analogy 任务测试词之间的 关系，例如 $king:queen$ 和 $man:woman$，它们在向量空间中的几何关系是否相似。 这些关系对应于向量的差异，即 $E(king)-E(queen)\\approx E(man)-E(woman)$ 或者，以稍微不同的形式，嵌入最接近 $E(king)-E(queen) + E(woman)$ 的词是否是 $man$。 语义和句法类比的示例： 数据集也有一些专门用于内在评估的数据集，例如： WordSim-353 数据集包含 353 对英语单词及其语义相似度分数，范围从 0.0 到 10.0。（注意：原始数据集混淆了相似性和相关性；链接版本大多修正了这一点。） SimLex-999 取代了 WordSim-353，包含 999 对单词及其相似度分数，使用相同的评分尺度。 BATS（The Bigger Analogy Test Set）包含 98000 个类比问题，用于测试单词类比与向量偏移之间的对应关系。 外在评估Extrinsic 评估可以使用任何 NLP 任务进行，但通常使用标准的序列标注任务，例如命名实体识别。 可以通过在嵌入式架构中切换不同的嵌入来评估它们，同时保持其他部分不变。 在使用嵌入时，有一个重要的区别是直接使用嵌入（“冻结”）而不改变它们，还是对它们进行 微调，即在任务数据集上与其他参数一起训练它们。 评估结果在某些共现矩阵上，Word2vec 变体、GloVe 和传统 SVD 之间的性能差异不大。最重要的是，他们发现 超参数调优对性能的影响大于算法的选择 SGNS 被证明是一个非常强的基线，在任何情况下都没有“显著表现不佳” 两个学习到的嵌入（目标和上下文）的和通常比单独使用其中一个表现显著更好 利用内部词结构Utilizing internal word structure 黑箱问题我们讨论的词嵌入完全基于分布，词的内部结构不起作用。因此， 词汇表外的词，和 在训练语料库中罕见的词 没有足够的嵌入，即使它们的 内部形态/字符结构（internalmorphological/character structure） 可以提供关于其语义和句法属性的丰富信息。 除了使用需要形态分析器的词素（morpheme）嵌入外，还出现了一些自监督解决方案。 fastTextfastText 算法基于 SGNS，但将 $n$-grams ($3\\leq n \\leq 6$) 添加到词汇表中，并将目标词建模为其所有组成部分嵌入的总和。 例如，对于单词 where 和 $n=3$，其组成部分是 &lt;wh、whe、her、ere、re&gt;，加上整个单词 &lt;where&gt;。 SGNS 架构被修改为 $$\\sigma(\\sum_{w\\in G(w_t)}E_t(w)\\cdot E_c(w_c))$$ 其中 $G(w_t)$ 是 $w_t$ 的所有组成部分的集合。 在相似性任务中，fastText 向量通常比原始 Word2vec 表现更好，尤其是在形态丰富的语言中。 一个额外的重要优势是，使用 fastText 可以通过将其组成 $n$-grams 的嵌入相加来生成未见词的有信息嵌入。 子词嵌入解决黑箱问题的一个更激进的解决方案是切换到子词分词（例如，使用 BPE）并使用已建立的算法仅为词汇表中的子词生成嵌入。 例如，PBEmb 使用 GloVe 为 BPE 分词生成的子词生成嵌入。类似于 fastText，可以通过组合组成子词的嵌入（例如，取平均值）来生成 OOV 词的嵌入。虽然表现相似，但这种类型的解决方案所需的词汇表明显小于 fastText。","link":"/AI/NLP/NLP-StaticNeuralEmbeddings/"},{"title":"NLP-Tokenization","text":"本章主要讲述了 NLP 的令牌化 基准：按空白字符分割 对于许多书写系统，按空白字符分割文本是一个有用的基准： ‘This isn’t an easy sentence to tokenize!’ $\\Rightarrow$[‘This’, &quot;isn’t&quot;, ‘an’, ‘easy’, ‘sentence’, ‘to’, ‘tokenize!’] 问题： 我们通常希望将标点符号视为单独的标记（但仅当它们确实是标点符号时，例如 ‘U.K.’ 或 ‘10,000.00$‘）； 这种解决方案无法分隔没有空白字符的标记对，例如带有附加成分的表达式，如 &quot;isn’t&quot;。 正则表达式和语言正则表达式我们需要引入更复杂的模式来以上下文相关的方式描述标记边界。一种流行的解决方案是使用正则表达式（简称 regex）。 给定一个有限的 $\\Sigma$ 符号字母表，$\\Sigma$ 上的正则表达式及其在 $\\Sigma^*$ 中的匹配通过同时递归定义如下： 空字符串和 $\\Sigma$ 中的任何单个符号都是 $\\Sigma$ 上的正则表达式，并匹配其自身。 如果 $r_1$ 和 $r_2$ 是 $\\Sigma$ 上的正则表达式，那么 它们的 连接，$r_1 r_2$ 也是 $\\Sigma$ 上的正则表达式，并且匹配那些恰好是匹配 $r_1$ 的字符串和匹配 $r_2$ 的字符串连接起来的字符串，且 它们的 交替，$r_1 \\vert r_2$ 也是 $\\Sigma$ 上的正则表达式，并且匹配那些恰好匹配 $r_1$ 或 $r_2$ 的字符串。 如果 $r$ 是 $\\Sigma$ 上的正则表达式，那么对 $r$ 应用 Kleene 星号 运算符，我们可以形成一个新的正则表达式 $r^*$，它恰好匹配那些由 0 个或多个匹配 $r$ 的字符串连接起来的字符串。 形式语言给定一个有限的字母表 $\\Sigma$，一个 形式语言 $\\mathcal L$ 是 $\\Sigma$ 上字符串的任意集合。这些字符串通常通过 语法 定义。 根据语法的复杂性，语言可以分为不同的 类型。最著名的是乔姆斯基层次结构： 正则语言：可以描述线性结构 编程：状态机 语言：单词，名词短语 上下文无关语言：可以描述树结构 编程：XML DOM，解析树 语言：短语结构语法（句子） 上下文相关语言：大多数人类语言是轻度上下文相关的 递归可枚举语言：所有可以通过算法解决的问题 回到正则表达式一个形式语言 $\\mathcal L$ 当且仅当存在一个正则表达式恰好匹配 $\\mathcal L$ 的元素时，才是 正则的。 有一些简单的形式语言不是正则的，例如“孪生语言” ${ww \\vert w \\in {a, b}^* }$。 尽管如此，正则表达式对于许多实际任务来说已经足够灵活，并且存在高效的算法来决定字符串 $s$ 是否匹配正则表达式（时间复杂度为 $\\mathcal O(\\mathrm{length}(s))$）。 有限状态接受器与正则语言有限状态接受器是消耗字符输入序列并可以“接受”或“拒绝”输入的有限状态机。它们与最简单的 FSA (有限状态自动机) 不同之处在于： 有一个明确的 开始状态， 一组指定的 接受状态，以及 它们的转换由有限字母表中的符号或空字符串标记。 当且仅当有限状态接受器具有从开始状态开始、在接受状态结束的转换序列，并且转换标签的连接是所讨论的输入时，它才 接受 输入。 接受单词“car”、“cars”、“cat”和“cats”的接受器： 可以简化为： 有限状态接受器与 正则语言/表达式 之间的联系由 Kleene 的 等价定理 建立： 当且仅当存在一个 FSA 接受器恰好接受其元素时，一个语言是正则的。 这种等价性在理论和实践中都很重要：有非常高效的算法可以 简化/最小化 有限状态接受器，并决定它们是否接受一个字符串。 正则表达式：扩展便利扩展 不增加表达能力，只是添加了一些有用的快捷方式，例如： 字符类匹配集合中的任何单个符号，例如 [0-9]； 补充字符类匹配 不在 补充集合中的任何字符，例如 [^ab]； 用于指定模式重复次数的运算符，例如，$r{m,n}$ 匹配 $s$ 如果 $s$ 重复 $r$ 模式 $k$ 次，其中 $m\\leq k \\leq n$。 可选匹配：$r? = r{0,1}$ Kleene plus：$r+ \\approx r{1,\\infty}$ 正则表达式：反向引用所谓的 反向引用 结构，允许命名和引用与正则表达式的早期部分相对应的匹配项，从而增加了表达能力。 例如，大多数当前的正则表达式库允许类似于以下的正则表达式： 1(?P&lt;a&gt;[ab]*)(?P=a) 它使用反向引用来定义前面提到的非正则“孪生语言”。 基于正则表达式的查找和替换除了将整个字符串与正则表达式匹配之外，还有两个基于正则表达式的常见任务： 查找与正则表达式匹配的字符串子串， 基于正则表达式的查找和替换：在其最简单的形式中，这是用给定的字符串替换匹配的子串，但现代正则表达式库提供了两个显著的额外功能： 正则表达式可以有前瞻和后顾部分，这些部分在查找匹配时使用，但不计入被替换的部分； 替换不必是固定的—它们可以包含对匹配部分的反向引用。 基于规则的分词基于正则表达式级联的分词核心思想：对输入执行基于正则表达式的替换，最终只需按空白字符分割即可。 Penn Tree Bank 附带的 分词器 sed 脚本 是一个很好的例子。几个具有代表性的规则（\\&amp; 指代完整匹配，\\n 指代第 $n$ 个组）： ‘...’ $\\Rightarrow$ ‘ ... ‘（分隔省略号） [,;:#$%&amp;] $\\Rightarrow$ ‘ \\&amp; ‘（分隔各种符号） ([^.])([.])([])}&quot;‘]*)[]*\\ $\\Rightarrow$ ‘\\1 \\2\\3’（假设句子输入并仅分隔最终句号） &quot;‘ll&quot; $\\Rightarrow$ &quot; ‘ll&quot;（分隔缩略词 ‘ll） 主要问题是如何正确处理例外情况：例如，单词结尾的句号应被分割，除了缩写。 标准解决方案是在执行相关替换之前，将有问题的表达式替换为无问题的占位符，例如： (etc\\. $\\vert$ i\\.e\\. $\\vert$ e\\.g\\.) $\\Rightarrow$ &lt;abbrev&gt; 此解决方案需要跟踪占位符替换，并在执行有问题的规则后恢复原始内容。 基于词法分析器的解决方案它们使用现成的“词法分析器”（lexical analyzers），最初是为计算机程序的 令牌化/词法分析 而开发的。 一个典型的词法分析器将字符流作为输入，并从中生成分类的标记流： 大多数词法分析器实际上是词法分析器生成器。它们的输入是标记类（类型）、正则表达式模式和 [RegexPattern] $\\Rightarrow$ [Action] 规则（其中最重要的操作是将实际匹配分类为给定类型的标记），并生成一个具体的、优化的词法分析器来执行给定的规则，例如通过生成分析器的 C 源代码。 SpaCy 的基于规则的分词器 输入文本按空白字符分割。 然后，分词器从左到右处理文本。对于每个子字符串，它执行两个检查： 子字符串是否匹配分词器异常规则？例如，“don’t”不包含空白字符，但应被分割。 前缀、后缀或中缀是否可以被分割？例如，逗号、句号等标点符号。 如果有匹配，则应用规则，分词器继续循环，从新分割的子字符串开始。 一个简单的例子：对 “Let’s go to N.Y.!” 进行分词 编辑距离除了将输入分割成单元外，分词还涉及将标记分类为类型，例如决定哪些类型 ‘Apple’, ‘apple’, ‘appple’ 属于。在许多情况下，这些决策需要字符串之间的相似性度量。 在这个领域中，最重要的度量家族之一是所谓的 编辑距离 家族，它通过将两个字符串相互转换所需的最少编辑操作次数来衡量它们之间的距离。 给定 一组 编辑操作（例如，从字符串中删除或插入一个字符），以及 一个 权重函数，它为每个操作分配一个权重， 两个字符串之间的 编辑距离（一个源字符串和一个目标字符串）是将源字符串转换为目标字符串所需的最小总权重。 Levenshtein 距离最重要的变体之一是所谓的 Levenshtein 距离，其中操作是 删除， 插入，和 替换字符 且所有操作的权重均为 1.0。 子词分词分词 与 子词分词经典的分词旨在将输入字符流精确地分割成语言学上有意义的单元：单词和标点符号。 这种类型的分词对于人类语言分析很有用，但对于构建大型语言模型却不适用，因为它 相当具有挑战性，因为存在各种书写系统和语言，它们都需要（有时是根本不同的）规则/模型 在较大的语料库上会生成巨大的词汇表，并且仍然会导致词汇外单词的问题 一种最近开发的替代方法是 subword tokenization。许多现代的深度端到端 NLP 架构使用子词分词而不是经典分词来分割输入。其主要优点是： 需要很少或几乎不需要预分词 统计和数据驱动：从语料库中学习分割模型（无需手动编写规则） 词汇表大小可以自由选择；它将包含最常见的单词和子词单元 与书写和语言无关 这对文本意味着： 输入文本将被分割成最常见的单词和子词 分割质量取决于词汇表大小 对于单一语言，30,000 个类型就足够了 一个常规的词汇表通常有几十万甚至几百万个类型 没有词汇外单词（在正确设置下！） 子词片段通常是有信息量的，边界经常接近形态学（morphological）边界 字节对编码 (BPE)Byte Pair Encoding 最初是一种用于字节序列的简单压缩技术，但可以推广到由有限字母表中的符号组成的任何序列。为了生成字母表上的序列的 编码/压缩 版本， 用字母表中的符号初始化符号列表，并且 反复计算所有符号对，并用新的 ‘AB’ 元素替换每个最频繁对 (‘A’, ‘B’) 的出现，并将 ‘AB’ 添加到符号列表中 这种技术如何用于文本的子词分词？诀窍是通过对文本应用 BPE，从训练语料库中学习用于分割的词汇。修改如下： 从粗略的预分词开始（通常非常简单，例如按空白字符分割） 不允许 BPE 合并跨越单词边界。 在实践中，这些修改通常通过向字母表中添加一个新的 ‘_‘ 单词起始（或单词结束）符号来实现，并规定 ‘_‘ 只能结束（或开始）合并项。 一个简单的例子：在不同数量的合并操作后，句子的 BPE 编码版本。 随着合并次数的增加，越来越多的符号变成完整的单词。 贪婪 BPE 子词分词使用 BPE 处理语料库会产生 一个包含所有字符及其合并结果的 词汇表 以及按执行顺序排列的 合并列表 然后，通过按照合并列表中的顺序执行所有适用的合并，对新的预分词输入进行子词分词。 WordPieceWordPiece 是一种子词分词方法，与 BPE 只有略微不同。不同之处在于： 合并 AB 对是那些具有最高值的对 $\\frac{freq(AB)}{freq(A) \\times freq(B)}$，其中 $freq(\\cdot)$ 是训练语料库中类型的频率 使用生成的词汇进行分词时，使用 MaxMatch 算法： 子词采样BPE 和 WordPiece 的默认子词分词策略会确定性地生成单词的贪婪匹配分解，即使存在有信息的替代分割： unrelated = unrelate + d unrelated = un + related 为了解决这个问题，开发了从可能的替代分解中概率采样的解决方案。 BPE dropout 在分词过程中随机丢弃一些 BPE 合并规则，而 Unigram 语言模型 基于一种新颖的概率子词分词方法，该方法从启发式估计的最优词汇表的超集开始，并递归地删除对构建训练语料库的简单（单项）概率语言模型最不有用的条目。 与 BPE 相比，递归 Unigram 语言模型词汇构建步骤的概率性质使得可以为替代分割分配合理的概率，并从中进行采样。 SentencePiece在其原始形式中，BPE 和 WordPiece 需要（粗略的）预分词作为预处理步骤。与此相反，SentencePiece 分词器库能够以相同的方式处理每个字符，甚至包括空格，并且可以将 BPE 或单项语言模型方法应用于原始句子甚至段落，从而消除了预分词的需要。 因此，SentencePiece 是从原始文本生成深度端到端模型输入的最流行解决方案之一。","link":"/AI/NLP/NLP-Tokenization/"},{"title":"NLP-Tooling","text":"工具 增强语言模型Augmenting Language Models 动机从2020年代初期开始，语言模型可以通过以下特性来描述： Few-shot learners 能够推理逻辑问题 容易产生幻觉 hallucinations（由于活跃的知识空白） 能够逐步遵循指令 知识可以以少样本的方式注入，这可以解释为克服幻觉。通过逐步处理，增强模型可以使用低复杂度的知识源来回答复杂问题。 与提示的连接有两种方法可以将外部信息注入类似Transformer的语言模型： 嵌入空间中的向量序列（cross-attn，prefix等） 将文本信息注入提示（特殊标记，格式等） 重要提示！在考虑增强的同时，应考虑使用适当的提示技术。基于Transformer的模型的上下文窗口具有固定长度，这是一个限制！ 检索最简单的解决方案：检索增强生成（RAG）。 获取一个外部知识库并查询它。然后，模型可以利用查询结果来回答问题。 示例提示： 1234567仅使用提供的上下文回答以下问题！问题：&lt;USER_INPUT\\&gt;上下文：&lt;RETRIEVED_CONTEXT\\&gt;答案：&lt;LLM\\&gt; 如何检索信息？查找相关信息的最常见方法是： 基于关键词的搜索（出现次数，正则表达式等） 基于向量相似度的搜索（TF-IDF，LM-embedding等） 关系查询 基于分类法（Taxonomy）的搜索（词典，维基，WordNet） 直接访问（链接，文档） 搜索方法基于向量相似度的搜索方法假设我们有某些文档的特征向量 ($e^i$)，其中 $i\\in I$，且 $||e^i||_2^2 = 1$。 检索过程应返回与嵌入的用户查询 $e^q$ 最接近的文档。 这是通过经典的最近邻搜索实现的。假设 $e \\in \\mathcal{R}^d$ 且 $|I| = N$，则检索的复杂度为 $O(Nd)$。 这随着嵌入大小（质量）和文档数量的增加而变得困难。搜索 $k$ 个最近邻也是如此。 近似最近邻搜索Approximate nearest neighbor search 预构建的索引可以减少推理时间，但内存和构建时间仍然是一个限制。存储和索引构建需要近似。 可能的解决方案： 哈希 量化 树结构 基于图的 上述原则在实践中经过改进并经常结合使用。 哈希与返回精确结果不同，哈希函数构建了分箱。使用LSH（Locality-Sensitive Hashing）函数族时，两个向量距离增加时碰撞概率单调递减。 通过分箱减少复杂度。在找到最近的分箱后可以进行细粒度搜索。 基于树的解决方案在树结构中，分支因子 $b$ 将搜索复杂度减少到 $\\log_b(N)$。 对于二叉 KD 树 $b=2$，构建此类树的简单解决方案是在最高方差数据维度的中位数处绘制一个垂直超平面。然后每一半使用相同的原则进行拆分。这继续进行，直到每个节点仅包含一个元素。 然后可以结合树和嵌入空间搜索算法来找到最近邻。例如：优先搜索。 优先搜索首先选择包含查询的节点（或单元），然后访问由查询与查询单元中的嵌入向量之间的距离初始化的最大嵌入空间距离限制的最近邻树节点。 量化给定由质心 $\\mathcal{C} = {c_i | i\\in I}$ 定义的码本，其中 $I = {0, 1, … m-1}$ 是有限的。 我们将每个实向量映射到最近的质心 $q(\\cdot)$。映射到 $c_i$ 的实向量集合是其 Voronoi 单元，用 $V_i$ 表示。 这意味着 $q(x) = \\text{arg}\\min\\limits_{c_i \\in C}d(x, c_i)$，其中 $d(\\cdot)$ 是距离函数。 $c_i = E_x[x|i] = \\int_{V_i}p(x)\\cdot x dx$，应定义为 Voronoi 单元的中心。 Product Quantization简单量化仍然效率低下，因为聚类中心需要使用复杂的算法（如 k-means，复杂度 $O(dm)$）来计算。在简单的 1 位/组件 $128$ 维量化向量的情况下，需要计算和存储 $m = 2^{128}$ 个质心。 这太多了！ 解决方案：我们应该将向量分解为多个段（类似于 MHA）。 在将向量分成 $L$ 段的情况下，每个段可以通过其特定的量化器进行量化。这意味着 $\\mathcal{C} = \\mathcal{C}_1 \\times \\mathcal{C}_2 \\times … \\times \\mathcal{C}_L$ 和 $I = I_1 \\times I_2 \\times … \\times I_L$ 应分解为子量化器和子索引的笛卡尔积。 在这种情况下，复杂度减少到 $O(dm^{\\frac{1}{L}})$。 每个段的量化值之间的距离可以计算并存储以供搜索步骤使用。 使用预计算的 $d(c_i, c_j)$ 表，我们可以轻松计算完整向量 $e^i$ 和 $e^q$ 的距离。在欧几里得距离的情况下等于： $$d(e^i, e^q)=d(q(e^i), q(e^q))=\\sqrt{\\sum\\limits_{l \\in L} d(q_l(e^i), q_l(e^q))^2}$$ 这导致平均搜索复杂度为 $N$ 次比较加上查找和求和 $L$ 查找表中的相应距离。如果 $N&gt;&gt;L$，则简化为 $O(N + L\\ \\log L \\cdot \\log\\ \\log N )$。 基于图的图方法构建一个索引，该索引采用适合邻居关系表示的形式。例如 Delaunay 图、相对最近邻图、k 最近邻图、最小生成树等。 这些图很难构建和存储，因此在构建过程中会进行近似。通常，具有“小世界”特性的图被构建。这些网络具有以下特性，给定一个常规网络的边重连概率 $p$： $L(p)$ 两个顶点之间的最短路径平均值应较小 $C(p)$ 聚类系数（完全连接的三元组（三角形）与图中所有三元组的比率）应较大 Small world 构建图NSW（navigable small worlds）用于创建可导航的小世界。在这里，顶点被迭代地插入到网络中。连接是通过一个随机性水平选择的，这创建了一个小世界网络，同时确保整个网络是可遍历的。 HNSW（hierarchical NSW）更进一步，通过将节点和链接组织成层次结构。那些具有长链接距离的层应插入到顶层，而较小距离（后插入）的节点放置在较低层。 HNSW 推理一个贪婪搜索算法从顶层节点之一初始化。然后它在层中寻找局部最小值，并在找到后切换到较低层，直到找到最接近查询的点。该算法的平均复杂度为 $O(\\log(N))$。 图推理一般来说，其他基于图的解决方案也遵循类似的原则。它们从一个种子顶点开始，然后通过图遍历，朝着与查询距离较小的方向前进。 检索增强Retrieval Augmentation 嵌入模型语义向量用于检索文档。这些文档通常被拆分成较短的片段。语义向量可以来自 TF-IDF、Word2Vec 嵌入、Masked- 或 Causal-LM 嵌入。也可以使用多模态选项。 专门的嵌入模型语言模型的预训练可能不会产生具有所需属性的嵌入空间。 一些额外的目标可以帮助对其进行调整： 监督语义相似性 Supervised semantic similarity 分类 聚类 Clustering 监督检索或重新排序 问答映射 更长的（句子、段落）文本表示 句子嵌入需要对句子级别进行微调，以正确表示较长文本的语义。 句子级别的监督数据集示例包括：句子相似性数据集、情感分析数据集、自然语言推理数据集（前提和一个蕴涵、矛盾或中性对），等等。 指令嵌入指令嵌入作为多任务训练嵌入出现，其中执行的任务取决于给模型的自然语言指令。指令训练也提高了领域适应性。 检索增强生成RAG 通常包括以下步骤： 问题形成：将用户查询重新表述为独立查询（考虑历史），关键词列表等 检索：使用嵌入和向量存储系统或搜索引擎等检索有用的段落 文档聚合：aggregation 将所有文档一起“填充”或“映射”一个转换（例如摘要） 答案形成：查询和上下文被输入到生成答案的语言模型中 假设文档嵌入Hypothetical 文档嵌入有助于为基于嵌入向量的检索系统生成更好的查询。HyDE 问题形成步骤被生成步骤取代，该步骤生成问题的“假”示例答案，并将其用作数据库中的查询。 实体记忆另一个可能的、更复杂的用例是当 LLM 也有能力修改数据库时。在这个数据库中存储了一个实体列表和相关知识。模型被迭代地提示更新这个数据库，然后它可以从数据库存储的实体信息中检索。 RAG 预训练模型将解码的信息传输到文本实际上效率不高。 检索增强预训练对于模型是可能的，其中预嵌入向量附加到编码输入，或者通过类似交叉注意力的机制提供信息。 REALM检索增强语言模型预训练使用由类似 BERT 的嵌入模型组成的神经检索器。这些模型是训练网络的一部分。检索器在 MLM 训练期间将检索到的文档嵌入与查询连接起来。 RETRO检索增强 Transformer 引入了一种技术，其中相关的上下文信息通过交叉注意力进行处理。检索是通过冻结的 BERT 嵌入进行的。检索到的块然后基于输入信息使用交叉注意力在编码器中进行修改。 在解码器中，交叉注意力将修改后的检索信息合并到输入中。 RETRO 块输入被切分成块，每个块分别检索信息。前面的块（及相关信息）按因果关系处理。 整个模型是可微分的，梯度可以通过网络流动。 在训练期间，检索到的信息是预先计算的。 工具API 调用基于文本的 API 可以通过 API 的输入和输出定义轻松调用。大多数 LLM 都经过微调，可以很好地处理 JSON 或 XML 格式。 此类 API 的一些示例包括： 搜索引擎 网络抓取 实时数据流 可执行文件，命令（例如：计算器） 代码解释器，模拟器 其他 LLM 实例 AutoGPT - 自我独白AutoGPT 通过在链式思维和反思类型提示中应用多次生成，能够进行更高阶的规划。AutoGPT 应用 $4+1$ 步骤的类似 CoT 的过程来控制动作： 思考：根据目标解释用户输入。 推理：关于如何处理此输入的 CoT。 计划：计划要执行的操作。 批评：反思行动结果。 行动：由 AutoGPT 生成输入的动作。 在计划和行动阶段，可以调用额外的专家 LLM 和外部工具。AutoGPT 系统通常只提示一组目标，其余由模型自行解决。示例工作流程（发送电子邮件）： 思考：联系 Joe，邮箱 Joe@inf.hu，发送一封礼貌的电子邮件，表明他应该完成 NLP 幻灯片。 推理：目标明确。我需要发送一封电子邮件给 Joe，邮箱 Joe@inf.hu，礼貌地要求他完成 NLP 幻灯片，并表明我是一个 AI 助手。 计划（+批评 Criticism）：使用 send_email 动作。{ “action”: “send_email”, “action_input”: &lt;JSON&gt;} 观察：邮件已发送。 Agent 循环 会话专家代理 工具微调模型微调模型以选择工具是困难的。引导可能是一个解决方案，其中使用大量 LLM 调用构建 API 调用图。这些连续调用按成功率排序，并选择通过率最高的几个解决方案纳入数据集。这样的微调可以增强语言模型的工具利用能力。 总结总结 I增强语言模型使用外部信息源来增强其能力。这些信息源的一个重要组是矢量化文档数据库。嵌入模型用于通过近似 NN 搜索算法检索相关信息。其他工具包括 Web API，甚至代码解释器。应用自我独白过程的模型能够通过规划和执行连续的动作来实现目标。 总结 II在检索增强生成过程中，检索到的文档被连接或总结，然后在第二个 LLM 步骤中输入模型以生成答案。 微调模型以使用检索到的信息或外部工具是可能的，并且可以提高性能。","link":"/AI/NLP/NLP-Tooling/"},{"title":"NLP-Transformers","text":"Attention is all you need 介绍最早的有影响力的 seq2seq 模型是 RNN，但后来的发展是通过发明 transformers 实现的，这是一种使用注意力机制作为完整层（full-fledged layers）的新型架构，而不是作为辅助 RNN 组件。 新架构的主要构建块是： 作为软字典查找的注意力 自注意力层，和 transformer 模块 直观感受经典数据库查询（宠物店）： 查询：Key = “cat” Key（动物） Value（价格） cat 1 dog 2 cat 3 parrot 4 Key（动物） Value（价格） 选择权重 cat 1 1 dog 2 0 cat 3 1 parrot 4 0 Output = $1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot 1 + 4 \\cdot 0 = 4$ 软数据库查询（宠物店）： 查询：Key ~ “cat” Key（动物） Value（价格） 选择权重 cat 1 0.4 dog 2 0.15 cat 3 0.4 parrot 4 0.05 Output = $1 \\cdot 0.4 + 2 \\cdot 0.15 + 3 \\cdot 0.4 + 4 \\cdot 0.05 = 2.1$ 数学公式回顾一下，注意力机制提供了基于查询的 $\\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$ 向量序列的聚合：给定一个 $\\mathbf{x^*}$ 查询向量，它们计算一个相关性分数序列 $$\\mathbf{s} = \\langle s(\\mathbf{x}_1, \\mathbf{x}^*),\\dots, s(\\mathbf{x}_n, \\mathbf{x}^*) \\rangle$$ 并返回加权和 $$\\mathop{\\mathrm{softmax}}(\\mathbf{s})\\cdot \\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$$ 作为根据相关性分数对 $\\mathbf{x}_i$ 进行总结或聚合的结果。 $s(\\cdot, \\cdot)$ 评分函数有所不同，我们看到一个选项是使用缩放点积： $$s(\\mathbf{x}_i, \\mathbf{x}^*) = \\frac{\\mathbf{x}_i\\cdot \\mathbf{x}^*}{\\sqrt{d}}$$ 其中 $d$ 是 $\\mathbf{x_i}$ 和 $\\mathbf{x^*}$ 的维数。 基于这个模式，transformer 注意力机制做了一个关键的改变：将 $\\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_n\\rangle$ 视为一个 字典，其中有 $\\mathcal K(\\cdot)$ 和 $\\mathcal V(\\cdot)$ 映射，将每个 $\\mathbf{x}_i$ 映射到相应的 $\\mathcal K(\\mathbf{x}_i)$ 键和 $\\mathcal V(\\mathbf{x}_i)$ 值。 假设还有一个 $\\mathcal Q(\\cdot)$ 查询 映射，它将 $\\mathbf{x}^*$ 映射到 $\\mathcal K$(.) 的范围（“key-space”），评分可以重新表述为计算查询和键之间的点积相似度分数 $$s(\\mathbf{x}_i, \\mathbf{x}^*) = \\frac{\\mathcal K (\\mathbf{x}_i)\\cdot \\mathcal Q (\\mathbf{x}^*)}{\\sqrt{d}}$$ （$d$ 现在是“key-space”的维数），检索到的值将是加权和 $$\\mathop{\\mathrm{softmax}}(\\langle s(\\mathbf{x}_1,\\mathbf{x}^*),\\dots,s(\\mathbf{x}_n,\\mathbf{x}^*) \\rangle)\\cdot \\mathcal V(\\langle \\mathbf{x_1},\\dots,\\mathbf{x}_n)\\rangle$$ Scaling然而，这种注意力机制存在一个问题。假设所有序列的每个向量元素都来自标准正态分布 $\\mathcal{N}(0, 1)$。它们的点积 $\\sum\\limits_{d}\\mathbf{x}_i\\cdot\\mathbf{x}_i^*$ 将具有 $\\mathcal{N}(0, d)$ 的分布，其中 $d$ 是向量的维数。为了将输出缩放回标准正态分布，点积被缩放为 $\\frac{1}{\\sqrt{d}}$。 Attention as a layer所述的注意力机制可以用作独立层来转换输入向量序列 $\\mathbf{I} = \\langle \\mathbf{i}_1,\\dots, \\mathbf{i}_n \\rangle$： 给定另一个序列 $\\mathbf{X} = \\langle \\mathbf{x}_1,\\dots, \\mathbf{x}_m \\rangle$ 和 $\\mathcal K(\\cdot),\\mathcal V(\\cdot),\\mathcal Q(\\cdot)$ 映射，对于每个输入 $\\mathbf{i_k}$，我们可以计算相应的 $\\mathcal Q(\\mathbf{i}_k)$ 查询，并使用它与 $\\mathcal K$ 和 $\\mathcal V$ 来 关注 $\\mathbf{X}$ 并计算相应的注意力响应 $\\mathbf{o}_k$。 结果是一个 $\\mathbf{O}=\\langle \\mathbf{o}_1,\\dots,\\mathbf{o}_n \\rangle$ 输出序列，整体上是输入 $\\mathbf{I}$ 的层输出。 注意力层类型根据层关注的位置（$\\mathbf{X}$ 的来源），我们可以区分自注意力层和交叉注意力层。 在 自注意力 层中，从输入生成的查询用于查询输入本身：$\\mathbf{X}=\\mathbf{I}$ 在 交叉注意力 层中，查询的是外部向量序列，例如，在编码器-解码器 transformer 架构中，由编码器创建的序列 至于映射 $\\mathcal K(\\cdot),\\mathcal V(\\cdot),\\mathcal Q(\\cdot)$，这三者通常都实现为线性投影，具有学习到的权重矩阵 $W_K, W_V, W_Q$。 多头注意力为了能够关注输入的多个方面，transformers 中的注意力层包含几个并行的注意力“头”，每个头都有不同的 $W_K, W_V, W_Q$ 三元组： 头输出被组合成一个层输出： Transformer 模块transformers 的构建块是由注意力和简单的分段前馈层组成的 transformer 模块。最简单的变体只包含一个自注意力层： 编码器编码器由 $N$ 个相同的层组成，这些层具有自注意力和逐元素（element-wise） FFN 模块，以及残差连接。编码序列（上下文）是最后一个编码器层的输出。每个自注意力都是双向的。 解码器解码器由 $N$ 个相同的层组成，这些层具有自注意力、交叉注意力和 FFN 模块，以及残差连接。交叉注意力将编码序列作为键和值，而查询来自解码器。每个自注意力是单向的，交叉注意力是双向的。 嵌入和位置编码Transformers 是为符号序列（例如文本）发明的，因此使用嵌入层将输入标记转换为向量表示。然后将此嵌入添加到位置编码向量中，该向量用于向模型传达位置信息。 Seq2seq Transformer 原始的 全 transformer 模型 是一个完全由 transformer 块构建的 Seq2seq 编码器-解码器 模型。在推理过程中，解码器部分逐步预测，类似于 RNNs 消耗已经预测的输出，但在训练过程中，它只需要通过教师强制进行一次前向传递。 训练通过向解码器添加分类头，可以在两个序列上训练模型。给定完整的输入序列，解码器被训练来预测输出序列中的下一个元素。 为了生成完整的序列，模型以自回归（auto-regressive）方式使用。模型的输出用作下一步的输入。然而，单个错误预测将导致错误的级联。为避免这种情况，模型通过教师强制进行训练。 掩码掩码用于防止模型关注某些元素。Transformers 中主要有两种类型的掩码： 填充（Padding）掩码 前瞻（Look-ahead）掩码（因果 causal 掩码） 编码器风格和解码器风格的模型某些应用只需要模型处理单个序列（例如语言建模）。在这种情况下，不需要交叉注意力和两个模块。我们只使用编码器或解码器（没有交叉注意力）。当存在双向信息时，使用编码器风格的模型，而对于因果问题，则使用解码器风格的模型。因此，两者之间的唯一区别是因果掩码。 上下文嵌入词嵌入的局限性传统的基于共现矩阵的词向量和第一代神经词嵌入有几个重要的局限性： 上下文独立性: 一个表面形式只有一个表示。例如，bank 在以下句子中的嵌入是相同的： I went to my bank to withdraw some money. （我去银行取了一些钱） We explored the river bank. （我们探索了河岸） 尽管这两个意思显然是不同的 单词是黑箱: 单词有内部结构：它们由字符组成，可以由几个词素组成，但 Word2vec、GloVe 等忽略了单词的内部结构 对未见过或罕见单词没有有用的表示: 由于单词被视为黑箱，这些模型无法为训练语料库中未出现或非常罕见的单词生成有用的表示 良好的覆盖需要巨大的模型尺寸: 一个单词只有在明确包含在模型的词汇表中时才会获得有意义的表示，但内存消耗通常是覆盖词汇表的线性函数 利用内部单词结构、处理 OOV 单词和减少词汇量的问题已通过以下方法有效解决： fastText 嵌入，尤其是 子词嵌入 但这些嵌入仍然是静态的，即将相同形式的标记映射到相同的嵌入向量。 NLP 领域最近最重要的发展之一是上下文嵌入的出现，与之相反，上下文嵌入可以根据上下文的不同来改变相同表面形式的嵌入，以反映语言差异。 Contextual embeddings上下文嵌入 是由深度网络（通常是基于 LSTM 或自注意力机制）生成的单词或子词表示，这些网络在自监督的、广泛的语言建模目标上进行（预）训练。 与静态嵌入不同，这些表示不能简单地以查找表的形式存储和部署，因为它们是根据每个标记的上下文动态计算的：对于一个 $\\mathbf{w} = \\langle w_1,\\dots ,w_n \\rangle$ 输入标记序列，网络生成一个嵌入序列 $$E(\\langle w_1,\\dots ,w_n \\rangle) = \\langle E_\\mathbf{w}(w_1),\\dots,E_\\mathbf{w}(w_n)\\rangle$$ 由于这种动态特性，网络本身必须用作 特征提取模块。 在 NLP 中，生成上下文嵌入的网络的预期用途类似于传统 NLP 中处理管道的角色：它们应该生成对下游任务有用的特征向量，实际上，希望只需要少量的进一步处理（例如，以浅层神经网络的形式）就能构建有用的 NLP 模型。 巨大的区别在于，上下文嵌入可以通过自监督方式学习，而不需要昂贵的监督训练集。 ELMoELMo（来自语言模型的嵌入，Embeddings from Language Models），第一个历史上重要的上下文嵌入模型，通过两个标准的单向语言建模任务学习词表示。 该架构首先使用字符级卷积生成上下文无关的嵌入，然后使用前向和后向双向 LSTM 层（它们的数量 $n$ 是一个可变的超参数）通过权重共享的 softmax 层预测下一个/上一个标记。 在第一近似（approximation）中，上下文相关的嵌入是模型生成的所有 $2n +1$ 个中间表示（$2n$ 个基于上下文的 LSTM 和一个静态字符的表示）。 尽管这些向量可以一起被视为“完整的”ELMo 表示，但对于实际的下游 NLP 任务，ELMo 的创建者实际上建议不要使用这种非常高维的表示，而是使用这些向量的低维组合。他们建议的解决方案是 简单地连接顶层 LSTM 层（前向和后向）的输出 在监督任务上学习 ELMo 表示的任务特定线性组合 FLAIRFLAIR 是一种与 ELMo 密切相关的上下文嵌入模型，但 完全由循环字符级语言模型（一个前向和一个后向）组成 从 LSTM 隐藏状态在标记的第一个和最后一个字符（从后向 LM 的第一个字符和从前向 LM 的最后一个字符）生成标记级嵌入 FLAIR 嵌入在序列标注任务中被证明非常有用，使用它们的浅层模型目前在命名实体识别（NER）和词性标注（POS-tagging）中排名第二。 基于 Transformer 的上下文嵌入Transformer 架构最初用于翻译（2017 年），但从 2018 年开始，开发了一系列基于 Transformer 的模型来生成上下文嵌入。最重要的研究领域是： 寻找有助于学习高质量表示的自监督任务 架构改进，特别是找到更高效的注意力变体 如何为下游任务 adapt/fine-tune 预训练的 representation 网络 GPTGPT（Generative Pre-Training）是一种基于 BPE 的，仅使用解码器的 transformer 模型，使用传统的“预测下一个标记”语言建模目标进行训练。上下文嵌入只是顶层 transformer 模块的输出。 与 ELMo 类似，GPT 的主要目标是提供一个有用的预训练“特征提取”模块，可以针对监督的 NLP 任务进行微调。微调意味着在监督下游任务上以端到端的方式更改预训练的 GPT 权重。 BERT下一个具有高度影响力的模型是谷歌的 BERT（Bidirectional Encoder Representations from Transformers），其主要创新是 使用了两个新的自监督目标，而不是传统的语言建模 掩码语言模型（masked language modeling）以及 下一句预测（next sentence prediction, NSP）和 相应的架构变化：该模型基于 transformer 编码器 架构 掩码语言模型目标是猜测随机掩码的标记： 下一句预测第二个目标是判断两句话在训练语料库中是否相互跟随或是随机抽取的： 微调上下文嵌入预训练语言模型生成的上下文嵌入不一定适用于具体的下游任务（分类、语义搜索等），因此可以通过微调预训练权重来提高性能。 微调可以通过以下方式进行： 在更能代表目标领域的语料库上使用无监督任务（这些任务通常与预训练任务相同） 在与目标任务相同或相关的监督任务上进行，例如语义搜索的相似性排序 后续趋势更新的模型在 NLP 任务中不断刷新最先进的技术，但通常伴随着参数数量的增加和更大的数据集： 虽然最初的 ELMo 模型有 9360 万个参数，但 GPT-3 有 1750 亿个参数，数据集的规模从 8 亿个标记增加到 3000 亿个标记。 知识蒸馏模型规模的巨大增加导致了对知识蒸馏 （distillation）方法的深入研究，以便能够基于原始模型生成更小、更高效的模型，而不会显著损失性能。 一个很好的例子是DistilBERT，这是一个经过蒸馏的 BERT 版本，旨在模仿 BERT 的输出。DistilBERT 保留了 BERT 97% 的性能，但参数减少了 40%，推理速度提高了 39%。 稀疏注意力变体提高效率的另一种方法是减少自注意力层中的注意力范围，因为在全注意力中，计算点积的数量与输入标记的数量成平方关系。线性替代方案包括： 全局注意力: 一组全局标记关注整个序列； 随机注意力: 对于每个查询，计算一组 $r$ 个随机键，该查询关注这些键； 窗口注意力: 仅关注固定半径内的局部邻居。 Big Bird 上下文嵌入模型结合了所有这些线性注意力类型，以显著增加输入标记的数量，而不会显著改变内存需求： 少样本学习、单样本学习和零样本学习一个有趣的方向是尝试直接使用模型，而不在下游任务上添加层和进行梯度更新。一些最近的模型，最重要的是 GPT-3，在各种下游任务中表现出令人惊讶的效果，这些任务在输入中进行了说明。有三种学习设置： 零样本学习：输入仅包含监督任务的简短描述和一个具体的输入实例提示，例如“将英语翻译成法语：cheese =$&gt;$ ” 单样本学习 和 少样本学习：除了简短的任务描述外，输入还包含一个或几个训练示例，然后是提示","link":"/AI/NLP/NLP-Transformers/"},{"title":"NLP-Zoo","text":"模型介绍 神 TM 动物园 LLM Zoo我们已经看到了动物园中的一些居民… 但还有更多！我们将看看一些最重要的语言模型。 （注意：大多数模型在发布时在许多 NLP/NLU 数据集上达到了最先进的水平。我们不会在每个模型下提到这一点。） BERT 家族BERT提醒一下：BERT 是一种基于transformer encoder架构的上下文（子）词表示。它在两个自我监督任务上进行了训练： 掩码语言模型（MLM） 下一句预测（NSP） 它有几种尺寸： 基础版：12 个 Transformer 块，110M 参数 大型版：24 个 Transformer 块，340M 参数 BERT 催生了一整个模型家族，它们保留了架构并通过微调细节寻求改进。 超参数Hyperparameters，BERT 带来了两个新的训练任务，但 NSP 被证明太简单了。 ALBERT 用句子顺序预测替代了它 RoBERTa 完全放弃了这个任务 RoBERTa 证明了训练更长时间和使用更多数据的重要性。 数据大小：16GB $\\rightarrow$ 160GB 批量大小：256 $\\rightarrow$ 8K 训练步骤：100K（相对）$\\rightarrow$ 500K 动态掩码：[MASK]标记的位置每次运行都会改变 这些变化在各种任务上带来了$3-4%$的改进（例如在 SQuaD 上减少了$60%$的错误率）。 跨距Spans，BERT 的掩码方案（[MASK]替换单个标记）使其在生成任务中难以使用（例如在问答中填充答案）： 奥克尼群岛上最古老的定居点是什么？ 最古老的定居点是[MASK]。 最古老的定居点是[MASK] [MASK]。 … （Skara Brae 实际上是 4 个标记：S ##kara B ##rae） 另一个问题是被掩码的标记被假定为条件独立的。 SpanBERT 掩码随机长度的跨距（平均 3.8 个标记） 基于跨距周围的标记预测它们： $$ \\mathbf{y}_i = f(\\mathbf{x}_{s-1}, \\mathbf{x}_{e+1}, \\mathbf{p}_{i-s+1}) $$ 引入了跨距边界目标 $\\mathcal{L}_{SBO}$，使得 $$ \\mathcal{L}(x_i) = \\mathcal{L}_{MLM}(x_i) + \\mathcal{L}_{SBO}(x_i) = -\\log P(x_i|\\mathbf{x}_i) - \\log P(x_i|\\mathbf{y}_i) $$ XLNet 完全不使用[MASK]标记或 MLM 自回归 autoregressive 训练任务在排列序列上（仍然是双向上下文） 可以建模上下文和目标之间的依赖关系 性能训练类似 BERT 的模型速度慢且占用大量内存。ALBERT通过以下方式解决了这些问题： 将$V \\times H$嵌入矩阵分解为两个矩阵：$V \\times E$ 和 $E \\times H$；（$V$：词汇表，$H$：隐藏层大小，$E$：嵌入大小；在 BERT 中，$E = H$） 层之间的权重共享 结果模型的参数比相应的 BERT 模型少 18 倍，训练速度快约 1.7 倍。然而，更大的模型（xxlarge）在性能上超过了 BERT Large （如果它们能收敛的话…）。 新技术DeBERTa 通过技术创新改进了常规 BERT： 解耦注意力（disentangled）机制为每个标记分配两个向量： 内容 位置 相对位置编码 在 softmax 层之前引入绝对位置 它在 SuperGLUE 中表现优于人类基线（90.3 对 89.8）。 全栈模型T5文本到文本转换 Transformer通过以下方式解决 NLP 任务： 将它们转换为带提示的 seq2seq 问题 用解码器替换 BERT 上的分类器头 它的训练方式为： 去噪 Denoising 目标：丢弃 15%的标记（类似于 MLM；优于自回归目标） 多任务预训练 在单个 NLP 任务上进行微调 最大的模型有 110 亿参数，并在 1 万亿个标记上进行了训练。 解码器模型GPT 家族GPT 家族是最著名的大型语言模型（LLM）。它们由OpenAI创建，规模不断增加： 模型 参数量 语料库 上下文长度 GPT-1 110M 1B 512 GPT-2 1.5B 40GB 1024 GPT-3 175B 300B 2048 InstructGPT 175B 77k 2048 GPT-4 ? ? 8192 GPT-3.5 和 GPT-4 的详细信息尚不可用。有一些估计，但许多甚至无法正确描述之前的模型。 GPT-1最初，GPT 被设计为一个自然语言理解（NLU）框架，类似于 ELMo 或 BERT： 它是第一个推广预训练 + 微调方法用于 NLP 任务的模型 自回归预训练并非出于文本生成的动机 结果： GPT-1 在测试的 12 个任务中有 9 个达到了最先进的水平 它展示了一些零样本能力 GPT-2更大的模型尺寸带来了更好的零样本性能： GPT-3架构和训练的变化： 交替使用密集和稀疏（dense and sparse）注意力层 采样训练（并非使用所有训练数据） 在几个任务上的少样本性能非常接近最先进水平。 问题： 防止基准测试的记忆化 输出中的偏见（性别、种族、宗教） 训练期间的高能耗（通过相对较小的训练语料库缓解） InstructGPT增加了指令支持。 RLHF（之前提到过） 与增加预训练分布对数似然的更新混合，以防止模型退化 1.3B 的 InstructGPT 比 175B 的 GPT-3 更受欢迎 API prompts 比 FLAN 或 T0 数据集更好 降低了毒性（toxicity），但没有减少偏见（bias） GPT-4更大、更好、多模态（视觉）。在考试中表现达到人类水平（前 10%）。 指令： 对考试没有帮助 扭曲（Skews）了置信度校准（calibration）（答案的对数似然与实际表现的相关性） 两种安全方法： RLHF 基于规则的奖励模型（RBRMs） 其他模型家族GPT 并不是唯一的 LLM 模型“家族”。还有一些竞争对手，包括开源和闭源的。 闭源 Claude（版本 3） Google 的 Gemini 开源 Meta 的 Llama（版本 3.2） Mistral（版本 0.3） 阿里巴巴的 Qwen（版本 2.5） 其他模型仅解码自回归模型已成为事实上的 LLM 标准，并且提出了许多其他模型。以下是一些值得注意的例子。 Megatron GPT（8.3B）和 BERT（3.9B）版本。训练于 174GB 文本 引入了模型并行（parallelism） Gopher 280B，训练于 MassiveText，但仅在 2350B 中的 300B 标记上（12.8%） 使用相对位置编码，允许对比训练期间看到的更长序列进行推理 GLaM 一个稀疏模型，具有 1.2T 参数，训练于 1.6T 标记 使用专家混合（Mixture of Experts）层与 transformer 层交错 每个标记仅激活模型的 8%（96.6B）训练成本是 GPT-3 的 $\\frac{1}{3}$ LaMDA 137B，训练于 1.56T 标记 一个专门用于对话的模型；训练语料库的 50% 由对话组成 针对质量、安全性和基础性（“基础指标”）进行微调 端到端模型，包括调用外部 IR 系统以确保基础性 FLAN 基于 LaMDA。使用数据集成方法进行指令微调，来自 62 个 NLP 数据集 比 LaMDA、GPT-3 或 GLaM 更好的零样本性能 PaLM 最大的模型之一：540B 参数，训练于 780B 文本 使用Pathways技术在 2 个 Pods 中的 6144 个 TPU v4 芯片上训练 不连续的改进：在某个模型大小之后准确性急剧跳跃（而不是连续的幂律） 突破性表现。在几个任务上，它比 平均人类表现 监督系统更好 负面趋势扩展法则已经证明，增加模型规模会沿着幂律曲线提高性能。这导致了越来越大的模型被发布。 问题大型模型有几个问题： 它们的训练和推理成本很高 只有少数参与者能够负担得起训练它们 即使在“低端”设备（例如 8 个 A100）上运行它们也是有问题的 它们有相当大的碳足迹，以至于论文现在通常会报告它 大多数模型是专有的和闭源的 新趋势 Chinchilla最近出现了一种新趋势，即在更多的标记上训练较小的模型，以实现可比甚至更好的结果。这是可能的，因为 上述模型通常训练不足 指令微调非常有效且便宜 Chinchilla 70B 参数，训练于 1.5T 标记 使用与 Gopher 相同数量的 FLOPs 和相同的训练集 性能优于 GPT-3 和 Gopher LLaMaChinchilla 是闭源的。LLaMa 是基于开放数据源创建类似 Chinchilla 模型的尝试。 最大的模型是 65B，训练于 1.4T 标记 包括架构上的“最佳实践” 预归一化（GPT3）：在输入而不是输出上归一化 SwiGLU 激活（PaLM） 旋转位置嵌入（GPTNeo） 即使是 13B 模型也优于 GPT-3 注意：不能用于商业用途。 LLaMa 变体 LLaMa2 更大（70B 参数，2.0T 标记，4k 上下文） 聊天指令 可以用于商业用途 Alpaca 斯坦福基于 LLaMa 7B 的指令模型。便宜（$600） 基于 ChatGPT 的 Self-instruct（不可商业使用） Vicuna 基于 LLaMa 13B + 来自 ShareGPT 的 70k 交互，成本 $300 比 Alpaca 好 90%，在 GPT-4 评判下接近 ChatGPT 10% 以内 多语言模型上述大多数模型仅在英语数据上训练，或最多包含 10%的非英语文本。然而，有几个模型有多语言版本。 mBERT： 一个多语言的 BERT 基础模型 在 104 种语言的维基百科上训练 XLM-RoBERTa 在 2.5TB 的 Common Crawl（CC）数据上训练，涵盖 100 种语言 在低资源语言上比 mBERT 高出 23% 性能与单语言的 RoBERTa 相当 XLM-RoBERTa 证明了维基百科不足以训练一个有竞争力的模型。 mT5 在包含 10,000 页或更多页面的 101 种语言的 CC 数据上训练 单语言性能接近 T5 跨语言零样本性能是最先进的，但偶尔会意外翻译成英语 BLOOM 一个在 46 种自然语言和 13 种编程语言上训练的解码器模型 1.61TB 的 ROOTS 语料库由国际研究人员合作编译 BLOOMZ 变体经过多语言多任务微调 迄今为止最强大的多语言 LLM 编码 许多 LLM 在预训练语料库中使用了一些源代码。这有助于推理，并允许它们进行一定程度的代码生成。而编码模型则明确为后者任务进行训练。 Code Llama是基于 LLaMa 2 的模型。它有相同的尺寸。由于编码模型还需要理解自然语言（NL）指令，因此基于常规 LLM 的模型表现更好。 它有三个版本： Code Llama：基础模型 Code Llama - Instruct：微调版本 Code Llama - Python：进一步在 Python 代码上训练 Code Llama 详情 训练语料库（500B）： 85% 来自 GitHub 的源代码 8% 与代码相关的 NL 讨论（如 StackOverflow 等） 7% NL 批次以保持 NLU 性能 Python 模型使用额外的 100B 个 Python 代码标记进行训练。 训练特点Code Llama 有两个额外的训练目标： 填充：在给定上下文的情况下预测程序的缺失部分 用于代码补全、文档生成等 仅较小的模型进行训练 长输入上下文：以实现库级别的推理 将最大上下文长度从 4096 增加到 100,000 在专门的长上下文微调阶段进行训练 指令微调通过自我指令完成： 生成单元测试和代码 添加通过测试的第一个代码片段 结果 指令：LLaMa 2 + 自我指令。生成单元测试和代码，并添加通过单元测试的代码。 其他模型闭源： Codex/copilot AlphaCode phi-1 GPT-4 开源： SantaCoder StarCoder 多模态图像-文本模型与 GPT-3 相比，GPT-4 的主要创新是其多模态性；特别是其使用图像输入的能力。然而，它并不是第一个具有图像到文本能力的系统。 主要的视觉机器学习目标是图像分类：给定一张图像，系统必须返回描述其内容的标签（集）。这通常通过在数百万标记图像上训练的监督系统来完成。 使用大型语言模型（LLM），可以在大型未标记的文本+图像语料库（网络数据）上预训练具有良好零样本性能的通用模型。以下是两个例子。 CLIPCLIP 通过将图像和文本编码到相同的嵌入空间来执行图像分类。 在训练期间，编码器使用对比目标进行训练。在测试时，类标签被编码，并返回与图像最（余弦）相似的标签。 FlamingoFlamingo 是一个“视觉语言模型”，可以基于混合的文本和视觉输入生成文本。 它使用冻结的视觉和文本编码器（例如 CLIP 和 Chinchilla），并且只训练操作其输出的语言模型。 开源模型上面讨论的许多模型都是闭源的；通常，训练数据也由专有语料库组成。然而，现在有几个开源的 LLM 可在 Hugging Face Hub 上使用： BLOOM 是完全开源的，数据和模型都是如此。然而，它的开发已经完成，不再进一步更新 LLaMa 是在开放数据上训练的，LLaMa 2 及以上版本可以免费使用。Llama 3.x 提供从 1B 到 405B 的模型 Mistral 是另一个替代方案，提供指令微调和 MoE 模型供下载 LAIONLAION（Large-scale Artificial Intelligence Open Network 大规模人工智能开放网络）旨在提供 100% 免费和开放的 LLM 管道，包括数据集、工具和模型。 一些精选项目： Openclip：CLIP 的开源重新实现 LAION5B：一个包含近 60 亿图像-文本对的语料库 OpenAssistant：正在开发的开源对话 AI。你也可以通过以下方式提供帮助： 添加新对话 标记现有对话 等等","link":"/AI/NLP/NLP-Zoo/"},{"title":"Numerical Methods II - Part 2","text":"时隔一年，老师添加了一点新题，所以又来更新一下。 Numerical Integral, Matrices of Geometrical Transforms近似计算定积分Write an M-file for using quadrature formulas.The name of the function be: numint Input arguments: integrand (as a string),the endpoints of the interval (a, b),number of divisors (n),type of the quadrature (rectangle, trapezoid, simpson) Output argument: the result of the integral. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117% 7.1 近似计算定积分% 积分（字符串）% 区间 (a, b) 的端点% 除数 (n)% 正交类型（矩形、梯形、辛普森形）function integralResult = numint(integrand, b, a, n, method)arguments % 检查integrand是否为字符串 integrand (1,1) string % 检查a和b是否为数值，且a小于b b (1,1) double {mustBeNumeric} a (1,1) double {mustBeNumeric, mustBeLessThan(a, b)} % 检查n是否为正整数 n (1,1) double {mustBeInteger, mustBePositive} % 检查method是否为有效的字符串选项 method (1,1) string {mustBeMember(method, [&quot;rectangle&quot;, &quot;trapezoid&quot;, &quot;simpson&quot;])}end % 将字符串形式的被积函数转换为函数句柄 f = str2func(integrand); % 根据所选的方法计算积分 switch method case 'rectangle' integralResult = rectangleMethod(f, a, b, n); case 'trapezoid' integralResult = trapezoidMethod(f, a, b, n); case 'simpson' integralResult = simpsonMethod(f, a, b, n); otherwise error('Unknown method. Please choose rectangle, trapezoid, or simpson.'); endend% 首先计算每个小区间的宽度 h，然后遍历每个小区间% 计算每个区间中点的函数值，并将所有这些值累加起来% 最后，将累加的和乘以小区间的宽度，得到积分的近似值% 这个方法在处理高度振荡或非常不规则的函数时可能不够精确% 在这种情况下，可能需要更多的区间（即更大的 n）function result = rectangleMethod(f, a, b, n) % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = 0; % 对每个小区间进行迭代 for i = 1:n % 计算当前小区间的中点 x_mid = a + (i - 0.5) * h; % 计算函数在中点的值并累加 integralSum = integralSum + f(x_mid); end % 计算最终的积分近似值 result = h * integralSum;end% 首先计算每个小区间的宽度 h% 然后，我们初始化积分和为区间两端点处函数值的平均值% （这是因为在梯形法中，区间两端的点只被计算一次）% 接着，我们遍历每个小区间的内部点，将这些点处的函数值累加到积分和中% 最后，将累加的和乘以小区间的宽度，得到积分的近似值% 这种方法比矩形法更精确，尤其是在函数比较平滑的情况下% 然而，对于高度振荡或非常不规则的函数，它仍然可能不够精确function result = trapezoidMethod(f, a, b, n) % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = 0.5 * (f(a) + f(b)); % 对每个小区间的内部点进行迭代 for i = 1:(n-1) x = a + i * h; integralSum = integralSum + f(x); end % 计算最终的积分近似值 result = h * integralSum;end% 我们首先确保 n 是一个正的偶数。然后，我们计算每个小区间的宽度 h% 接着，我们初始化积分和为区间两端点处函数值的和% 在遍历每个小区间的内部点时，我们根据这些点是奇数位置还是偶数位置% 分别乘以 4 或 2（这是辛普森法的特点）% 最后，将累加的和乘以 h/3，得到积分的近似值function result = simpsonMethod(f, a, b, n) % 确保n为偶数 if mod(n, 2) ~= 0 error('n must be a positive even integer.'); end % 计算每个小区间的宽度 h = (b - a) / n; % 初始化积分结果 integralSum = f(a) + f(b); % 对每个小区间的内部点进行迭代 for i = 1:n-1 x = a + i * h; if mod(i, 2) == 0 integralSum = integralSum + 2 * f(x); else integralSum = integralSum + 4 * f(x); end end % 计算最终的积分近似值 result = (h / 3) * integralSum;end 原点 affine 变换Write an M-file, what gives the matrix of any affin transform with fixed point in OriginThe name of the file: affin1 Input arguments: The images of points (0, 1) and (1, 0). Output argument: The matrix of the transform. If someone calls the function without input arguments give them an opportunity for the graphical input. 12345678910111213141516171819202122232425262728% 7.2 计算具有原点固定点的 affine 变换矩阵% 输入参数:% imageOf01 - 点 (0, 1) 变换后的图像% imageOf10 - 点 (1, 0) 变换后的图像% 输出参数:% A - 变换的矩阵function A = affin1(imageOf01, imageOf10) if nargin == 0 % 如果没有输入参数，通过图形界面获取输入 disp('请图形化输入点 (0, 1) 和 (1, 0) 变换后的图像'); [x1, y1] = ginput(1); % 获取点 (0, 1) 变换后的图像 [x2, y2] = ginput(1); % 获取点 (1, 0) 变换后的图像 imageOf01 = [x1; y1]; imageOf10 = [x2; y2]; end % 验证输入参数 if ~isequal(size(imageOf01), [2, 1]) || ~isequal(size(imageOf10), [2, 1]) error('输入参数的大小必须是 2x1'); end % 计算 affine 变换矩阵 A = [imageOf10, imageOf01]; % 输出变换矩阵 disp('Affine 变换矩阵为:'); disp(A);end 12% 输入示例A = affin1([2; 3], [4; 1]) 三角变换Write an M-file, what gives the matrix of any affin transform.The name of the m-file: affin2 Input arguments: a triangle (with the coordinates of the edges) and the image of the triangle (also with the edges) Output argument: The matrix of the transform. Give an opportunity for graphical input (as in the previous exercise) Draw a figure in both cases. 123456789101112131415161718192021222324252627282930313233343536% 7.3 计算基于一个三角形及其映射后的三角形的仿射变换矩阵%% 使用方法:% A = affin2(triangle, image_triangle)% 其中 triangle 和 image_triangle 是包含三角形顶点坐标的 3x2 矩阵% 如果没有给出参数，则使用图形输入function A = affin2(triangle, image_triangle) if nargin == 0 % 没有输入参数，使用图形输入 disp('点击以定义原始三角形的顶点：'); triangle = ginput(3); disp('点击以定义映射后三角形的顶点：'); image_triangle = ginput(3); end if size(triangle, 1) ~= 3 || size(image_triangle, 1) ~= 3 error('两个三角形都必须有 3 个顶点。'); end % 构造变换矩阵 % 添加一行 1 以处理仿射变换 T = [triangle, ones(3, 1)]; T_image = [image_triangle, ones(3, 1)]; % 求解变换矩阵 A = T_image' / T'; % 绘制原始三角形和变换后的三角形 figure; plot([triangle(:,1); triangle(1,1)], [triangle(:,2); triangle(1,2)], 'b-o'); hold on; plot([image_triangle(:,1); image_triangle(1,1)], [image_triangle(:,2); image_triangle(1,2)], 'r-o'); legend('原始三角形', '变换后的三角形'); title('三角形的仿射变换'); hold off;end 1234% 输入示例triangle = [0, 0; 1, 0; 0, 1];image_triangle = [2, 3; 4, 1; 5, 5];A = affin2(triangle, image_triangle) 等边三角形Give 3 points in the plane. Two of them, P (2; 3) and Q (4; 2), lie on different sides of an equilateral triangle.The third point, S (3; 3), is the centroid of the triangle.Use MATLAB to find the vertices of a triangle (by adding the coordinates of the vertices) and make an illustration for the exercise. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162% 定义点 P, Q 和 SP = [2, 3];Q = [4, 2];S = [3, 3];% 计算三角形的边长side_length = sqrt((Q(1) - P(1))^2 + (Q(2) - P(2))^2);% 计算外接圆的半径R = side_length / sqrt(3);% 计算三角形的顶点% 我们已经有两个顶点（P 和 Q），我们需要找到第三个顶点（R）% 计算 PQ 的中点mid_PQ = (P + Q) / 2;% 计算中点到质心的向量vec_mid_to_centroid = S - mid_PQ;% 计算 PQ 的垂直向量perpendicular = [vec_mid_to_centroid(2), -vec_mid_to_centroid(1)];% 归一化垂直向量perpendicular = perpendicular / norm(perpendicular);% 计算第三个顶点R_vertex = S + R * perpendicular;% 检查 R_vertex 是否与 S 在 PQ 的同一侧% 如果不是，反转方向if dot(R_vertex - mid_PQ, vec_mid_to_centroid) &lt; 0 R_vertex = S - R * perpendicular;end% 绘制三角形figure;hold on;grid on;axis equal;% 绘制点plot(P(1), P(2), 'ro');plot(Q(1), Q(2), 'ro');plot(S(1), S(2), 'bo');plot(R_vertex(1), R_vertex(2), 'go');% 绘制三角形的边plot([P(1), Q(1)], [P(2), Q(2)], 'r');plot([P(1), R_vertex(1)], [P(2), R_vertex(2)], 'r');plot([Q(1), R_vertex(1)], [Q(2), R_vertex(2)], 'r');% 添加注释text(P(1), P(2), ' P');text(Q(1), Q(2), ' Q');text(S(1), S(2), ' S (质心)');text(R_vertex(1), R_vertex(2), ' R');title('具有顶点 P, Q 和 R 的等边三角形');xlabel('X 轴');ylabel('Y 轴');hold off;","link":"/Math/Matlab/Numerical-Methods-II-1/"},{"title":"OpenStack 学习日记 | 第一天","text":"由于本人最近需要从事 OpenStack 相关工作，所以急需对 OpenStack 进行学习本系列日记仅作为本人的学习记录学习材料为 《每天 5 分钟玩转 OpenStack》 学习前需要知道的OpenStack 涉及的范围广计算，储存，网络，虚拟化，可用性，安全性，灾备等一些列关于 IT 基础设施的范围 OpenStack 都有涵盖 OpenStack 是一个平台它的各个组件都采用了 Driver 架构，支持各种的具体实现。比如 OpenStack 储存服务 Cinder 只定义抽象 API，而具体实现交给具体的 Driver比如基于 LVM 的 iSCSI， EMC，或者开源的 Ceph，GlusterFS 等等 这里我们可以类比到 Entity Framework，它只定义了上层的 API而具体的数据库操作交给了你指定的 Driver，如 Npgsql OpenStack 是一个分布式系统这也是学习它的比较大的阻碍，因为它原生就是分布式的，各个组件拆的很散不过我们学习的时候都使用 All-in-one 部署模式 我们要学习的内容 预备知识 虚拟化 云计算 核心组件 架构 认证 Keystone 镜像 Glance 计算 Nova 储存 Cinder 网络 Neutron 写在最前面 – 每天 5 分钟玩转 OpenStack（1） 虚拟化虚拟化是云计算的基础虚拟机(Guest)共享物理机(Host)的资源，比如 CPU，内存，硬盘，网络，磁盘等 这主要通过 Hypervisor 来实现，比如 KVM，Xen，VMWare 等等 1 类虚拟化Hypervisor 是一个操作系统，直接安装在物理机上最典型的就是 Windows 上的 Hyper-V其他的还有 Xen 和 ESXi 2 类虚拟化Hypervisor 作为操作系统中的一个程序或者模块运行最典型的有 KVM 和 VMware Workstation 对比理论上讲，1 类虚拟化性能比 2 类的要好而 2 类虚拟化会更灵活，比如支持嵌套虚拟化 KVM对我来说 KVM 已经是一个听过无数次的词了OpenStack 对 KVM 的支持最好，全称叫 Kernel-based Virtual Machine也就是说它基于 Linux 的内核实现，它有一个模块叫 kvm.ko，只用于管理虚拟 CPU 和内存 那我们就要问了，那 IO 虚拟化呢，这个交给 Linux 内核与 QEMU 实现 Libvirt这是 KVM 的管理工具，包含三个模块后台 daemon，api 库，和 命令行工具 virshvirsh 和 virt-manager 是一定要会用的 虚拟化 – 每天 5 分钟玩转 OpenStack（2） 安装我们使用 Ubuntu，安装 KVM 需要的包 1sudo apt install qemu-kvm qemu-system libvirt-bin virt-manager bridge-util qemu-kvm 和 qemu-system 是 KVM 和 QEMU 的核心包，提供 CPU、内存和 IO 虚拟化功能 libvirt-bin 就是 libvirt，用于管理 KVM 等 Hypervisor virt-manager 是 KVM 图形化管理工具 bridge-utils 和 vlan，主要是网络虚拟化需要，KVM 网络虚拟化的实现是基于 linux-bridge 和 VLAN 准备 KVM 实验环境 – 每天 5 分钟玩转 OpenStack（3） 对于我自己来说，使用 KVM 等本来就是轻车熟路了，所以我跳过这一部分 启动第一个 KVM 虚机 – 每天 5 分钟玩转 OpenStack（4） 远程管理 KVM 虚机 – 每天 5 分钟玩转 OpenStack（5） CPU 虚拟化KVM 虚拟机 在宿主机中其实是一个 QEMU-KVM 进程，与其他进程一同被调度虚拟中的每一个 vCPU 就对应 QEMU-KVM 进程中的一个 线程 这就表明 vCPU 的总数可以超过物理机的 CPU 总数，这叫 CPU OverCommit 超配这个特性让虚拟机能充分利用宿主机的 CPU 资源，但是这也导致了 VPS 中令人诟病的超售行为 内存虚拟化这一段算是我看的比较迷糊的一段不过说到底也不需要了解多少，只需要知道它并不是像一个普通程序那样分配内存即可中间存在大量的内存地址转换，各个厂家也为了转换效率做了很多特殊的优化Guest Virtual Address -&gt; Guest Physical Address -&gt;Host Virtual Address -&gt; Host Physical Address 内存也是可以超配的，所以超售机一大堆 CPU 和内存虚拟化原理 – 每天 5 分钟玩转 OpenStack（6） 储存虚拟化目录类型文件目录类型是最常用的KVM 将宿主机目录 /var/lib/libvirt/images/ 作为默认的 Storage Pool 这个目录下面的每一个文件就是一个 Volume说白了就是用文件来当磁盘，我们最常用的方式存储方便、移植性好、可复制、可远程访问KVM 支持 raw, qcow2, qed, vmdk, vdl 格式的磁盘文件 KVM 存储虚拟化 – 每天 5 分钟玩转 OpenStack（7） LVM 类型这个用的不多，也就是把实际的磁盘划出来给虚拟机用，跳过 LVM 类型的 Storage Pool – 每天 5 分钟玩转 OpenStack（8） 网络虚拟化这章是虚拟化中最复杂，最重要的部分 Linux Bridge其实就是网桥，用来做 TCP/IP 二层协议交换的模块对于我来说这玩意接触的也比较多 KVM 网络虚拟化基础 – 每天 5 分钟玩转 OpenStack（9） 这里记录几个重点 修改 /etc/network/interfaces 以配置网桥 使用 ifconfig 查看 IP 配置 brctl show 查看当前 Linux Bridge 的配置 动手实践虚拟网络 – 每天 5 分钟玩转 OpenStack（10） virbr0virbr0 是 KVM 默认创建的一个 Bridge，其作用是为连接其上的虚机网卡提供 NAT 访问外网的功能。virbr0 默认分配了一个 IP 192.168.122.1，并为连接其上的其他虚拟网卡提供 DHCP 服务。这没啥好难的就是一个 NAT 网关而已 理解 Virbr0 – 每天 5 分钟玩转 OpenStack（11） VLAN也就是虚拟局域网，隔离用，二层交换机，不需要想的太复杂在一张网卡下面划分多个空间而已 Linux 如何实现 VLAN – 每天 5 分钟玩转 OpenStack（12） 具体如何配置就等到要用的时候现查不过还是修改 /etc/network/interfaces 动手实践 Linux VLAN – 每天 5 分钟玩转 OpenStack（13） 云计算 IaaS（Infrastructure as a Service）提供的服务是虚拟机典型的有 AWS，OpenStack 等 PaaS（Platform as a Service）提供的服务是应用的运行环境比如 Github Pages SaaS（Software as a Service）提供的是应用服务对象通常是最终用户，就像 Gmail OpenStack is a cloud operating system that controls large pools of compute, storage,and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface. OpenStack 对数据中心的计算、存储和网络资源进行统一管理 云计算与 OpenStack – 每天 5 分钟玩转 OpenStack（14） OpenStack写日记的时候最新版本是 Yoga，下一个版本是 Zed 首先列出模块列表 名称 用途 中文 cyborg Accelerator Life Cycle Management 用于管理硬件和软件加速资源（如 GPU）的框架 freezer Backup, Restore, and Disaster Recovery service 备份、恢复和灾难恢复服务 ironic Bare Metal service 裸机服务 cinder Block Storage service 存储服务 ceilometer Data collection service 数据收集服务 kuryr Bridge between container framework and OpenStack abstractions 容器框架和 OpenStack 抽象之间的桥梁 keystone Identity Service 管理身份验证、服务规则和服务令牌功能 senlin Clustering service 集群服务 storlets Compute inside Object Storage service 对象存储服务中的计算 nova Compute service 计算服务，管理 VM 的生命周期 neutron network connectivity as a service 网络连接服务，负责创建和管理 L2、L3 网络， 为 VM 提供虚拟网络和物理网络连接 zun Containers service 容器服务 horizon Dashboard 仪表盘 designate DNS service DNS 服务 ec2-api EC2 API compatibility layer EC2 API 兼容层 glance Image service 启动镜像服务 watcher Infrastructure Optimization service 基础设施优化服务 masakari Instances High Availability Service 实例高可用性服务 barbican Key Manager service 密钥管理器服务 octavia Load-balancer service 负载均衡器服务 neutron Networking service 网络服务 tacker NFV Orchestration service NFV 管理器，用于监视、配置 NFV 和管理 NFV 全生命周期 swift Object Storage service 对象存储服务 heat Orchestration service REST 服务，能够基于一个声明式的模板，通过装配引擎装配组合若干个云应用 placement Placement service REST API 堆栈和数据模型，用于跟踪资源提供程序的清单和使用情况，以及不同的资源类别 cloudkitty Rating service 计费服务 vitrage RCA (Root Cause Analysis) service 用于组织、分析和扩展 OpenStack 的告警和事件 blazar Resource reservation service 资源保留服务 manila Shared File Systems service 共享文件系统服务 aodh Telemetry Alarming services 遥测报警服务 ceilometer Telemetry Data Collection service 遥测数据采集服务 https://www.openstack.org/software/project-navigator/这么一大堆模块一时半会肯定是学不完的，我们挑重点学习搞清楚 OpenStack 是图和对计算，网络，储存资源进行管理的 核心组件 Nova 管理计算资源，是核心服务。 Neutron 管理网络资源，是核心服务。 Glance 为 VM 提供 OS 镜像，属于存储范畴，是核心服务。 Cinder 提供块存储，VM 怎么也得需要数据盘吧，是核心服务。 Swift 提供对象存储，不是必须的，是可选服务。 Keystone 认证服务，没它 OpenStack 转不起来，是核心服务。 Ceilometer 监控服务，不是必须的，可选服务。 Horizon 大家都需要一个操作界面吧。 OpenStack 本身是一个分布式系统，不但各个服务可以分布部署，服务中的组件也可以分布部署这也使得 OpenStack 比一般系统复杂，学习难度也更大 OpenStack 架构 – 每天 5 分钟玩转 OpenStack（15） 搭建 Dev 环境我一般使用 MicroStack 一键解决 搭建 OpenStack 实验环境 – 每天 5 分钟玩转 OpenStack（16） 部署 DevStack – 每天 5 分钟玩转 OpenStack（17） Keystone对于天天跟 OAuth 打交道的我这部分其实可以跳过 Authentication 解决的是“你是谁？”的问题 Authorization 解决的是“你能干什么？”的问题 Keystone 负责管理和维护每个 Service 的 Endpoint Service 通过 Endpoint 暴露自己的 API 理解 Keystone 核心概念 – 每天 5 分钟玩转 OpenStack（18） 通过例子学习 Keystone – 每天 5 分钟玩转 OpenStack（19） Glance这玩意还储存快照 Glance 支持多种 backend，包括 A directory on a local file system（这是默认配置） GridFS Ceph RBD Amazon S3 Sheepdog OpenStack Block Storage (Cinder) OpenStack Object Storage (Swift) VMware ESX 没啥好讲的，需要用到时候现查，而且大部分操作都可以通过 GUI 完成 理解 Glance – 每天 5 分钟玩转 OpenStack（20） 创建 Image – 每天 5 分钟玩转 OpenStack（21） 如何使用 OpenStack CLI – 每天 5 分钟玩转 OpenStack（22） NovaCompute Service Nova 是 OpenStack 最核心的服务，负责维护和管理云环境的计算资源。OpenStack 作为 IaaS 的云操作系统，虚拟机生命周期管理也就是通过 Nova 来实现的。 nova-api接收和响应客户的 API 调用， 还支持 Amazon EC2 API nova-scheduler虚机调度服务，负责决定在哪个计算节点上运行虚机 nova-compute管理虚机的核心服务，通过调用 Hypervisor API 实现虚机生命周期管理 nova-conductornova-compute 经常需要更新数据库，比如更新虚机的状态出于安全性和伸缩性的考虑，nova-compute 并不会直接访问数据库 nova-console用户可以通过多种方式访问虚机的控制台：nova-novncproxy，基于 Web 浏览器的 VNC 访问nova-spicehtml5proxy，基于 HTML5 浏览器的 SPICE 访问nova-xvpnvncproxy，基于 Java 客户端的 VNC 访问 nova-consoleauth负责对访问虚机控制台请求提供 Token 认证 nova-cert提供 x509 证书支持 总之我越看越觉得 OpenStack 就是在 Hypervisor 上套了一层又一层而且我个人对 Python 写的大型项目是完全没有好感 理解 Nova 架构 – 每天 5 分钟玩转 OpenStack（23） 部署方案哪里有那么复杂，专门负责装 VPS 的 Hypervisor 就装 nova-compute然后其他服务放别处就行了 OpenStack 默认是用 RabbitMQ 作为 Message Queue，好评 Nova 组件如何协同工作 – 每天 5 分钟玩转 OpenStack（24） 设计思路说那么多到底还是解耦，疯狂解耦然后各种抽象 API，疯狂增加项目体积再加入各种调度，最离谱的是居然默认用 MySQL当然对大型集群这都不算什么 OpenStack 通用设计思路 – 每天 5 分钟玩转 OpenStack（25） 组件 Nova 组件详解 – 每天 5 分钟玩转 OpenStack（26） flavor 就是 plan，选 VPS 配置 Filter scheduler 是 nova-scheduler 默认的调度器 通过过滤器（filter）选择满足条件的计算节点 通过权重计算（weighting）选择在最优（权重值最大）的计算节点上创建 Instance RetryFilter 的作用是刷掉之前已经调度过的节点 为提高容灾性和提供隔离服务，可以将计算节点划分到不同的 Availability Zone 中 RamFilter 将不能满足 flavor 内存需求的计算节点过滤掉 DiskFilter 将不能满足 flavor 磁盘需求的计算节点过滤掉 CoreFilter 将不能满足 flavor vCPU 需求的计算节点过滤掉 ComputeFilter 保证只有 nova-compute 服务正常工作的计算节点才能够被 nova-scheduler 调度 ComputeCapabilitiesFilter 根据计算节点的特性来筛选可以从 Metadata 中筛选架构之类的 ImagePropertiesFilter 根据所选 image 的属性来筛选匹配的计算节点镜像也带 Metadata，可以限定比如只能运行在 kvm 上之类的 ServerGroupAntiAffinityFilter 可以尽量将 Instance 分散部署到不同的节点上 ServerGroupAffinityFilter 会尽量将 instance 部署到同一个计算节点上 nova-scheduler 的默认实现是根据计算节点空闲的内存量计算权重值：空闲内存越多，权重越大，instance 将被部署到当前空闲内存最多的计算节点上 看 Nova-Scheduler 如何选择计算节点 – 每天 5 分钟玩转 OpenStack（27） 每隔一段时间，nova-compute 就会报告当前计算节点的资源使用情况和自己的状态 这不就是微服务么，eureka 既视感 instance 的 launch、shutdown、reboot、suspend、resume、terminate、resize、migration、snapshot Nova-Compute 部署 Instance 详解 – 每天 5 分钟玩转 OpenStack（28） 生命周期OpenStack 的日志格式都是统一的，如下&lt;时间戳&gt;&lt;日志等级&gt;&lt;代码模块&gt;&lt;Request ID&gt;&lt;日志内容&gt;&lt;源代码位置&gt; 教你看懂 OpenStack 日志 – 每天 5 分钟玩转 OpenStack（29）Launch 和 Shut Off 操作详解 – 每天 5 分钟玩转 OpenStack（30）Start Instance 操作详解 – 每天 5 分钟玩转 OpenStack（31）Nova reboot 和 lock 操作 – 每天 5 分钟玩转 OpenStack（32）Terminate Instance 操作详解 – 每天 5 分钟玩转 OpenStack（33）Pause/Resume Instance 操作详解 – 每天 5 分钟玩转 OpenStack（34）Nova Suspend/Rescue 操作详解 – 每天 5 分钟玩转 OpenStack（35）Snapshot Instance 操作详解 – 每天 5 分钟玩转 OpenStack（36）Rebuild Instance 操作详解 – 每天 5 分钟玩转 OpenStack（37）Shelve Instance 操作详解 – 每天 5 分钟玩转 OpenStack（38）Unshelve Instance 操作详解 – 每天 5 分钟玩转 OpenStack（39）Migrate Instance 操作详解 – 每天 5 分钟玩转 OpenStack（40）Resize Instance 操作详解 – 每天 5 分钟玩转 OpenStack（41）Live Migrate 操作 – 每天 5 分钟玩转 OpenStack（42）计算节点宕机了怎么办？Evacuate - 每天 5 分钟玩转 OpenStack（43）1 张图秒懂 Nova 16 种操作 – 每天 5 分钟玩转 OpenStack（44） 上面这一大堆操作都是属于遇到了现查来得更快，而且很多都浅显易懂，盲猜也能用个大概","link":"/Cloud/OpenStack/OpenStack-%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0-%E7%AC%AC%E4%B8%80%E5%A4%A9/"},{"title":"Numerical Methods II","text":"很多很好玩的数值方法是 Matlab 苦手，所以很多高血压代码 Machine Numbers机器数转十进制Our first M-file computes the value of a machine number. Let us choose fl1 as name of function and of course as name of the file also.We give a vector as input parameter. The last coordinate of vector gives thecharacteristic of machine number (in tenary numeral system). We store the signedmantissa in the other coordinates. The output argument be the real number what is represented by our machine number. The first bit of mantissa we can use for storing the sign of the number.(Originally this bit is surely 1.) When the number is positive, then the signbit be 0,in case of negative numbers we use 1 as first bit. We don’t have to know the parameters of machine number set for convertingthe number. The length of mantissa can be read from input data. And weassume that the bounds of characteristic are such that our carachteristic be allowed. Before starting computation let us check whether the given data can be amachine number or not. (All but last coordinates are from set {0,1} and last is an integer.) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546% 1. 机器数转十进制% 第一位是正负号% 中间是二进制% 最后一位是指数位function dec = fl1(vector)arguments % 限定输入必须是一维数组 vector (1,:)end isaninteger = @(x) isfinite(x) &amp; x == floor(x); % 判断 最后一位是整数 if ~isaninteger(vector(end)) % 如果不是，将返回值标记为无效 dec = nan; return end % 对数组内容进行验证，起始 到 倒数第二位 for n = vector(1:end-1) % 只能是二进制 if ~(n == 0 || n == 1) dec = nan; return end end % 初始化赋值 dec = 0; % 从 第二位 到 倒数第二位 for n = 2:length(vector)-1 if vector(n) == 1 % 二进制转十进制算法 dec = dec + 1/(2^(n-1)); end end % 位移，应用指数位 dec = dec * 2^vector(end); % 检查正负号 if vector(1) dec = -dec; return endend 在数轴上展示机器数Let us write anothe M-file, called fl2. It displays the elements of a given machinenumber set on the real axis. Compute the number of elements and the followingparameters: M∞, ε0, ε1. (They will be the output arguments of the function) The function waits 3 (integer) number as input.They are the parameters of the set: t, k1, k2. Let us check whether the input parameters are appropriate.(t ∈ N+ and k1, k2 ∈ Z, and of course k1 &lt; k2) For the computation we can call our first function (fl1) The set is symmetric. We can use this property for the faster computation. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859% 1. 在数轴上展示机器数，输出最大最小值，和与1的偏差function [max, min, diff] = fl2(digits, bottomExp, topExp, draw)% M∞, ε0, ε1arguments % 限定它们只能是一位数字 digits (1,1) bottomExp (1,1) topExp (1,1) % 布尔值，可选参数，默认为真 draw (1,1) = 1end isaninteger = @(x) isfinite(x) &amp; x == floor(x); % 最大位数必须大于零 且 是整数 % 低指数 小于或者等于 高指数，同时是整数 if ~(digits &gt; 0 &amp;&amp; isaninteger(digits)) ... || bottomExp &gt; topExp ... || ~isaninteger(bottomExp) ... || ~isaninteger(topExp) max = nan; return end mn = []; % 遍历出全部位数的机器数可能性 % n 从 1 开始枚举 到 最大位数 for n = 1:digits % 括号里面是十进制数组，长度为 2^n % 如 [0, 1, 2, 3]，-1 的原因是从 0 开始 % de2bi 会把数组里面的每一个数都转换成二进制 % 矩阵 m 有 2^n 行 n 列 % 这样写的好处是写起来简单，问题是会产生大量重复内容 m = de2bi(0:(2^n)-1); % 按行遍历矩阵，取出每一个二进制结果 for k = 1:size(m, 1) % 遍历所有的指数大小可能性，同样会产生大量重复内容 for e = bottomExp:topExp % 把二进制结果转换为机器数，并储存 % 这种持续变换矩阵大小的行为效率低下，但是写起来简单 mn = [mn, fl1([0, m(k, :), e])]; end end end % 将所有重复项排除，此方法会自动从小到大排序 mn = unique(mn); max = mn(end); min = mn(1); % 找出 1 的位置，并且取出它的下一位，算出误差 diff = mn(find(mn == 1) + 1) - 1; % 对称 mn = [-mn, mn]; if draw plot(mn, repelem(0, length(mn)), &quot;o&quot;) endend 十进制转机器数The third function finds the machine number what representates the given real number. The name be fl3. The function waits the real number and parameters of set ofmachine numbers (t, k1, k2.) as input. And gives back a vector with t+1 coordinates.The last coordinate be the characteristic and the firs t stores the signedmantissa. (As in case of input argument of function fl1). The first bit of mantissa is the sign-bit as in exercise 1.The value of sign is 0 when number is positive and 1 when it is negative. Check the input arguments whether they are appropriate.And the real number whether can representate in machine number set. (ε0 ≤ |r| ≤ M∞) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667% 1. 十进制转机器数function vector = fl3(digits, bottomExp, topExp, dec) % fl2 自带检查了所以这里就不再重复检查 [max] = fl2(digits, bottomExp, topExp, 0); % min &lt;= dec &lt;= max 防止溢出 if isnan(max) || ~((-max &lt;= dec) &amp;&amp; (dec &lt;= max)) vector = nan; return end sgn = 0; % 记录十进制正负 if sign(dec) == -1 sgn = 1; end % 取十进制绝对值 dec = abs(dec); % 抹掉小数，把整数位转换成二进制 int = fix(dec); bin = []; % 只有整数不为零的情况才需要转换 if int bin = de2bi(int); end % 整数二进制的长度就是未标准化的机器数的指数 % 我们可能得到这样两种情况：111.2222... 和 0.1111... % 只有第一种情况我们需要把整数位全部位移到小数位上 % 这时候就产生了指数位（指数位是可以为零的） power = length(bin); % 0.小数部分 * 2^(1:位数) 再取它 除以二 的余，并且抹掉小数 % 乘2取整，顺序排列，不断的在小数位上乘2 bin = [bin, fix(rem(rem(dec,1) * pow2(1:digits), 2))]; if power % 强行截断超出部分，只留超出的第一位，进行舍零入一 bin = bin(1:digits + 1); end % 是否需要进位 over = 0; % 只有当整数向后位移的情况才可能超出 if power over = bin(end); end % 逆向遍历数组 for n = digits:-1:1 if over % 是 1 则变成 0，继续进位 if bin(n) bin(n) = 0; else % 如果是 0 则 停止进位 bin(n) = 1; over = 0; end else break end end % 我们不需要考虑溢出的情况，因为最开始就已经检查过范围了 vector = [sgn, bin(1:digits), power];end 机器数相加Let us write a function for addition between machine numbers. Let us call the file to fl4. It waits for two vectors as input. (They are representatethe machine numbers as before). The output be a vector with the machine number of the sum. Use machine-addition. The double conversion is not acceptable. (To computethe real numbers belongs to inputs, summing them and reconverting tomachin number is not allowed.) Check the inputs. (They have to have same length and have to be machine numbers) If one of the numbers is negative (the first bit is 1) then in real the operationis a substraction. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596% 1. 机器数相加function vector = fl4(a, b)arguments a (1,:) b (1,:)end % 检查合法性，但是并没有检查完整 if ~isvector(a) || ~isvector(b) || length(a) ~= length(b) vector = nan; return end % 取出两个的指数位 ac = a(end); bc = b(end); % 目标指数 char = ac; % 取出两个的二进制数据 abin = a(2:end - 1); bbin = b(2:end - 1); % 二进制长度 len = length(abin); % 如果两个指数不相等 if ac ~= bc diff = ac - bc; if ac &gt; bc % align % A 大所以扩大 B for n = 1:diff bbin = [0, bbin]; end bbin = bbin(1:len); else for n = 1:-diff abin = [0, abin]; end % 目标指数转为大的那个 char = bc; abin = abin(1:len); end end % fliplr 将数组从左向右翻转 % 当使用 bi2de 或者 de2bi 时 % 第一位是 least significant bit 最低有效位 % 最后一位是 most significant bit 最高有效位 % 所以是小端序的，我们必须反转它 ad = bi2de(fliplr(abin)); bd = bi2de(fliplr(bbin)); % 处理符号 if a(end - 1) ad = -ad; end if b(end - 1) bd = -bd; end % 相加并转回二进制 dres = ad + bd; bin = fliplr(de2bi(abs(dres))); % 新结果与原始数据长度差 dlen = length(bin) - len; % 增加指数位 char = char + dlen; if length(bin) &gt; len % 如果太长了就截断，我们不改变机器数的长度 bin = bin(1:len); elseif length(bin) &lt; len % 如果不足，就在后面补 0 for n = 1:-dlen bin = [bin, 0]; end end % 处理符号 sgn = 0; if sign(dres) == -1 sgn = 1; end % 基本上只是简单实现了两个机器数的加减 % 没有判断两个输入的合法性 % 也没有判断是否溢出 % 而且实际还用的是十进制加减 % 总的来说不是很合格 vector = [bin, sgn, char];end Gaussian Elimination计算高斯消去Write an M-file to compute Gaussian Elimination.The name of the file be gaussel1 Input parameters: the coefficient matrix (A) and the right-side vector (b) of LES. Output argument: the solution vector x Use the Matlab row-operations for organisation of algorithm. If GE can’t be solved without row or coloumn swap write an error messageand terminate the program. In case of underdetermined LES give a base solution and warn the user of this. In case the user asked it, display the matrices A(i) during computation. To checking our function we can use the exercises from numerical I. +1 We can prepare our function to accept LES with multiple right sides. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384% 2. 计算高斯消去function x = gaussel1(A, b, display)arguments A % 右向量，只能有一列 b (:,1) display (1,1) = 0end [ARow, ACol] = size(A); BRow = size(b, 1); if ~ismatrix(A) || ARow ~= BRow error(&quot;ValidationException&quot;); end % 方程个数小于未知量个数的方程组 % 此时有无穷多组解，展示一个基本解 if(ARow &lt; ACol) warning('A is underdetermined, the basic solution with at most m nonzero components is') disp(A\\b) % 超定是方程个数大于未知量个数的方程组，且列满秩 % 一般是不存在解的矛盾方程，只能求一个最接近的解 elseif(ARow &gt; ACol &amp;&amp; rank(A) == ACol) % 显示一个使用最小二乘法，且 norm(A*x-b) &amp; norm(x) 最小 % 线性方程的最小范数最小二乘解，指示它是离原点最近的解，但仍然进行GJ warning('A is overdetermined, the minimum norm least-squares solution is') disp(lsqminnorm(A, b)) end M = [A, b]; [rows, cols] = size(M); % 主元容差，主要是为了控制精度问题，如 magic(4) % https://ww2.mathworks.cn/help/matlab/ref/rref.html#mw_5f53d9c8-72e8-42cc-bda8-ef84cf56ba93 tolerance = eps * max(rows, cols) * norm(M, inf); % Gauss-Jordan r = 1; for c = 1:cols % 找出当前列中，绝对值最大的数字，及其所在的行 % 使用部分主元消去法可减少（但会不消除）计算中的舍入误差 % 主元位置：行中最左边的非零元素 [num, target] = max(abs(M(r:end, c))); % 加上 r 的原因是因为上面 max 判断的是被截断的矩阵 target = r + target - 1; if (num &lt;= tolerance) % 跳过当前列，将近似零的项直接变成零 % 这可以防止使用小于容差的非零主元元素进行运算 M(r:end, c) = zeros(rows - r + 1, 1); if display disp(M) end else % 交换最大行与当前行 M([target, r], c:end) = M([r, target], c:end); if display disp(M) end % 标准化最大行（把主元变成1） M(r, c:end) = M(r, c:end) / M(r, c); if display disp(M) end % 消除当前的列（消元），但是要除开当前行 erow = [1:r - 1, r + 1:rows]; M(erow, c:end) = M(erow, c:end) - M(erow, c) * M(r, c:cols); if display disp(M) end % 检查是否完成行遍历 if (r == rows) break; end r = r + 1; end end x = M(:, end);end Whole PivotingExtend the previous m-file (but save as a new name for example gaussel2) withsteps of partial and whole pivoting method. Using partial or whole pivoting could be choosen by user(for example according to a boolean input parameter), but if the partial pivoting is stuckedthen automatically switch to whole pivoting method. If we used whole pivoting despite user has choosen partial pivoting, then inform user about the switch Give an opportunity for displaying matrices A(i) during computation. Don’tforget that pivoting method can be changed the matrix so we have to displayit after row and coloumn swap. Don’t forget that the pivoting method can be changed the solution. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869% 2. 完全交换，注释看前面一个function x = gaussel2(A, b, display)arguments A b (:,1) display (1,1) = 0end M = [A, b]; [rows, cols] = size(M); xOrd=(1:length(b))'; tolerance = eps * max(rows, cols) * norm(M, inf); % Whole Pivoting r = 1; for c = 1:cols - 1 % 找出行列最大值 [maxc, rowI] = max(abs(M(r:end, c:end - 1))); [num, colI] = max(maxc); row = rowI(colI) + c - 1; col = colI + c - 1; if (num &lt;= tolerance) M(r:end, c) = zeros(rows - r + 1, 1); if display disp(M) end else % 交换列 M(r:end, [col, c]) = M(r:end, [c, col]); if display disp(M) end % 交换行 M([row, r], c:end) = M([r, row], c:end); if display disp(M) end % 交换X oldOrd = xOrd(c); xOrd(c) = xOrd(col); xOrd(col) = oldOrd; % 标准化 M(r, c:end) = M(r, c:end) / M(r, c); if display disp(M) end % 消元 erow = [1:r - 1, r + 1:rows]; M(erow, c:end) = M(erow, c:end) - M(erow, c) * M(r, c:cols); if display disp(M) end if (r == rows) break; end r = r + 1; end end % 调换回正常顺序 x = M(xOrd, end);end 求逆矩阵Apply Gaussian elimantion for computing inverse of an square matrix.The name of function: gaussel3 Check input argument(s) before computing Compute the determinant of matrix.If you have written the function gaussel1 such that it accepts multipleright-sides, then you can call it during computation. 12345678910111213141516171819202122232425262728293031323334353637383940414243% 2. 求逆矩阵function x = gaussel3(A) [row, col] = size(A); if row ~= col error(&quot;A is not a square matrix&quot;) end % 判断是否是奇异矩阵，如果是则不可逆 if det(A) == 0 warning(&quot;A is singular matrix&quot;) end A = [A, eye(row)]; for c = 1:row % 在消元操作之前选择一个最大的元素作为主元 % 这样可以避免主元为零的情况，从而提高精度 [~, maxI] = max(abs(A(c:row, c))); % 得到原来矩阵A中的行索引 maxI = maxI + c - 1; % 将矩阵A的第maxI行作为主元行，并将主元行转化为单位矩阵 % （主元行中的第c个元素是1，其余元素都是0） % 这样一来，矩阵A的第maxI行就成为了消元的基准行 % 在后续的消元操作中，其他行都需要根据这一行进行消元 A(maxI, :) = A(maxI, :) / A(maxI, c); temp = A(c, :); % 将矩阵A的主元行移动到第c行，使得在后续的消元操作中 % 只需要对矩阵A的第c行以下的部分进行消元 A(c, :) = A(maxI, :); A(maxI, :) = temp; for j = 1:row if(j ~= c) % 消元操作，使得矩阵A的第j行的第c个元素变为0 A(j, :) = A(j, :) - A(j, c) * A(c, :); end end end x = A(:, row + 1:size(A, 2));end QR-decompositionGram-SchmidtWrite an M-file for QR-decomposition using Gram-Schmidt orthogonalization. Letus call the function to: gramschmidt Input parameter: a square matrix (A) Output arguments: an orthogonal matrix (Q) and an upper triangular matrix (R),such that satisfy A = Q·R To check existence of decomposition (the columns of A have to be linearindependent) we can use any included function of Matlab. The included functions can be used for computing norms,but we can compute via definition also. 123456789101112131415161718192021222324252627282930313233343536373839404142434445% 3. Gram-Schmidt正交法% 选择一组线性无关的向量。然后通过计算每个向量与之前所有向量的投影% 并将这些投影从原始向量中减去，来逐步构造出一组正交向量% 1. 对于矩阵A的每一列，计算该列向量在之前处理的所有基向量上的投影分量% 2. 减去投影分量，得到一个正交化的基向量% 3. 更新正交矩阵Q和上三角矩阵Rfunction [Q, R] = gramschmidt(A) [m, n] = size(A); if (m ~= n) error(&quot;A should be a square matix&quot;) end if (rank(A) ~= size(A, 2)) % 加了这个 magic 就过不了了 warning(&quot;the columns of A have to be linear independent&quot;) end Q = zeros(m); R = zeros(m); % 从最左侧的列向量向右 for col = 1:n a = A(:, col); q = a; % 减去 A 中当前列向量在之前已找到的基向量上的投影分量 for b = 1:col-1 % 计算给定列向量a在已处理的基向量Q的第b列上的投影分量 r = Q(:, b)' * a; % 减去当前列向量在之前处理的基向量上的投影分量 q = q - r * Q(:, b); % 记录对应 R 矩阵中的元素值 R(b, col) = r; end % 对当前基向量进行正交化 q = q / norm(q); % 更新结果 Q(:, col) = q; R(col, col) = a' * q; endend HouseholderWrite an M-file to give the matrix of a Householder transformation, from a knownpoint and its image. The name of function let be: householder Input parameters: the coordinatas of the point and its image (P, P’) PointP (and ofcourse P’ also) can be from Rn where n is not predetermined. Output argument: the matrix of Householder-transformation Take care of choosing sign during transformation (the parameter σ effectsthe stability of the method) 123456789101112131415161718% 3. Householder 变换主要就是那个公式，没有什么别的function H = householder(P, Prem)arguments P (:,1) Prem (:,1) % P'end % 解题参考 NumSampleTest1SolutionsP1 213 if (size(P) ~= size(Prem)) error(&quot;Size P not equal to Size ImgP&quot;) end u = P - Prem; v = u / norm(u); % H(v) = I - 2 * v * v' H = eye(size(P, 1)) - 2 * (v * v');end 点映射The third function will asking data via graphical input. (It works for 2D points)Display points and the hyperspace of reflection. Ask for another point (also viagraphical input) and apply the transformation to the new point. The functionhouseholder can be called during the algorithm.the name of function: hhgraph 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172% 3. 交互点映射function hhgraph() clf; hold on; ax = gca; ax.XAxisLocation = &quot;origin&quot;; ax.YAxisLocation = &quot;origin&quot;; button = questdlg(&quot;Click a point&quot;, &quot;First Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX, PointY] = ginput(1); plot(PointX, PointY, &quot;rd&quot;) R = distance(PointX, PointY, 0, 0); viscircles([0, 0], R); button = questdlg(&quot;Click another point&quot;, &quot;Second Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX2, PointY2] = ginput(1); plot(PointX2, PointY2, &quot;rd&quot;) syms x y u; % 圆的标准方程 c = x ^ 2 + y ^ 2 - R ^ 2; % 计算点 (x,y) 到第二个点（PointX2,PointY2）之间的欧几里得距离 d = (x - PointX2) ^ 2 + (y - PointY2) ^ 2; % 求出第二个点（PointX2,PointY2）在反射变换后的位置，以确定反射变换矩阵 H h = d + u * c; % 前两个参数表示 h 关于 x 和 y 的一阶导数，它们用来求解 h 关于 x 和 y 的根 % 这些根是 h 关于 x 和 y 的极值点，它们决定了反射变换后第二个点的位置 % 第三个参数表示 h 关于 u 的一阶导数，它用来求解 h 关于 u 的根 % 这个根是 h 关于 u 的极值点，它决定了反射变换矩阵 H 的值 res = solve(diff(h, x) == 0, diff(h, y) == 0, diff(h, u) == 0); x = res.x; y = res.y; % 它们的值分别是第二个点反射变换后的两个可能位置与原点之间的欧几里得距离 d1 = (x(1) - PointX2) ^ 2 + (y(1) - PointY2) ^ 2; d2 = (x(2) - PointX2) ^ 2 + (y(2) - PointY2) ^ 2; % 选择更小的那一个作为反射变换后第二个点的位置 % 反射变换后第二个点的最终位置应该是离原点最近的那一个 if (d1 &lt;= d2) PointX2 = x(1); PointY2 = y(1); else PointX2 = x(2); PointY2 = y(2); end plot(PointX2, PointY2, &quot;rd&quot;) H = householder([PointX, PointY]', [PointX2, PointY2]'); button = questdlg(&quot;Click new point&quot;, &quot;Third Step&quot;, &quot;OK&quot;, &quot;Cancel&quot;, &quot;OK&quot;); if strcmpi(button, &quot;Cancel&quot;) return; end [PointX3, PointY3] = ginput(1); plot(PointX3, PointY3, &quot;rd&quot;) res = (H * [PointX3, PointY3]')'; plot(res(1), res(2), &quot;rd&quot;)end Householder QR 分解Write an M-filet to realize QR-decomposition with Householder algorithm. Letus call our function to: hhalg Input parameter: a square matrix (A) Output arguments: an orthogonal matrix (Q) and an upper triangular matrix (R),such that satisfy A = Q·R The previous functions can be called. 1234567891011121314151617181920212223242526272829303132333435363738394041424344% Householder QR 分解function [Q, R] = hhalg(A) [m, n] = size(A); if (m ~= n) error(&quot;A should be a square matix&quot;) end % 预分配，减少动态内存分配，提高性能 % 反射变换矩阵、正交矩阵和上三角矩阵 H = eye(m); Q = eye(m); R = A; for col = 1:n % x = aₖ x = R(col:m, col); % 跳过已满足条件不需要反射的部分 % 非零矩阵元素的数目 % 这是因为反射变换的作用是将向量 x 的第一个元素变为正数 if ~nnz(x(2:end)) continue end % v = aₖ - βeₖ，其中 eₖ 为单位正交基 v = x; % β=‖x‖取值保持与x(1)一致，β 是向量 x 的模长 v(1) = v(1) + sign(x(1)) * norm(x); v = v / v(1); % 反射变换：I - 2*u*conj(u) 可整理得下式 % 随着逐列推进，Householder 反射变换部分占右下部分越来越小 % (v * v') / (v' * v) 表示反射变换矩阵 H 的右下角部分 h = eye(m - col + 1) - 2 * (v * v') / (v' * v); H(col:m, col:m) = h; % 使用反射变换矩阵 H 更新正交矩阵 Q 和上三角矩阵 R R = H * R; Q = Q * H'; % 将预分配的内存重置 H(col:m, col:m) = eye(m - col + 1); endend Iterative solutions of LESJacobi 迭代Write an M-file for Jacobi iteration. The file name be: jacobi Input parameters: The matrix of LES A and a vector for the right-side: b Output argument: the approximation of the solution vector: x We can use the vectorial form of the iteration 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778% 4. Jacobi迭代function [x, k, index] = jacobi(A, b, ep, itMax)arguments A b (:,1) ep (1,1) = 1e-5 itMax (1,1) = 100end % 求线性方程组的雅可比迭代法，其中， % A为方程组的系数矩阵； % b为方程组的右端项; % ep为精度要求，缺省值为1e-5; % itMax 为最大迭代次数，缺省值为100; % x为方程组的解; % k为迭代次数; [row, col] = size(A); bRow = length(b); %当方程组行与列的维数不相等时，停止计算，并输出出错信息。 if row ~= col error('The rows and columns of matrix A must be equal'); end % 当方程组与右端项的维数不匹配时，停止计算，并输出出错信息。 if col ~= bRow error('The columns of A must be equal the length of b'); end % 迭代次数 k = 0; % 上一次迭代的结果 x = zeros(row, 1); % 当前迭代的结果 y = zeros(row, 1); % index为指标变量，index=0表示迭代失败，index=1表示收敛到指定要求 index = 1; % A = U + L + D % Ax = b % (U + L + D)x = b % Dx = -(U + L)x + b % Dx = -(A - D)x + b % x = -D^-1 * (U + L) * x + D^-1 * b % x(k+1) = Bj x(k) + cj % Bj = -D^-1 (L + U) % cj = D^-1 * b while 1 for r = 1:row y(r) = b(r); for j = 1:row if j ~= r % 用当前的 x 来更新 y y(r) = y(r) - A(r, j) * x(j); end end % A 中第 r 行第 r 列的元素过小，导致无法更新 y，无法进行下一次迭代 if abs(A(r, r)) &lt; 1e-10 &amp;&amp; k == itMax index = 0; return; end % 更新迭代解 y(r) = y(r) / A(r, r); end k = k + 1; if norm(y - x, inf) &lt; ep break; end x = y; endend Gauss SeidelWrite an M-file for Gauss-Seidel iteration. The file name be: gaussseid As in previously at Jacobi iteration. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455% 4. 用 Gauss Seidel 迭代法解线性方程组 Ax=b% A为方程组的系数矩阵% b为方程组的右端项%epsilon：近似解的误差%Max：迭代的最大次数function x = gaussseid(A, b, epsilon, Max)arguments A b (:,1) epsilon (1,1) = 1e-5 Max (1,1) = 1000end [row, col] = size(A); bRow = length(b); %当方程组行与列的维数不相等 if row ~= col error('The rows and columns of matrix A must be equal'); end % 当方程组与右端项的维数不匹配 if col ~= bRow error('The columns of A must be equal the length of b'); end %迭代初始值 x = zeros(bRow, 1); %diag(A)是取出对角元的向量，对该向量再作用diag()函数表示以该对角元向量生成对角矩阵 D = diag(diag(A)); %将矩阵分裂为A=D-L-U %下三角 L = -tril(A, -1); %上三角 U = -triu(A, 1); %G-S迭代法的迭代公式 Xk+1 = (D-L)^(-1) * U * Xk + (D - L)^(-1) * b B = (D-L) \\ U; g = (D-L) \\ b; %开始迭代Xk+1 = B * x + g %最大迭代次数 for k=1:Max %计算Xk+1用y存放 y=B*x + g; %相邻两次迭代之间相差小于阈值 if norm(x-y) &lt; epsilon break; end %存放单步结果用于判断收敛 x = y; endend Iterative solution of non-linear equations, Interpolation二分法Write an m-file for bisection method and call the file: bisect Input arguments: the function f (we want to find one of the zeros). Give itas a string (the variable can be denoted by x or we can give the notationas another parameter. We will need the ends of the starting interval (a, b),the number of steps (n). Output arguments: the appropriate approximation of root: x^∗and the error estimation ε. Before start we have to check the interval (is there a root inside?) To evaluate function we can use function eval 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162% 5. 二分法% x 根% tolerance 迭代误差function [x, tolerance] = bisect(f, a, b, k_max)arguments % 一元标量函数 如 f = @(x) x^2-1 f (1,1) function_handle % 起始区间 a (1,1) % 结束区间 b (1,1) % 最大迭代数 k_max (1,1) = 200end % 第一次迭代的 root 估计 % 接下来会持续更新 c 也就是每一次迭代的值 c = (a + b) / 2; % 如果是f(x)的根，直接返回根的估计值 if f(c) == 0 x = c; return end % 第一次迭代时，函数在左区间和中点的值 % 同样，这两个值在接下来会持续更新 fa = f(a); fc = f(c); % bisection iteration for k = 1:k_max % 为 0 就是已经找到根了 if fc == 0 break; % 两个y相乘为正就说明还在x轴上方 elseif (fa * fc &gt; 0) % 向右收敛 a = c; % 无需重复计算 fa = fc; else % 如果小于零就说明有一个y在x轴下方了 % 这时向左收敛 b = c; end % 更新区间中点（估计的根） c = (a + b) / 2; % 更新 y 轴结果 fc = f(c); end % 结果 x = c; % 误差 tolerance = b - a;end Least Squares Method, Generalised inverse最小二乘法Write an m-file for approximation with least squares method.The name of file: lsmapprox Input arguments: order of polynomial (n), nodes of approximation (in avector), vector of function values in nodes Output argument(s): the coefficients of the polynomial Let us draw a picture to illustrate the approximation. (We can use theincluded function polyval) 12345678910111213141516171819202122232425262728293031323334353637383940414243% 6. 最小二乘法计算拟合多项式系数% Polynomial curve fitting% 返回 p 向量保存多项式系数，由最高次向最低次排列function p = lsmapprox(x, y, n)arguments % x，y为拟合数据向量 x y % 拟合多项式次数 % 如 1 为 一次函数 n (1,1)end if ~isequal(size(x), size(y)) error(&quot;x, y require the same dimensionality&quot;) end % 但实际上我们需要的是列向量 x = x(:); y = y(:); % 使用一维向量 x 构造具有 n + 1 列 和 m = length(x) 行 的 % 范德蒙（Vandermonde）矩阵 V = [x^n ... x^2 x ones(size(x))] % p(x) = p1·x^n + p2·x^(n-1) + ... pn·x + pn + 1 V(:, n + 1) = ones(length(x), 1, class(x)); for j = n:-1:1 % TIMES (.*) 执行按元素相乘 V(:, j) = x .* V(:, j + 1); end % 然后我们把 V 进行 QR 分解，然后再使用 \\ 除法进行求解，随后得到多项式系数p [Q, R] = qr(V, 0); % p = V\\y p = R \\ (Q' * y); % 返回行向量 p = p'; % 绘图 y1 = polyval(p, x); plot(x, y, 'o', x, y1, '-')end 广义逆矩阵Write an m-file to find the generalised inverse of a given matrix.The name of file: geninv Input argument: the matrix (A). Output argument: The generalised inverse (A+) Use the rank factorisation if the matrix is not fullranked. For the matrixoperations we can use the included functions of Matlab (eg.: rank, inv,instead of solving LES we can use the command G=F\\A, etc.) 123456789101112131415161718192021% 6. 求矩阵的广义逆矩阵% 当 A 不是 fullranked （列满秩）的时候，逆不唯一% A ∈ C^(m * n) 若存在 C 满足 AXA = A XAX = X 则 X 是 A 的广义逆矩阵function APlus = geninv(A) r = rank(A); % 如果 A 不是 fullranked，则使用 秩分解 % rank factorization 来计算GINV if r == size(A, 1) % Moore-Penrose 伪逆 APlus = pinv(A); else % A = U * S * V' % 奇异值分解得到的矩阵 U、奇异值矩阵 S 和 V 的转置矩阵 [U,S,V] = svd(A); SPlus = zeros(size(A)); % 将 S 的逆矩阵插入到秩分解中 SPlus(1:r, 1:r) = inv(S(1:r, 1:r)); APlus = V * SPlus * U'; endend","link":"/Math/Matlab/Numerical-Methods-II/"},{"title":"OpenStack 学习日记 第二天","text":"Cinder操作系统挂载储存空间的方法有： Block Storage 块储存：通过本地协议（SCSI、SAS）等挂载裸磁盘，每个磁盘叫做 Volume 卷 文件系统储存：通过网络协议（NFS、CIFS）等挂载远程文件系统，分布式就是这种 Block Storage Service 提供对 volume 从创建到删除整个生命周期的管理从 instance 的角度看，挂载的每一个 Volume 都是一块硬盘 Cinder： 提供 REST API 使用户能够查询和管理 volume、volume snapshot 以及 volume type 提供 scheduler 调度 volume 创建请求，合理优化存储资源的分配 通过 driver 架构支持多种 back-end（后端）存储方式，包括 LVM，NFS，Ceph 和其他诸如 EMC、IBM 等商业存储产品和方案 组件 cinder-api接收 API 请求，调用 cinder-volume 执行操作 cinder-volume管理 volume 的服务，与 volume provider 协调工作，管理 volume 的生命周期运行 cinder-volume 服务的节点被称作为存储节点，LVM 是默认的 provider cinder-schedulerscheduler 通过调度算法选择最合适的存储节点创建 volume volume provider数据的存储设备，为 volume 提供物理存储空间支持多种 volume provider，每种 provider 通过自己的 driver 与 cinder-volume 协调工作 Message QueueCinder 各个子服务通过消息队列实现进程间通信和相互协作因为有了消息队列，子服务之间实现了解耦，这种松散的结构也是分布式系统的重要特征 Database数据库是安装在控制节点上的 其他 理解 Cinder 架构 – 每天 5 分钟玩转 OpenStack（45） 主要还是在讲传统分布式设计 掌握 Cinder 的设计思想 – 每天 5 分钟玩转 OpenStack（46） cinder-api 是整个 Cinder 组件的门户，所有 cinder 的请求都首先由 nova-api 处理 cinder-volume 在存储节点上运行，OpenStack 对 Volume 的操作，最后都是交给 cinder-volume 来完成的cinder-volume 自身并不管理真正的存储设备，存储设备是由 volume provider 管理的。cinder-volume 与 volume provider 一起实现 volume 生命周期的管理 Cinder 组件详解 – 每天 5 分钟玩转 OpenStack（47） 调度器Filter scheduler 是 cinder-scheduler 默认的调度器 AvailabilityZoneFilter为提高容灾性和提供隔离服务，可以将存储节点和计算节点划分到不同的 Availability Zone 中 CapacityFilter将存储空间不能满足 Volume 创建需求的存储节点过滤掉 CapabilitiesFilter不同的 Volume Provider 有自己的特性（Capabilities），比如是否支持 thin provision 等Cinder 允许用户创建 Volume 时通过 Volume Type 指定需要的 Capabilities Weighter通过 scheduler_default_weighers 指定计算权重的 weigher，默认为 CapacityWeigherCapacityWeigher 基于存储节点的空闲容量计算权重值，空闲容量最大的胜出 掌握 cinder-scheduler 调度逻辑 – 每天 5 分钟玩转 OpenStack（48） 操作 准备 LVM Volume Provider – 每天 5 分钟玩转 OpenStack（49） Create Volume 操作（Part I） – 每天 5 分钟玩转 OpenStack（50） Create Volume 操作（Part II） – 每天 5 分钟玩转 OpenStack（51） Create Volume 操作（Part III） – 每天 5 分钟玩转 OpenStack（52） Attach Volume 操作（Part I） – 每天 5 分钟玩转 OpenStack（53） Attach Volume 操作（Part II） – 每天 5 分钟玩转 OpenStack（54） Detach Volume 操作 – 每天 5 分钟玩转 OpenStack（55） Extend Volume 操作 – 每天 5 分钟玩转 OpenStack（56） Delete Volume 操作 – 每天 5 分钟玩转 OpenStack（57） Snapshot Volume 操作 – 每天 5 分钟玩转 OpenStack（58） Backup Volume 操作 – 每天 5 分钟玩转 OpenStack（59） Restore Volume 操作 – 每天 5 分钟玩转 OpenStack（60） Boot From Volume – 每天 5 分钟玩转 OpenStack（61） NFS NFS Volume Provider（Part I） – 每天 5 分钟玩转 OpenStack（62） NFS Volume Provider（Part II） – 每天 5 分钟玩转 OpenStack（63） NFS Volume Provider（Part III） – 每天 5 分钟玩转 OpenStack（64） Neutron“软件定义网络（software-defined networking, SDN）”所具有的灵活性和自动化优势 Neutron 的设计目标是实现“网络即服务（Networking as a Service）”在设计上遵循了基于 SDN 实现网络虚拟化的原则，在实现上充分利用了 Linux 系统上的各种网络相关的技术 Neutron 为整个 OpenStack 环境提供网络支持，包括二层交换，三层路由，负载均衡，防火墙和 VPN 等 二层交换 SwitchingNova 的 Instance 是通过虚拟交换机连接到虚拟二层网络的Neutron 支持多种虚拟交换机，包括 Linux 原生的 Linux Bridge 和 Open vSwitchNeutron 除了可以创建传统的 VLAN 网络，还可以创建基于隧道技术的 Overlay 网络，比如 VxLAN 和 GRE 三层路由 RoutingNeutron 支持多种路由，包括 Linux 原生的 Linux Bridge 和 Open vSwitchInstance 可以配置不同网段的 IP，Neutron 的 router（虚拟路由器）实现 instance 跨网段通信router 通过 IP forwarding，iptables 等技术来实现路由和 NAT 负载均衡 Load BalancingLoad-Balancing-as-a-Service（LBaaS）支持多种负载均衡产品和方案，不同的实现以 Plugin 的形式集成到 Neutron，目前默认的 Plugin 是 HAProxy。 防火墙 FirewallingSecurity Group：通过 iptables 限制进出 instance 的网络包FWaaS：限制进出虚拟路由器的网络包，也是通过 iptables 实现 Neutron 功能概述 – 每天 5 分钟玩转 OpenStack（65） 概念Neutron 支持多种类型的 network，包括 local, flat, VLAN, VxLAN 和 GRE。 locallocal 网络与其他网络和节点隔离。local 网络中的 instance 只能与位于同一节点上同一网络的 instance 通信，local 网络主要用于单机测试 flatflat 网络是无 vlan tagging 的网络。flat 网络中的 instance 能与位于同一网络的 instance 通信，并且可以跨多个节点。 vlanvlan 网络是具有 802.1q tagging 的网络。vlan 是一个二层的广播域，同一 vlan 中的 instance 可以通信，不同 vlan 只能通过 router 通信。vlan 网络可以跨节点，是应用最广泛的网络类型 vxlanvxlan 是基于隧道技术的 overlay 网络。vxlan 网络通过唯一的 segmentation ID（也叫 VNI）与其他 vxlan 网络区分vxlan 中数据包会通过 VNI 封装成 UDP 包进行传输因为二层的包通过封装在三层传输，能够克服 vlan 和物理网络基础设施的限制 gregre 是与 vxlan 类似的一种 overlay 网络。主要区别在于使用 IP 包而非 UDP 进行封装 Neutron 网络基本概念 – 每天 5 分钟玩转 OpenStack（66） 组件 Neutron Server对外提供 OpenStack 网络 API，接收请求，并调用 Plugin 处理请求。 Plugin处理 Neutron Server 发来的请求，维护 OpenStack 逻辑网络的状态， 并调用 Agent 处理请求。 Agent处理 Plugin 的请求，负责在 network provider 上真正实现各种网络功能。 network provider提供网络服务的虚拟或物理网络设备，例如 Linux Bridge，Open vSwitch 或者其他支持 Neutron 的物理交换机。 QueueNeutron Server，Plugin 和 Agent 之间通过 Messaging Queue 通信和调用。 Database存放 OpenStack 的网络状态信息，包括 Network, Subnet, Port, Router 等。 Neutron 架构 – 每天 5 分钟玩转 OpenStack（67） 部署 方案 1：控制节点 + 计算节点控制节点：部署的服务包括：neutron server, core plugin 的 agent 和 service plugin 的 agent计算节点：部署 core plugin 的 agent，负责提供二层网络功能。 方案 2：控制节点 + 网络节点 + 计算节点控制节点：部署 neutron server 服务网络节点：部署的服务包括：core plugin 的 agent 和 service plugin 的 agent计算节点：部署 core plugin 的 agent，负责提供二层网络功能。 Neutron 物理部署方案 – 每天 5 分钟玩转 OpenStack（68） 结构 Core API对外提供管理 network, subnet 和 port 的 RESTful API。 Extension API对外提供管理 router, load balance, firewall 等资源 的 RESTful API。 Commnon Service认证和校验 API 请求。 Neutron CoreNeutron server 的核心处理程序，通过调用相应的 Plugin 处理请求。 Core Plugin API定义了 Core Plgin 的抽象功能集合，Neutron Core 通过该 API 调用相应的 Core Plgin。 Extension Plugin API定义了 Service Plgin 的抽象功能集合，Neutron Core 通过该 API 调用相应的 Service Plgin。 Core Plugin实现了 Core Plugin API，在数据库中维护 network, subnet 和 port 的状态，并负责调用相应的 agent 在 network provider 上执行相关操作，比如创建 network。 Service Plugin实现了 Extension Plugin API，在数据库中维护 router, load balance, security group 等资源的状态，并负责调用相应的 agent 在 network provider 上执行相关操作，比如创建 router。 理解 Neutron Server 分层模型 – 每天 5 分钟玩转 OpenStack（69） Neutron 如何支持多种 network provider – 每天 5 分钟玩转 OpenStack（70） ML2Moduler Layer 2（ML2）是 Neutron 在 Havana 版本实现的一个新的 core plugin，用于替代原有的 linux bridge plugin 和 open vswitch plugin 传统 core plugin 存在两个突出的问题: 无法同时使用多种 network provider 开发新的 core plugin 工作量大 详解 ML2 Core Plugin（I） – 每天 5 分钟玩转 OpenStack（71） ML2 对二层网络进行抽象和建模，引入了 type driver 和 mechanism driver这两类 driver 解耦了 Neutron 所支持的网络类型（type）与访问这些网络类型的机制（mechanism）其结果就是使得 ML2 具有非常好的弹性，易于扩展，能够灵活支持多种 type 和 mechanism。 Type DriverNeutron 支持的每一种网络类型都有一个对应的 ML2 type driver。type driver 负责维护网络类型的状态，执行验证，创建网络等。ML2 支持的网络类型包括 local, flat, vlan, vxlan 和 gre Mechanism DriverNeutron 支持的每一种网络机制都有一个对应的 ML2 mechanism driver mechanism driver 负责获取由 type driver 维护的网络状态，并确保在相应的网络设备（物理或虚拟）上正确实现这些状态 mechanism driver 有三种类型 Agent-based包括 linux bridge, open vswitch 等 Controller-based包括 OpenDaylight, VMWare NSX 等 基于物理交换机包括 Cisco Nexus, Arista, Mellanox 等 详解 ML2 Core Plugin（II） – 每天 5 分钟玩转 OpenStack（72） Service PluginCore Plugin/Agent 负责管理核心实体：net, subnet 和 port而对于更高级的网络服务，则由 Service Plugin/Agent 管理Service Plugin 及其 Agent 提供更丰富的扩展功能，包括路由，load balance，firewall 等 DHCPdhcp agent 通过 dnsmasq 为 instance 提供 dhcp 服务 Routingl3 agent 可以为 project（租户）创建 router，提供 Neutron subnet 之间的路由服务路由功能默认通过 IPtables 实现 Firewalll3 agent 可以在 router 上配置防火墙策略，提供网络安全防护另一个与安全相关的功能是 Security Group，也是通过 IPtables 实现Firewall 安全策略位于 router，保护的是某个 project 的所有 networkSecurity Group 安全策略位于 instance，保护的是单个 instance Load BalanceNeutron 默认通过 HAProxy 为 project 中的多个 instance 提供 load balance 服务 Service Plugin / Agent – 每天 5 分钟玩转 OpenStack（73） 两张图总结 Neutron 架构 – 每天 5 分钟玩转 OpenStack（74） 为 Neutron 准备物理基础设施（I） – 每天 5 分钟玩转 OpenStack（75） 为 Neutron 准备物理基础设施（II） – 每天 5 分钟玩转 OpenStack（76）","link":"/Cloud/OpenStack/OpenStack-%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0-%E7%AC%AC%E4%BA%8C%E5%A4%A9/"},{"title":"Stable Marriage Problem","text":"研究生学习开始啦 本文是 Design and Analysis of Algorithms 的一部分 这节课介绍了一些著名的问题解决方案及其典型算法，并且还有它们的实践内容 Problem Description 有 n 个男人和 n 个女人 每个人都有一个 preference list，即对另一性别的人的偏好排序 问题：如何匹配男女，使得每个人都能得到满意的匹配？(稳定) 稳定：不存在一对男女，他们之间相互更喜欢。换言之，不存在一对男人和女人，他们都更喜欢对方而不是他们当前的配偶。 如果存在一对男女，他们不是当前匹配中的伴侣，但相互之间都优先于他们各自的伴侣则称其为 rogue / vogue couple / 阻碍对 (为什么要叫这个名) 存在 rogue couple 的匹配是不稳定的，因为这对男女都有动机离开他们当前的伴侣而彼此匹配 如果我们允许同性恋，那么这个问题就是 Stable Roommates Problem，在这种情况下 没有 稳定匹配 Unisex Case让我们来看一个不可能进行稳定匹配的例子，它需要与第四个人创造一个三角恋 A -&gt; B / D / CB -&gt; D / A / CC -&gt; N/AD -&gt; A / B / C C 的喜好无关紧要，因为 C 是每个人的最后选择 Proof让我们假设存在稳定匹配： 有 [A, D] 那么另一对必然是 [B, C] 但是 A 相比 D 更喜欢 B，B 相比 C 更喜欢 A 所以 [A, B] 应该是一对 那么 [C, D] 就是另一对 但是 B 相比 A 更喜欢 D，D 相比 C 更喜欢 B …… 无限循环 所以不存在稳定匹配 但是在 bipartite graph (二分图) 中，我们一定可以找到稳定匹配 这类问题无法使用 greedy 或者 induction (or recursion) 算法解决，所以我们需要 Gale-Shapley Algorithm也叫 Deferred Acceptance 算法 Steps 每个男人都向他的首选求婚 每个女人都暂时选择她当前最喜欢的求婚者，拒绝其他人 每个被拒绝的男人向他的下一个选择求婚 重复步骤 2 和 3，直到每个女人都接受了一个求婚者 我们将每一轮定义为一天女人在每一轮接受的求婚都是临时的，这就是为什么此算法又叫 Deferred Acceptance 延迟接受 的原因。 Theorem 1: 在 $n^2 + 1$ 天内结束反证让我们来看看算法还未终止时必须发生的一件事情：某个男孩从他的名单上划掉一个女孩 为什么？因为算法如果没有终止，那么某个女孩至少有两位追求者那至少有一个人会被拒绝，则他会把她划掉 因此，如果算法没有在 $n^2 + 1$ 次内终止，那么总共会有 $n^2 + 1$ 次划掉但是，每个人最多只能划掉 n 次，所以最多可以有 $n^2$ 次划掉我们有了矛盾。最后一天只有接受，没有拒绝 $n^2 + 1$ 并不是算法的最坏情况，所以让我们来计算 最坏 $(n - 1)^2 + 1$让我们来举一个最坏的情况：每个男孩都会被拒绝 n - 1 次总不能被拒绝 n 次吧，那不是就没人要了 总求婚数 = 总拒绝数 + 总接受数则$$ 总求婚数_{直到第 n - 1 天} = 男孩的数量 \\times 每个男孩的求婚数 = n \\times (n - 1) $$得到$$ 总求婚数 = n \\times (n - 1) + 1 = n^2 - n + 1 $$ 在第一天，每个男人都会求婚，则进行了 n 次求婚随后的每一天，都只会有 一个 男人求婚（这也是为什么总求婚数可以计算总天数的原因） 所以我们可以据此求出总天数：$$ 总天数 = 总求婚数 - 第一天求婚的次数 + 第一天 = [n^2 - n + 1] - n + 1 = n^2 - 2n + 2 $$ 所以，在最坏的情况下，$\\Omega (n^2)$ 天内中止（算法所需的时间至少与参与者数量的平方成正比） 大 $O$ 记号提供了一个上界，表示运行时间的增长速率不会快于某个特定的函数大 $\\Omega$ 记号提供了一个下界，表示运行时间的增长速率至少是某个特定函数 Lemmas 当男孩结婚时，他已经遍历了所有更喜欢的女孩 如果一个男孩到头来也没结婚，那么他一定遍历过了所有女孩 每个女孩都会嫁给 追求过 她的男孩中最喜欢的那个 如果一个女孩被追求过，那么她一定会结婚 Theorem 2: 在算法中，每个人都会结婚在有以上 Lemmas 后，我们可以反证这个定理 假设一个男孩 B 没有结婚 但是在 L2 中说明了他遍历了所有女孩 但是根据 L4，每个女孩都会结婚 由于男孩的数量等于女孩的数量 因此每个人都会结婚 Theorem 3: 算法总是产生稳定匹配为了自相矛盾，假设有一对 rogue [B, G]运行算法，有 [B, G1] 和 [B1, G] 如果 [B, G1]，但是 B 更喜欢 G则根据 L1，B 一定追求过 G，G 拒绝了 但根据 L3，G 一定接受了比 B 更好的男孩所以 G 比 B 更喜欢 B1意味着 [B, G] 不是 rogue couple （我怎么看不懂呢，这个 不是 到底是怎么推出来的） Theorem 4 / 5: 算法会产生 求婚 / 被求婚 方的 最佳 / 悲观 匹配定义： 最佳伴侣是他 / 她从可能的伴侣中最喜欢的 悲观伴侣是他 / 她从可能的伴侣中最不喜欢的 Boy optimal / Girl optimal 男性主动求婚，女性被动选择，持续优化直至男性满足，导致女性最坏结果 Uniqueness：如果两种情况下算法得到相同的匹配结果，那么这个结果就是唯一的稳定匹配 Max Magnitude $\\theta (2^n)$习题证明题Suppose there are $n$ boys and $n$ girls. $m$ boys are tall and the same number of girls are blonde.Boys prefer blonde girls to non-blonde girls.Girls prefer tall boys to non-tall boys. 金发配高个Show that in every stable match, blonde girls are paired with tall boys. 这题是在说有一些高个男生和一些金发女生，男生更喜欢金发女生，女生更喜欢高个男生要证明在每一个稳定匹配中，金发女生都会和高个男生配对 要证明，我们假设矛盾：存在一个稳定组合 $(b, g)$ 有 $b$ 是高个男生, $g$ 不是金发女生 或者 $b$ 不是高个男生, $g$ 是金发女生 1 和 2 是对称的，所以我们分析 1，同理可得 2 令高个的反义为矮个，金发的反义为黑发 既然有 高个配黑发，由于男女人数相同，那么一定有一个 $(b’, g’)$ 是矮个配金发 我们发现 $g’$ 更喜欢 $b$，因为 $g’$ 更喜欢高个所以 $(b, g’)$ 是 rogue couple，这就与题目中的稳定匹配矛盾了 证明思路：假设初始匹配稳定，随后找出 rogue couple，导致违反稳定匹配的条件 相同偏好If all the girls have the same preference list, then there is only one stable pairing. 要证明只存在一种稳定匹配，我们就假设有 A / B 两种稳定匹配 A 有 $(g, b)$，而在 B 中有 $(g, b’)$同一个女生出现在不同的匹配中 由于所有女生偏好相同，则在任何稳定匹配中，将完全由男生的优先级决定，无论 g 与谁匹配，其他女生的相对偏好不变 由于同一个女生出现在了不同的匹配中，这意味着至少在某个匹配中，她得到了相对于另一个匹配更 高 / 低 优先级的男生 因为如果 $g$ 在 B 中能与 $b’$ 匹配，那么在 A 中与 $b$ 匹配的的其他女生将偏好 $b’$这就导致了 rogue couple，违反了稳定匹配的条件 最优解There is no pairing, stable or unstable, in which all the boys are better off than when the Gale-Shapley algorithm is used. 这题意思就是证明 GS 算法是最优解（而且是 boy optimal） 假设存在一个配对，在这个配对中所有的男孩比使用 GS 算法时更满意这意味着每个男孩都与他的偏好列表中更高位的女孩配对了 然而，根据 GS 算法的性质，算法结束时每个男性都无法与他偏好列表中更高位的女性配对因为这样的女性要么与他们自己的偏好列表中更高位的男性配对，要么在追求过程中拒绝了这些男性 因此，如果所有男性在某个配对中都比 GS 算法的结果更满意那么这意味着至少有一个男性与他的偏好列表中的一个女性配对而该女性在 GS 算法中拒绝了他 如果所有男孩在某个配对中都比 GS 算法的结果更满意那么至少会有一对男女是不稳定的，因为至少有一个女孩可以与她更偏好的男孩配对所以不存在这样的匹配，因为它会违反 GS 算法的稳定匹配性质 匹配题 Boy b1 g1 g4 g3 g2 g5 b2 g3 g1 g4 g2 g5 b3 g4 g3 g5 g1 g2 b4 g1 g5 g2 g4 g3 b5 g4 g1 g5 g3 g2 Girl g1 b4 b2 b1 b5 b3 g2 b4 b1 b3 b2 b5 g3 b4 b3 b1 b2 b5 g4 b1 b3 b4 b2 b5 g5 b2 b3 b5 b1 b4 Day g1 g2 g3 g4 g5 1 b1, b4 - b2 b3, b5 - 2 b4, b5 - b2 b3, b1 - 3 b4 - b2, b3 b1 b5 4 b4, b2 - b3 b1 b5 5 b4 - b3 b1, b2 b5 6 b4 b2 b3 b1 b5 (g1, b4), (g2, b2), (g3, b3), (g4, b1), (g5, b5)","link":"/Algorithm/Stable-Marriage-Problem/"},{"title":"Turing Machines","text":"自动寄 删除 010创建一个图灵机，它复制二进制输入到输出，并删除所有的 010 States Start End Tape Head Position Start Start Stop A0 0 A B0 0 B Copy Stop 1234567891011121314151617181920212223// 处理 0 开头，转到 A[Start; 0; SP]-&gt;[A; ANY; ANY; &gt;; S]// 处理 1 开头，直接复制[Start; 1; SP]-&gt;[Start; ANY; 1; &gt;; &gt;]// 为空，结束[Start; SP; SP]-&gt;[Stop; ANY; ANY; S; S]// 在 0 1 _ 时，转 B[A; 1; SP]-&gt;[B; ANY; ANY; &gt;; S]// 在 0 0 _ 时，写入 0，转 Start[A; 0; SP]-&gt;[Start; ANY; 0; S; &gt;]// 在 0 0 S 时，写入 0，结束[A; SP; SP]-&gt;[Stop; ANY; 0; S; &gt;]// 在 0 1 0 时，略过，回到 Start[B; 0; SP]-&gt;[Start; ANY; ANY; &gt;; S]// 在 0 1 1 时，将 0 复制，转 Copy 1[B; 1; SP]-&gt;[Copy; ANY; 0; S; &gt;]// 在 0 1 S 时，将 0 复制，转 Copy 1[B; SP; SP]-&gt;[Copy; ANY; 0; S; &gt;]// Copy 1[Copy; ANY; SP]-&gt;[Start; ANY; 1; S; &gt;] 把 00 变成 ##但是不处理超过 2 个 0 的情况 States Start End Tape Head Position Start Start Stop A0 0 Zero1 Zero2 FindOne Trans Trans2 Stop 1234567891011121314151617181920212223242526272829303132// 0 _ 转 Zero1[Start; 0]-&gt;[Zero1; 0; &gt;]// 1 _ 回到开始[Start; 1]-&gt;[Start; 1; &gt;]// 为空，结束[Start; SP]-&gt;[Stop; SP; S]// 0 0 _ 继续计数[Zero1; 0]-&gt;[Zero2; 0; &gt;]// 0 1 _ 回到开始[Zero1; 1]-&gt;[Start; 1; &gt;]// 0 S 结束[Zero1; SP]-&gt;[Stop; SP; S]// 0 0 0 不处理[Zero2; 0]-&gt;[FindOne; 0; &gt;]// 0 0 1 变换前两个为 #[Zero2; 1]-&gt;[Trans; 1; 2*&lt;]// 0 0 S 变换前两个为 #[Zero2; SP]-&gt;[Trans; SP; 2*&lt;]// 第一次写入[Trans; 0]-&gt;[Trans2; #; &gt;]// 第二次写入[Trans2; 0]-&gt;[Start; #; &gt;]// 找到下一个 1[FindOne; 1]-&gt;[Start; 1; &gt;]// 仍然是 0[FindOne; 0]-&gt;[FindOne; 0; &gt;]// 结束[FindOne; SP]-&gt;[Stop; SP; S] 011 变 ABCD States Start End Tape Head Position Start Start Stop A0 0 Zero B0 0 One Copy BCD CD D Stop 1234567891011121314151617181920212223242526272829303132// 0 _ 计数[Start; 0; SP]-&gt;[Zero; 0; SP; &gt;; S]// 1 _ 复制[Start; 1; SP]-&gt;[Start; 1; 1; &gt;; &gt;]// 为空，结束[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 0 1 _ 计数[Zero; 1; SP]-&gt;[One; 1; SP; &gt;; S]// 0 0 _ 复制 0，回到开始[Zero; 0; SP]-&gt;[Start; 0; 0; S; &gt;]// 0 S 复制 0，停止[Zero; SP; SP]-&gt;[Stop; SP; 0; S; &gt;]// 0 1 1 变换，写入 A[One; 1; SP]-&gt;[BCD; 1; A; S; &gt;]// 0 1 0 复制 0，转 Copy 1[One; 0; SP]-&gt;[Copy; 0; 0; &lt;; &gt;]// 0 1 S 复制 0，转 Copy 1[One; SP; SP]-&gt;[Copy; SP; 0; &lt;; &gt;]// 写入 B[BCD; ANY; SP]-&gt;[CD; ANY; B; S; &gt;]// 写入 C[CD; ANY; SP]-&gt;[D; ANY; C; S; &gt;]// 写入 D，回到开始[D; ANY; SP]-&gt;[Start; ANY; D; &gt;; &gt;]// Copy 0[Copy; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// Copy 1[Copy; 1; SP]-&gt;[Start; 1; 1; &gt;; &gt;] 多个 1 变一个 1 States Start End Tape Head Position Start Start Stop A0 0 One B0 0 Stop 12345678910111213// 0 复制[Start; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 复制并计数[Start; 1; SP]-&gt;[One; 1; 1; &gt;; &gt;]// 为空，停止[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 1 0 复制，回到开始[One; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 1 找到下一个 0[One; 1; SP]-&gt;[One; 1; ANY; &gt;; S]// 1 S 停止[One; SP; SP]-&gt;[Stop; SP; SP; S; S] 11 变 112 States Start End Tape Head Position Start Start Stop A0 0 One B0 0 Two Stop 12345678910111213141516// 0 复制[Start; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 复制并计数[Start; 1; SP]-&gt;[One; 1; 1; &gt;; &gt;]// 为空，停止[Start; SP; SP]-&gt;[Stop; SP; SP; S; S]// 1 1 添加 2[One; 1; SP]-&gt;[Two; 1; 1; S; &gt;]// 1 0 复制并回到开始[One; 0; SP]-&gt;[Start; 0; 0; &gt;; &gt;]// 1 S 停止[One; SP; SP]-&gt;[Stop; SP; SP; S; S]// +2s[Two; ANY; SP]-&gt;[Start; ANY; 2; &gt;; &gt;] 0000… 变 4444… States Start End Tape Head Position Start Start Stop A0 0 One Two Three Trans Stop 1234567891011121314151617181920212223242526272829303132// 0，计数[Start; 0]-&gt;[One; 0; &gt;]// 1，跳过[Start; 1]-&gt;[Start; 1; &gt;]// 为空，停止[Start; SP]-&gt;[Stop; SP; S]// 0 0[One; 0]-&gt;[Two; 0; &gt;]// 0 1 回[One; 1]-&gt;[Start; 1; &gt;]// 0 S 停止[One; SP]-&gt;[Stop; SP; S]// 0 0 0[Two; 0]-&gt;[Three; 0; &gt;]// 0 0 1[Two; 1]-&gt;[Start; 1; &gt;]// 0 0 S 停止[Two; SP]-&gt;[Stop; SP; S]// 0 0 0 0，转换[Three; 0]-&gt;[Trans; 4; 3*&lt;]// 0 0 0 1 回[Three; 1]-&gt;[Start; 1; &gt;]// 0 0 0 S 停止[Three; SP]-&gt;[Stop; SP; S]// 4 0 0 4[Trans; 0]-&gt;[Trans; 4; &gt;]// Stop Trans[Trans; 4]-&gt;[Start; ANY; &gt;] 二进制乘 3 States Start End Tape Head Position Start Start Stop A0 0 X Non Carry Stop 1234567891011121314151617181920212223// 在结果最前加一个 0[Start; 0; SP]-&gt;[X; 0; 0; S; &gt;][Start; 1; SP]-&gt;[X; 1; 0; S; &gt;]// 复制[X; 0; SP]-&gt;[X; 0; 0; &gt;; &gt;][X; 1; SP]-&gt;[X; 1; 1; &gt;; &gt;]// 在输入最后加一个 0[X; SP; SP]-&gt;[Non; 0; SP; S; &lt;]// 不进位[Non; 0; 0]-&gt;[Non; 0; 0; &lt;; &lt;][Non; 0; 1]-&gt;[Non; 0; 1; &lt;; &lt;][Non; 1; 0]-&gt;[Non; 1; 1; &lt;; &lt;][Non; 1; 1]-&gt;[Carry; 1; 0; &lt;; &lt;][Non; SP; SP]-&gt;[Stop; SP; SP; S; S]// 进位[Carry; 0; 0]-&gt;[Non; 0; 1; &lt;; &lt;][Carry; 0; 1]-&gt;[Carry; 0; 0; &lt;; &lt;][Carry; 1; 0]-&gt;[Carry; 1; 0; &lt;; &lt;][Carry; 1; 1]-&gt;[Carry; 1; 1; &lt;; &lt;][Carry; SP; SP]-&gt;[Stop; SP; 1; S; S]","link":"/Algorithm/TM/Turing-Machines/"},{"title":"分而治之","text":"本文是 Design and Analysis of Algorithms 的一部分 每天大清早是真的起不来床这课的 Kahoot 我是一分也没拿到 Inversion Count定义给定一个数组 $A$，如果 $i &lt; j$ 且 $A[i] &gt; A[j]$，则称 $(i, j)$ 是 $A$ 的一个逆序对 也就是说，某个前面的元素比后面的元素大，这样的对数就是逆序对 如有 arr[] = [8, 4 ,2, 1]则逆序对为 (8, 4), (8, 2), (8, 1), (4, 2), (4, 1), (2, 1)共 6 对 简单解法 遍历数组 对于元素 $A[i]$，遍历 $A[i+1:]$，统计比 $A[i]$ 小的元素个数 累加 123456789101112const arr = [8, 4, 2, 1];let count = 0;for (let i = 0; i &lt; arr.length; i++) { for (let j = i + 1; j &lt; arr.length; j++) { if (arr[i] &gt; arr[j]) { count++; } }}console.log(count); // 6 $O(n^2)$ Merge Sort首先复习一下 归并排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051MergeSortInversion(A, low, high) { if (low &lt; high) { mid := (low + high) / 2 leftCount := MergeSortInversion(A, low, mid) rightCount := MergeSortInversion(A, mid + 1, high) mergeCount := Merge(A, low, mid, high) return leftCount + rightCount + mergeCount }}Merge(A, low, mid, high) { leftIndex := low rightIndex := mid + 1 arrayIndex := low inversionCount := 0 tempArray := [] while (leftIndex &lt;= mid &amp;&amp; rightIndex &lt;= high) { if (A[leftIndex] &lt;= A[rightIndex]) { tempArray[arrayIndex] = A[leftIndex] leftIndex++ } else { tempArray[arrayIndex] = A[rightIndex] rightIndex++ inversionCount += mid - leftIndex + 1 } arrayIndex++ } while (leftIndex &lt;= mid) { tempArray[arrayIndex] = A[leftIndex] leftIndex++ arrayIndex++ } while (rightIndex &lt;= high) { tempArray[arrayIndex] = A[rightIndex] rightIndex++ arrayIndex++ } for (i := low; i &lt;= high; i++) { A[i] = tempArray[i] } return inversionCount} 时间复杂度为 $O(n \\log{n})$ Max Increasing给定一个数组 $A$，找到一对 $(i, j)$ 有 $1 \\leq i \\leq j \\leq n$ 使得 $A[j] - A[i]$ 最大 通常找最大差值的问题使用 $O(n)$ 的算法解决，不过这里要求分治法所以 123456789101112131415FindMaxDiff(A, low = 0, high = len(A) - 1) { if (low &gt;= high) return 0 mid := (low + high) / 2 leftMaxDiff := FindMaxDiff(A, low, mid) rightMaxDiff := FindMaxDiff(A, mid + 1, high) leftMin := FindMin(A, low, mid) rightMax := FindMax(A, mid + 1, high) crossMaxDiff := rightMax - leftMin return Math.max(leftMaxDiff, rightMaxDiff, crossMaxDiff)} 第 $k$ 大Given different real numbers an array A[1:n] and an integer $1 \\leq k \\leq n$.Let’s determine the $k$-th biggest element of the array.The cost of the procedure should be $O(n \\log{n})$. 快速选择其实就是快排中轴值计算的过程，时间复杂度为 $O(n)$ 123456789101112131415161718192021222324252627282930QuickSelect(A, low = 1, high = n, k) { if (low = high) return A[low] pivotIndex := Partition(A, low, high) position := pivotIndex - low + 1 if (k = position) return A[pivotIndex] else if (position &gt; k) return QuickSelect(A, low, pivotIndex - 1, k) else return QuickSelect(A, pivotIndex + 1, high, k - position)}Partition(A, low, high) { pivot := A[high] i := low - 1 for (j := low; j &lt; high; j++) { if (A[j] &lt;= pivot) { i++ Swap(A[i], A[j]) } } Swap(A[i + 1], A[high]) return i + 1} 但其实如果要达到 $\\theta(n \\log{n})$ 的话直接快速排序然后取第 $k$ 个元素就好了","link":"/Algorithm/%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B/"},{"title":"匈牙利留学攻略2024","text":"有个朋友要我帮他做做攻略，现在发出来造福大家，希望对你也能有所帮助。本文以随笔的形式写成，如有错误纰漏请指正。 关于生活去匈牙利留学是一个不错的选择。这个国家有着非常辉煌的过去，很多目前位于匈牙利的学校，以前都位于目前来说的其他国家，因为曾经那些地方都属于匈牙利的领土。生活成本与成都市中心持平，房租较贵，如果住学校学生宿舍或者专门为学生提供的第三方宿舍，则与成都持平，不建议住在郊区，稍微住的远一点可以，但是远一点房租也不会便宜多少。 匈牙利的公共交通系统较为发达，全欧洲第一条地铁就位于布达佩斯，每个大城市都有夜间班车，所以打车是不必要的，而且间隔时间也跟国内差不多，不会出现德国那种在工作时间一辆公交车也得等半小时的情况。火车线路九成都是国营，覆盖了几乎全匈牙利，虽然开得慢，但好在票价不贵，购买匈牙利通票即可无限次乘坐公共交通，骨折价乘坐火车。不要逃票，真的会罚款，查的很严。 欧洲的肉比国内便宜，但是蔬菜很贵，种类很少，去欧洲任意国家留学都要求做饭技能，因为下馆子是国内的两到三倍价格，高档餐厅一份牛排能买到一千人民币。中餐好吃的不多，合口味的不多，贵的倒是一抓一大把还不好吃，但是种类齐全，烧烤火锅炸鸡奶茶之类的全部都有，也有很大的亚洲超市，所以生活质量取决于钱包厚度。 匈牙利人吃的喝的都没有什么奇怪的东西，而且它们也是黄种人，对中国人没有什么偏见，它们是整个欧洲唯一一个和我们一样姓在前，名在后的国家，跟中国与俄罗斯的关系不错，但是它是北约国家，政府在整个欧盟内都属于比较会找茬的。它们也有很多在野党，但是执政党就一个，所以相对来说很稳定，并且匈牙利不收难民，所以在火车上你可以睡觉。 在匈牙利我基本没用过现金，它们用它们自己的货币，福林，欧元并不在匈牙利广泛流通。随身携带银行卡和现金不是必要的，NFC 刷手机几乎都能用，有些小店只收现金，但是你大可以换个地方消费。欧洲的税赋很高，收入乱七八糟加起来基本上交国家一半，匈牙利有电子产品 27%的税，所以在国内买好了电子产品再带去。 在匈牙利生病了，如果有医保或者商业保险基本就不用担心价格问题。但如果没有，如果不是要死的病，往返一趟国内机票也没多少钱。匈牙利有中医，还不少。私立医院较多，服务好但是很贵，有的还不能走国家医保，只能刷商业保险或自费。但是匈牙利的医院并不会出现今年预约 CT 明年才能做上的情况，真有问题的当场就给处理了，但是排队肯定是比国内久的。 让我们来说说学校匈牙利的学校基本都是中小班教学，但是，三分听七分做，老师能教的东西很有限，并且没有辅导员的角色，更没有班级一说，甚至学期都可以很模糊，提前毕业和推迟毕业更是家常便饭，有些专业的老师也不是很在乎你到底来不来上课，作业写不写，因为你毕不毕业跟他们一点关系都没有，你挂科他不扣钱，你考得好他也没奖金，除非你帮他做出什么科研成果，不然老师是不会主动的。 所以，出门在外，全靠自己，无论是生活还是学习。三年本科，两年研究生，后面还有博士等。他人是指望不上的，作弊被发现看老师，老师管的话，根据规定可以直接开除，老师不管的话也就是个重考。课程不难，认真学认真做了都能过。在匈牙利 1 是最差（挂科），5 是最好，重考会影响最终成绩，在国内找工作绩点肯定不能差了，但是在国外，绩点看得过去就行，它们不是很在乎这个。 国外的研究生学习阶段，跟中国的差距非常大。它们的研究生是本科的延续，你一样要上课，它就是一个缩短版的，更有方向性的本科，并不会像国内一样一来就有导师带着你做项目，所有的项目和项目组都需要你自己争取加入。有些项目组会发薪资，但是绝大部分项目都是没有钱的。 博士就跟国内差不多了，这是一份体面的工作，学校会开一个还过得去的薪资，但是所有的博士生都需要去给本科研究生讲课，大部分课程都会分两部分：概念课与实践课。概念课按规定都是教授讲课，所以你的实践课老师大概率是博士生，你的导师也大概率是博士生，因为教授实在不够用。 全匈牙利的学校，申请大都用的是 DreamApply 的系统，学生教务系统全部都是 Neptun，大部分学校都用的微软 O365，面试用 Skype。学生信息统一接入国家教育部门，移民局在你续签居留许可的时候会检查你的学习进度，表现很差的会拒签，三年本科最多读六年。 奖学金对于那些没有在国内上本科，并且本科学校恰好有匈牙利交换项目的学生来说就别想了。更何况匈牙利的平均学费相比于 US / UK 等并没有多少钱，大约 2 万人民币一学期，具体取决于专业。入学以后第一个学期可以申请转为奖学金，但是名额有限，且基本被匈牙利学联包圆了。温馨提示，离学联和其成员尤其是管事的远一点。中国人专坑中国人。 对于语言成绩，匈牙利大部分学校都要求雅思 5.5，或者同等水平的证明，这个因学校而异。高考成绩可有可无，但是高中毕业证和高中成绩单一定要有。申请后一定有面试，但不一定有笔试，取决于专业，我们统称其为入学考试。如果入学考试表现不好的，可能会发配到预科，如果再差一点的，面试官觉得预科都救不了你的，就会直接拒绝。附带预科的录取通知书是四年，但是一年预科读完后你不一定还继续在同一个学校继续读，也可以去其他学校，甚至换一个专业。 QS / THE / USNEWS 排名都没有太多参考意义，很多都是买的，尤其是 QS。建议参考 软科（中国）和 CWUR （沙特阿拉伯）的排名。 让我们来根据 2024 年排名来介绍一下各个学校。 罗兰大学（平均 406 名）https://apply.elte.hu/ CWUR 517 / 软科 501 展示了它不俗的实力。北京交通大学和北京邮电大学今年跟它同一排名。 优势学科：心理学，物理，地球物理，地质，数学，和全部艺术与人文类专业。罗兰大学属于综合类院校，是匈牙利最大，等级最高的学校，出了 5 个诺贝尔奖，最早是皇室直属。现在的校名是以其著名物理学家 Loránd Eötvös 得来。 罗兰大学除了其优势学科以外，其他学科都不一定比得上一些专门学校，但是也不失为一个好的选择。学校每个学院都分布在整个布达佩斯的不同地方，每个校区都离得很远，甚至还有一个 Szombathely 校区，距离布达佩斯 228KM。但是每个专业的学生都不会离开自己的学院，而去其他学院上课，选修课基本也是如此，所以不必担心通勤问题。 罗兰大学的 AI 系有 8 张 A100 40G 显卡专门给学生做项目用的，在普遍穷的叮当响的匈牙利学校中，这算是不错的待遇了。校企合作项目也很多，就看个人争取了。 塞格德大学https://apply.u-szeged.hu/en_GB/ 这个学校很有意思，它有一个非常辉煌的过去，曾经长期跻身于全球 200 名左右。而现在，软科 411，CWUR 709 的巨大偏差，让人无法准确估计这个学校到底是什么水平。它最初是由波兰的国王建立的，在 16 世纪末，是匈牙利唯一的高等教育机构。 它不在首都布达佩斯，而是在匈牙利第三大城市塞格德，邻近塞尔维亚，是一所综合类院校，就目前来说，没有特别出彩的专业，但是也没有特别差的专业，我也较少听到有关它的信息。 塞麦尔维斯大学https://semmelweis.hu/admission/process/ 你别看它软科排名 601 就小瞧它，因为它根本不在乎排名。它的医学是全世界前 200 名的，解剖学与生理学长期位于 100 名左右。THE 常年给它 250 左右的综合排名。这是一所医科大学，只有与医学相关的专业，覆盖了各个方面。Semmelweis 被誉为“母亲们的救星”，这所大学就是以他的名字命名的。 在欧洲，最赚钱的是牙科。匈牙利所有的医学类专业都一定需要预科，其他专业的预科不一定需要语言成绩，但是医学是一定要的，也不高，雅思 5.5 属于医学预科入门门槛，这个成绩其他一些专业都可以直接入学了。预科通过率 50%，本科按时毕业率 20%（可能都还不到）。要背的东西特别多，从预科就要开始背医学词典。 但是如果学成归来，无论哪个医学专业，甚至是兽医，在欧洲找份工作，那也是真的挣。 德布勒森大学https://edu.unideb.hu/programs.php 德布勒森是匈牙利第二大城市。其为综合类大学，学校排名也就是 650 左右，但是它的农业相关专业很不错，其他专业也不差。它还有着匈牙利为数不多的超算，但是需要排队使用。我经常能遇见在德布勒森上学的人。 布达佩斯技术大学https://xplore.bme.hu/available-programmes/ BME 是理工科专业大学，看它的排名意义不大（800），因为实践型的它没有太多科研产出。这个学校三天一小考，五天一大考，直接让你回到高中生活，毕业也比较困难，我见过计算机本科延毕两年然后转校的（看样子是没认真学）。但是研究生有几乎一对一的导师，能省去很多麻烦。就理工科专业来说，罗兰是比不上 BME 的。出来去科技公司之类的也比较好找到工作。 佩奇大学https://apply.pte.hu/ 不是小猪佩奇，英文发音也不一样，所以你说这个事情给外国人，他们是不理解的。为匈牙利第五大城市，但是有机场可以直飞德国慕尼黑。 这是一所综合类大学，排名很低（~1k），很好毕业，性价比是它的代名词，如果家中拮据，不失为一个选择，毕竟，学习靠自己。学院分散于整个佩奇，有的在山上，有的在市中心，有的藏在居民区，不如说整个佩奇城市，都是围绕着这个大学运行的。 但是它的医学院不错，并且是独立运作的，如果塞梅维尔斯去不了，佩奇医学院也不错。并且它还有全匈牙利最好的预科学院，环境好，宿舍好，老师也好。如果一定要预科，可以来这里先读一年，会比较好适应。 考文纽斯大学https://corvinus-university.dreamapply.com/ 这是在布达佩斯的一个商学院，而商学院有个特点就是基本不参与排名。如果看 FT 管理学硕士排名的话，它保持在全球 100 名以内。该大学的主楼是联合国教科文组织遗产的一部分。 这所学校名人没出多少，但是达官显贵很多。匈牙利最大的国有银行行长，Wizz 航空 CEO，特朗普的副助理等人均从这个学校毕业。如果想学管理，从政，搞钱之类的，这是个不错的地方。 关于申请每个学校名字下面的链接就是申请地址，需要注意的是，每个学校每个专业都可能有不同的开放周期，请看好时间，不要错过了提交期限。匈牙利的学校基本都有春季入学和秋季入学两种选择，这也导致它们一年也有两个毕业季，当然，六月和九月是最热闹的。 申请是完全不需要中介帮忙的，因为系统会给你很好的提示，需要什么材料，材料怎么写，应该是什么样的，都比较清楚。对于所有的材料，如果原文是中文的，能想办法开英文版的就开英文版，开不了英文版的，比如高中毕业证，则需要公证处翻译并公正。不要相信任何中介的包过等承诺，匈牙利的学校与中介没有任何合作，如果你真的有钱，可以去捐一栋楼，让学校给你发个荣誉学位，这比中介靠谱多了，并且国内好多中介关于匈牙利的业务都是转包的。 还有一点需要注意的是，不要用 QQ 数字邮箱。网易，Outlook 等都能正常收发学校的消息，而 QQ 邮箱很容易进学校邮件系统的垃圾箱。并且如果要给学校发邮件咨询任何消息，一定要有礼貌，邮件格式网上都有，并且不要轰炸学校邮箱，真的会给你拉黑的，一个事情短期内发一封，学校的人看到了一定会回的。如果是很重要或者很急的事情，那么可以将邮件同时发给多个相关的老师。 你还需要去办一张旅行健康证，这个网上搜一下就有。如果有什么传染性疾病的话，还是治好了再去吧。有些学校要求填写学校自己的健康证明单，这个打印下来给你办健康证的地方的医生，他们知道该怎么填。如果你缺少一些必要的疫苗，这也是一个补种的好机会。 你的个人简历需要使用 Europass 制作，如果你有高中以上的学历，当然可以写进去，但请准备好证明，如成绩单等。不需要写高中以前的内容，也没必要写你是不是团员和党员。请把你的个人经历制作的丰富一些，项目经验，组织工作，个人技能，有什么写什么，让人感觉你是一个能干，优秀的人。如果你实在没有什么东西可以写，也可以马上去考一些证书，Google 等大公司都有网上在线考试，这些完全可以用于丰富你的简历。对于简历到底该怎么写，我的个人意见是在你原有的基础上夸大其词，如遇团队项目把功劳揽过来即可，不要凭空捏造一些你完全没有经历过的事情。最后，多去知乎上看看其他人是怎么写的。 动机信不要照抄，不要全靠 AI，不要把对面当傻子。学校会给你动机信的提示，告诉你应该从哪些方面考虑。我的建议是，你可以先多去看看别人是怎么写的，然后你用中文写好，不要写流水账，然后让几个朋友来帮你看看，然后再翻译到英文。不需要华丽的辞藻，不需要复杂的语法，需要的是清晰易懂的表达和实际的内容，还有不要拼错单词和用错语法，这个事情 AI 很擅长。动机信一页就够，学校会给字符数限制。对于不需要直接在文本框内粘贴动机信的，同样使用 Europass 制作 Cover Letter 的 PDF。 如果你的资料有问题，学校会发邮件告诉你修改或者补充，多交材料没关系，你可以把你认为有用的，英文版本的，都传上去，但是要用英文命好文件名。最后你就可以等面试和笔试（如果有）通知了。对于面试，和国内找工作的远程面试一样的要求，安静地点，干净背景，整洁的你。不需要正装，但不要奇装异服，不需要化妆因为摄像头自带美颜（清晰度低），不要用手机面试。 我在匈牙利的学校只经历过四次面试。一次是我入学预科（我直接报的预科），基本没问什么内容，因为他默认你啥也不会，英语也不好，不然为什么要去预科呢。第二次是预科结束以后的转正面试，会开始问专业问题了，但是不会很深奥，主要是看你反应速度，都是比较简单的问题，如果你还需要想半天的话，那基本上就没戏了。第三次是我转专业的面试，这种情况下，除了专业问题，还会问你的动机。第四次是研究生面试，面试到一半直接开始在线答题，我计算机专业问了一个 python 脚本运行结果的问题，我好像还答错了，它考的是 python 的变量作用域，比较巧妙的问题。 总的来说，面试除了一开始的一分钟自我介绍，剩下的除了专业问题，就是你为什么来匈牙利，为什么选这个学校，为什么是这个专业的基本问题了。学校的面试官给你约面都会提前定时间，如果你的时间恰好不合适，也是完全可以提前一周协调的，当然如果临到头了协调会直接当你缺席。如果是技术问题导致的面试失败或者中断，学校会安排二次面试，但是如果是有人闯入了你的镜头，那就是你自己的问题了，面试中你这边绝对不可以出现第二个人，但是你可以使用辅助软件。面试可比国内找工作的面试简单多了，并且持续时间也就 15 分钟，不需要紧张。 如果一切顺利，你足够优秀，你就能收到录取通知书了，匈牙利的学校都有一个最晚发通知书的期限，你一定能在那之前收到结果。如果你不是很优秀，可能会分配到预科，这也完全没有问题。如果你被某个学校的专业拒绝了，为了避免你没地方去，最好是一次性申请多个学校的多个专业，无非就是多交一点申请费而已。在拿到 offer 后，你最多可以选择推迟一年入学。 关于签证在收到录取通知后，你必须第一时间提交签证申请，在此之前，你可以提前准备好一些必要的材料。护照肯定是必要的，同时你需要向学校支付学费，办理签证需要学校的学费收据。有些学校可以在线银行卡支付，同时请让你的监护人为你办理一张 Visa 或者 Master 的外币附属卡，银联是用不了的。如果学校不接受在线付款，你可以找在欧洲的熟人帮忙转账，实在没有的，找国内的私立银行，如民生银行，它们的转账手续费更低。 匈牙利的签证现在基本都是签证中心在办理，并且网点很多，服务也还行，会清楚的告诉你所有需要的材料。通过签证中心提交的申请不容易被面签，并且签证中心也会预审材料，有问题的会立即要求修改。一旦被要求面签，那就得亲自去匈牙利大使馆了，不过他们也不会问你太复杂的问题，如实回答，不要编造内容，并且不要表露出移民倾向，问就是最后回国。 对于未成年人，还需要监护人的授权同意书，大使馆会告诉你怎么写。所有法定监护人的单位均需要开具英文版的收入证明，注意是所有。如果有困难，收入不要写的太低即可，移民局也无权查证，其他情况就如实填写，不要夸大其词，如果怀疑起来，移民局会要银行流水。你还需要一份旅行保险，这个各个保险公司都有对应的产品，注意一下保额不要太低即可。 你还需要准备一份存款证明，金额不需要太多，在国内银行存个 5 万多人民币的定期就行了，然后让银行出具一份英文证明即可。而且也不用担心锁定之类的问题，毕竟交几块钱就可以解冻，拿出来继续用。这些钱是移民局来确保你不是去匈牙利当难民，而是去学习的，所以不建议存款证明造假（如临时借钱），不然交不起学费被遣返，或者被拒签，是一件对未来很有负面影响的事情。请注意，如果需要解冻，请你拿到签证以后再操作。 你还需要提前找好房子，最好是在拿到通知书后再签订合同（如果时间充足），不要过于相信中介，如果能住宿舍，第一学期最好住宿舍，不要去赌你能远程找到好房子，你可以到了那再立刻开始找自己想住的地方，宿舍是可以中途退出的。申请签证需要正确的租房合同和去匈牙利的机票。 签证的事情就听签证中心和大使馆的，一切顺利你就能拿到签证了。 关于启程你可以购买学生机票，这样你就有两个行李托运额度了。匈牙利是发达国家，不需要带的像去逃难或者去无人区一样，你能想到的东西那边基本都能买得到，只需要带上你的生活必需品和电子产品即可。电子产品一定不要带包装，甚至是发票，否则容易被收税。不要购买任何德国入境欧盟的机票，会被疯狂上税，到匈牙利有直飞的，不贵。 到了匈牙利你行李多的话可以预定接送，但是如果你能处理的了行李，机场接驳公交车非常方便。我自己从始至终就只坐过一次接送专车，省心是省心，贵也是真的贵。注意，你只有在拿到学生证或者临时纸质学生证后才能购买学生票。 最后，学校在开学前会组织多次线上线下的交流答疑会，还是很建议去参加听一下的。选课什么的会在开学前进行，你会收到学校的详细介绍邮件，跟着邮件有什么不懂的礼貌咨询注册处即可。开学前几天到匈牙利，在学校报道以后就可以着手准备领取居留卡和办理学生证等后续事项了，这些学校都会给你邮件指示和一定程度上的帮助，总之在这些事情上，联系学校就是最正确的选择。 后记匈牙利还有很多学校我就不一一介绍了，比如李斯特音乐学院，全球排名第 15 的音乐专业，学费也是贵的吓人。还有什么 Obuda 综合类大学，兽医大学，BGE 金融大学，农业大学等等……要将出国留学这件事情放在一个合适的位置，不要太焦虑，也不要满不在乎，随时做好两手准备才是硬道理。希望这篇攻略能对你有所帮助。","link":"/Memo/%E5%8C%88%E7%89%99%E5%88%A9%E7%95%99%E5%AD%A6%E6%94%BB%E7%95%A52024/"},{"title":"数据库概念入门","text":"所以说我们老师考这些的意义是什么呢 第一周Data -&gt; Database -&gt; Data Warehouse都什么年代了还在用数据仓库 Physical Data 是储存在实体介质上的数据Logical Data 是指数据的逻辑结构有 Add / Modify / Delete / Merging / Breaking 这什么玩意写的乱七八糟的 数据独立性物理独立性 程序与磁盘数据相互独立 程序不需要了解如何储存数据 数据如何储存由 DBMS 管理 物理储存改变，程序无需改变 逻辑独立性 程序与数据库的逻辑结构相互独立 数据逻辑结构改变，程序无需改变 数据独立性的重要性 数据质量 维护成本 安全性 结构化 Implementation (Layers of data) 减少重复 备份 物理层面容易修改，提高性能 合着真就不说人话 三级模式结构Physical Schema内模式（储存模式），对应 物理（内部）级描述了数据在磁盘上的存储方式和物理结构 Conceptual Schema概念模式（逻辑模式），对应 概念（逻辑）级是对数据库中全部数据的逻辑结构和特征的总体描述是全局视图，由 Data Description Language 描述 External Schema外模式（用户模式），对应 用户（视图）级是用户所看到的数据库的数据视图是概念模式的一个子集，包换特定用户使用的那部分数据由 Data Manipulation Language 操作 关系模型突然发现老师的 PPT 内容都是网上抄的 概念 Attribute: Column Table: Relation Tuple: Row Degree: Count(Column) Cardinality: Count(Row) Relation key: 比如主键 Domain: 数据类型，约束等 Relation Schema: 表名 和 其中的列 Relation Instance: 表中的数据 完整性约束Domain Constraints123... ColName INT CHECK(ColName = 3) NOT NULL ...-- AndCREATE TRIGGER SomeName ... Key Constraints主键约束 Referential Integrity Constraints外键约束 优势 简单 结构独立 易用 能够查询 数据独立 可扩展 第二周 RDBMS: Relational Database Management System关系型数据库管理系统 SQLWhy 方便存取数据 有助于描述数据 允许对数据库中的数据进行定义和操作 创建和删除表 创建和使用 函数，View，储存过程 设置权限 这些都是老师说的，我持保留意见 Types DDL: Data Definition Language 定义 CREATE ALTER DROP TRUNCATE DML: Data Manipulation Language 操作 INSERT UPDATE DELETE DCL: Data Control Language 权限 GRANT REVOKE TCL: Transaction Control Language 事务 COMMIT ROLLBACK SAVEPOINT DQL: Data Query Language 查询 SELECT 索引查看索引 1EXEC sp_helpindex 表名 聚集索引Clustered Index 表中行数据的物理顺序与索引的逻辑顺序相同 一个表只能有一个聚集索引 Primary Key 默认 非聚集索引Nonclustered Index 储存的是指向表中行的指针 UNIQUE 默认 索引覆盖Covering Indexes 索引中包含了所有要查询的字段 提高性能 第三周维护Maintenance Repair 重组索引 重建索引 更新统计信息 一致性和完整性检查Consistency and Integrity 修复和清理 Normalization数据库规范化 保护数据 消除冗余 消除不一致的依赖关系 不一致用户在 Customer 表中查找 Address 是合理的但是在这里查找 负责这个客户的 员工的 Salary 就不合理了这应该去 Employee 表中查找 不一致的依赖关系 会使数据难以访问 非规范化表 学生编号 指导教师 咨询室 课程 1 课程 2 课程 3 1022 Jones 412 101-07 143-01 159-02 4123 Smith 216 101-07 143-01 179-04 1NF：消除重复的列 消除单个表中的重复列 为每组相关数据单独创建一个表 使用主键标识每组相关数据 学生编号 指导教师 咨询室 课程 1022 Jones 412 101-07 1022 Jones 412 143-01 1022 Jones 412 159-02 4123 Smith 216 101-07 4123 Smith 216 143-01 4123 Smith 216 179-04 2NF：消除重复的行 为应用于多条记录的值，创建单独的表 用外键连接这些表 Table Student 学生编号 指导教师 咨询室 1022 Jones 412 4123 Smith 216 Table Course 学生编号 课程 1022 101-07 1022 143-01 1022 159-02 4123 101-07 4123 143-01 4123 179-04 3NF：消除与主键无关的数据指导教师和咨询室是与学生编号无关的数据 Table Student 学生编号 指导教师 1022 Jones 4123 Smith Table Teacher 名称 咨询室 Jones 412 Smith 216 主键 不能为空 唯一 几乎不会改变 Composite Key复合主键是指由多个字段组成的主键 外键 可空 不唯一 依赖完整性 ER 图 实体 Entity用矩形表示，也就是表 属性 Attribute用椭圆表示，也就是列 关系 Relationship用菱形表示，也就是表之间的关系 派生属性可以由其他属性计算得出，虚线比如 Age 可以由 Birthday 计算得出 多值属性可以有多个值，双椭圆比如书有多个作者 复合属性由多个属性组成比如名字由姓和名组成 可选属性 复合实体用于多对多联系，矩形内加一个菱形 弱实体必须依赖另一个实体存在比如学生是强实体，成绩单是弱实体必须是一对一或者一对多的关系用双层矩形表示 一对一 一对多 多对多需要复合实体帮助 步骤 Entity Identification找实体 Relationship Identification找关系 Cardinality Identification一对多之类的 Identify Attributes找 Column Create the ER Diagram画图 数据仓库数据仓库，OLAP，使用数据库系统来帮助洞察业务典型的有 Redshift，主要用于数据分析比如，20~30 岁女性用户在过去五年的第一季度化妆品类商品的购买行为与公司进行的促销活动方案之间的关系 数据库是为读写优化的，而数据仓库是为只读优化的 事实表主要特点是含有大量的数据，并且这些数据是可以汇总，并被记录的 维度表分析数据的窗口，包含事实表中事实记录的特性 星形模式 Star一张事实表和多张维度表组成 雪花模式 Snowflake每一个维度表都可以向外连接多个子维度表 星系模式 Galaxy多个事实表版本的星型模型，多张事实表共用模型中的维度表 Data Cube专指那些远大于内存的数据集合，它用来存储和表示多维度数据 钻取 Drill Down从高维度到低维度比如，对第二季度的总销售数据进行钻取可以得到第二季度中每个月的销售数据 上卷 Roll Up从低维度到高维度比如，将 4，5，6 月的销售数据进行上卷可以得到第二季度的销售数据 切片 Slice对特定值进行分析比如，只选择电子产品的销售数据 切块 Dice对特定范围进行分析比如，选择第一季度和第二季度的销售数据 旋转 Rotate交换维度比如，通过旋转实现产品和地域的维度互换 元数据元数据通常包括有关数据仓库中数据的描述信息、数据的属性和结构、以及数据之间的关系等元数据可以帮助人们更好地理解和使用数据仓库中的数据，并且在数据仓库的管理和维护方面也起着重要作用","link":"/Database/Theory/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"},{"title":"数理逻辑2 B卷","text":"Mathematical Logic 完全理解！ CoqideAP ∧ (Q ∧ R), (S ∧ E) ∧ U, E ⇒ W ⊢ (Q ∧ P) ∧ W 123456789101112131415161718192021222324252627Require Import Classical.Parameters P Q R S U E W: Prop.Hypothesis P1: P /\\ (Q /\\ R).Hypothesis P2: (S /\\ E) /\\ U.Hypothesis P3: E -&gt; W.Goal (Q /\\ P) /\\ W.Proof.pose proof(proj1 P1).pose proof(proj2 P1).pose proof(proj1 H0).pose proof(conj H1 H).pose proof(proj1 P2).pose proof(proj2 H3).pose proof(P3 H4).pose proof(conj H1 H).pose proof(conj H6 H5).exact H7.Qed. BQ, Q ⇒ P ∨ R, R ⇒ S ⊢ P ∨ S 12345678910111213141516171819202122Require Import Classical.Parameters P Q R S: Prop.Hypothesis P1: Q.Hypothesis P2: Q -&gt; P \\/ R.Hypothesis P3: R -&gt; S.Goal P \\/ S.Proof.pose proof(P2 P1).destruct H.left.exact H.right.pose proof(P3 H).exact H0.Qed. CS ⇒ P, Q ⇒ E ⊢ (P ⇒ Q) ⇒ (S ⇒ E) 1234567891011121314151617181920Require Import Classical.Parameters P Q E S: Prop.Hypothesis P1: S -&gt; P.Hypothesis P2: Q -&gt; E.Goal (P -&gt; Q) -&gt; (S -&gt; E).Proof.intros H.assert(S -&gt; E).intros H1.apply P2.apply H.apply P1.exact H1.exact H0.Qed. D(P ⇒ Q) ⇒ (P ⇒ R) ⇒ (Q ⇒ R ⇒ W) ⇒ P ⇒ W 1234567891011121314Require Import Classical.Theorem Implies : forall P Q R W : Prop, (P -&gt; Q) -&gt; (P -&gt; R) -&gt; (Q -&gt; R -&gt; W) -&gt; P -&gt; W.Proof.intros P Q R W PQ PR QR PW.apply QR.apply PQ.exact PW.apply PR.exact PW.Qed. Symbolize No superhero is faster than Spiderman. Some evil superheros can climb on the wall. Evil superheros are not faster than Spiderman. If someone is faster than Spiderman, then Spiderman is evil. Everone who is faster than Spiderman is evil and can climb on the wall. There is someone who is faster than anyone who can climb on the wall. Someone who is faster than Spiderman is evil. Only those who are evil can be faster than those who are not faster than Spiderman. Find TruthUD: { Potter, Granger, Weasley }Extension H: { Potter, Weasley }Extension W: { Granger, Weasley }Extension R: { (Potter, Granger), (Granger, Potter), (Weasley, Granger) }Referent a: Potter ∃x(Rxa ∧ Rax) ∀x(Rxa ∨ Rax) ∀x(Hx ⇔ Wx) ∀x(Rxa ⇒ Wx) ∀x[Wx ⇒ (Hx ∧ Wx)] ∃x(Rxx) ∃x∃y(Rxy) ∀x∀y(Rxy) ∀x∀y(Rxy ∨ Ryx) ∀x∀y∀z[(Rxy ∧ Ryz) ⇒ Rxz] IsConsistentP ⇒ Q, Q ∧ (P ∨ P), ¬(Q ∨ R) IsValid R ⇒ (P ∨ Q), R ∧ Q ⊢ R ⇒ P ¬R ⇒ Q, ¬P ∨ ¬Q, ¬(P ⇔ Q) ⊢ ¬(P ∨ Q) Symbolize &amp; IsValidEvery dwarf that saw Snowhite biting into the apple want to save her.Someone (a dwarf) let the stepmother into the house.Those dwarfs that want to save Snowite did not let the stepmother into the house.Therefore: Not every dwaft saw Snowhite biting the apple. Natural Deduction P ∨ Q ⇒ R ⊢ (P ∧ Q) ⇒ R 1234567891011121314151617Require Import Classical.Parameters P Q R: Prop.Hypothesis P1: P \\/ Q -&gt; R.Goal (P /\\ Q) -&gt; R.Proof.intro.destruct H.apply P1.left.exact H.Qed. (R ∧ S) ⇒ (P ∧ ¬Q), E ∧ (E ⇒ S), Q ⊢ R ⇒ P 123456789101112131415161718192021222324Require Import Classical.Parameters P Q R S E: Prop.Hypothesis P1: (R /\\ S) -&gt; (P /\\ ~Q).Hypothesis P2: E /\\ (E -&gt; S).Hypothesis P3: Q.Goal R -&gt; P.Proof.intro.pose proof(proj1 P2).pose proof(proj2 P2).pose proof(H1 H0).pose proof(conj H H2).pose proof(P1 H3).pose proof(proj1 H4).exact H5.Qed. j is a constant, ∀x(¬Mx ∨ Ljx), ∀x(Bx ⇒ Ljx), ∀x(Mx ∨ Bx) ⊢ ∀xLjx ∃x∀yPxy ⊢ ∀y∃xPxy ∀xPx, ∃x(Px ⇒ ∀yQy), ∀x(Qx ⇒ Rx) ⊢ ∃x(Qx ∧ Rx) Argument invalid, Prove∃x(Dx), ∃x(Ex), ∀x(Dx ∨ Ex) ⊢ ∃x(Dx ∧ Ex)","link":"/Math/Logic/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%912-B%E5%8D%B7/"},{"title":"记一次面试题","text":"参加了一次 黑客排名 的技术面试 得到的经验就是别去看那有的没的的题干，很浪费时间，而是要： 看示例输入 看示例输出 找输入输出的关系 写框架代码 找题中的细节要求 完善代码 Test &amp; Debug 我有 70 分钟作答 ，但是吧，这题弱智都做得出来，无非是时间问题 算法题从 List&lt;List&lt;int&gt;&gt; 中找出最大相邻相同数字的方阵长度，比如 输入 1231 1 11 1 01 0 1 输出 2 解本题需要用到 动态规划 的思想 二维数组 dp 来记录以每个元素为右下角的最大相邻相同数字的方阵长度然后遍历输入的矩阵，根据当前元素的值来更新 dp最后，返回 dp 中的最大值作为最大相邻相同数字的方阵长度 12345678910111213141516171819202122232425262728static int FindMaxSquareLength(List&lt;List&lt;int&gt;&gt; matrix) { var rows = matrix.Count; var cols = matrix[0].Count; var maxLength = 0; var dp = new int[rows, cols]; for (var i = 0; i &lt; rows; i++) for (var j = 0; j &lt; cols; j++) { if (i == 0 || j == 0) dp[i, j] = matrix[i][j]; else if (matrix[i][j] == 1) dp[i, j] = Math.Min(dp[i - 1, j - 1], Math.Min(dp[i - 1, j], dp[i, j - 1])) + 1; maxLength = Math.Max(maxLength, dp[i, j]); } return maxLength;}List&lt;List&lt;int&gt;&gt; matrix = new() { new() { 1, 1, 1 }, new() { 1, 1, 0 }, new() { 1, 0, 1 }};var maxLength = FindMaxSquareLength(matrix);Console.WriteLine(&quot;最大相邻相同数字的方阵长度为: &quot; + maxLength); 技能题编写一个 HTTP GET 查询 URL: https://jsonmock.hackerrank.com/api/transactions它不提供除了 ?page=num 以外的查询参数 编写代码以实现 1List&lt;string&gt; maximumTransfer(string name, string city) 其中，找出最大的 credit 为 [0]，最大的 debit 为 [1] 解这个真没啥好说的，单纯考基本功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596static async Task&lt;List&lt;string&gt;&gt; maximumTransfer(string name, string city) { var result = new List&lt;string&gt;(); var allData = await GetAllData(); var maxCredit = decimal.MinValue; var maxDebit = decimal.MinValue; var maxCreditAmount = &quot;&quot;; var maxDebitAmount = &quot;&quot;; foreach (var data in allData.Where(data =&gt; data.userName == name &amp;&amp; data.location.city == city)) switch (data.txnType) { case &quot;credit&quot;: { var creditAmount = ParseAmount(data.amount); if (creditAmount &gt; maxCredit) { maxCredit = creditAmount; maxCreditAmount = data.amount; } break; } case &quot;debit&quot;: { var debitAmount = ParseAmount(data.amount); if (debitAmount &gt; maxDebit) { maxDebit = debitAmount; maxDebitAmount = data.amount; } break; } } result.Add(maxCreditAmount); result.Add(maxDebitAmount); return result;}static async Task&lt;List&lt;Data&gt;&gt; GetAllData() { var allData = new List&lt;Data&gt;(); var currentPage = 1; var totalPages = 1; while (currentPage &lt;= totalPages) { var url = $&quot;https://jsonmock.hackerrank.com/api/transactions?page={currentPage}&quot;; using (var client = new HttpClient()) { var response = await client.GetAsync(url); if (response.IsSuccessStatusCode) { var json = await response.Content.ReadAsStringAsync(); Root root = JsonConvert.DeserializeObject&lt;Root&gt;(json); allData.AddRange(root.data); totalPages = root.total_pages; } else throw new($&quot;Failed to retrieve data from {url}. Status code: {response.StatusCode}&quot;); } currentPage++; } return allData;}static decimal ParseAmount(string amount) { var cleanedAmount = amount.Replace(&quot;$&quot;, &quot;&quot;).Replace(&quot;,&quot;, &quot;&quot;); return decimal.Parse(cleanedAmount);}var maxTransfer = await maximumTransfer(&quot;John Doe&quot;, &quot;New York&quot;);Console.WriteLine(&quot;Max Credit: &quot; + maxTransfer[0]);Console.WriteLine(&quot;Max Debit: &quot; + maxTransfer[1]);internal class Data { public int id { get; set; } public int userId { get; set; } public string userName { get; set; } public object timestamp { get; set; } public string txnType { get; set; } public string amount { get; set; } public Location location { get; set; } public string ip { get; set; }}internal class Location { public int id { get; set; } public string address { get; set; } public string city { get; set; } public int zipCode { get; set; }}internal class Root { public int page { get; set; } public int per_page { get; set; } public int total { get; set; } public int total_pages { get; set; } public List&lt;Data&gt; data { get; set; }} SQL 题写一个 SQL 查询，有表 12customers(id: smallint, name:varchar)warehouses(customer_id, volume: decimal, is_active:smallint) 期望输出 1record(name, warehouses, min_volume, max_volume, total_volume) 只有 active 的仓库才被列出，按 name 排序 解或许 ChatGPT 写的比你更快更好 ，有的时候找找自己原因，好吧，这么多年了工资涨没涨，有没有认真工作，好不，这么多年都是这个代码质量我真的疯掉了。 123456789101112131415SELECT c.name AS name, COUNT(w.customer_id) AS warehouses, MIN(w.volume) AS min_volume, MAX(w.volume) AS max_volume, SUM(w.volume) AS total_volumeFROM customers c INNER JOIN warehouses w ON c.id = w.customer_idWHERE w.is_active = 1GROUP BY c.id, c.nameORDER BY c.name;","link":"/Program/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"论使用WebCodecs对视频进行处理","text":"原文 更新于 2022-02-10，由 Aloento 翻译，具体以原文为准 现代的 Web 技术为视频提供了丰富的处理能力，例如 Media Stream API、Media Recording API、Media Source API, 和 WebRTC API 等，它们提供了丰富的工具以便 录制、传输、回放视频流。这些 API 虽然封装了很多高级功能以便方便的完成既定任务，但它们并不能让你处理视频流的内部细节，如 按帧处理 和 处理未 Muxed 的视频或音频块等。为了实现以上目的，你不得不使用一些类似 WebAssembly 的方式来把浏览器本就自带的编解码器（通常它们都有硬件加速）又一次的引入，这属实是对资源的浪费。 而 WebCodecs API 为程序员提供了使用浏览器自带编解码器的能力，来提高你的工作流效率，具体而言： 音视频的编解码 视频原始帧 图像解码 WebCodecs API 对于需要完全控制媒体内容处理方式的场景是非常有用的，例如视频编辑、视频会议、视频流等。 视频处理工作流帧 是视频处理的基本单位，因此，在 WebCodecs 中，大多数类要么使用帧，要么产生帧。编码器将帧转为编码的 chunks（块），而解码器则做相反的事情。VideoFrame 有一个可以接受 CanvasImageSource 的构造函数来于其他的 Web API 很好的配合。所以它可以被用于 drawImage() 和 texImage2D() 等函数中. 此外，它还可以从 canvases, bitmaps, video elements 和 其他 video frames 中创建。 WebCodecs API 可以用 Insertable Streams API，让 WebCodecs 和 media stream tracks 一起工作。 MediaStreamTrackProcessor 将媒体流分解为单个帧。 MediaStreamTrackGenerator 从帧序列中创建媒体流。 WebCodecs 和 Web Workers按照设计，WebCodecs API 以异步方式在主线程之外完成所有繁重的工作。但是由于帧和 Chunk 的回调经常在一秒之类被调用多次，这可能导致主线程的混乱，导致网页 UI 的缓慢和卡顿，所以我们最好将处理工作放到 Worker 线程中。 而 ReadableStream 有一个简便的方法可以将来自媒体流的帧全部自动转移到 Worker 线程中，例如，从摄像头的来的流通过 MediaStreamTrackProcessor 获取到 ReadableStream 后，就可以在 Worker 线程中被 VideoEncoder 处理。 我们甚至可以通过 HTMLCanvasElement.transferControlToOffscreen 在主线程之外进行渲染。但如果所有的高级接口都不满足你的需求，VideoFrame 本身也是可以在不同的 Worker 中转移的。 WebCodecs 的编解码Encoding / 编码 我们从 VideoFrame 开始，有三种方法来构建视频帧。 从图片源，如 canvas, image bitmap, 或 video element. 1234const canvas = document.createElement(&quot;canvas&quot;);// Draw something on the canvas...const frameFromCanvas = new VideoFrame(canvas, { timestamp: 0 }); 使用 MediaStreamTrackProcessor 从 MediaStreamTrack 中提取帧 1234567891011const stream = await navigator.mediaDevices.getUserMedia({…});const track = stream.getTracks()[0];const trackProcessor = new MediaStreamTrackProcessor(track);const reader = trackProcessor.readable.getReader();while (true) { const result = await reader.read(); if (result.done) break; const frameFromCamera = result.value;} 从 BufferSource 中的原始二进制像素中创建帧 123456789101112131415161718const pixelSize = 4;const init = { timestamp: 0, codedWidth: 320, codedHeight: 200, format: &quot;RGBA&quot;,};const data = new Uint8Array(init.codedWidth * init.codedHeight * pixelSize);for (let x = 0; x &lt; init.codedWidth; x++) { for (let y = 0; y &lt; init.codedHeight; y++) { const offset = (y * init.codedWidth + x) * pixelSize; data[offset] = 0x7f; // Red data[offset + 1] = 0xff; // Green data[offset + 2] = 0xd4; // Blue data[offset + 3] = 0x0ff; // Alpha }}const frame = new VideoFrame(data, init); 无论它们来自哪里，帧都可以用 VideoEncoder 编码为 EncodedVideoChunk。而 VideoEncoder 需要两个参数： 两个函数，用来处理已编码数据块和产生的错误，传入后不可变。 编码器配置，用来配置输出的视频流参数，可以使用 configure() 进行修改。 如果你指定的配置不被浏览器支持，configure() 方法将抛出 NotSupportedError。所以我们建议你调用异步静态方法 VideoEncoder.isConfigSupported() 来预先检查你的配置是否被用户的浏览器支持。 12345678910111213141516171819202122const init = { output: handleChunk, error: (e) =&gt; { console.log(e.message); },};const config = { codec: &quot;vp8&quot;, width: 640, height: 480, bitrate: 2_000_000, // 2 Mbps framerate: 30,};const { supported } = await VideoEncoder.isConfigSupported(config);if (supported) { const encoder = new VideoEncoder(init); encoder.configure(config);} else { // Try another config.} 编码器设置好以后，你就可以通过 encode() 方法来传入帧了。configure() 和 encode() 都不需要等待实际工作结束，它们会立刻返回。编码器允许多个帧同时排队等待编码，encodeQueueSize 表示队列中有多少帧还未处理。 如果你传入的参数或调用方法的顺序不正确，则方法可以立刻抛出错误，也可以通过你设置的 error() 回调函数报告错误。如果编码成功，就会调用你设置的 output() 回调函数。这里需要强调一点，如果你的帧不再使用，你应该调用 close() 来释放资源。 12345678910111213141516171819202122let frameCounter = 0;const track = stream.getVideoTracks()[0];const trackProcessor = new MediaStreamTrackProcessor(track);const reader = trackProcessor.readable.getReader();while (true) { const result = await reader.read(); if (result.done) break; const frame = result.value; if (encoder.encodeQueueSize &gt; 2) { // Too many frames in flight, encoder is overwhelmed // let's drop this frame. frame.close(); } else { frameCounter++; const keyframe = frameCounter % 150 == 0; encoder.encode(frame, { keyFrame }); frame.close(); }} 最后，我们编写一个处理从编码器中得到的 Chunks 的函数，来完成最终的编码。一般来说，这个函数会把 Chunk 发往服务器，或者将 Chunk Muxing 到一个容器中来生成一个视频文件。 1234567891011121314151617181920212223function handleChunk(chunk, metadata) { if (metadata.decoderConfig) { // Decoder needs to be configured (or reconfigured) with new parameters // when metadata has a new decoderConfig. // Usually it happens in the beginning or when the encoder has a new // codec specific binary configuration. (VideoDecoderConfig.description). fetch(&quot;/upload_extra_data&quot;, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/octet-stream&quot; }, body: metadata.decoderConfig.description, }); } // actual bytes of encoded data const chunkData = new Uint8Array(chunk.byteLength); chunk.copyTo(chunkData); fetch(`/upload_chunk?timestamp=${chunk.timestamp}&amp;type=${chunk.type}`, { method: &quot;POST&quot;, headers: { &quot;Content-Type&quot;: &quot;application/octet-stream&quot; }, body: chunkData, });} 如果你需要确保所有的编码请求都已经完成，你可以调用异步函数 flush()。 1await encoder.flush(); Decoding / 解码 设置 VideoDecoder 的方法与设置 VideoEncoder 的类似：在创建解码器的是否传入两个参数，并调用 configure() 修改解码器参数。解码器的参数会因编码器的不同而不同，比如一个 H.264 解码器可能需要一个 AVCC 格式的二进制 blob，除非流是以 Annex B 编码的。(encoderConfig.avc = { format: &quot;annexb&quot; }) 1234567891011121314151617181920const init = { output: handleFrame, error: (e) =&gt; { console.log(e.message); },};const config = { codec: &quot;vp8&quot;, codedWidth: 640, codedHeight: 480,};const { supported } = await VideoDecoder.isConfigSupported(config);if (supported) { const decoder = new VideoDecoder(init); decoder.configure(config);} else { // Try another config.} 在准备好解码器后，你需要给它一个 EncodedVideoChunk。要创建 Chunk，你需要： 一个编码视频数据的 BufferSource Chunk 的开始时间戳，单位是微秒（Chunk 中第一个编码帧的媒体时间） Chunk 的类型： key，如果 Chunk 可以独立于之前的数据块进行解码，则为关键帧类型 delta Chunk 必须在其他块被解码以后才能被解码 编码器产生的所有 Chunk 都是可以用解码器解码的。之前提到的错误报告和方法的异步等事项，对解码器也是如此。 12345678910const responses = await downloadVideoChunksFromServer(timestamp);for (let i = 0; i &lt; responses.length; i++) { const chunk = new EncodedVideoChunk({ timestamp: responses[i].timestamp, type: responses[i].key ? &quot;key&quot; : &quot;delta&quot;, data: new Uint8Array(responses[i].body), }); decoder.decode(chunk);}await decoder.flush(); 现在，我们把解码好的帧展现在页面上。最好确保解码器的输出回调函数(handleFrame())迅速返回。在下面的例子中，它只是将一个帧添加到准备渲染的帧队列中。渲染是独立进行的，由两个步骤组成： 等待合适的时机来展示帧 在 Canvas 上绘制帧 一旦帧不再被使用，就调用 close() 来在 GC 之前释放底层内存，这将减少平均内存使用量。 1234567891011121314151617181920212223242526272829303132333435const canvas = document.getElementById(&quot;canvas&quot;);const ctx = canvas.getContext(&quot;2d&quot;);let pendingFrames = [];let underflow = true;let baseTime = 0;function handleFrame(frame) { pendingFrames.push(frame); if (underflow) setTimeout(renderFrame, 0);}function calculateTimeUntilNextFrame(timestamp) { if (baseTime == 0) baseTime = performance.now(); let mediaTime = performance.now() - baseTime; return Math.max(0, timestamp / 1000 - mediaTime);}async function renderFrame() { underflow = pendingFrames.length == 0; if (underflow) return; const frame = pendingFrames.shift(); // Based on the frame's timestamp calculate how much of real time waiting // is needed before showing the next frame. const timeUntilNextFrame = calculateTimeUntilNextFrame(frame.timestamp); await new Promise((r) =&gt; { setTimeout(r, timeUntilNextFrame); }); ctx.drawImage(frame, 0, 0); frame.close(); // Immediately schedule rendering of the next frame setTimeout(renderFrame, 0);} Dev Tips在 Chrome DevTools 中使用 Media Panel，查看媒体日志和调试 WebCodecs。 Demo下面这个例子展示了 Canvas 上的动画是如何被： 通过 MediaStreamTrackProcessor 以 25fps 的帧率采集到 ReadableStream 中 转发到 Worker 线程 编码成 H.264 的视频 再次解码为帧序列 使用 transferControlToOffscreen() 在另一个 Canvas 上渲染 new-webcodecs-blogpost-demo Other demosAlso check out our other demos: Decoding gifs with ImageDecoder Capture camera input to a file MP4 playback Other samples 使用 WebCodecs API兼容性检查检查对 WebCodecs 的支持: 123if (&quot;VideoEncoder&quot; in window) { // WebCodecs API is supported.} 请注意，WebCodecs API 只在 secure contexts 下运行，所以如果 self.isSecureContext 是 false，则检测会失败。 FeedbackThe Chrome team wants to hear about your experiences with the WebCodecs API. Tell us about the API designIs there something about the API that doesn’t work like you expected? Or arethere missing methods or properties that you need to implement your idea? Have aquestion or comment on the security model? File a spec issue on thecorresponding GitHub repo, or addyour thoughts to an existing issue. Report a problem with the implementationDid you find a bug with Chrome’s implementation? Or is the implementationdifferent from the spec? File a bug at new.crbug.com.Be sure to include as much detail as you can, simple instructions forreproducing, and enter Blink&gt;Media&gt;WebCodecs in the Components box.Glitch works great for sharing quick and easy repros. Show support for the APIAre you planning to use the WebCodecs API? Your public support helps theChrome team to prioritize features and shows other browser vendors how criticalit is to support them. Send emails to media-dev@chromium.org or send a tweetto @ChromiumDev using the hashtag#WebCodecsand let us know where and how you’re using it. Hero image byDenise Janson Unsplash.","link":"/Program/WebCodecs/%E8%AE%BA%E4%BD%BF%E7%94%A8WebCodecs%E5%AF%B9%E8%A7%86%E9%A2%91%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86/"},{"title":"论如何在C++&#x2F;CLI中使用LINQ：记一次奇妙的C++大作业","text":"123456“救我，你一定要救我啊！” 我的同学对我如是说“¿”“C++要考试了！我整不来啊，我感觉挺简单的题”“......”“请你吃顿饭”“彳亍” 然后我就收到了这么两道题目： 准备 生成 20 个可被 2 或 5 整除，介于 1 至 100 之间的无重复随机数 Write a program (in C++) that generates and calculates 20 different random numbers that can be divided by 2 or 5. Random numbers must be generated from 1 to 200,the same number cannot be included in the array! The random number generation should be written in a function, i.e. the return value of the function should be an array! 随机产生 50 个人的工资表，并列出平均、最高低工资 Given a list in which the wages of 50 people are stored (in EUR). Write a program (in C++) that determines what the average wage is, who has the highest wage, who has the lowest wage, and who has the wages below average. 乍一看感觉这题确实就是初学者的题目，不过如果我使用普通的方法完成这题就不能称之为 “奇妙” 的大作业了，所以在犹豫一阵后我决定，使用 C++/CLI 来完成顺带再期待一下老师如果看到一堆 CLI 代码会作何反应（ 什么是 C++/CLIC++/CLI 是 C++ 的扩展，让我们可以同时享受 C# 和 C++ 的特性，是微软的就我个人而言，如果能用 C++/CLI 的话那我绝对不会用传统的 C++而且这玩意据我了解在中国没多少人用，或者说老外也不怎么用因为这玩意不上不下的，说实话 C# 的 unsafe 已经足够了 而且就目前为止，它仍然不能跨平台，Core 以后也无法生成独立程序了 寄 There isn’t currently a template for C++/CLI console or Windows applications that can be used with .NET Core.Instead you must put application entry point outside of the C++/CLI code. 所以作业是用 .NET Framework，不过本文使用 .NET Core所以查个资料，学习起来着实有点费力，以后有空可以专门讲讲 在撰写这篇文章时我目前心目中的优先级：C# &gt; Go &gt; Rust &gt; C++/CLI &gt; TS &gt; Java &gt; Python &gt; JS &gt; C++ &gt; C一天到晚只想用托管类语言的我已经是个废物了 话费不多的请直接跳到文章最后看结果接下来我会一点点讲述我的心路历程 做题 准备项目 用 VS 2022 创建一个新的 C# .NET Core 解决方案 在解决方案中添加一个 C++/CLI .NET Core 类库项目 这里如果使用空白项目的话需要自己配置很多东西而且微软对 C++/CLI 的支持是越来越不好了注意：CLI 项目更改以后需要生成一下才能在 C# 中看到变化 Func: GetRandoms首先我们来实现生成随机数的函数既然两个题目都要求了随机数的产生那么我们就专门做一个函数出来复用 尽可能多的复用我认为是一件非常好的习惯无论是在写代码，还是在生活中 函数定义12345678910using namespace System;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq { public: static List&lt;int&gt;^ GetRandoms(int min, int max, int num) { return nullptr; }}; 这就是我的格式习惯，一股子 Java 味让我们来分析一下这个代码 这是在一个 .h 头文件里面的代码 声明函数的写法就是传统的 C++ namespace 和 using 都和 C# 一样，只不过把 . 变成 :: public 是为了让 C# 可以访问 ref 表明这是一个托管类 static 在我这里是 Helper 的统一写法 List&lt;int&gt;^ 返回一个 托管的 ^ List&lt;int&gt; 类型 托管类型都是从 C# 来的用 C++/CLI 托管的代码可以无缝在 C# 中使用，反之亦然 基本功能1234567891011121314static List&lt;int&gt;^ GetRandoms(int min, int max, int num) { auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res;} Random::Shared 说明了我们现在在使用 .NET Core gcnew 表明了我们要生成一个 托管的 对象 if 语句用来排除重复的随机数，并且确保是 2 和 5 的倍数 i++ 表明我们已经得到了目标，所以我们要让 i 加一，不可以让 for 语句来完成 至此，有一些编程基础的都应该轻松看懂除了一些 CLI 的独特语法以外，其余的和传统 C++ / C# 并无太大区别 数据验证我们写代码的时候还是不要过于相信用户会按照你的想法来使用它毕竟 一个测试工程师走进一家酒吧，啥也没干酒吧就炸了 所以我们简单的加一句： 12if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) throw gcnew ArgumentOutOfRangeException(); 这里我没有写具体的说明，不过正式写代码的时候，报错一定要写清楚原因 完全体123456789101112131415161718192021222324252627#pragma onceusing namespace System;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq sealed { public: static List&lt;int&gt;^ GetRandoms(const int min, const int max, const int num) { if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw gcnew ArgumentOutOfRangeException(); } auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res; } };} Func: GetWagesList我是把两道题一起做的，所以在这个 CLILinq 类里应该还有第二题的方法这个方法用来产生一些随机的 Name:Wages 键值对由于时间关系，我们这里生成的名字就直接按 ASCII 取了 123456789101112static Dictionary&lt;Char, double&gt;^ GetWagesList() { auto random = Random::Shared; auto dictionary = gcnew Dictionary&lt;Char, double&gt;(); Char c = 65; for (auto i = 0; i &lt; 50; i++) { auto wage = random-&gt;NextDouble() * 1000; dictionary-&gt;Add(c++, wage); } return dictionary;} 因为比较简单，所以直接上代码这里不用 char 而是 Char，这样可以直接被 C# 转字符串，方便输出 调用：第一题第一题的调用比较无脑，直接用就行了 123456static void Invoke() { auto randomList = GetRandoms(1, 200, 20); for each (auto num in randomList) { Console::WriteLine(num); }} LINQ：第二题第二题的实际逻辑就在这里也是 LINQ 出场的地方 （原谅我前面瞎扯了那么多） 我们先看实现代码 123456789101112131415161718static void Invoke() { auto wageDic = GetWagesList(); auto v = wageDic-&gt;Values; double sum = 0; for each (auto num in v) { sum += num; } auto avg = sum / 50; auto c = System::Globalization::CultureInfo::CultureInfo::CreateSpecificCulture(&quot;eu-ES&quot;); Console::WriteLine(&quot;Average: &quot; + avg.ToString(&quot;C&quot;, c) + &quot;\\n&quot;); auto ordered = Enumerable::OrderBy(wageDic, gcnew Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;(Select)); for each (auto one in ordered) { Console::WriteLine(one.Key + &quot;: &quot; + one.Value.ToString(&quot;C&quot;, c)); }} for each (auto num in v) 这部分其实就是 Enumerable.Aggregate 的简单实现毕竟要交作业，不能写的那么高级 （其实是嫌麻烦） CultureInfo 就是设置个格式化区域，这里转成欧洲的货币格式avg.ToString(&quot;C&quot;, c) 就是把 avg 转成 Currency LINQ接下来就是 Enumerable.OrderBy 的实现为了搞懂如何传入这个方法需要的参数，我搞了一个多小时到处找资料和 debug… 由于 C++ 11 之前就没有 lambda 表达式，后面有了也非常奇怪所以 LINQ 压根就没有提供类似的调用方式所以我们必须使用 gcnew Func() 的方式传递一个委托 首先，我们必须清楚 Func 的泛型类型到底是什么C++/CLI 在这里 IDE 是完全没有代码提示的，所以我们需要自行分析最好的方式就是在 C# 里面写同样的代码，然后看它们的类型 在这里，Dictionary&lt;Char, double&gt; 的单个元素的类型是 KeyValuePair&lt;Char, double&gt;所以很显然我们需要 Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;现在我们就有了它的类型，然后我们需要实现这个委托 这个委托是一个选择器，它的作用是从类型中选择出一个对象来作为排序的依据在我们这里，就是要从 KeyValuePair 中把 Value 选出来 随后就有了以下代码 123static double Select(KeyValuePair&lt;Char, double&gt; a) { return a.Value;} 非常简单，在特定情况下，你也可以尝试直接内联它之后的事情就非常简单了，该调用调用，该输出输出 实际上先贴一堆代码，可以粗略看看 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697namespace Aloento.SCLILinq;using System.Globalization;public sealed class SCLILinq { public static List&lt;int&gt; GetRandoms(int min, int max, int num) { Random random = null; List&lt;int&gt; list = null; if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw new ArgumentOutOfRangeException(); } random = Random.Shared; list = new List&lt;int&gt;(num); int num2 = 0; while (num2 &lt; num) { int num3 = random.Next(min, max); if (!list.Contains(num3) &amp;&amp; (num3 % 2 == 0 || num3 % 5 == 0)) { num2++; list.Add(num3); } } return list; } public static Dictionary&lt;char, double&gt; GetWagesList() { Random random = null; Dictionary&lt;char, double&gt; dictionary = null; random = Random.Shared; dictionary = new Dictionary&lt;char, double&gt;(); char c = 'A'; for (int i = 0; i &lt; 50; i++) { double value = random.NextDouble() * 1000.0; char key = c; c = (char)(c + 1); dictionary.Add(key, value); } return dictionary; } public static double Select(KeyValuePair&lt;char, double&gt; a) { return a.Value; } public static void Invoke() { List&lt;int&gt; list = null; Dictionary&lt;char, double&gt; dictionary = null; Dictionary&lt;char, double&gt;.ValueCollection valueCollection = null; CultureInfo cultureInfo = null; IOrderedEnumerable&lt;KeyValuePair&lt;char, double&gt;&gt; orderedEnumerable = null; IEnumerator&lt;KeyValuePair&lt;char, double&gt;&gt; enumerator = null; list = GetRandoms(1, 200, 20); List&lt;int&gt;.Enumerator enumerator2 = list.GetEnumerator(); while (enumerator2.MoveNext()) { int current = enumerator2.Current; Console.WriteLine(current); } Console.WriteLine(&quot;\\n-------------------------------\\n&quot;); dictionary = GetWagesList(); valueCollection = dictionary.Values; double num = 0.0; Dictionary&lt;char, double&gt;.ValueCollection.Enumerator enumerator3 = valueCollection.GetEnumerator(); while (enumerator3.MoveNext()) { double current2 = enumerator3.Current; num += current2; } double num2 = num / 50.0; cultureInfo = CultureInfo.CreateSpecificCulture(&quot;eu-ES&quot;); string str = &quot;\\n&quot;; double num3 = num2; string str2 = num3.ToString(&quot;C&quot;, cultureInfo); Console.WriteLine(string.Concat(&quot;Average: &quot; + str2, str)); orderedEnumerable = Enumerable.OrderBy(dictionary, new Func&lt;KeyValuePair&lt;char, double&gt;, double&gt;(Select)); enumerator = orderedEnumerable.GetEnumerator(); try { while (enumerator.MoveNext()) { KeyValuePair&lt;char, double&gt; current3 = enumerator.Current; double value = current3.Value; string format = &quot;C&quot;; string str3 = value.ToString(format, cultureInfo); string arg = &quot;: &quot;; Console.WriteLine(string.Concat(current3.Key + arg, str3)); } } finally { IEnumerator&lt;KeyValuePair&lt;char, double&gt;&gt; enumerator4 = enumerator; if (enumerator4 != null) { enumerator4.Dispose(); long num4 = 0L; } else { long num4 = 0L; } } }} 这是直接对 C++/CLI 生成的库反编译的结果我们可以发现，这就相当于是写了一堆 C# 而已如果带指针之类的，就是 unsafe所以：没必要，别用 C++/CLI 适用范围 如果你想 Wrapper 一个 C / C++ 的库给 C# 用 如果你想让 .NET 与其他语言一起工作 让 C++ 享受 .NET 的生态 如果你闲得慌想找点事情干 在大部分情况下，C++/CLI 的存在都是为了高效的让 C# 与 C / C++ 交互而使用使用它可以让你的 .NET 项目享受到 C++ 全套的生态，反之亦然毕竟 P/Invoke 并不优雅 在托管类语言中，C++/CLI 在一定程度上让 C# 成了最容易与 C / C++ 交互的语言进而让它也更容易与能够和 C / C++ 交互的语言交互 使用它，你需要同时掌握 C# 和 C++而且在很多时候，IDE 不会给你有效的提示所以学习它需要很多时间来尝试 结论12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970using namespace System;using namespace Linq;using namespace Collections::Generic;namespace Aloento::CLILinq { public ref class CLILinq sealed { public: static List&lt;int&gt;^ GetRandoms(const int min, const int max, const int num) { if (max / 2 + max / 5 - (min / 2 + min / 5) &lt; num) { throw gcnew ArgumentOutOfRangeException(); } auto random = Random::Shared; auto res = gcnew List&lt;int&gt;(num); for (auto i = 0; i &lt; num;) { auto r = random-&gt;Next(min, max); if (!res-&gt;Contains(r) &amp;&amp; (r % 2 == 0 || r % 5 == 0)) { i++; res-&gt;Add(r); } } return res; } static Dictionary&lt;Char, double&gt;^ GetWagesList() { auto random = Random::Shared; auto dictionary = gcnew Dictionary&lt;Char, double&gt;(); Char c = 65; for (auto i = 0; i &lt; 50; i++) { auto wage = random-&gt;NextDouble() * 1000; dictionary-&gt;Add(c++, wage); } return dictionary; } static double Select(KeyValuePair&lt;Char, double&gt; a) { return a.Value; } static void Invoke() { auto randomList = GetRandoms(1, 200, 20); for each (auto num in randomList) { Console::WriteLine(num); } Console::WriteLine(&quot;\\n-------------------------------\\n&quot;); auto wageDic = GetWagesList(); auto v = wageDic-&gt;Values; double sum = 0; for each (auto num in v) { sum += num; } auto avg = sum / 50; auto c = System::Globalization::CultureInfo::CultureInfo::CreateSpecificCulture(&quot;eu-ES&quot;); Console::WriteLine(&quot;Average: &quot; + avg.ToString(&quot;C&quot;, c) + &quot;\\n&quot;); auto ordered = Enumerable::OrderBy(wageDic, gcnew Func&lt;KeyValuePair&lt;Char, double&gt;, double&gt;(Select)); for each (auto one in ordered) { Console::WriteLine(one.Key + &quot;: &quot; + one.Value.ToString(&quot;C&quot;, c)); } } };}","link":"/Program/C/CLI/%E8%AE%BA%E5%A6%82%E4%BD%95%E5%9C%A8CPPCLI%E4%B8%AD%E4%BD%BF%E7%94%A8LINQ%E4%B9%8B%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%A5%87%E5%A6%99%E7%9A%84CPP%E5%A4%A7%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"},{"name":"考试","slug":"考试","link":"/tags/%E8%80%83%E8%AF%95/"},{"name":"数据科学","slug":"数据科学","link":"/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"习题","slug":"习题","link":"/tags/%E4%B9%A0%E9%A2%98/"},{"name":"SQLServer","slug":"SQLServer","link":"/tags/SQLServer/"},{"name":"Matplotlib","slug":"Matplotlib","link":"/tags/Matplotlib/"},{"name":"编程","slug":"编程","link":"/tags/%E7%BC%96%E7%A8%8B/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"数值方法","slug":"数值方法","link":"/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"},{"name":"云","slug":"云","link":"/tags/%E4%BA%91/"},{"name":"OpenStack","slug":"OpenStack","link":"/tags/OpenStack/"},{"name":"图灵机","slug":"图灵机","link":"/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"},{"name":"匈牙利","slug":"匈牙利","link":"/tags/%E5%8C%88%E7%89%99%E5%88%A9/"},{"name":"留学","slug":"留学","link":"/tags/%E7%95%99%E5%AD%A6/"},{"name":"攻略","slug":"攻略","link":"/tags/%E6%94%BB%E7%95%A5/"},{"name":"逻辑","slug":"逻辑","link":"/tags/%E9%80%BB%E8%BE%91/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"翻译","slug":"翻译","link":"/tags/%E7%BF%BB%E8%AF%91/"},{"name":"音视频","slug":"音视频","link":"/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"WebCodecs","slug":"WebCodecs","link":"/tags/WebCodecs/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"CLI","slug":"CLI","link":"/tags/CLI/"},{"name":"LINQ","slug":"LINQ","link":"/tags/LINQ/"},{"name":".NET","slug":"NET","link":"/tags/NET/"}],"categories":[{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Data Science","slug":"Data-Science","link":"/categories/Data-Science/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Program","slug":"Program","link":"/categories/Program/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"MSSQL","slug":"Database/MSSQL","link":"/categories/Database/MSSQL/"},{"name":"Python","slug":"Program/Python","link":"/categories/Program/Python/"},{"name":"NLP","slug":"AI/NLP","link":"/categories/AI/NLP/"},{"name":"Math","slug":"Math","link":"/categories/Math/"},{"name":"Cloud","slug":"Cloud","link":"/categories/Cloud/"},{"name":"TM","slug":"Algorithm/TM","link":"/categories/Algorithm/TM/"},{"name":"Memo","slug":"Memo","link":"/categories/Memo/"},{"name":"Theory","slug":"Database/Theory","link":"/categories/Database/Theory/"},{"name":"Matlab","slug":"Math/Matlab","link":"/categories/Math/Matlab/"},{"name":"OpenStack","slug":"Cloud/OpenStack","link":"/categories/Cloud/OpenStack/"},{"name":"Logic","slug":"Math/Logic","link":"/categories/Math/Logic/"},{"name":"WebCodecs","slug":"Program/WebCodecs","link":"/categories/Program/WebCodecs/"},{"name":"C++","slug":"Program/C","link":"/categories/Program/C/"},{"name":"CLI","slug":"Program/C/CLI","link":"/categories/Program/C/CLI/"}],"pages":[]}