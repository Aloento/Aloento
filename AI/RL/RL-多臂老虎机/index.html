<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>RL-多臂老虎机 - Aloento</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f0f0f0"><meta name="application-name" content="Aloento"><meta name="msapplication-TileImage" content="/img/Aloento.png"><meta name="msapplication-TileColor" content="#f0f0f0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aloento"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="72x72" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="96x96" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="128x128" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="256x256" href="/img/Aloento.png"><meta name="description" content="强化学习强化的不是机器模型而是我的猪脑"><meta property="og:type" content="blog"><meta property="og:title" content="RL-多臂老虎机"><meta property="og:url" content="https://aloen.to/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/"><meta property="og:site_name" content="Aloento"><meta property="og:description" content="强化学习强化的不是机器模型而是我的猪脑"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://aloen.to/img/og_image.png"><meta property="article:published_time" content="2025-02-23T15:09:25.000Z"><meta property="article:modified_time" content="2025-06-02T14:16:29.693Z"><meta property="article:author" content="Aloento"><meta property="article:tag" content="笔记"><meta property="article:tag" content="AI"><meta property="article:tag" content="RL"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://aloen.to/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://aloen.to/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/"},"headline":"RL-多臂老虎机","image":["https://aloen.to/img/og_image.png"],"datePublished":"2025-02-23T15:09:25.000Z","dateModified":"2025-06-02T14:16:29.693Z","author":{"@type":"Person","name":"Aloento"},"publisher":{"@type":"Organization","name":"Aloento","logo":{"@type":"ImageObject","url":"https://aloen.to/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/"}},"description":"强化学习强化的不是机器模型而是我的猪脑"}</script><link rel="canonical" href="https://aloen.to/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/"><link rel="icon" href="/img/Aloento.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aloento</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://Q-Audio.org/Aloento">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-23T15:09:25.000Z" title="2/23/2025, 3:09:25 PM">2025-02-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-06-02T14:16:29.693Z" title="6/2/2025, 2:16:29 PM">2025-06-02</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/RL/">RL</a></span><span class="level-item">23 minutes read (About 3435 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">RL-多臂老虎机</h1><div class="content"><p><del>强化学习</del><br><del>强化的不是机器模型</del><br><del>而是我的猪脑</del></p>
<span id="more"></span>

<h1 id="老虎机"><a href="#老虎机" class="headerlink" title="老虎机"></a>老虎机</h1><h2 id="单臂"><a href="#单臂" class="headerlink" title="单臂"></a>单臂</h2><p>现在在你面前有一台老虎机，它有固定的中奖率，当你拉动它，你就会从固定的概率分布中得到奖励。而这个情况不能视作一个强化学习问题，因为它只有一个状态和一个动作，你不能通过任何方法来优化你的策略。</p>
<h2 id="多臂"><a href="#多臂" class="headerlink" title="多臂"></a>多臂</h2><p>既然如此，我们就拿来多台老虎机。现在在你面前有数台单臂老虎机，它们各自有不同的中奖分布。现在给定有限的拉动次数 T，你如何拉动这些老虎机来最大化你的收益呢？</p>
<p>这个问题是一个 非联想的，评估性的反馈问题，及每次反馈只评估当前动作，也就是独立事件。</p>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li><p>非联想的：Non-Assocative，即每次动作的结果不会影响到接下来你对其他老虎机的预期收益。你只是单纯的记录下每个老虎机的平均奖励，然后选择最大的那个。</p>
</li>
<li><p>联想的：Associative，当前动作的结果会影响到未来动作的预期收益。你从这次拉动中获得的信息，会影响到你对其他老虎机的选择。在类似于上下文老虎机中，你的动作会影响其他老虎机的中奖概率。</p>
</li>
<li><p>评估性的：Evaluative，你得到的奖励，只是你当前动作的结果，你只能知道你刚刚得到了多少收益，而不能知道其他老虎机的中奖概率。</p>
</li>
<li><p>指导性的：Instructive，在这种情况下，你不光能得到当前的结果，还能得到其他可能的结果信息。比如你拉动了一个老虎机，你不仅得到奖励，还能得到其他老虎机的奖励信息，即使你没有选择它们。</p>
</li>
</ul>
<h1 id="Formalization"><a href="#Formalization" class="headerlink" title="Formalization"></a>Formalization</h1><p>需要数学的方式表达此问题才能应用到计算机中。所以我们定义：</p>
<ul>
<li>t 时刻</li>
<li>$A_t$ 在 t 时刻选择的动作</li>
<li>$R_t$ 在 t 时刻得到的奖励</li>
<li>$q_*(a)$ 动作 a 的真实值，是一个固定值，但通常未知</li>
<li>$Q_t(a)$ 在 t 时刻对动作 a 的估计值，根据过去的经验得到</li>
</ul>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>假设你面前有三个老虎机 1, 2, 3，你有 4 个可用次数：</p>
<table>
<thead>
<tr>
<th>时刻 t</th>
<th>选择 $A_t$</th>
<th>奖励 $R_t$</th>
<th>期望 $Q_t(1)$</th>
<th>$Q_t(2)$</th>
<th>$Q_t(3)$</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
<td>5</td>
<td>5</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>3</td>
<td>5</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td><strong>1</strong></td>
<td>4</td>
<td>4.5</td>
<td>3</td>
<td>4</td>
</tr>
</tbody></table>
<p>每次选择一个动作并获得奖励后，需要更新对该动作的估计值。这里我们使用简单的平均值来估计：</p>
<div>
$$
Q_t(a) = \frac{\sum_{i=1}^{t-1} R_i \cdot \mathbb{1}_{A_i = a}}{\sum_{i=1}^{t-1} \mathbb{1}_{A_i = a}}
$$
</div>

<p>$\mathbb{1}_{A_i &#x3D; a}$ 是一个指示函数，当 $A_i &#x3D; a$ 时为 1，否则为 0。确保了只有选择了动作 a 的时候才会更新估计值。</p>
<p>这就是 Action-value Methods，即通过动作的估计值来选择动作。</p>
<h2 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h2><p>简而言之，如果一个事情你做的次数足够多，那么它的平均结果（预估收益）就会接近于它的真实情况。比如抛硬币，正反面比例会越来越接近 0.5。</p>
<h2 id="探索和利用"><a href="#探索和利用" class="headerlink" title="探索和利用"></a>探索和利用</h2><p>让我们来理解一下 探索 (Exploration) 和 利用 (Exploitation) 的概念。</p>
<ul>
<li><p>在任何时间步，至少有一个动作的估计值是最大的。也就是说如果我们选择了一个最大的动作，这就是利用，或者贪婪动作。</p>
</li>
<li><p>如果我们选择非贪婪动作，那么就是探索，去试试看能否找到更好的动作。</p>
</li>
</ul>
<p>像之前表中我们在 t&#x3D;4 的时候选择了 1，这就是贪婪动作。但是我们会发现一个问题：</p>
<ul>
<li>为了获得最大奖励，我们偏好选择已知的最大动作</li>
<li>但是如果我们不去探索其他动作，我们就无法知道其他动作的真实值</li>
<li>所以我们需要在探索和利用之间找到一个平衡</li>
</ul>
<h1 id="epsilon-greedy"><a href="#epsilon-greedy" class="headerlink" title="$\epsilon$-greedy"></a>$\epsilon$-greedy</h1><p>它是平衡探索和利用的一个简单有效的方法。</p>
<ul>
<li>以 $\epsilon$ 的概率进行探索，而不考虑价值估计</li>
<li>以 $1-\epsilon$ 的概率进行利用（贪心动作），选择已知的最大价值动作</li>
</ul>
<h2 id="练习：计算概率"><a href="#练习：计算概率" class="headerlink" title="练习：计算概率"></a>练习：计算概率</h2><p>当 $\epsilon &#x3D; 0.5$ 时，计算有两个动作，且选择贪心动作的概率。</p>
<blockquote>
<p>two actions 不是说你选两次，而是说你在每次选择动作的时候，一共有两个可能，如选 A 或 B。</p>
</blockquote>
<ol>
<li><p>情况 1：确定选择 ($1-\epsilon$)：&#x3D; 0.5 的概率直接选择贪心动作</p>
</li>
<li><p>情况 2：随机选择所有动作，也包括选中贪心动作的概率，此时：</p>
<ul>
<li>选择贪心动作的概率 &#x3D; 非贪心动作的概率 &#x3D; 0.5</li>
<li>同时发生 情况 2 &amp; 情况 2 选中贪心动作 的概率 &#x3D; 0.5 * 0.5 &#x3D; 0.25</li>
</ul>
</li>
</ol>
<p>所以选择贪心动作的概率 &#x3D; 情况 1 + 情况 2 &#x3D; 0.5 + 0.25 &#x3D; 0.75</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">           选择方式</span><br><span class="line">          /      \</span><br><span class="line">   情况1 (0.5)   情况2 (0.5)</span><br><span class="line">      /             /   \</span><br><span class="line">选贪心动作      选A(0.5) 选B(0.5)</span><br></pre></td></tr></table></figure>

<h2 id="练习：策略选择"><a href="#练习：策略选择" class="headerlink" title="练习：策略选择"></a>练习：策略选择</h2><p>有 K 臂老虎机，K &#x3D; 4，四个动作标记为 [1, 2, 3, 4]。应用 $\epsilon$-greedy &amp; sample-average 方法来选择动作。所有动作初始值 $Q_1(a) &#x3D; 0$。假设前五个时间步的动作和奖励序列如下：</p>
<table>
<thead>
<tr>
<th>时刻 t</th>
<th>选择 $A_t$</th>
<th>奖励 $R_t$</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>3</td>
<td>0</td>
</tr>
</tbody></table>
<p>问：在哪些时间步 <strong>一定</strong> 发生了探索？在哪些时间步 <strong>可能</strong> 发生了探索？</p>
<p>解：</p>
<p>由于 5 步内未选择 4，所以在表中隐去。情况描述的是从上一个状态到当前状态。</p>
<table>
<thead>
<tr>
<th>时刻 t</th>
<th>选择 $A_t$</th>
<th>奖励 $R_t$</th>
<th>期望 $Q_t(1)$</th>
<th>$Q_t(2)$</th>
<th>$Q_t(3)$</th>
<th>情况</th>
<th>细节</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-</td>
<td>初始值</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>可能</td>
<td>所有动作初始等效，无法区分</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>一定</td>
<td>选择了一个非最优动作</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1.5</td>
<td>0</td>
<td>可能</td>
<td>选择了最大值动作，但是 1 和 2 值相同</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1.66</td>
<td>0</td>
<td>可能</td>
<td>2 成为最优，但 2 可能是被随机选中的</td>
</tr>
<tr>
<td>5</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>1.66</td>
<td>0</td>
<td>一定</td>
<td>选择了一个非最优动作</td>
</tr>
</tbody></table>
<h1 id="增量更新"><a href="#增量更新" class="headerlink" title="增量更新"></a>增量更新</h1><p>记录所有的奖励数据需要占用大量内存，incremental implementation 可以节省内存。通过推导，我们能够得到加权平均的增量更新公式：</p>
<p>$$<br>Q_{n+1} &#x3D; Q_n + \alpha \cdot (R_n - Q_n)<br>$$</p>
<p>其中：</p>
<ul>
<li>$Q_{n+1}$ 是新的估计值</li>
<li>$Q_n$ 是旧的估计值</li>
<li>$R_n$ 是本次奖励</li>
<li>$\alpha$ 是学习率，通常是一个小于 1 的值</li>
</ul>
<h2 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h2><ul>
<li><p>静态环境<br>当 $\alpha &#x3D; \frac{1}{n}$ 时，即学习率随着时间步的增加而减小，适用于 Stationary Environment，即环境的奖励分布不会随时间变化，保证了所有过去的数据都以同等权重参与更新。</p>
</li>
<li><p>动态环境<br>当学习率是一个固定值，通常 $0 &lt; \alpha \leq 1$ 时，适用于 Non-Stationary Environment，即环境的奖励分布会随时间变化，近期的奖励对估计值影响更大，而早期的奖励影响较小。</p>
</li>
</ul>
<p>而使用固定的学习率，其实是一种 指数加权平均 (Exponential Weighted Average)，通过对普通加权平均公式的变形，我们可以得到：</p>
<p>$$<br>Q_{n+1} &#x3D; (1-\alpha)^n Q_1 + \sum_{i&#x3D;1}^n \alpha(1-\alpha)^{n-i} R_i<br>$$</p>
<p>阅读公式我们可以知道：</p>
<ul>
<li>当 $n$ 很大时，$(1-\alpha)^n$ 趋近于 0，即初始值的影响越来越小</li>
<li>第二项是一个加权和，权重随着时间步的增加而减小，也就是说近期的奖励对估计值影响更大</li>
<li>较大的 $\alpha$ 适合快速变化的环境</li>
</ul>
<h1 id="乐观初始值"><a href="#乐观初始值" class="headerlink" title="乐观初始值"></a>乐观初始值</h1><p>Optimistic Initial Values 通过人为的为所有动作的估计值设置一个过高的初始值，可以鼓励探索。随着时间步的增加，估计值会逐渐收敛到真实值。相比与 $\epsilon$-greedy，它不依赖随机探索，而是基于策略性搜索。代理会确保所有动作都被选择一次，然后根据奖励来调整估计值，而不会陷入局部最优。适用于静态环境和早期探索。</p>
<h1 id="上限置信区间"><a href="#上限置信区间" class="headerlink" title="上限置信区间"></a>上限置信区间</h1><p>一种更智能的决策方案是 Upper Confidence Bound (UCB)。它的公式是：</p>
<p>$$<br>A_t &#x3D; \arg \max_a \left[ Q_t(a) + c \sqrt{\frac{\ln t}{N_t(a)}} \right]<br>$$</p>
<p>公式直观的分为三部分：</p>
<ul>
<li><p>$Q_t(a)$ 利用项，是动作 a 当前的最佳估计值，高则 UCB 也高，意味着可能是好选择</p>
</li>
<li><p>$\sqrt{\frac{\ln t}{N_t(a)}}$ 探索项</p>
<ul>
<li>未被尝试的动作 $N_t(a)$ 较小，置信界较大，需要更多的探索</li>
<li>已被尝试的动作 $N_t(a)$ 较大，置信界较小，主要依赖于 $Q_t(a)$，即利用</li>
<li>随着时间步的增加，探索压力逐渐减小，因为 $ln t$ 的增长速度很慢，而 $N_t(a)$ 一直增加</li>
<li>$c$ 是一个探索参数，控制探索的强度，越大越多探索</li>
</ul>
</li>
<li><p>$A_t$ 是选择的动作，$\arg \max_a$ 来决定最大 UCB 值及其对应的动作</p>
</li>
</ul>
<p>当 UCB 高的时候，代表了两种情况，一是动作本来就很好（$Q_t(a)$ 高），二是动作未被充分尝试过（$N_t(a)$ 低），而这个结果本身代表着 探索 + 利用 的收益估计值。该方法优于 $\epsilon$-greedy，减少随机性带来的浪费，适用于静态环境。</p>
<blockquote>
<p>探索项其实是通过 Hoeffding Inequality 推导出来的，不等式提供了样本均值与真实均值的误差范围，误差项的形式正是 $\sqrt{\frac{\ln t}{N_t(a)}}$。</p>
</blockquote>
<h1 id="策略梯度"><a href="#策略梯度" class="headerlink" title="策略梯度"></a>策略梯度</h1><p>它通过调整每个动作的概率来优化策略。使用 softmax 函数来表示：</p>
<p>$$<br>\pi_t(a) &#x3D; \frac{e^{H_t(a)}}{\sum_{b&#x3D;1}^K e^{H_t(b)}}<br>$$</p>
<p>其中：</p>
<ul>
<li>$\pi_t(a)$ 是动作 a 在 t 时刻被选择的概率</li>
<li>$H_t(a)$ 是动作 a 在 t 时刻的偏好值，不直接表示概率，而是一个中间量</li>
<li>K 是动作的数量</li>
</ul>
<p>此算法不会死板地只选一个动作，因为所有的选择都有一定概率被探索，更适合非静态环境，但是对学习率较敏感，不容易调优。</p>
<h2 id="梯度上升（Ascent）"><a href="#梯度上升（Ascent）" class="headerlink" title="梯度上升（Ascent）"></a>梯度上升（Ascent）</h2><p>我们的目标是优化动作选择的概率，而不是直接估计奖励值。在时间 t：</p>
<ol>
<li>选中动作 a</li>
<li>得到奖励 $R_t$</li>
<li>计算奖励与 平均奖励 $\bar{R_t}$ 的差值 $\delta_t &#x3D; R_t - \bar{R_t}$<ul>
<li>如果 $\delta_t &gt; 0$，则动作 a 是好的，我们希望增加它的概率</li>
<li>如果 $\delta_t &lt; 0$，则动作 a 是坏的，我们希望减少它的概率</li>
</ul>
</li>
<li>更新偏好值 $H_t(a)$，其他未选中的 $H_t(b)$ 也会轻微变化，因为 softmax 函数的特性</li>
</ol>
<p>所以公式如下, 其中 $\alpha$ 是学习率：</p>
<p>$$<br>H_{t+1}(a) &#x3D; H_t(a) + \alpha (R_t - \bar{R_t})(1 - \pi_t(a))<br>$$</p>
<p>其他未选中的动作：</p>
<p>$$<br>H_{t+1}(b) &#x3D; H_t(b) - \alpha (R_t - \bar{R_t})\pi_t(b)<br>$$</p>
<h1 id="关联搜索"><a href="#关联搜索" class="headerlink" title="关联搜索"></a>关联搜索</h1><p>Assocative Search 是对之前 联想任务 的扩展，是在 多情境（context）下的决策优化。</p>
<ul>
<li>在 Associative 中，动作可能影响未来收益，但问题仍然是单一情境。</li>
<li>而在 Associative Search 中，不仅要学习单个情境下的最优动作，还需要在多个情境中学习不同策略。</li>
</ul>
<p>对于这种问题，我们为每一种情境学习一个独立的策略。如果动作不仅影响奖励，还影响接下来的情境，那么这个问题就升级为完整的强化学习任务。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>现在有两组 2-臂老虎机，你面对的老虎机组会在每个时间步随机变化：</p>
<ol>
<li>A 组（概率 0.5）：<ul>
<li>Arm 1 的真实值：0.1</li>
<li>Arm 2 的真实值：0.2</li>
</ul>
</li>
<li>B 组（概率 0.5）：<ul>
<li>Arm 1 的真实值：0.9</li>
<li>Arm 2 的真实值：0.8</li>
</ul>
</li>
</ol>
<p>你无论如何也不知道它们的真实值，问：</p>
<ol>
<li>如果你 不知道 当前是 A 组还是 B 组，你会如何选择动作？</li>
<li>如果你 知道 当前是 A 组还是 B 组，你会如何选择动作？</li>
</ol>
<h3 id="情况-1"><a href="#情况-1" class="headerlink" title="情况 1"></a>情况 1</h3><p>如果我不能知道当前情况，那么我只能根据期望值来决策：</p>
<p>对于 Arm 1，它的期望奖励是：</p>
<p>$$<br>E[R_1] &#x3D; 0.5 \cdot 0.1 + 0.5 \cdot 0.9 &#x3D; 0.5<br>$$</p>
<p>对于 Arm 2，它的期望奖励是：</p>
<p>$$<br>E[R_2] &#x3D; 0.5 \cdot 0.2 + 0.5 \cdot 0.8 &#x3D; 0.5<br>$$</p>
<p>所以，由于两个动作的期望奖励相同，我会随机选择一个动作。<br>最大期望收益就是 0.5。</p>
<h3 id="情况-2"><a href="#情况-2" class="headerlink" title="情况 2"></a>情况 2</h3><p>当我知道现在的情况时，我就能够有针对性的选择策略。</p>
<ol>
<li><p>在 A 组时（概率 0.5）：</p>
<ul>
<li>选择 Arm 1 的期望奖励是 0.1</li>
<li>选择 Arm 2 的期望奖励是 0.2</li>
<li>所以我会选择 Arm 2</li>
</ul>
</li>
<li><p>在 B 组时（概率 0.5）：</p>
<ul>
<li>选择 Arm 1 的期望奖励是 0.9</li>
<li>选择 Arm 2 的期望奖励是 0.8</li>
<li>所以我会选择 Arm 1</li>
</ul>
</li>
</ol>
<p>它的最大期望奖励是：</p>
<p>$$<br>E[R_{best}] &#x3D; 0.5 \cdot 0.2 + 0.5 \cdot 0.9 &#x3D; 0.55<br>$$</p>
<p>有额外的上下文信息（context）可以帮助提高决策质量，这正是 <strong>关联搜索（Associative Search）</strong> 的关键思想。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>RL-多臂老虎机</p><p><a href="https://aloen.to/AI/RL/RL-多臂老虎机/">https://aloen.to/AI/RL/RL-多臂老虎机/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Aloento</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2025-02-23</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2025-06-02</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/RL/">RL</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/AI/RL/RL-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">RL-马尔可夫决策过程</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Algorithm/%E8%BF%B7%E5%AE%AB%E5%AF%BB%E8%B7%AF/"><span class="level-item">迷宫寻路</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/Aloento.png" alt="Aloento"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Aloento</p><p class="is-size-6 is-block">Reindeer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Foot of Sacred Mountain</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">70</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">37</p></a></div></div></nav></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/CogSci/"><span class="level-start"><span class="level-item">CogSci</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/RL/"><span class="level-start"><span class="level-item">RL</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/TM/"><span class="level-start"><span class="level-item">TM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Cloud/"><span class="level-start"><span class="level-item">Cloud</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Cloud/OpenStack/"><span class="level-start"><span class="level-item">OpenStack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Data-Science/"><span class="level-start"><span class="level-item">Data Science</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/MSSQL/"><span class="level-start"><span class="level-item">MSSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Theory/"><span class="level-start"><span class="level-item">Theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math/Logic/"><span class="level-start"><span class="level-item">Logic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/Matlab/"><span class="level-start"><span class="level-item">Matlab</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Memo/"><span class="level-start"><span class="level-item">Memo</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/"><span class="level-start"><span class="level-item">Program</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Program/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/WebCodecs/"><span class="level-start"><span class="level-item">WebCodecs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/NET/"><span class="tag">.NET</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">39</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C#</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS/"><span class="tag">JS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LINQ/"><span class="tag">LINQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenStack/"><span class="tag">OpenStack</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RL/"><span class="tag">RL</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQLServer/"><span class="tag">SQLServer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WebCodecs/"><span class="tag">WebCodecs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B9%A0%E9%A2%98/"><span class="tag">习题</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91/"><span class="tag">云</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A0%E5%AF%86%E8%B4%A7%E5%B8%81/"><span class="tag">加密货币</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%88%E7%89%99%E5%88%A9/"><span class="tag">匈牙利</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"><span class="tag">图灵机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%BB%E7%95%A5/"><span class="tag">攻略</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"><span class="tag">数值方法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"><span class="tag">数据科学</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%95%99%E5%AD%A6/"><span class="tag">留学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">54</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%BB%E8%AF%91/"><span class="tag">翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%80%83%E8%AF%95/"><span class="tag">考试</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A4%E7%9F%A5%E7%A7%91%E5%AD%A6/"><span class="tag">认知科学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%BB%E8%BE%91/"><span class="tag">逻辑</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tag">面试</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"><span class="tag">音视频</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://Q-Audio.org" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Q-Audio</span></span><span class="level-right"><span class="level-item tag">q-audio.org</span></span></a></li><li><a class="level is-mobile" href="https://Musi.Land" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">MusiLand</span></span><span class="level-right"><span class="level-item tag">musi.land</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#老虎机"><span class="level-left"><span class="level-item">1</span><span class="level-item">老虎机</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#单臂"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">单臂</span></span></a></li><li><a class="level is-mobile" href="#多臂"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">多臂</span></span></a></li><li><a class="level is-mobile" href="#定义"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">定义</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Formalization"><span class="level-left"><span class="level-item">2</span><span class="level-item">Formalization</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#例子"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">例子</span></span></a></li><li><a class="level is-mobile" href="#大数定律"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">大数定律</span></span></a></li><li><a class="level is-mobile" href="#探索和利用"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">探索和利用</span></span></a></li></ul></li><li><a class="level is-mobile" href="#epsilon-greedy"><span class="level-left"><span class="level-item">3</span><span class="level-item">$\epsilon$-greedy</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#练习：计算概率"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">练习：计算概率</span></span></a></li><li><a class="level is-mobile" href="#练习：策略选择"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">练习：策略选择</span></span></a></li></ul></li><li><a class="level is-mobile" href="#增量更新"><span class="level-left"><span class="level-item">4</span><span class="level-item">增量更新</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#学习率"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">学习率</span></span></a></li></ul></li><li><a class="level is-mobile" href="#乐观初始值"><span class="level-left"><span class="level-item">5</span><span class="level-item">乐观初始值</span></span></a></li><li><a class="level is-mobile" href="#上限置信区间"><span class="level-left"><span class="level-item">6</span><span class="level-item">上限置信区间</span></span></a></li><li><a class="level is-mobile" href="#策略梯度"><span class="level-left"><span class="level-item">7</span><span class="level-item">策略梯度</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#梯度上升（Ascent）"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">梯度上升（Ascent）</span></span></a></li></ul></li><li><a class="level is-mobile" href="#关联搜索"><span class="level-left"><span class="level-item">8</span><span class="level-item">关联搜索</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#练习"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">练习</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#情况-1"><span class="level-left"><span class="level-item">8.1.1</span><span class="level-item">情况 1</span></span></a></li><li><a class="level is-mobile" href="#情况-2"><span class="level-left"><span class="level-item">8.1.2</span><span class="level-item">情况 2</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-06-01T09:58:41.000Z">2025-06-01</time></p><p class="title"><a href="/Memo/%E9%87%8F%E5%8C%96%E6%97%A5%E8%AE%B0/">量化日记</a></p><p class="categories"><a href="/categories/Memo/">Memo</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-24T08:50:53.000Z">2025-05-24</time></p><p class="title"><a href="/AI/RL/RL-Endterm/">RL-Endterm</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-24T04:19:25.000Z">2025-05-24</time></p><p class="title"><a href="/AI/RL/RL-%E8%B5%84%E6%A0%BC%E8%BF%B9/">RL-资格迹</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-07T02:15:33.000Z">2025-05-07</time></p><p class="title"><a href="/Algorithm/DAA-Endterm/">DAA Endterm</a></p><p class="categories"><a href="/categories/Algorithm/">Algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-05T09:19:25.000Z">2025-05-05</time></p><p class="title"><a href="/Data-Science/ITDS-%E5%88%86%E7%B1%BB/">ITDS-分类</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">June 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">May 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><span>&copy; 2025 Aloento</span><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>