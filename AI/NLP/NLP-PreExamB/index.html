<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>NLP-PreExamB - Aloento</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f0f0f0"><meta name="application-name" content="Aloento"><meta name="msapplication-TileImage" content="/img/Aloento.png"><meta name="msapplication-TileColor" content="#f0f0f0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aloento"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="72x72" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="96x96" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="128x128" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="256x256" href="/img/Aloento.png"><meta name="description" content="论文加考试，要死了"><meta property="og:type" content="blog"><meta property="og:title" content="NLP-PreExamB"><meta property="og:url" content="https://aloen.to/AI/NLP/NLP-PreExamB/"><meta property="og:site_name" content="Aloento"><meta property="og:description" content="论文加考试，要死了"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://aloen.to/img/og_image.png"><meta property="article:published_time" content="2024-11-16T10:22:06.000Z"><meta property="article:modified_time" content="2025-03-18T15:49:27.609Z"><meta property="article:author" content="Aloento"><meta property="article:tag" content="考试"><meta property="article:tag" content="笔记"><meta property="article:tag" content="AI"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://aloen.to/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://aloen.to/AI/NLP/NLP-PreExamB/"},"headline":"NLP-PreExamB","image":["https://aloen.to/img/og_image.png"],"datePublished":"2024-11-16T10:22:06.000Z","dateModified":"2025-03-18T15:49:27.609Z","author":{"@type":"Person","name":"Aloento"},"publisher":{"@type":"Organization","name":"Aloento","logo":{"@type":"ImageObject","url":"https://aloen.to/AI/NLP/NLP-PreExamB/"}},"description":"论文加考试，要死了"}</script><link rel="canonical" href="https://aloen.to/AI/NLP/NLP-PreExamB/"><link rel="icon" href="/img/Aloento.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aloento</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://Q-Audio.org/Aloento">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-16T10:22:06.000Z" title="11/16/2024, 10:22:06 AM">2024-11-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-18T15:49:27.609Z" title="3/18/2025, 3:49:27 PM">2025-03-18</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/NLP/">NLP</a></span><span class="level-item">41 minutes read (About 6180 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">NLP-PreExamB</h1><div class="content"><p><del>论文加考试，要死了</del></p>
<span id="more"></span>

<h1 id="B1-注意力机制"><a href="#B1-注意力机制" class="headerlink" title="B1 注意力机制"></a>B1 注意力机制</h1><h2 id="Seq2seq-基础"><a href="#Seq2seq-基础" class="headerlink" title="Seq2seq 基础"></a>Seq2seq 基础</h2><p>S2S 是基于 RNN 的，将一个任意长度的序列，变成另一个任意长度的序列。</p>
<p>它由 编码器 和 解码器 组成。</p>
<p>编码器输出一个固定长度的向量，其维度是隐藏层的大小。<br>一般是编码器最后的状态（单向 RNN），或者是平均或最大池化（双向 RNN）。</p>
<h2 id="瓶颈问题"><a href="#瓶颈问题" class="headerlink" title="瓶颈问题"></a>瓶颈问题</h2><p>这会导致问题，如果信息量太大，而隐藏层向量太小，会导致信息丢失。</p>
<p>为了解决此问题，我们需要注意力机制。</p>
<h2 id="RNN-网络中的注意力"><a href="#RNN-网络中的注意力" class="headerlink" title="RNN 网络中的注意力"></a>RNN 网络中的注意力</h2><p>解码器使用自身当前状态，与 编码器 的各个时间步的隐藏状态 进行比较，计算出每个输入的权重，它表示了每个输入对当前输出的重要性。</p>
<p>随后，用权重 对编码器所有隐藏状态进行加权求和，得到一个上下文向量。</p>
<p>解码器结合上下文与自身的隐藏状态，生成更好的输出。</p>
<h2 id="注意力的属性"><a href="#注意力的属性" class="headerlink" title="注意力的属性"></a>注意力的属性</h2><p>所以，注意力有</p>
<ul>
<li><p>权重分配：通过计算 Query 和 Key 的相似度，得到每个 Key 的权重。</p>
</li>
<li><p>上下文向量：根据权重，对 Value 进行加权求和。</p>
</li>
<li><p>可反向传播：注意力机制是可微的。</p>
</li>
</ul>
<p>其中</p>
<p>Query：当前输入 或 当前解码器状态。</p>
<p>Key：信息的摘要，编码器的隐藏状态。</p>
<p>Value：信息的实际内容，通常与 Key 相同。</p>
<h1 id="B2-注意力作为层和-Transformer-架构"><a href="#B2-注意力作为层和-Transformer-架构" class="headerlink" title="B2 注意力作为层和 Transformer 架构"></a>B2 注意力作为层和 Transformer 架构</h1><h2 id="点积注意力"><a href="#点积注意力" class="headerlink" title="点积注意力"></a>点积注意力</h2><p>前面提到了 “比较”，而使用点积是最简单有效计算权重的方法。</p>
<p>简单来说，将 $Q · K_i$ ，相似性越高，点积越大。</p>
<p>为了避免过大的点积，我们可以将结果除以 $\sqrt{d_k}$，其中 $d_k$ 是 Key 的维度。</p>
<p>然后对所有 Key 的点积进行 softmax，得到一个权重向量，表示了每个 Key 对当前 Query 的重要性。</p>
<p>最后，将 $Value_i$ 与权重相乘，然后求和，得到上下文向量。</p>
<h2 id="缩放的作用"><a href="#缩放的作用" class="headerlink" title="缩放的作用"></a>缩放的作用</h2><p>我们只需要将点积除以 $\sqrt{d_k}$，就能稳定计算结果，避免点积过大过小。</p>
<p>当 $Q$ 和 $K$ 的维度很大时，点积的值会很大，导致 softmax 的梯度很小，使得训练困难。</p>
<h2 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h2><p>简而言之，让模型在多个视角下观察输入。<br>比如，对于翻译任务，一个头关注主语，一个关注宾语，一个关注动词。</p>
<p>首先，用线性变化生成多组 $Q$、$K$ 和 $V$，一组对应一个头，每个头都有自己的权重。</p>
<p>并行计算权重，然后将结果拼接，再次进行线性变换，得到最终结果。</p>
<h2 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h2><p>而自注意力，主要是捕捉元素之间的依赖关系。</p>
<p>简单来说，这次的 Query、Key 和 Value 都是出自同一个输入序列。</p>
<p>比如 I Love AI. 我们分别查询：</p>
<p>I 与 I, Love, AI 的关系，得到一个权重。<br>Love 与 I, Love, AI 的关系，得到一个权重。<br>AI 与 I, Love, AI 的关系，得到一个权重。</p>
<p>然后对所有权重进行加权求和，得到一个上下文向量。</p>
<h2 id="交叉注意力"><a href="#交叉注意力" class="headerlink" title="交叉注意力"></a>交叉注意力</h2><p>CrossAttention 也就是前面说的给 编码器 和解码器 之间建立联系的注意力。</p>
<p>Query 是解码器当前状态，Key 和 Value 是编码器的隐藏状态。</p>
<p>解码器逐步生成每个单词，每次生成时，都会用交叉注意力参考编码器的隐藏状态。</p>
<h1 id="B3-使用-RNN-和-Transformer-的上下文嵌入"><a href="#B3-使用-RNN-和-Transformer-的上下文嵌入" class="headerlink" title="B3 使用 RNN 和 Transformer 的上下文嵌入"></a>B3 使用 RNN 和 Transformer 的上下文嵌入</h1><h2 id="Transformer-架构"><a href="#Transformer-架构" class="headerlink" title="Transformer 架构"></a>Transformer 架构</h2><p>它包含：</p>
<ul>
<li>注意力机制<ul>
<li>自注意力 （双向）</li>
<li>多头注意力 （可选）</li>
</ul>
</li>
<li>位置编码 （可选）</li>
<li>Feedforward</li>
<li>残差归一</li>
</ul>
<h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><blockquote>
<p>输入序列 -&gt; 输入嵌入-&gt; 位置编码 -&gt; 编码器 [6…12] -&gt; 输出</p>
</blockquote>
<blockquote>
<p>每个编码器：上一个输出 -&gt; 多头自注意 -&gt; 残差归一 -&gt; 前馈 -&gt; 残差归一 -&gt; 输出</p>
</blockquote>
<p>编码器的输入是源序列（比如需要翻译的文本）</p>
<h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><blockquote>
<p>输出序列 -&gt; 输出嵌入 -&gt; 位置编码 -&gt; 解码器 [6…12] -&gt; 输出</p>
</blockquote>
<blockquote>
<p>每个解码器：上一个输出 -&gt; <strong>掩码</strong>多头自注意 -&gt; 残差归一 -&gt; 多头<strong>交叉</strong>注意力 -&gt; 残差归一 -&gt; 前馈 -&gt; 残差归一 -&gt; 输出</p>
</blockquote>
<p>解码器的输入：</p>
<ul>
<li>训练时：教师强制（比如翻译 I Love AI. 输入为 “我爱”）</li>
<li>推理时：模型已经生成的部分</li>
</ul>
<h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>由于输入的每个词都会被转换为向量表示，导致模型无法区分词的位置。<br>位置编码通过将位置信息添加到向量中，解决这个问题。</p>
<p>我们使用 sin 和 cos 函数，它们的周期性与它们不同频率的组合，<br>使得每个位置的编码都是唯一的，并且有助于模型理解单词之间的距离关系。</p>
<h2 id="掩码"><a href="#掩码" class="headerlink" title="掩码"></a>掩码</h2><p>控制模型在处理数据时的可见性。</p>
<p>padding 掩码：在对较短句子进行填充后，将填充的数据位置标记为 0，使模型不会关注这些 [PAD]。</p>
<p>Look-ahead 掩码：在训练解码器时，确保模型不会看到未来的信息，使其只基于已经生成的单词进行预测。</p>
<h2 id="推理和训练"><a href="#推理和训练" class="headerlink" title="推理和训练"></a>推理和训练</h2><p>训练时使用教师强制，计算损失，反向传播，梯度下降</p>
<p>推理则前向传播，逐步生成单词，直到生成结束标记。</p>
<h2 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h2><p>Embeddings from Language Models，第一个上下文嵌入模型。<br>它与 Word2Vec 不同，能够判断多义词。</p>
<ul>
<li>首先它使用 CNN 将单词转为向量</li>
<li>然后使用双向 LSTM，将单词的前后文结合起来</li>
<li>将多层 LSTM 的输出加权和</li>
</ul>
<h2 id="GPT-训练目标"><a href="#GPT-训练目标" class="headerlink" title="GPT 训练目标"></a>GPT 训练目标</h2><p>Generative Pre-Training 仅使用解码器，目标是预测下一个单词。<br>它不能像 BERT 一样考前后文，它只考虑前文。</p>
<p>与 ELMo 类似，它提供一个预训练的“特征提取”模块</p>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><p>Bidirectional Encoder Representations，用于生成上下文嵌入。<br>它能够考虑单词的前后文，更好的理解单词的含义。</p>
<p>它使用了 Masked Language Model，它随机隐藏一些单词，然后让模型猜。</p>
<p>还使用了 Next Sentence Prediction，它随机给模型两个句子，让模型判断这两个句子是否相邻。</p>
<h1 id="B4-对话系统"><a href="#B4-对话系统" class="headerlink" title="B4 对话系统"></a>B4 对话系统</h1><h2 id="对话系统的类型"><a href="#对话系统的类型" class="headerlink" title="对话系统的类型"></a>对话系统的类型</h2><ul>
<li>task-oriented：帮助用户完成特定任务</li>
<li>open-domain：用于娱乐或其他目的</li>
</ul>
<p>或者</p>
<ul>
<li>用户发起：如问答系统</li>
<li>系统控制：系统主动发起，如日历提醒</li>
<li>混合：用户和系统都可以发起</li>
</ul>
<h2 id="一般对话需求"><a href="#一般对话需求" class="headerlink" title="一般对话需求"></a>一般对话需求</h2><ul>
<li><p>Grounding：确认理解对方所说内容，建立一个共同语境。</p>
<p>一个人说出新内容，另一个人确认，有不明白的地方，再次确认。</p>
</li>
<li><p>Adjacency pairs：问与答，请求与回应等。</p>
<p>是话语与响应的相关性。</p>
</li>
<li><p>Pragmatic inferences：根据对话的上下文，推断对方的意图。</p>
<p>假设对方是有理性的，说的话是有意义，真实，清晰的。</p>
</li>
</ul>
<h2 id="开放对话系统"><a href="#开放对话系统" class="headerlink" title="开放对话系统"></a>开放对话系统</h2><p>基于规则，比如模式匹配。（古老）</p>
<p>基于检索或生成，比如知识库和GPT。（现代）</p>
<h2 id="任务导向对话系统"><a href="#任务导向对话系统" class="headerlink" title="任务导向对话系统"></a>任务导向对话系统</h2><p>在确定任务后，用槽值填充，它类似于表单，系统通过提问每一个槽位，填充信息并执行。</p>
<h2 id="对话状态系统"><a href="#对话状态系统" class="headerlink" title="对话状态系统"></a>对话状态系统</h2><p>与任务导向系统相比，它广泛使用机器学习。</p>
<h3 id="对话状态系统组件和使用语言模型的实现"><a href="#对话状态系统组件和使用语言模型的实现" class="headerlink" title="对话状态系统组件和使用语言模型的实现"></a>对话状态系统组件和使用语言模型的实现</h3><ul>
<li><p>Dialog State Tracker<br>使用 BERT 来选择对话状态。根据历史，跟踪用户目标和信息。</p>
</li>
<li><p>Dialog Policy<br>使用强化学习，根据对话状态，选择下一步的动作。</p>
</li>
<li><p>NUL<br>使用机器学习来识别用户的领域，意图，槽值。</p>
</li>
<li><p>NLG<br>使用Transformer来生成自然语言响应。</p>
</li>
</ul>
<h2 id="简化的任务导向对话系统"><a href="#简化的任务导向对话系统" class="headerlink" title="简化的任务导向对话系统"></a>简化的任务导向对话系统</h2><p>使用单一S2S模型，如SimpleTOD，来完成所有任务，减少复杂性和错误。</p>
<h2 id="模式引导系统"><a href="#模式引导系统" class="headerlink" title="模式引导系统"></a>模式引导系统</h2><p>它使用预定义的schema graph来生成对话。</p>
<h2 id="对话系统的评估"><a href="#对话系统的评估" class="headerlink" title="对话系统的评估"></a>对话系统的评估</h2><ul>
<li>attractive：继续对话的意愿</li>
<li>有多像人类</li>
<li>上下文的连贯性</li>
<li>流畅性</li>
<li>有多少车轱辘话</li>
<li>任务成功率</li>
<li>填充正确率</li>
<li>用户满意度</li>
</ul>
<p>等</p>
<h1 id="B5-LLM-推理"><a href="#B5-LLM-推理" class="headerlink" title="B5 LLM 推理"></a>B5 LLM 推理</h1><h2 id="通用推理参数"><a href="#通用推理参数" class="headerlink" title="通用推理参数"></a>通用推理参数</h2><ul>
<li><p>topP<br>将元素概率从大到小排列，然后从大到小加起来，加到 P 为止。</p>
</li>
<li><p>topK<br>保留最大的 K 个元素。</p>
</li>
<li><p>采样<br>比如 greedy，beam search，random sampling</p>
</li>
<li><p>logit 偏置<br>使模型更倾向于选择某些词。</p>
</li>
<li><p>温度<br>文本多样性</p>
</li>
</ul>
<h2 id="边缘推理"><a href="#边缘推理" class="headerlink" title="边缘推理"></a>边缘推理</h2><p>在资源有限的设备上，量化到 4 bit，优化 CPU 向量操作，内存映射</p>
<h2 id="高效推理"><a href="#高效推理" class="headerlink" title="高效推理"></a>高效推理</h2><p>使用 GPU 等进行推理，问题是内存带宽</p>
<ul>
<li><p>缓存<br>保存先前计算的键和值对，重用它们<br>高内存占用<br>低 GPU 利用率，因为 batch size 不能很大</p>
</li>
<li><p>Flash<br>并行，将 Q·K 矩阵分块<br>高 GPU 利用率<br>复杂，高内存占用</p>
</li>
</ul>
<p>Softmax 耗时，所以用 Flashdecoding 并行计算</p>
<p>处理并发可以使用分页缓存，预填充，将多个小序列合并为一个序列，以及将长序列分割为多个序列。</p>
<h2 id="辅助生成"><a href="#辅助生成" class="headerlink" title="辅助生成"></a>辅助生成</h2><p>先用一个小模型生成草稿，然后大模型修正草稿。</p>
<h2 id="推测解码"><a href="#推测解码" class="headerlink" title="推测解码"></a>推测解码</h2><ul>
<li><p>有限状态机引导<br>类似于根据 schema 生成</p>
</li>
<li><p>分类器引导<br>比如区分特定风格的文本，小模型生成多个候选，分类器打分</p>
</li>
<li><p>专家引导<br>和分类器类似，专家模型根据其领域，对生成的文本进行打分和反馈</p>
</li>
</ul>
<h2 id="水印"><a href="#水印" class="headerlink" title="水印"></a>水印</h2><p>水印用于溯源和检测。</p>
<ul>
<li><p>Red list<br>生成过程中，有一组不允许的词，从绿名单中采样</p>
</li>
<li><p>soft mark<br>在绿名单上加偏置，比 red list 更好</p>
</li>
</ul>
<p>水印一般用概率检验。</p>
<h1 id="B6-LLM-对齐"><a href="#B6-LLM-对齐" class="headerlink" title="B6 LLM 对齐"></a>B6 LLM 对齐</h1><h2 id="对齐在-AI-中的作用"><a href="#对齐在-AI-中的作用" class="headerlink" title="对齐在 AI 中的作用"></a>对齐在 AI 中的作用</h2><p>确保模型符合人类期望，和道德标准。</p>
<h2 id="指令跟随模型"><a href="#指令跟随模型" class="headerlink" title="指令跟随模型"></a>指令跟随模型</h2><ul>
<li>有帮助的：真正尝试执行所描述的任务</li>
<li>诚实的：提供准确的信息，包括在适当情况下表达不确定性</li>
<li>无害的：不具有攻击性、歧视性，也不推荐或帮助危险或不道德的行为</li>
</ul>
<h2 id="合成指令数据集"><a href="#合成指令数据集" class="headerlink" title="合成指令数据集"></a>合成指令数据集</h2><p>通过生成并收集大量正确的AI 问答，来训练模型。</p>
<h2 id="监督微调"><a href="#监督微调" class="headerlink" title="监督微调"></a>监督微调</h2><p>在特定数据集上进一步训练。</p>
<h2 id="人类反馈强化学习"><a href="#人类反馈强化学习" class="headerlink" title="人类反馈强化学习"></a>人类反馈强化学习</h2><p>Reinforcement Learning from Human Feedback</p>
<p>通过人类对答案的打分，通过强化学习，如 Proximal Policy Optimization，微调模型</p>
<h2 id="聊天模型"><a href="#聊天模型" class="headerlink" title="聊天模型"></a>聊天模型</h2><p>指令微调不支持多轮对话，所以需要聊天模型。<br>我们直接使用历史对话数据（而不是一问一答），来训练模型。</p>
<h1 id="B7-提示与答案工程"><a href="#B7-提示与答案工程" class="headerlink" title="B7 提示与答案工程"></a>B7 提示与答案工程</h1><h2 id="LLM-提示基础"><a href="#LLM-提示基础" class="headerlink" title="LLM 提示基础"></a>LLM 提示基础</h2><p>提示词应该 详细、具体 和 精确，它可以包括一些描述，约束，示例，步骤等。</p>
<h2 id="提示挖掘与改写"><a href="#提示挖掘与改写" class="headerlink" title="提示挖掘与改写"></a>提示挖掘与改写</h2><p>挖掘，是从数据中提取有效提示词，以便模型能够更好的生成答案。</p>
<p>假设我们有一个需要从 France is the capital of Paris 中提取国家和首都之间关系的任务</p>
<ul>
<li><p>中间词提示<br>可以使用提示词 [x] is the capital of [y] ，来提取</p>
</li>
<li><p>依存关系提示<br>可以使用提示 capital of [x] is [y] ，来提取</p>
</li>
</ul>
<p>而改写，就是生成多个提示，并选择最佳的。</p>
<h2 id="基于梯度的提示优化"><a href="#基于梯度的提示优化" class="headerlink" title="基于梯度的提示优化"></a>基于梯度的提示优化</h2><p>我想要莎士比亚风格的诗，但是我不知道怎么描述。</p>
<p>初始提示可能是：请写一首关于爱情的诗。<br>随后我们可以使用梯度下降，来优化提示：请写一首关于爱情的莎士比亚风格的诗。</p>
<h2 id="提示生成模型"><a href="#提示生成模型" class="headerlink" title="提示生成模型"></a>提示生成模型</h2><p>一类专门生成提示词的模型。通常使用 T5 或 Transformer。</p>
<h2 id="前缀微调"><a href="#前缀微调" class="headerlink" title="前缀微调"></a>前缀微调</h2><p>添加一小段前缀，来让模型生成更好的答案。</p>
<p>比如，你让AI生成一个故事，是一个悬疑故事，那么你可以在前面加上：请写一个悬疑故事。<br>然后我们使用训练数据，使 AI 看到 “悬疑” 后，能够生成类似的故事。<br>最后，每次你让 AI 生成故事时，都加上这个前缀，它就会生成更好的悬疑故事。</p>
<h2 id="答案工程"><a href="#答案工程" class="headerlink" title="答案工程"></a>答案工程</h2><p>也就是对回答进行调优。</p>
<ul>
<li><p>定义输出格式<br>比如，你要求 AI 回答问题时，只说 “是” 或 “否”。</p>
</li>
<li><p>映射输出<br>比如，它回答 这是真的，我们可以映射为 “是”。</p>
</li>
<li><p>优化答案<br>根据具体情况进一步优化，比如需要专业回答，那么 天气有点冷 可以改为 温度较低。</p>
</li>
</ul>
<h2 id="提示集成"><a href="#提示集成" class="headerlink" title="提示集成"></a>提示集成</h2><p>你同时准备多个提示词，然后让模型分别回答，最后综合回答，得到全面准确的答案。</p>
<h2 id="基于推理结构的提示"><a href="#基于推理结构的提示" class="headerlink" title="基于推理结构的提示"></a>基于推理结构的提示</h2><p>为复杂问题提供一个清晰的思路，一步步解决问题</p>
<ul>
<li><p>Chain-of-Thought<br>因为 xxx, 并且 yyy, 所以 zzz</p>
</li>
<li><p>Self-consistency<br>尝试多个解决问题的方法，然后选择最一致的结果</p>
</li>
<li><p>Self-ask<br>AI 自己问自己问题，然后回答</p>
</li>
<li><p>Knowledge-generating<br>比如先写出标准数学公式，然后再进行代入计算</p>
</li>
<li><p>Tree &#x2F; Graph of-thought<br>通过多条路径，如果不通，则回到上一步，选择另一条路径</p>
</li>
<li><p>程序辅助<br>比如使用 Python 代码，来协助 AI 解决问题</p>
</li>
</ul>
<h1 id="B8-嵌入模型与向量搜索"><a href="#B8-嵌入模型与向量搜索" class="headerlink" title="B8 嵌入模型与向量搜索"></a>B8 嵌入模型与向量搜索</h1><h2 id="向量相似性搜索在增强-LMs-中的作用"><a href="#向量相似性搜索在增强-LMs-中的作用" class="headerlink" title="向量相似性搜索在增强 LMs 中的作用"></a>向量相似性搜索在增强 LMs 中的作用</h2><p>它就像是一个搜索引擎，帮助 AI 找到最相关的信息。</p>
<h2 id="近似最近邻搜索"><a href="#近似最近邻搜索" class="headerlink" title="近似最近邻搜索"></a>近似最近邻搜索</h2><p>首先它将知识文本转换为向量，构建索引，储存起来，<br>当需要查找信息的时候，把问题转为向量，然后计算问题向量与所有文本向量之间的相似性，<br>找到最相似的文本，然后用这个文本来回答问题。</p>
<h2 id="局部敏感哈希"><a href="#局部敏感哈希" class="headerlink" title="局部敏感哈希"></a>局部敏感哈希</h2><p>通过 Binning 分箱，将数据分为多个桶，搜索时先找到相似的桶，然后再在桶内搜索。</p>
<h2 id="product-Quantization-量化"><a href="#product-Quantization-量化" class="headerlink" title="[product] Quantization 量化"></a>[product] Quantization 量化</h2><p>将复杂数据转为简单数据，比如将浮点数转为整数，减少计算量。</p>
<p>我们使用 Product 量化，将向量拆分成多个子向量，然后对每个子向量进行量化，然后组合。</p>
<h2 id="KD-树与优先搜索"><a href="#KD-树与优先搜索" class="headerlink" title="KD 树与优先搜索"></a>KD 树与优先搜索</h2><p>KD 树是一个多层分类系统，将数据按不同特征分层。</p>
<p>比如，高的在左，低的在右，然后再按颜色分，再按大小分，等等。</p>
<p>当需要查找的时候，使用优先搜索，找到最近的点。</p>
<p>优先搜索总是先找最有可能包含答案的节点，<br>然后计算当前位置与最有可能包含答案的节点的距离，<br>并将其设置为初始距离限制，<br>然后递归地搜索其他节点，直到找到最近的点。</p>
<h2 id="图索引"><a href="#图索引" class="headerlink" title="图索引"></a>图索引</h2><p>通过连接相似的节点，形成网络。</p>
<p>小世界是一种特殊的图，你可以通过很少的中间节点找到任何一个节点。</p>
<p>Navigable SW 直接沿着相似的边查找<br>Hierarchical NSW 在小世界中增加层次结构，减少搜索时间</p>
<h2 id="嵌入模型"><a href="#嵌入模型" class="headerlink" title="嵌入模型"></a>嵌入模型</h2><p>一个专门将数据转为向量的模型。<br>比如 Word2Vec，BERT，TF-IDF 等。</p>
<p>其中，我们有句子嵌入，和指令嵌入等。</p>
<h1 id="B9-检索与工具增强的-LLMs"><a href="#B9-检索与工具增强的-LLMs" class="headerlink" title="B9 检索与工具增强的 LLMs"></a>B9 检索与工具增强的 LLMs</h1><h2 id="增强-LMs-概述"><a href="#增强-LMs-概述" class="headerlink" title="增强 LMs 概述"></a>增强 LMs 概述</h2><p>我们需要额外的工具来给 AI 提供知识，减少 hallucination。</p>
<p>一种是直接将内容填到提示词中，另一种就是嵌入空间向量。</p>
<h2 id="检索增强生成"><a href="#检索增强生成" class="headerlink" title="检索增强生成"></a>检索增强生成</h2><p>Retrieval-Augmented Generation</p>
<ul>
<li>将用户问题转为查询，关键词</li>
<li>使用向量数据库或搜索引擎检索</li>
<li>将收集到的信息聚合</li>
<li>生成答案</li>
</ul>
<h2 id="假设文档嵌入"><a href="#假设文档嵌入" class="headerlink" title="假设文档嵌入"></a>假设文档嵌入</h2><p>AI 为问题生成一个假设答案，然后用这个假设答案去搜索</p>
<h2 id="RAG-微调模型"><a href="#RAG-微调模型" class="headerlink" title="RAG 微调模型"></a>RAG 微调模型</h2><p>Retrieval-Augmented Language Model</p>
<p>使用 检索器（查文档），编码器（文档和输入一起编码），生成器（生成答案） 三个模块。<br>关键是在训练时，同时优化三个模块。</p>
<p>Retrieval-Enhanced Transformer</p>
<p>增强的 Transformer，检索使用 BERT，然后用在编码器中用 交叉注意力 整合检索信息。</p>
<h2 id="自我独白模型"><a href="#自我独白模型" class="headerlink" title="自我独白模型"></a>自我独白模型</h2><p>通过 Chain-of-Thought 来进行多次生成，完成复杂任务，如 AutoGPT。</p>
<p>Think, Reason, Plan, Reflect, Act</p>
<h2 id="工具微调的可能性"><a href="#工具微调的可能性" class="headerlink" title="工具微调的可能性"></a>工具微调的可能性</h2><p>引导模型调用外部工具，按成功率排序，将最好的结果纳入数据集。</p>
<h1 id="B10-高效注意力机制"><a href="#B10-高效注意力机制" class="headerlink" title="B10 高效注意力机制"></a>B10 高效注意力机制</h1><h2 id="稀疏注意力"><a href="#稀疏注意力" class="headerlink" title="稀疏注意力"></a>稀疏注意力</h2><p>传统注意力需要计算输入序列每个元素之间的权重，这会导致计算量过大。</p>
<p>所以我们将全局注意力转为多个小矩阵，比如行和列两个方向的矩阵。</p>
<h2 id="因式分解"><a href="#因式分解" class="headerlink" title="因式分解"></a>因式分解</h2><p>其中，有固定注意力，每个位置只关注固定数量的其他位置，适合文本。</p>
<p>跨步注意力，跳跃选择位置，每个位置只关注间隔一定步长的其他位置，适合图像。</p>
<h2 id="位置嵌入类型"><a href="#位置嵌入类型" class="headerlink" title="位置嵌入类型"></a>位置嵌入类型</h2><p>Extrapolation 是指模型的泛化能力，比如模型是用短句训练的，但是要它生成长句。</p>
<p>传统方法使用 Sinusoidal，<br>sin 和 cos 函数，将位置信息嵌入到向量中。</p>
<h2 id="ALiBi"><a href="#ALiBi" class="headerlink" title="ALiBi"></a>ALiBi</h2><p>Attention with Linear Biases，引入相对位置偏差。</p>
<p>它根据 Q 与 K 的距离，静态添加一个非学习的偏置。</p>
<h2 id="RoPe"><a href="#RoPe" class="headerlink" title="RoPe"></a>RoPe</h2><p>Rotary Positional Embedding，<br>将 Sinusoida 嵌入到每个 Q 和 K 上</p>
<h2 id="位置插值"><a href="#位置插值" class="headerlink" title="位置插值"></a>位置插值</h2><p>也就是将长序列，映射到短序列上。</p>
<p>假设模型支持的最大序列长度为 512，位置信息是线性分布的，例如：<br>位置编码：[0, 1, 2, …, 511]</p>
<p>扩展到 2048 的上下文窗口，PI 会根据比例映射新位置：<br>新位置编码：[0, 0.25, 0.5, …, 511.75]</p>
<h2 id="闪电注意力"><a href="#闪电注意力" class="headerlink" title="闪电注意力"></a>闪电注意力</h2><p>按块逐步计算注意力得分和上下文向量，避免了直接存储整个注意力矩阵。<br>并且让每块分别计算 softmax，减少了内存占用。</p>
<h1 id="B11-LLM-的蒸馏与量化"><a href="#B11-LLM-的蒸馏与量化" class="headerlink" title="B11 LLM 的蒸馏与量化"></a>B11 LLM 的蒸馏与量化</h1><h2 id="蒸馏设置与训练目标"><a href="#蒸馏设置与训练目标" class="headerlink" title="蒸馏设置与训练目标"></a>蒸馏设置与训练目标</h2><p>我们用一个大模型作为教师，一个小模型作为学生。<br>在训练学生时，我们不再用 one-hot，而是直接使用教师的输出，它包含了更多信息，而不是简单的 0 和 1。</p>
<p>这种方法叫做 Knowledge Distillation。它会有一定的损失。</p>
<h2 id="权重量化算法"><a href="#权重量化算法" class="headerlink" title="权重量化算法"></a>权重量化算法</h2><p>它将连续值映射到离散值，从高精度转为低精度，从而减少内存和计算量。<br>量化后会引入误差，有时需要再训练。</p>
<p>算法有 GPTQ， AWQ 等。</p>
<h2 id="模型尺寸增加对量化误差的影响"><a href="#模型尺寸增加对量化误差的影响" class="headerlink" title="模型尺寸增加对量化误差的影响"></a>模型尺寸增加对量化误差的影响</h2><p>模型越大，量化误差的积累就越多，导致整体误差增加。<br>简单的量化方法无法捕捉复杂的分布模式，导致更大的误差。</p>
<p>我们可以使用分块和混合精度来减少误差。</p>
<h1 id="B12-参数高效微调方法"><a href="#B12-参数高效微调方法" class="headerlink" title="B12 参数高效微调方法"></a>B12 参数高效微调方法</h1><h2 id="高效适应的优势"><a href="#高效适应的优势" class="headerlink" title="高效适应的优势"></a>高效适应的优势</h2><p>节省时间和资源，只训练模型的小部分就能完成微调，更灵活，适应性强。</p>
<h2 id="适配器"><a href="#适配器" class="headerlink" title="适配器"></a>适配器</h2><p>在大模型前插入一个小模块，冻结原始模型，只训练适配器，可以有效避免灾难性遗忘问题。</p>
<p>适配器可以插入到模型的每一层中。</p>
<h2 id="瓶颈适配器"><a href="#瓶颈适配器" class="headerlink" title="瓶颈适配器"></a>瓶颈适配器</h2><p>而适配器的结构就是瓶颈一样的，它使用一个降为层，减少训练参数，然后 ReLu，再升维。</p>
<h2 id="低秩适应"><a href="#低秩适应" class="headerlink" title="低秩适应"></a>低秩适应</h2><p>引入低秩矩阵分解，将权重矩阵分解为两个低秩矩阵的乘积。然后在模型的每一层中插入这两个矩阵，训练时只修改这两个矩阵，保持原有模型不变。</p>
<h2 id="P-微调"><a href="#P-微调" class="headerlink" title="P*-微调"></a>P*-微调</h2><p>类似于前缀微调</p>
<p>在输入的特定位置插入可学习的提示，模型会使用这些提示来完成任务。训练时，只训练这些提示的参数，保持原有模型不变。</p>
<h2 id="内在维度与模型尺寸的关系"><a href="#内在维度与模型尺寸的关系" class="headerlink" title="内在维度与模型尺寸的关系"></a>内在维度与模型尺寸的关系</h2><p>Intrinsic Dimensions 实际上就是模型在特定任务上的最小参数数量。这表明大模型对特定任务，存在一个低维的有效子空间。</p>
<p>这就为什么我们可以通过适配器，低秩适应等方法，来减少模型的参数数量，提高效率。</p>
<h1 id="B13-专家混合"><a href="#B13-专家混合" class="headerlink" title="B13 专家混合"></a>B13 专家混合</h1><h2 id="MoE-的属性"><a href="#MoE-的属性" class="headerlink" title="MoE 的属性"></a>MoE 的属性</h2><p>Mixture of Experts 本质是将多个模型组合在一起，每个模型专注于不同的任务。</p>
<ul>
<li><p>数据集划分<br>每个专家处理的输入，这一般由门控网络动态决定</p>
</li>
<li><p>专家模型<br>每个模型的架构都由可能不同，但是有相同的输入输出</p>
</li>
<li><p>门控网络<br>为每个输入选择合适的专家</p>
</li>
<li><p>混合策略<br>决定如何将专家的输出加权组合</p>
</li>
<li><p>路由<br>屏蔽那些低权重，不合适的专家</p>
</li>
<li><p>稀疏性<br>激活的专家只有少数，高效</p>
</li>
</ul>
<h2 id="现代-MoE-架构在深度学习中的应用"><a href="#现代-MoE-架构在深度学习中的应用" class="headerlink" title="现代 MoE 架构在深度学习中的应用"></a>现代 MoE 架构在深度学习中的应用</h2><p>如 NLP，CV，多模态任务等。</p>
<h2 id="基于-MoE-的语言模型"><a href="#基于-MoE-的语言模型" class="headerlink" title="基于 MoE 的语言模型"></a>基于 MoE 的语言模型</h2><p>如 Switch Transformer，它使用一个门控网络，根据输入选择不同的模型。</p>
<h2 id="MoE-适配器"><a href="#MoE-适配器" class="headerlink" title="MoE 适配器"></a>MoE 适配器</h2><p>结合 MoE 和 Adapter，通过在模型中加入多个专家，并使用适配器来动态选择与组合专家输出。</p>
<h2 id="快速前馈层"><a href="#快速前馈层" class="headerlink" title="快速前馈层"></a>快速前馈层</h2><p>UltraFastBERT 使用 FFL，主要是将权重分解为两个低秩矩阵的乘积来减少计算量。<br>Hierarchical MoE，将 MoE 分为多个层次，也使用 FFL。</p>
<h1 id="B14-数据集与自举"><a href="#B14-数据集与自举" class="headerlink" title="B14 数据集与自举"></a>B14 数据集与自举</h1><h2 id="LM-训练步骤所需的数据集类型"><a href="#LM-训练步骤所需的数据集类型" class="headerlink" title="LM 训练步骤所需的数据集类型"></a>LM 训练步骤所需的数据集类型</h2><ul>
<li><p>预训练数据集<br>如网络文本，书籍论文，代码等</p>
</li>
<li><p>微调数据集<br>如 NER，QA 等特殊任务的数据集</p>
</li>
<li><p>指令数据集<br>用于训练模型理解指令的数据集，内容一般是 指令-回答<br>可以人工编写，也可以 Self-instruct</p>
</li>
<li><p>基准测试数据集<br>用于评估模型性能的数据集，包含标准化的测试用例</p>
</li>
</ul>
<h2 id="不同数据源的特征"><a href="#不同数据源的特征" class="headerlink" title="不同数据源的特征"></a>不同数据源的特征</h2><ul>
<li><p>网络<br>易于获取，多样，质量参差不齐，包含大量噪声，偏见等</p>
</li>
<li><p>artistic<br>比如书籍，音乐，不容易获取，需要一定程度的转码</p>
</li>
<li><p>专业<br>如论文，报告等，高质量，结构化</p>
</li>
</ul>
<h2 id="使用-LLMs-自举训练"><a href="#使用-LLMs-自举训练" class="headerlink" title="使用 LLMs 自举训练"></a>使用 LLMs 自举训练</h2><p>也是用大模型生成数据，然后用小模型学习。<br>但是小模型使用的是大模型批量生成的数据集，而不是向量，和蒸馏不同。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>NLP-PreExamB</p><p><a href="https://aloen.to/AI/NLP/NLP-PreExamB/">https://aloen.to/AI/NLP/NLP-PreExamB/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Aloento</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-11-16</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2025-03-18</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E8%80%83%E8%AF%95/">考试</a><a class="link-muted mr-2" rel="tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/AI/NLP/NLP-Contrastive/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NLP-Contrastive</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/AI/NLP/NLP-ReducedComplexity/"><span class="level-item">NLP-ReducedComplexity</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/Aloento.png" alt="Aloento"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Aloento</p><p class="is-size-6 is-block">Reindeer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Foot of Sacred Mountain</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">59</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">35</p></a></div></div></nav></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">33</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/RL/"><span class="level-start"><span class="level-item">RL</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/TM/"><span class="level-start"><span class="level-item">TM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Cloud/"><span class="level-start"><span class="level-item">Cloud</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Cloud/OpenStack/"><span class="level-start"><span class="level-item">OpenStack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Data-Science/"><span class="level-start"><span class="level-item">Data Science</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/MSSQL/"><span class="level-start"><span class="level-item">MSSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Theory/"><span class="level-start"><span class="level-item">Theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math/Logic/"><span class="level-start"><span class="level-item">Logic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/Matlab/"><span class="level-start"><span class="level-item">Matlab</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Memo/"><span class="level-start"><span class="level-item">Memo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/"><span class="level-start"><span class="level-item">Program</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Program/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/WebCodecs/"><span class="level-start"><span class="level-item">WebCodecs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/NET/"><span class="tag">.NET</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">33</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C#</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS/"><span class="tag">JS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LINQ/"><span class="tag">LINQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenStack/"><span class="tag">OpenStack</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RL/"><span class="tag">RL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQLServer/"><span class="tag">SQLServer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WebCodecs/"><span class="tag">WebCodecs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B9%A0%E9%A2%98/"><span class="tag">习题</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91/"><span class="tag">云</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%88%E7%89%99%E5%88%A9/"><span class="tag">匈牙利</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"><span class="tag">图灵机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%BB%E7%95%A5/"><span class="tag">攻略</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"><span class="tag">数值方法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"><span class="tag">数据科学</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%95%99%E5%AD%A6/"><span class="tag">留学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">48</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%BB%E8%AF%91/"><span class="tag">翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%80%83%E8%AF%95/"><span class="tag">考试</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%BB%E8%BE%91/"><span class="tag">逻辑</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tag">面试</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"><span class="tag">音视频</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://Q-Audio.org" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Q-Audio</span></span><span class="level-right"><span class="level-item tag">q-audio.org</span></span></a></li><li><a class="level is-mobile" href="https://Musi.Land" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">MusiLand</span></span><span class="level-right"><span class="level-item tag">musi.land</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#B1-注意力机制"><span class="level-left"><span class="level-item">1</span><span class="level-item">B1 注意力机制</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Seq2seq-基础"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Seq2seq 基础</span></span></a></li><li><a class="level is-mobile" href="#瓶颈问题"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">瓶颈问题</span></span></a></li><li><a class="level is-mobile" href="#RNN-网络中的注意力"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">RNN 网络中的注意力</span></span></a></li><li><a class="level is-mobile" href="#注意力的属性"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">注意力的属性</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B2-注意力作为层和-Transformer-架构"><span class="level-left"><span class="level-item">2</span><span class="level-item">B2 注意力作为层和 Transformer 架构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#点积注意力"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">点积注意力</span></span></a></li><li><a class="level is-mobile" href="#缩放的作用"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">缩放的作用</span></span></a></li><li><a class="level is-mobile" href="#多头注意力"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">多头注意力</span></span></a></li><li><a class="level is-mobile" href="#自注意力"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">自注意力</span></span></a></li><li><a class="level is-mobile" href="#交叉注意力"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">交叉注意力</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B3-使用-RNN-和-Transformer-的上下文嵌入"><span class="level-left"><span class="level-item">3</span><span class="level-item">B3 使用 RNN 和 Transformer 的上下文嵌入</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Transformer-架构"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Transformer 架构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#编码器"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">编码器</span></span></a></li><li><a class="level is-mobile" href="#解码器"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">解码器</span></span></a></li></ul></li><li><a class="level is-mobile" href="#位置编码"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">位置编码</span></span></a></li><li><a class="level is-mobile" href="#掩码"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">掩码</span></span></a></li><li><a class="level is-mobile" href="#推理和训练"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">推理和训练</span></span></a></li><li><a class="level is-mobile" href="#ELMo"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">ELMo</span></span></a></li><li><a class="level is-mobile" href="#GPT-训练目标"><span class="level-left"><span class="level-item">3.6</span><span class="level-item">GPT 训练目标</span></span></a></li><li><a class="level is-mobile" href="#BERT"><span class="level-left"><span class="level-item">3.7</span><span class="level-item">BERT</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B4-对话系统"><span class="level-left"><span class="level-item">4</span><span class="level-item">B4 对话系统</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#对话系统的类型"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">对话系统的类型</span></span></a></li><li><a class="level is-mobile" href="#一般对话需求"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">一般对话需求</span></span></a></li><li><a class="level is-mobile" href="#开放对话系统"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">开放对话系统</span></span></a></li><li><a class="level is-mobile" href="#任务导向对话系统"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">任务导向对话系统</span></span></a></li><li><a class="level is-mobile" href="#对话状态系统"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">对话状态系统</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#对话状态系统组件和使用语言模型的实现"><span class="level-left"><span class="level-item">4.5.1</span><span class="level-item">对话状态系统组件和使用语言模型的实现</span></span></a></li></ul></li><li><a class="level is-mobile" href="#简化的任务导向对话系统"><span class="level-left"><span class="level-item">4.6</span><span class="level-item">简化的任务导向对话系统</span></span></a></li><li><a class="level is-mobile" href="#模式引导系统"><span class="level-left"><span class="level-item">4.7</span><span class="level-item">模式引导系统</span></span></a></li><li><a class="level is-mobile" href="#对话系统的评估"><span class="level-left"><span class="level-item">4.8</span><span class="level-item">对话系统的评估</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B5-LLM-推理"><span class="level-left"><span class="level-item">5</span><span class="level-item">B5 LLM 推理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#通用推理参数"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">通用推理参数</span></span></a></li><li><a class="level is-mobile" href="#边缘推理"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">边缘推理</span></span></a></li><li><a class="level is-mobile" href="#高效推理"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">高效推理</span></span></a></li><li><a class="level is-mobile" href="#辅助生成"><span class="level-left"><span class="level-item">5.4</span><span class="level-item">辅助生成</span></span></a></li><li><a class="level is-mobile" href="#推测解码"><span class="level-left"><span class="level-item">5.5</span><span class="level-item">推测解码</span></span></a></li><li><a class="level is-mobile" href="#水印"><span class="level-left"><span class="level-item">5.6</span><span class="level-item">水印</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B6-LLM-对齐"><span class="level-left"><span class="level-item">6</span><span class="level-item">B6 LLM 对齐</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#对齐在-AI-中的作用"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">对齐在 AI 中的作用</span></span></a></li><li><a class="level is-mobile" href="#指令跟随模型"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">指令跟随模型</span></span></a></li><li><a class="level is-mobile" href="#合成指令数据集"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">合成指令数据集</span></span></a></li><li><a class="level is-mobile" href="#监督微调"><span class="level-left"><span class="level-item">6.4</span><span class="level-item">监督微调</span></span></a></li><li><a class="level is-mobile" href="#人类反馈强化学习"><span class="level-left"><span class="level-item">6.5</span><span class="level-item">人类反馈强化学习</span></span></a></li><li><a class="level is-mobile" href="#聊天模型"><span class="level-left"><span class="level-item">6.6</span><span class="level-item">聊天模型</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B7-提示与答案工程"><span class="level-left"><span class="level-item">7</span><span class="level-item">B7 提示与答案工程</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#LLM-提示基础"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">LLM 提示基础</span></span></a></li><li><a class="level is-mobile" href="#提示挖掘与改写"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">提示挖掘与改写</span></span></a></li><li><a class="level is-mobile" href="#基于梯度的提示优化"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">基于梯度的提示优化</span></span></a></li><li><a class="level is-mobile" href="#提示生成模型"><span class="level-left"><span class="level-item">7.4</span><span class="level-item">提示生成模型</span></span></a></li><li><a class="level is-mobile" href="#前缀微调"><span class="level-left"><span class="level-item">7.5</span><span class="level-item">前缀微调</span></span></a></li><li><a class="level is-mobile" href="#答案工程"><span class="level-left"><span class="level-item">7.6</span><span class="level-item">答案工程</span></span></a></li><li><a class="level is-mobile" href="#提示集成"><span class="level-left"><span class="level-item">7.7</span><span class="level-item">提示集成</span></span></a></li><li><a class="level is-mobile" href="#基于推理结构的提示"><span class="level-left"><span class="level-item">7.8</span><span class="level-item">基于推理结构的提示</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B8-嵌入模型与向量搜索"><span class="level-left"><span class="level-item">8</span><span class="level-item">B8 嵌入模型与向量搜索</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#向量相似性搜索在增强-LMs-中的作用"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">向量相似性搜索在增强 LMs 中的作用</span></span></a></li><li><a class="level is-mobile" href="#近似最近邻搜索"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">近似最近邻搜索</span></span></a></li><li><a class="level is-mobile" href="#局部敏感哈希"><span class="level-left"><span class="level-item">8.3</span><span class="level-item">局部敏感哈希</span></span></a></li><li><a class="level is-mobile" href="#product-Quantization-量化"><span class="level-left"><span class="level-item">8.4</span><span class="level-item">[product] Quantization 量化</span></span></a></li><li><a class="level is-mobile" href="#KD-树与优先搜索"><span class="level-left"><span class="level-item">8.5</span><span class="level-item">KD 树与优先搜索</span></span></a></li><li><a class="level is-mobile" href="#图索引"><span class="level-left"><span class="level-item">8.6</span><span class="level-item">图索引</span></span></a></li><li><a class="level is-mobile" href="#嵌入模型"><span class="level-left"><span class="level-item">8.7</span><span class="level-item">嵌入模型</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B9-检索与工具增强的-LLMs"><span class="level-left"><span class="level-item">9</span><span class="level-item">B9 检索与工具增强的 LLMs</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#增强-LMs-概述"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">增强 LMs 概述</span></span></a></li><li><a class="level is-mobile" href="#检索增强生成"><span class="level-left"><span class="level-item">9.2</span><span class="level-item">检索增强生成</span></span></a></li><li><a class="level is-mobile" href="#假设文档嵌入"><span class="level-left"><span class="level-item">9.3</span><span class="level-item">假设文档嵌入</span></span></a></li><li><a class="level is-mobile" href="#RAG-微调模型"><span class="level-left"><span class="level-item">9.4</span><span class="level-item">RAG 微调模型</span></span></a></li><li><a class="level is-mobile" href="#自我独白模型"><span class="level-left"><span class="level-item">9.5</span><span class="level-item">自我独白模型</span></span></a></li><li><a class="level is-mobile" href="#工具微调的可能性"><span class="level-left"><span class="level-item">9.6</span><span class="level-item">工具微调的可能性</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B10-高效注意力机制"><span class="level-left"><span class="level-item">10</span><span class="level-item">B10 高效注意力机制</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#稀疏注意力"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">稀疏注意力</span></span></a></li><li><a class="level is-mobile" href="#因式分解"><span class="level-left"><span class="level-item">10.2</span><span class="level-item">因式分解</span></span></a></li><li><a class="level is-mobile" href="#位置嵌入类型"><span class="level-left"><span class="level-item">10.3</span><span class="level-item">位置嵌入类型</span></span></a></li><li><a class="level is-mobile" href="#ALiBi"><span class="level-left"><span class="level-item">10.4</span><span class="level-item">ALiBi</span></span></a></li><li><a class="level is-mobile" href="#RoPe"><span class="level-left"><span class="level-item">10.5</span><span class="level-item">RoPe</span></span></a></li><li><a class="level is-mobile" href="#位置插值"><span class="level-left"><span class="level-item">10.6</span><span class="level-item">位置插值</span></span></a></li><li><a class="level is-mobile" href="#闪电注意力"><span class="level-left"><span class="level-item">10.7</span><span class="level-item">闪电注意力</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B11-LLM-的蒸馏与量化"><span class="level-left"><span class="level-item">11</span><span class="level-item">B11 LLM 的蒸馏与量化</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#蒸馏设置与训练目标"><span class="level-left"><span class="level-item">11.1</span><span class="level-item">蒸馏设置与训练目标</span></span></a></li><li><a class="level is-mobile" href="#权重量化算法"><span class="level-left"><span class="level-item">11.2</span><span class="level-item">权重量化算法</span></span></a></li><li><a class="level is-mobile" href="#模型尺寸增加对量化误差的影响"><span class="level-left"><span class="level-item">11.3</span><span class="level-item">模型尺寸增加对量化误差的影响</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B12-参数高效微调方法"><span class="level-left"><span class="level-item">12</span><span class="level-item">B12 参数高效微调方法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#高效适应的优势"><span class="level-left"><span class="level-item">12.1</span><span class="level-item">高效适应的优势</span></span></a></li><li><a class="level is-mobile" href="#适配器"><span class="level-left"><span class="level-item">12.2</span><span class="level-item">适配器</span></span></a></li><li><a class="level is-mobile" href="#瓶颈适配器"><span class="level-left"><span class="level-item">12.3</span><span class="level-item">瓶颈适配器</span></span></a></li><li><a class="level is-mobile" href="#低秩适应"><span class="level-left"><span class="level-item">12.4</span><span class="level-item">低秩适应</span></span></a></li><li><a class="level is-mobile" href="#P-微调"><span class="level-left"><span class="level-item">12.5</span><span class="level-item">P*-微调</span></span></a></li><li><a class="level is-mobile" href="#内在维度与模型尺寸的关系"><span class="level-left"><span class="level-item">12.6</span><span class="level-item">内在维度与模型尺寸的关系</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B13-专家混合"><span class="level-left"><span class="level-item">13</span><span class="level-item">B13 专家混合</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#MoE-的属性"><span class="level-left"><span class="level-item">13.1</span><span class="level-item">MoE 的属性</span></span></a></li><li><a class="level is-mobile" href="#现代-MoE-架构在深度学习中的应用"><span class="level-left"><span class="level-item">13.2</span><span class="level-item">现代 MoE 架构在深度学习中的应用</span></span></a></li><li><a class="level is-mobile" href="#基于-MoE-的语言模型"><span class="level-left"><span class="level-item">13.3</span><span class="level-item">基于 MoE 的语言模型</span></span></a></li><li><a class="level is-mobile" href="#MoE-适配器"><span class="level-left"><span class="level-item">13.4</span><span class="level-item">MoE 适配器</span></span></a></li><li><a class="level is-mobile" href="#快速前馈层"><span class="level-left"><span class="level-item">13.5</span><span class="level-item">快速前馈层</span></span></a></li></ul></li><li><a class="level is-mobile" href="#B14-数据集与自举"><span class="level-left"><span class="level-item">14</span><span class="level-item">B14 数据集与自举</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#LM-训练步骤所需的数据集类型"><span class="level-left"><span class="level-item">14.1</span><span class="level-item">LM 训练步骤所需的数据集类型</span></span></a></li><li><a class="level is-mobile" href="#不同数据源的特征"><span class="level-left"><span class="level-item">14.2</span><span class="level-item">不同数据源的特征</span></span></a></li><li><a class="level is-mobile" href="#使用-LLMs-自举训练"><span class="level-left"><span class="level-item">14.3</span><span class="level-item">使用 LLMs 自举训练</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-18T03:55:21.000Z">2025-03-18</time></p><p class="title"><a href="/Data-Science/ITDS-%E8%81%9A%E7%B1%BB/">ITDS-聚类</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-12T06:55:06.000Z">2025-03-12</time></p><p class="title"><a href="/Data-Science/ITDS-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">ITDS-聚类分析</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-12T02:30:00.000Z">2025-03-12</time></p><p class="title"><a href="/Data-Science/ITDS-%E7%AE%80%E4%BB%8B/">ITDS-简介</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T16:18:12.000Z">2025-03-12</time></p><p class="title"><a href="/AI/RL/RL-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">RL-动态规划</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-05T09:05:17.000Z">2025-03-05</time></p><p class="title"><a href="/AI/RL/RL-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/">RL-马尔可夫决策过程</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><span>&copy; 2025 Aloento</span><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>