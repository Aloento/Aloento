<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>NLP-Classification-SequenceTagging - Aloento</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f0f0f0"><meta name="application-name" content="Aloento"><meta name="msapplication-TileImage" content="/img/Aloento.png"><meta name="msapplication-TileColor" content="#f0f0f0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aloento"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="72x72" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="96x96" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="128x128" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="256x256" href="/img/Aloento.png"><meta name="description" content="分类和序列标注"><meta property="og:type" content="blog"><meta property="og:title" content="NLP-Classification-SequenceTagging"><meta property="og:url" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/"><meta property="og:site_name" content="Aloento"><meta property="og:description" content="分类和序列标注"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/bow.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/iob1.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/iob2.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/hmm.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-1.png"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-2.png"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-3.png"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-4.png"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/vite.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/viterbi-5.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/disc.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_normalized.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_unnormalized.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/crf.jpg"><meta property="article:published_time" content="2024-10-05T12:04:00.000Z"><meta property="article:modified_time" content="2025-03-17T15:00:21.721Z"><meta property="article:author" content="Aloento"><meta property="article:tag" content="笔记"><meta property="article:tag" content="AI"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/bow.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/"},"headline":"NLP-Classification-SequenceTagging","image":["https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/bow.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/iob1.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/iob2.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/hmm.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-1.png","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-2.png","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-3.png","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/min-sum-4.png","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/vite.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/viterbi-5.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/disc.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_normalized.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_unnormalized.jpg","https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/crf.jpg"],"datePublished":"2024-10-05T12:04:00.000Z","dateModified":"2025-03-17T15:00:21.721Z","author":{"@type":"Person","name":"Aloento"},"publisher":{"@type":"Organization","name":"Aloento","logo":{"@type":"ImageObject","url":"https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/"}},"description":"分类和序列标注"}</script><link rel="canonical" href="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/"><link rel="icon" href="/img/Aloento.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aloento</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://Q-Audio.org/Aloento">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-05T12:04:00.000Z" title="10/5/2024, 12:04:00 PM">2024-10-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-17T15:00:21.721Z" title="3/17/2025, 3:00:21 PM">2025-03-17</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/NLP/">NLP</a></span><span class="level-item">35 minutes read (About 5253 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">NLP-Classification-SequenceTagging</h1><div class="content"><p>分类和序列标注</p>
<span id="more"></span>

<h1 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h1><h2 id="文本分类任务"><a href="#文本分类任务" class="headerlink" title="文本分类任务"></a>文本分类任务</h2><p>文本分类任务是从给定的 $C&#x3D;{c_1,\dots,c_n}$ 类别&#x2F;分类标签集中为 $d$ 文本&#x2F;文档 分配适当的标签。</p>
<p>代表性的例子包括</p>
<ul>
<li><p><strong>情感分析</strong>：根据文档表达的情感进行分类。标签集示例：</p>
<ul>
<li>{ positive, negative, ambigous }</li>
<li>{ admiration, amusement, annoyance, approval, …, sadness, surprise }</li>
</ul>
</li>
<li><p><strong>垃圾邮件检测</strong>：SPAM，二分类决定消息是否为未经请求的邮件</p>
</li>
<li><p><strong>作者身份检测</strong>：从指定的作者集中确定谁写了文本</p>
</li>
<li><p><strong>作者特征检测</strong>：作者是男性还是女性，他们的年龄等</p>
</li>
<li><p><strong>主题&#x2F;话题检测</strong>：文档属于预定义列表中的哪个 主题&#x2F;话题，例如，在国会图书馆分类系统中 { 医学, 农业, 科学, 美术, … }</p>
</li>
<li><p><strong>体裁检测</strong>：Genre，确定文本的体裁，例如，从集合 { 科幻, 冒险, 爱情故事, 悬疑, 历史, 西部 } 中分配标签</p>
</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul>
<li><strong>手工设计的基于规则的系统</strong>：例如，使用精心设计的与类别正相关或负相关的词列表。</li>
</ul>
<p> 这些系统可以达到良好的性能，但需要大量的手工工作，并且难以维护和适应。</p>
<ul>
<li><p><strong>机器学习方法</strong>：在包含标记文档的监督数据集上学习的模型：<br>${\langle d_i, c_i \rangle}_{i\in {1, \dots, N}}$</p>
<p>方法范围从线性机器学习方法如逻辑回归（logistic regression）到深度神经网络。</p>
</li>
</ul>
<h1 id="词袋表示法"><a href="#词袋表示法" class="headerlink" title="词袋表示法"></a>词袋表示法</h1><p>Bag of words</p>
<p>许多基于机器学习的分类方法需要将输入表示为固定长度的数值向量。对于长度不一的文本，一个常见的方法是使用词袋表示法：</p>
<ul>
<li>使用词汇表 $V&#x3D;{w_1,\dots,w_N}$ 对输入文本进行分词</li>
<li>并将它们表示为 $|V|&#x3D;N$ 维的词频向量，即，对于一个文档 $d$，$BOW_V(d)&#x3D;\langle c_{1,d}, \dots, c_{N,d}\rangle$，其中每个 $c_{i,d}$ 是 $w_i$ 在 $d$ 中的出现次数</li>
</ul>
<p>一个简单的例子：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/bow.jpg" alt="bow"></p>
<h2 id="词袋表示法的改进"><a href="#词袋表示法的改进" class="headerlink" title="词袋表示法的改进"></a>词袋表示法的改进</h2><p>基本的 BOW 表示法可以通过几种方式进行改进，可能最重要的三种是：</p>
<ul>
<li>从 BOW 向量中省略<strong>stopword</strong>（非信息词）的计数。什么算作停用词取决于任务和领域，但通常会考虑（某些）功能词，例如限定词作为停用词</li>
<li>向 BOW 表示中添加一些词序列计数，例如，<strong>bigram</strong>或<strong>三元组</strong>计数</li>
<li>根据词的信息量对词进行加权：最广泛使用的方法是根据<strong>词频</strong>和<strong>逆文档频率</strong>（term frequency-inverse document frequency）进行加权</li>
</ul>
<h2 id="TF-IDF-方案"><a href="#TF-IDF-方案" class="headerlink" title="TF-IDF 方案"></a>TF-IDF 方案</h2><p>TF-IDF 加权方案的基本假设是，出现在大部分训练文档中的词不如只出现在少数文档中的词信息量大。因此，TF-IDF 向量相应地通过文档频率来折扣 word counts（term frequencies）。一个简单但广泛使用的变体：</p>
<p>$$TF{\text -}IDF(d)&#x3D;\langle tf_{1,d}\cdot idf_1, \dots, tf_{N,d}\cdot idf_N\rangle$$</p>
<p>其中 $tf_{i,d}$ 只是 $w_i$ 在 $d$ 中的出现次数，而</p>
<div>
$$idf_i = \log\frac{\mathrm{\# of \space all \space documents}}{\mathrm{\# of \space documents \space containing} \space w_i }$$
</div>

<h2 id="二进制词袋表示法"><a href="#二进制词袋表示法" class="headerlink" title="二进制词袋表示法"></a>二进制词袋表示法</h2><p>词袋表示法的一种有趣的简化是仅指示单词的存在或不存在：</p>
<p>$$BOW_{bin}(d)&#x3D;\mathop{\mathrm{sign}}(BOW(d))$$</p>
<p>其中 $\mathop{\mathrm{sign}}$ 函数的应用是逐元素的，即，</p>
<p>$$BOW_{bin}(d)&#x3D;\langle \mathop{\mathrm{sign}}(c_{1,d}), \dots, \mathop{\mathrm{sign}}(c_{N,d})\rangle$$</p>
<p>事实证明，在许多情况下，这些更简单且占用内存更少的表示法可以代替正常的 BOW 向量使用，而不会有明显的性能差异。</p>
<h1 id="朴素贝叶斯与词袋表示法"><a href="#朴素贝叶斯与词袋表示法" class="headerlink" title="朴素贝叶斯与词袋表示法"></a>朴素贝叶斯与词袋表示法</h1><p>Naive Bayes classifier with BOW</p>
<p>在其最简单的形式中，朴素贝叶斯（NB）分类器是一种生成模型，建模 $\mathbf{x}$ 观测特征向量和它们的 $c$ 类别标签的联合分布为</p>
<p>$$P(\mathbf{x}, c) &#x3D; P(c)\prod_{i&#x3D;1}^D P(x_i \space \vert \space c)$$</p>
<p>该模型被称为“朴素”，因为它基于<em>条件独立假设</em>（conditional<br>independence assumption），即在给定类别标签的情况下，所有观测特征彼此独立。</p>
<p>NB 模型可以通过指定以下内容来精确描述：</p>
<ul>
<li>类别标签的分类分布 $P(c)$，以及</li>
<li>每个 $x_i$ 观测特征和 $c_j$ 标签的 $P(x_i \space \vert \space c_j)$ 分布</li>
</ul>
<p>$P(c)$ 始终是一个分类（伯努利或“多项”）分布，而 $P(x_i \space \vert \space c_j)$ 分布的选择取决于 $x_i$ 的类型；对于连续的 $x_i$，它可以是任何连续分布，高斯分布是一个常见的选择。</p>
<p>NB 模型可以通过将 NB 假设应用于单个标记来适应文本分类：假设每个标记是根据分类条件分布 $P(w \space | \space c)$ 独立选择的。如果 $\mathbf{x}$ 是一个词袋向量，$c$ 是一个类别标签，这意味着</p>
<p>$$P(\mathbf{x}, c) &#x3D; P(c) \prod_{i&#x3D;1}^{|V|}P(w_i \space \vert \space c)^{x_i}$$</p>
<p>为了数值稳定性，对两边取对数：</p>
<p>$$\log P(\mathbf{x}, c) &#x3D; \log P(c) + \sum_{i&#x3D;1}^{|V|}x_i \log P(w_i \space \vert \space c)$$</p>
<p>这意味着，给定一个 $\mathbf{x}$ 词袋向量和一个向量</p>
<p>$$\theta_c&#x3D;\langle \log P(w_1 \space \vert \space c),\dots,\log P(w_{|V|} \space \vert \space c) \rangle$$</p>
<p>表示类别 $c$ 的条件对数概率，</p>
<p>$$\log P(\mathbf{x}, c) &#x3D; \log P(c) + \theta_c \cdot \mathbf{x}$$</p>
<p>即 $(\mathbf{x}, c)$ 的对数概率对于每个 $c_i$ 是一个简单的线性函数。对于一个文档 $d$，预测最可能的类别也非常简单：</p>
<div>
$$\hat c = \mathop{\mathrm{argmax}}_{c\in C}(\log P(c) + \theta_{c} \cdot BOW(d))$$
</div>

<p>模型参数的最大似然估计可以基于简单的计数：</p>
<div>
$$P(c) \approx \frac{\# \mathrm{of} \space c \space \mathrm{documents}}{ \# \mathrm{of \space all \space documents }}$$
</div>

<div>
$$P(w \space | \space c) \approx \frac{\# w \space \mathrm{occurrences \space in} \space c \space \mathrm{documents}}{\# of \space \mathrm{words \space in} \space c \space \mathrm{documents}}$$
</div>

<p>由于我们基本上在处理每个类别的（unigram）语言模型，数据稀疏性再次带来了问题。</p>
<p>最极端的情况是，如果一个词 $w\in V$ 在任何 $c$ 类别的文档中都没有出现，那么基于语料库的最大似然估计 $P(w \space | \space c)&#x3D;0$，因此，对于任何包含 $w$ 的非零计数的 $\mathbf{x}$ 词袋向量的文档，</p>
<p>$$P(\mathbf{x}, c) &#x3D; P(c) \prod_{i&#x3D;1}^{|V|}P(w_i \space \vert \space c)^{x_i}&#x3D;0$$</p>
<p>无论它们包含任何其他词。</p>
<p>解决方案是使用适当的平滑方法，例如，加一平滑。</p>
<h2 id="朴素贝叶斯的局限性"><a href="#朴素贝叶斯的局限性" class="headerlink" title="朴素贝叶斯的局限性"></a>朴素贝叶斯的局限性</h2><p>尽管基于 BOW 的 NB 模型相对简单，可以用于估计和预测，并且表现尚可，但也存在一些缺点：</p>
<ul>
<li>NB 条件独立假设相当不现实，并且在基本 BOW 模型中会导致误导性的概率预测</li>
<li>NB 假设使得使用 $N$-gram 基于 BOW 的特征向量比使用 unigram 更加值得怀疑</li>
<li>对于判别任务使用完整的生成模型通常会带来一些性能损失</li>
</ul>
<h2 id="判别线性方法"><a href="#判别线性方法" class="headerlink" title="判别线性方法"></a>判别线性方法</h2><p>在经典学习算法领域中，最重要的替代方法是使用 BOW 向量的<em>判别方法</em>之一：</p>
<ul>
<li>感知器变体 perceptron variant</li>
<li>逻辑回归</li>
<li>支持向量机（SVM），</li>
<li>基于决策树的集成方法，如随机森林或梯度提升树</li>
</ul>
<p>这些模型不假设条件独立，并且在使用改进的（例如基于 $N$-gram 的）BOW 表示作为输入时没有问题。</p>
<blockquote>
<p>有些出乎意料的是，在某些应用中，在朴素贝叶斯文本分类器中使用重叠(overlapping)的 $N$-gram 实际上对性能有<em>益处</em>，例如，character $N$-gram 经常用于语言识别的 NB 模型中。</p>
</blockquote>
<h1 id="序列标注"><a href="#序列标注" class="headerlink" title="序列标注"></a>序列标注</h1><p>序列标注任务通常是将给定有限标签集 $T$ 中的一个标签分配给可变长度输入序列的每个元素。在 NLP 中，输入序列通常是 $\langle w_1,\dots,w_n \rangle$ 的<em>标记</em>序列。因此，序列标注任务也被称为 <strong>标记分类</strong>。</p>
<p>在传统的 NLP 流水线中，有些任务是明确的序列标注任务，例如词性标注（POS-tagging）和形态标注（morphological tagging）。其他任务，如名词短语分块（NP-chunking）、命名实体识别（NER）或关键词识别，可以通过简单的技巧转化为序列标注任务。</p>
<h2 id="IOB-标注"><a href="#IOB-标注" class="headerlink" title="IOB 标注"></a>IOB 标注</h2><p>Inside-Outside-Beginning</p>
<p>这些任务表面上是跨度查找和跨度标注任务：目标是找到属于某些类别的标记跨度。</p>
<p>例如，在（最小）名词短语（NP）分块的情况下：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/iob1.jpg" alt="http:&#x2F;&#x2F;www.nltk.org&#x2F;book&#x2F;ch07.html"></p>
<p>IOB 技巧是将 跨度识别&#x2F;标注 （span identification） 任务重新表述为序列标注任务。如果有 $T_1,\dots,T_N$ 个要识别的跨度类型，那么我们引入三种类型的标记级别标签：</p>
<ul>
<li><p>对于所有跨度类型的 $B$（开始）标签：<br>$BT_1,\dots,BT_N$ 表示给定类型的跨度的第一个标记</p>
</li>
<li><p>对于所有跨度类型的 $I$（内部）标签：<br>$IT_1,\dots,IT_N$ 表示一个标记在跨度内（作为第二个或更晚的元素），最后</p>
</li>
<li><p>对于不属于任何要找到的跨度类型的标记，使用唯一的 $O$ 标签</p>
</li>
</ul>
<p>使用这些标签，跨度识别任务变成了序列标注任务。</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/iob2.jpg" alt="http:&#x2F;&#x2F;www.nltk.org&#x2F;book&#x2F;ch07.html"></p>
<p>除了 IOB（BIO）之外，还有其他方案，最流行的是 BIOES，它引入了 $ET_i$ <em>结束</em>标签，以及用于单标记跨度的 $ST_i$ 标签。</p>
<h2 id="序列标注的挑战"><a href="#序列标注的挑战" class="headerlink" title="序列标注的挑战"></a>序列标注的挑战</h2><p>序列标注的主要挑战是元素标签与其他元素的特征（包括它们的标签）之间的复杂相互依赖性：在大多数 NLP 标注任务中，标签是 <strong>强烈依赖上下文</strong> 的。</p>
<p>另一个重要问题是特征工程：哪些序列元素的特征与标注相关？如果要正确处理词汇表外的单词，那么至少有些特征可能应该基于单词的表面形式，例如其大写、后缀等。</p>
<h2 id="序列标注的监督方法"><a href="#序列标注的监督方法" class="headerlink" title="序列标注的监督方法"></a>序列标注的监督方法</h2><p>这些方法假设有一个监督数据集</p>
<p>$$D&#x3D;{\langle \mathbf{x_1},\mathbf{y_1} \rangle,\dots, \langle \mathbf{x_N},\mathbf{y_N} \rangle}$$</p>
<div>
其中每对 $\langle \mathbf{x}_i, \mathbf{y}_i \rangle$ 包含一个要标注的序列 $\langle x_1^i,\dots,x_{n_i}^i\rangle$ 和对应的正确标签序列 $\langle y_1^i,\dots,y_{n_i}^i\rangle$。
</div>

<p>我们将讨论的方法都是<em>概率方法</em>（probabilistic）：它们要么建模 $P(\mathbf{X}, \mathbf{Y})$ 联合分布（generative model），要么建模 $P(\mathbf{Y} \space | \space \mathbf{X})$ 条件分布（判别模型，discriminative model）。</p>
<h1 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h1><p>(Hidden Markov models) HMMs 是基于假设<strong>可观察</strong>序列 $\mathbf{x}$ 的元素实际上依赖于位置上对应的<strong>隐藏</strong>序列 $\mathbf{y}$ 的元素的 $P(\mathbf{X}, \mathbf{Y})$ 分布的<em>生成模型</em>，而这些隐藏元素又根据马尔可夫模型分布。条件独立假设共同遵循以下图形模型：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/hmm.jpg" alt="tikzpicture"></p>
<p>由于关于 $Y$ 的马尔可夫模型假设，有一个 $A$ 矩阵指定所有标签的<strong>转移概率</strong>，因此对于任何适当的 $k, i, j$，</p>
<p>$$P(Y_k&#x3D;y_j \space | \space Y_{k-1}&#x3D;y_i) &#x3D; a_{i j}$$</p>
<p>HMMs 还假设 $P(X \space | \space Y)$ <strong>发射概率</strong>与位置无关：因此也有一个 $B$ 矩阵，对于任何 $k, i, j$，</p>
<p>$$P(X_k&#x3D; x_j \space | \space Y_{k}&#x3D; y_i) &#x3D; b_{i j}$$</p>
<p>假设最终有一个包含每个可能 $y_i$ 标签的起始概率的 $\Pi$ 向量：</p>
<p>$$P(Y_1 &#x3D; y_i) &#x3D; \pi_i,$$</p>
<p>具体的 $\langle \mathbf{x}, \mathbf{y} \rangle &#x3D;\langle \langle x_{l_1},\dots,x_{l_n} \rangle, \langle y_{m_1},\dots,y_{m_n} \rangle \rangle$ 对的概率可以计算为</p>
<p>$$P(\mathbf{x}, \mathbf{y}) &#x3D; \pi_{m_1} b_{m_1 l_1} \prod_{i&#x3D;2}^na_{m_{i-1} m_i}b_{m_i l_i}.$$</p>
<p>$A, B$ 和 $\Pi$ 中概率的最大似然估计 (MLE) 可以通过简单计数来计算。如果训练数据集包含 $N$ 个序列，那么</p>
<div>
$$
\begin{equation}
\begin{gathered} \pi_i = \frac{C(\mathrm{first~~element~~is~~} y_i)}{N}\\ \nonumber
 a_{ij} = \frac{C(\langle y_i,y_j\rangle)}{\sum_kC(\langle y_i,y_k\rangle)}\\ \nonumber
 b_{ij} = \frac{C(y_i \mathrm{~~emits~~} x_j)}{C(y_i)} \nonumber
\end{gathered}
\end{equation}
$$
</div>

<p>与其他基于计数的 MLE 方法类似，在数据稀疏（sparse）的情况下可能需要平滑处理。</p>
<h1 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h1><p>Viterbi algorithm</p>
<p>给定一个训练好的 HMM 及其 $\pi, A, B$ 参数，以及一个长度为 $n$ 的输入序列 $\mathbf{x}$，我们希望确定最可能的对应标签序列 $\mathbf{y}$，即找到</p>
<p>$$\mathop{\mathrm{argmax}}_{\mathbf{y}\in Y^n} P(\mathbf{y} | \mathbf{x}, \Pi, A, B)$$</p>
<p>这等价于</p>
<p>$$\mathop{\mathrm{argmax}}_{\mathbf{y}\in Y^n} P(\mathbf{x}, \mathbf{y} | \Pi, A, B)$$</p>
<p>穷举搜索是不可行的，因为有 $|Y|^n$ 种可能的标签序列。</p>
<h2 id="动机：最小和算法"><a href="#动机：最小和算法" class="headerlink" title="动机：最小和算法"></a>动机：最小和算法</h2><p>我们如何根据如下图所示的图表找到 A 和 B 之间的最低成本路径？</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/min-sum-1.png" alt="min-sum1"></p>
<p>与时间复杂度可能是 A 和 B 之间最短路径长度的指数级的暴力（brute）解决方案不同，我们可以使用一个简单的 <strong>消息传递</strong> 方法。</p>
<p>从 A 开始，每个节点</p>
<ul>
<li>接收来自其前驱节点（predecessors）的关于它们从 A 的最小和距离的消息</li>
<li>基于这些消息，计算自己的最小和距离和入边，并</li>
<li>将其最小和距离发送给所有后继节点</li>
</ul>
<p>最终，消息到达 B，B 能够计算出 A-B 的最小和距离，并且可以重建 A 和 B 之间的最小和路径。</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/min-sum-2.png" alt="min-sum2"></p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/min-sum-3.png" alt="Min-Sum algorithm message passing steps"></p>
<p>Min-Sum 算法可以适应解决我们的问题，因为它可以在不进行任何显著更改的情况下用于最大化节点之间路径上的乘积（max-product），并且 HMM 的 transition&#x2F;emission 概率具有所需的有向无环图结构：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/min-sum-4.png" alt="HMM 模型中的转移路径"></p>
<h2 id="The-Viterbi-algorithm"><a href="#The-Viterbi-algorithm" class="headerlink" title="The Viterbi algorithm"></a>The Viterbi algorithm</h2><p>更正式地说，HMM 的 conditional independence assumptions 有以下结果：如果我们知道，对于所有 $y_i\in Y$，值</p>
<div>
$$
\mathbf{y}^{n-1}_i = \mathop{\mathrm{argmax}}_{\mathbf{y}\in Y^{n-1}~\wedge~\mathbf{y}[n-1] = y_i} P(\mathbf{x}[1:n-1], \mathbf{y} ~|~ \Pi, A, B)
$$
</div>

<p>（即以 $y_i$ 结尾的最可能的 $n-1$ 长度标签序列），那么最可能的 $\mathbf{y}$ 可以通过仅比较 $|Y|^2$ 个延续来计算：</p>
<div>
$$
\mathbf{y} = \mathop{\mathrm{argmax}}_{\mathbf{y}\in \{\langle \mathbf{y}_i^{n-1},~y \rangle ~|~ i \in 1\dots |Y|~\wedge~ y \in Y\}} P(\mathbf{x}, \mathbf{y} ~|~ \Pi, A, B)
$$
</div>

<p>这就提出了以下算法：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/vite.jpg" alt="Viterbi algorithm"></p>
<p>算法通常通过逐步填充一个 $|Y| \times \mathrm{length}(\mathbf{x})$ 表来实现。在<em>前向传递</em>中，它</p>
<ol>
<li>计算 $y_i^t$ 的概率，并</li>
<li>维护到最可能的 $\mathbf{y}^{t-1}$ 的反向引用</li>
</ol>
<p>在<em>后向传递</em>中，选择最可能的 $y_i^n$ 并通过跟随反向引用恢复 $\mathbf{y}$。</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/viterbi-5.jpg" alt="https:&#x2F;&#x2F;cs.rice.edu&#x2F;~ogilvie&#x2F;comp571&#x2F;viterbi-algorithm&#x2F;"></p>
<p>维特比是一种 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Dynamic_programming">动态规划</a> 算法，与穷举搜索形成鲜明对比，其时间复杂度为 $\mathcal O(\mathrm{length}(\mathbf{x})|Y|^2)$</p>
<p>跟踪部分 $\mathbf{y}_i^t$ 序列元素及其概率的表仅占用 $\mathcal{O}(\mathrm{length}(\mathbf{x})|Y|)$ 空间。</p>
<p>直接计算要比较的概率需要乘以非常接近于零的数字，因此通常使用对数概率的和来进行计算。</p>
<p>注意：正如我们所见，维特比算法也被称为 <strong>最小和</strong> 或 <strong>最大积</strong> 算法的应用。</p>
<h1 id="判别序列标注方法"><a href="#判别序列标注方法" class="headerlink" title="判别序列标注方法"></a>判别序列标注方法</h1><p>Discriminative methods</p>
<p>与朴素贝叶斯序列分类器类似，HMM 是生成模型，建模输入和标签的概率，这在我们的设置中是不必要的。我们可以通过“反转”输入和标签之间的箭头并对 $\mathbf{X}$ 进行条件化来构建类似结构但<em>判别</em>的模型：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/disc.jpg" alt="tikzpicture"></p>
<h2 id="最大熵马尔可夫模型"><a href="#最大熵马尔可夫模型" class="headerlink" title="最大熵马尔可夫模型"></a>最大熵马尔可夫模型</h2><p>Maximum entropy Markov models (MEMMs)</p>
<p>根据前面的图形模型假设，</p>
<div>
$$
P(\mathbf{Y}~|~\mathbf{X}) = P(Y_1~|~ \mathbf{X})\prod_{m=2}^n P(Y_m|Y_{m-1}, \mathbf{X})
$$
</div>

<p>MEMMs 通过使 $Y_m$ 仅在当前观测 $O_m$ 上条件依赖来形式化这个通用模型：</p>
<div>
$$
P(\mathbf{Y}~|~\mathbf{X}) = P(Y_1~|~O_1)\prod_{m=2}^n P(Y_m|Y_{m-1},O_m)
$$
</div>

<p>那么 $Y_m$ 如何依赖于 $\mathbf{X}$ 呢？诀窍在于如何定义 $O_m$。</p>
<h2 id="特征函数"><a href="#特征函数" class="headerlink" title="特征函数"></a>特征函数</h2><p>$Y_{m-1},O_m$ 对被定义为 $\mathbf{f}(y_k,\mathbf{x}, m)$，其中 $f(\cdot)$ 是一个基于 $Y_{m-1}&#x3D;y_k$ 和 $x$ 在 $m$ 处生成 feature vector 的函数。</p>
<p>在 NLP 中，我们仅在要标注元素周围的<em>上下文窗口</em>内对<em>local features</em>进行条件化。由语言学家设计的一些用于词性标注的示例特征：</p>
<ul>
<li><p>上下文窗口中 $x_m$ 周围的元素，例如 $\langle x_{m-1}, x_{m}, x_{m+1} \rangle$</p>
</li>
<li><p>上下文窗口元素的后缀（固定长度）</p>
</li>
<li><p>上下文窗口元素的前缀（固定长度）</p>
</li>
<li><p>上下文窗口元素的大小写信息</p>
</li>
<li><p>前一个元素的词性标注 $y_k$</p>
</li>
</ul>
<h2 id="MEMMs"><a href="#MEMMs" class="headerlink" title="MEMMs"></a>MEMMs</h2><p>个别的 $P(Y_m|Y_{m-1},X_m)$ 概率类似于使用 softmax 函数的<em>multinomial logistic regression</em>进行建模：</p>
<div>
$$
P(Y_m = y_i|Y_{m-1}=y_k,\mathbf{x})=\frac{\exp (\mathbf{w}_i \cdot \mathbf{f}(y_k,
  \mathbf{x}, m))}{\sum_{j=1}^{|Y|}\exp (\mathbf{w}_j \cdot \mathbf{f}(y_k,
  \mathbf{x}, m))}
$$
</div>

<p>其中每个 $\mathbf{w}_i$ 是 $y_i\in Y$ 标签的权重向量。</p>
<p>MEMM 这个名称来源于在 NLP 中，多项逻辑回归更常被称为<em>maximum entropy</em>。</p>
<h2 id="标签偏置"><a href="#标签偏置" class="headerlink" title="标签偏置"></a>标签偏置</h2><p>尽管 MEMMs 比 HMMs 更灵活（例如，标签可以依赖于上下文的其他特征而不仅仅是前一个标签），但它们也有重要的局限性。</p>
<p>也许最重要的是标签概率是<em>局部归一化</em>的：$\sum_{y\in Y}P(y~|y_{m-1}, \mathbf{x}, m)&#x3D;1$，无论模型对上下文有多“熟悉”，因此模型无法表达对给定上下文中的标签的一般低置信度。</p>
<p>这导致了所谓的<a target="_blank" rel="noopener" href="https://awni.github.io/label-bias/">Label bias</a>问题：模型无法轻易从在低置信度情况下做出的过去标注错误中恢复。</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>一个词性标注器将句子 <em>“cat sat”</em> 标注为 <code>ARTICLE VERB</code>，因为</p>
<ul>
<li><p>标注器无法从 <code>&lt;S&gt;</code> 处 <em>cat</em> 的偏斜后验分布（skewed posterior distribution）中恢复，使用<strong>局部</strong>归一化（图1）。</p>
</li>
<li><p>未归一化的 $\mathbf{w}_i \cdot \mathbf{f}(\cdot)$ 观测值（图2）显示</p>
<ol>
<li>标注器对”<em>cat</em>“ 开始一个句子没有信心</li>
<li><strong>全局</strong> <code>NOUN VERB</code> 具有更高的分数（对数和沿边缘相加）</li>
</ol>
</li>
</ul>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_normalized.jpg" alt="图1, memm_inference_normalized"></p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/memm_inference_unnormalized.jpg" alt="图2, memm_inference_unnormalized"></p>
<h2 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h2><p>线性链条件随机场（Linear chain Conditional Random Fields）是判别模型，旨在避免标签偏置。它们假设以下 <strong>undirected</strong> 结构：</p>
<p><img src="/AI/NLP/NLP-Classification-SequenceTagging/crf.jpg" alt="tikzpicture"></p>
<p>根据这些假设，</p>
<div>
$$P(\mathbf{Y}~|~\mathbf{X}) = \frac{1}{Z(\mathbf{X})}\prod_{m=1}^{n-1}
\phi_{m}(Y_m, Y_{m+1}, \mathbf{X})$$
</div>

<p>与 MEMMs 有些类似，$\phi_m(\cdot)$ <strong>势函数</strong> （potential）通过特征函数和相应的权重向量线性建模。它们基本上是 softmax 的分子：</p>
<p>$$\phi_m(y_m, y_{m+1},\mathbf{x})&#x3D;{\exp (\mathbf{w} \cdot<br>      \mathbf{f}(y_m,y_{m+1}, \mathbf{x}, m))}$$</p>
<p>关键区别在于归一化是<em>全局</em>的：</p>
<div>
$$P(\mathbf{y}~|~\mathbf{x}) =
    \frac{\exp(\sum_{m=1}^{n-1}\mathbf{w}\cdot\mathbf{f}(y_m,y_{m+1},
    \mathbf{x}, m))} {\sum_{\mathbf{y}'\in
    Y^n}\exp(\sum_{m=1}^{n-1}\mathbf{w}\cdot\mathbf{f}(y'_m,y'_{m+1},
    \mathbf{x}, m))}$$
</div>

<h2 id="优化和推理"><a href="#优化和推理" class="headerlink" title="优化和推理"></a>优化和推理</h2><p>MEMMs 和线性链 CRFs 都可以使用标准的凸优化技术进行优化，例如梯度下降，并且在训练模型后，可以使用维特比算法的变体有效地找到给定输入的最可能标签序列。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>NLP-Classification-SequenceTagging</p><p><a href="https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/">https://aloen.to/AI/NLP/NLP-Classification-SequenceTagging/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Aloento</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-10-05</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2025-03-17</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/AI/NLP/NLP-DependencyParsing/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NLP-DependencyParsing</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/AI/NLP/NLP-NGram-LM/"><span class="level-item">NLP-NGram-LM</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/Aloento.png" alt="Aloento"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Aloento</p><p class="is-size-6 is-block">Reindeer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Foot of Sacred Mountain</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">58</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">35</p></a></div></div></nav></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">33</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/RL/"><span class="level-start"><span class="level-item">RL</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/TM/"><span class="level-start"><span class="level-item">TM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Cloud/"><span class="level-start"><span class="level-item">Cloud</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Cloud/OpenStack/"><span class="level-start"><span class="level-item">OpenStack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Data-Science/"><span class="level-start"><span class="level-item">Data Science</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/MSSQL/"><span class="level-start"><span class="level-item">MSSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Theory/"><span class="level-start"><span class="level-item">Theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math/Logic/"><span class="level-start"><span class="level-item">Logic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/Matlab/"><span class="level-start"><span class="level-item">Matlab</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Memo/"><span class="level-start"><span class="level-item">Memo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/"><span class="level-start"><span class="level-item">Program</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Program/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/WebCodecs/"><span class="level-start"><span class="level-item">WebCodecs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/NET/"><span class="tag">.NET</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">33</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C#</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS/"><span class="tag">JS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LINQ/"><span class="tag">LINQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenStack/"><span class="tag">OpenStack</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RL/"><span class="tag">RL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQLServer/"><span class="tag">SQLServer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WebCodecs/"><span class="tag">WebCodecs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B9%A0%E9%A2%98/"><span class="tag">习题</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91/"><span class="tag">云</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%88%E7%89%99%E5%88%A9/"><span class="tag">匈牙利</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"><span class="tag">图灵机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%BB%E7%95%A5/"><span class="tag">攻略</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"><span class="tag">数值方法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"><span class="tag">数据科学</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%95%99%E5%AD%A6/"><span class="tag">留学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">47</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%BB%E8%AF%91/"><span class="tag">翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%80%83%E8%AF%95/"><span class="tag">考试</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%BB%E8%BE%91/"><span class="tag">逻辑</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tag">面试</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"><span class="tag">音视频</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://Q-Audio.org" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Q-Audio</span></span><span class="level-right"><span class="level-item tag">q-audio.org</span></span></a></li><li><a class="level is-mobile" href="https://Musi.Land" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">MusiLand</span></span><span class="level-right"><span class="level-item tag">musi.land</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#文本分类"><span class="level-left"><span class="level-item">1</span><span class="level-item">文本分类</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#文本分类任务"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">文本分类任务</span></span></a></li><li><a class="level is-mobile" href="#方法"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">方法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#词袋表示法"><span class="level-left"><span class="level-item">2</span><span class="level-item">词袋表示法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#词袋表示法的改进"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">词袋表示法的改进</span></span></a></li><li><a class="level is-mobile" href="#TF-IDF-方案"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">TF-IDF 方案</span></span></a></li><li><a class="level is-mobile" href="#二进制词袋表示法"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">二进制词袋表示法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#朴素贝叶斯与词袋表示法"><span class="level-left"><span class="level-item">3</span><span class="level-item">朴素贝叶斯与词袋表示法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#朴素贝叶斯的局限性"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">朴素贝叶斯的局限性</span></span></a></li><li><a class="level is-mobile" href="#判别线性方法"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">判别线性方法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#序列标注"><span class="level-left"><span class="level-item">4</span><span class="level-item">序列标注</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#IOB-标注"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">IOB 标注</span></span></a></li><li><a class="level is-mobile" href="#序列标注的挑战"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">序列标注的挑战</span></span></a></li><li><a class="level is-mobile" href="#序列标注的监督方法"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">序列标注的监督方法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#隐马尔可夫模型"><span class="level-left"><span class="level-item">5</span><span class="level-item">隐马尔可夫模型</span></span></a></li><li><a class="level is-mobile" href="#维特比算法"><span class="level-left"><span class="level-item">6</span><span class="level-item">维特比算法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#动机：最小和算法"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">动机：最小和算法</span></span></a></li><li><a class="level is-mobile" href="#The-Viterbi-algorithm"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">The Viterbi algorithm</span></span></a></li></ul></li><li><a class="level is-mobile" href="#判别序列标注方法"><span class="level-left"><span class="level-item">7</span><span class="level-item">判别序列标注方法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#最大熵马尔可夫模型"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">最大熵马尔可夫模型</span></span></a></li><li><a class="level is-mobile" href="#特征函数"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">特征函数</span></span></a></li><li><a class="level is-mobile" href="#MEMMs"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">MEMMs</span></span></a></li><li><a class="level is-mobile" href="#标签偏置"><span class="level-left"><span class="level-item">7.4</span><span class="level-item">标签偏置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#示例"><span class="level-left"><span class="level-item">7.4.1</span><span class="level-item">示例</span></span></a></li></ul></li><li><a class="level is-mobile" href="#条件随机场"><span class="level-left"><span class="level-item">7.5</span><span class="level-item">条件随机场</span></span></a></li><li><a class="level is-mobile" href="#优化和推理"><span class="level-left"><span class="level-item">7.6</span><span class="level-item">优化和推理</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-12T06:55:06.000Z">2025-03-12</time></p><p class="title"><a href="/Data-Science/ITDS-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">ITDS-聚类分析</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-12T02:30:00.000Z">2025-03-12</time></p><p class="title"><a href="/Data-Science/ITDS-%E7%AE%80%E4%BB%8B/">ITDS-简介</a></p><p class="categories"><a href="/categories/Data-Science/">Data Science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T16:18:12.000Z">2025-03-12</time></p><p class="title"><a href="/AI/RL/RL-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">RL-动态规划</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-05T09:05:17.000Z">2025-03-05</time></p><p class="title"><a href="/AI/RL/RL-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/">RL-马尔可夫决策过程</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-02-23T15:09:25.000Z">2025-02-23</time></p><p class="title"><a href="/AI/RL/RL-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA/">RL-多臂老虎机</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/RL/">RL</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><span>&copy; 2025 Aloento</span><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>