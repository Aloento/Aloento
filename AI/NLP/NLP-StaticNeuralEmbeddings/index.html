<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>NLP-StaticNeuralEmbeddings - Aloento</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f0f0f0"><meta name="application-name" content="Aloento"><meta name="msapplication-TileImage" content="/img/Aloento.png"><meta name="msapplication-TileColor" content="#f0f0f0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aloento"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="72x72" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="96x96" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="128x128" href="/img/Aloento.png"><link rel="apple-touch-icon" sizes="256x256" href="/img/Aloento.png"><meta name="description" content="静态嵌入式神经网络"><meta property="og:type" content="blog"><meta property="og:title" content="NLP-StaticNeuralEmbeddings"><meta property="og:url" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/"><meta property="og:site_name" content="Aloento"><meta property="og:description" content="静态嵌入式神经网络"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/neural_lm.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/skipgram.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_arch.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/hierarchic_softmax.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/glove.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_tsne.jpg"><meta property="og:image" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/analogy.jpg"><meta property="article:published_time" content="2024-10-08T13:04:05.000Z"><meta property="article:modified_time" content="2024-11-08T13:07:42.085Z"><meta property="article:author" content="Aloento"><meta property="article:tag" content="笔记"><meta property="article:tag" content="AI"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/neural_lm.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/"},"headline":"NLP-StaticNeuralEmbeddings","image":["https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/neural_lm.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/skipgram.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_arch.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/hierarchic_softmax.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/glove.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_tsne.jpg","https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/analogy.jpg"],"datePublished":"2024-10-08T13:04:05.000Z","dateModified":"2024-11-08T13:07:42.085Z","author":{"@type":"Person","name":"Aloento"},"publisher":{"@type":"Organization","name":"Aloento","logo":{"@type":"ImageObject","url":"https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/"}},"description":"静态嵌入式神经网络"}</script><link rel="canonical" href="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/"><link rel="icon" href="/img/Aloento.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aloento</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://Q-Audio.org/Aloento">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-08T13:04:05.000Z" title="10/8/2024, 1:04:05 PM">2024-10-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-08T13:07:42.085Z" title="11/8/2024, 1:07:42 PM">2024-11-08</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/NLP/">NLP</a></span><span class="level-item">26 minutes read (About 3841 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">NLP-StaticNeuralEmbeddings</h1><div class="content"><p>静态嵌入式神经网络</p>
<span id="more"></span>

<h1 id="词向量和神经网络"><a href="#词向量和神经网络" class="headerlink" title="词向量和神经网络"></a>词向量和神经网络</h1><p>LSI 和 LSA 的成功表明，基于分布的词向量表示对于 NLP 任务非常有用。在神经网络 NLP 模型中，连续的、密集的词表示尤其重要，因为它们</p>
<ul>
<li>可以用作信息丰富且经济的表示，而不是简单地对词进行独热编码</li>
<li>可以帮助减少模型参数的数量</li>
<li>可以通过神经网络从文本语料库中以自监督的方式学习</li>
</ul>
<p>一个由神经网络学习到的词向量的最早实例之一可以在语言模型中找到：</p>
<p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/neural_lm.jpg" alt="neural_lm"></p>
<p>$C$ 是一个嵌入层，将词汇索引映射到实数向量：</p>
<p>$$C: [0, |V|-1]  \rightarrow \mathbb R^d$$</p>
<p>（静态）词嵌入的维度通常在 50 到 600 之间。</p>
<p>从技术上讲，嵌入层可以通过多种方式实现，例如，作为一个以独热编码词索引为输入的密集层（在这种情况下，词向量表示为层的权重矩阵），或者作为一个表示为数组的查找表等。</p>
<p>关于嵌入层的重要经验教训：</p>
<ul>
<li>嵌入是<em>静态的</em>：相同类型的标记在不同上下文中具有相同的嵌入</li>
<li>使用端到端训练的词嵌入层的模型比传统的 <em>n</em>-gram 语言模型表现更好</li>
<li>使用词共现频率矩阵的前几个主成分作为词特征向量，而不是训练的嵌入，没有同样的性能优势</li>
<li>使用神经网络学习词嵌入是一种扩展训练语料库的可行方法</li>
</ul>
<h1 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h1><h2 id="区别特征"><a href="#区别特征" class="headerlink" title="区别特征"></a>区别特征</h2><p>Word2vec，也是一个神经网络家族，从语料库中学习有用的分布式词表示，但具有几个新颖的特征：</p>
<ul>
<li><p>它是一个专用架构：<strong>表示学习</strong> （representation learning）是其唯一目标</p>
</li>
<li><p>它基于一种新的基于语料库的自监督预测任务</p>
</li>
<li><p>架构被故意保持非常简单，以便能够在具有大词汇量的巨大语料库上进行训练</p>
</li>
</ul>
<h2 id="Skipgrams"><a href="#Skipgrams" class="headerlink" title="Skipgrams"></a>Skipgrams</h2><p>Word2vec 基于 <em>skipgrams</em>，它是 $n$-grams 的推广：虽然 $n$-gram 是文本的<em>连续</em>、长度为 $n$ 的子序列，但 skipgrams 可以包含一定数量的“jumps”：如果基本序列是 $\langle w_1, \dots ,w_N \rangle$，那么具有最多 $k$ 跳距的 $n$ 长度 skipgrams 集合是</p>
<p>$$<br>{\langle w_{i_1} ,\dots ,w_{i_n}\rangle | i_1&lt;\dots&lt;i_n\in[1, N],i_n - i_1  \leq  n -1 + k }<br>$$</p>
<p>可以有额外的限制，例如对单个跳跃的数量和长度的限制。</p>
<h2 id="Word2vec-任务"><a href="#Word2vec-任务" class="headerlink" title="Word2vec 任务"></a>Word2vec 任务</h2><p>Word2vec 任务具体基于长度为 $2c$ 的 skipgrams，在中心有一个单词跳跃。有两种任务变体及其相关的模型架构：</p>
<ul>
<li><strong>CBOW</strong>: Continuous Bag of Words 预测 skipgram 中心的缺失词</li>
<li><strong>SkipGram</strong>: 给定 缺失&#x2F;跳过 的词，预测 skipgram 的元素。与 CBOW 任务不同，每个 skipgram 对应一个分类示例，SkipGram 任务为每个 skipgram 生成多个 $\langle$ 中心词，skipgram 中的词 $\rangle$ 示例</li>
</ul>
<p>skipgram 任务的简单示例：</p>
<p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/skipgram.jpg" alt="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_arch.jpg" alt="w2v_arch"></p>
<p>虽然 SkipGram（右）只是将 $E(\cdot)$ 嵌入映射应用于其一个词输入，CBOW（左）嵌入输入 skipgram 中的所有词并计算它们的和。</p>
<p>在将输入投影到词嵌入空间后，这两种架构都仅使用一个带权重矩阵 $W \in \mathbb R^{|V|\times d}$ 的线性投影和一个最终的 softmax 层来生成词汇表中所有词的预测概率：</p>
<p>$$CBOW(\langle w_{t-c},\dots ,w_{t+c} \rangle) &#x3D; \mathop{\mathrm{softmax}}(W\sum_{i}E(w_i))$$</p>
<p>$$SkipGram(w_t) &#x3D; \mathop{\mathrm{softmax}}(W_{}E(w_t))$$</p>
<p>这两种模型都使用标准的负对数似然损失和 SGD 进行训练，但在示例采样方面有一些有趣的差异。</p>
<p>值得注意的是，投影矩阵 $W \in \mathbb R^{|V|\times d}$ 也可以看作是词汇表在相同 $R^d$ 空间中的 $E’(\cdot)$ 嵌入。使用这种表示法，两个模型对于特定单词 $w_j$ 的 logits（线性输出）可以简单地写成：</p>
<div>
$$CBOW_{linear}[\langle w_{t-c}, \dots ,w_{t+c} \rangle](w_j) = \sum_{i}E(w_i) \cdot E'(w_j),$$
</div>

<div>
$$SkipGram_{linear}[w_t](w_j) = E(w_t) \cdot E'(w_j)$$
</div>

<p>如这种表示法所示，最小化负对数似然训练目标是一种增加输入嵌入和正确预测嵌入的点积的方法。</p>
<p>由于这种表示法所显示的对称性，可以选择<em>绑定两层的权重</em>，使得对所有 $w\in V$ 都有 $E(w) &#x3D; E’(w)$。</p>
<p>尽管这种方法经常被采用，但通常也会保持它们的不同，并且仅使用输入嵌入 $E(\cdot)$ 的向量作为最终结果，或者将它们结合起来，例如取它们的平均值。</p>
<h2 id="数据点生成和采样"><a href="#数据点生成和采样" class="headerlink" title="数据点生成和采样"></a>数据点生成和采样</h2><p>对于 CBOW 变体，我们只需将 $c$ 半径的上下文窗口滑动通过语料库，并在每一步生成一个</p>
<p>$$\langle \langle w_{t-c}, \dots ,w_{t-1}, w_{t+1}, \dots ,w_{t+c} \rangle, w_t \rangle$$</p>
<p>$\langle$ 输入，正确输出 $\rangle$ 数据点。</p>
<p>对于 SkipGram，过程更为复杂，因为在每一步中，实际使用的上下文窗口半径 $r$ 是从 $[1, c]$ 区间内随机选择的，并且为每个 $w_i\in \langle w_{t-r}, \dots ,w_{t-1}, w_{t+1}, \dots ,w_{t+r}\rangle$<br>单词生成一个 $\langle w_t, w_i\rangle$ 数据点。其效果是离目标词越近的词被采样的概率越高。</p>
<h2 id="避免-full-softmax"><a href="#避免-full-softmax" class="headerlink" title="避免 full softmax"></a>避免 full softmax</h2><p>由于对一个 $|V|$ 长度的向量计算全 softmax 对于大 $V$ 来说是昂贵的，Word2vec 实现通常使用更便宜的输出层替代方案。</p>
<p>一种解决方案是 <strong>hierarchical softmax</strong>，它基于一个二叉树，其叶子是词汇表中的单词。网络的线性输出对应于内部节点，分配给一个单词 $w$ 的概率可以通过仅计算路径上 $o$ 输出的 $\sigma(o)$ 值来计算。使用平衡树，这个技巧将训练期间 softmax 计算的复杂度从 $\mathcal O(|V|)$ 降低到 $\mathcal O({\log |V|})$，并且通过巧妙的树结构可以进一步减少。</p>
<h2 id="Hierarchical-softmax"><a href="#Hierarchical-softmax" class="headerlink" title="Hierarchical softmax"></a>Hierarchical softmax</h2><p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/hierarchic_softmax.jpg" alt="hierarchic_softmax"></p>
<p>说明：如果路径上的线性输出是 $o(w_2, 1), o(w_2, 2), o(w_2, 3)$，那么分配给 $w_2$ 的概率可以计算为 $(1-\sigma(o(w_2,1)))(1-\sigma(o(w_2,2)))\sigma(o(w_2,3))&#x3D; \sigma(-o(w_2,1))\sigma(-o(w_2,2))\sigma(o(w_2,3))$。</p>
<h2 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h2><p>另一种替代方案是 <strong>Negative sampling</strong>。这涉及将 SkipGram 任务重新表述为一个二元分类问题。</p>
<ul>
<li><p>我们将语料库中的早期 SkipGram $\langle$ 中心词，背景词 $\rangle$ 数据点视为正例</p>
</li>
<li><p>并且通过从代表整个语料库的噪声分布中采样，为每个中心词生成一定数量的负例“假背景词”</p>
</li>
</ul>
<p>负采样技巧使得简化网络架构成为可能，达到</p>
<p>$$SGNS(w_{t}, w_{c}) &#x3D; \sigma(E_t(w_t)\cdot E_c(w_c))$$</p>
<p>其中 $E_t(\cdot)$ 是目标（中心）词嵌入，而 $E_c(\cdot)$ 是背景词嵌入。对于从 $P_n$ 噪声分布中采样的 $k$ 个负样本，每个真实 $\langle w_t, w_c\rangle$ 数据点的负对数似然损失将是</p>
<p>$$- [ \log SGNS(w_{t}, w_{c}) + \sum_{\substack{i&#x3D;1 \ w_i \sim P_n}}^k \log(1 - SGNS(w_{t}, {w_i}))]$$</p>
<h2 id="Word2vec-作为矩阵分解"><a href="#Word2vec-作为矩阵分解" class="headerlink" title="Word2vec 作为矩阵分解"></a>Word2vec 作为矩阵分解</h2><p>在 Word2Vec 成功之后，许多研究调查了它与基于计数的矩阵分解方法的关系，结果发现它们密切相关：SGNS 目标等价于分解基于词共现的 $M$ 矩阵，其元素为</p>
<p>$$m_{ij} &#x3D; \max(0, PMI(w_i, w_j )- \log k)$$</p>
<p>其中 $PMI(w_i,w_j)$ 是 $w_i$ 和 $w_j$ 的 $\log\left(\frac{P(w_i, w_j)}{P(w_i)P(w_j)}\right)$ <em>点互信息</em>，$k$ 是负样本的数量。</p>
<h2 id="Pointwise-Mutual-Information"><a href="#Pointwise-Mutual-Information" class="headerlink" title="Pointwise Mutual Information"></a>Pointwise Mutual Information</h2><p>PMI 衡量单词在彼此上下文中出现的频率与它们独立出现的频率相比的差异。上下界由 $w_i$ 和 $w_j$ 从不 ($P(w_i, w_j) &#x3D; 0$) 或总是 ($P(w_i, w_j) &#x3D; P(w_i)$ 或 $P(w_i, w_j) &#x3D; P(w_j)$) 共现的情况提供：</p>
<p>$$-\infty \leq PMI(w_i, w_j) \leq \min(-\log(p(w_i)), -\log(p(w_j)))$$</p>
<p>PMI 公式中的 $\frac{P(w_i, w_j)}{P(w_i)P(w_j)}$ 比例可以基于目标词-上下文词共现计数估计为</p>
<div>
$$\frac{C(w_i, w_j)C(\mathrm{\langle target~word, context~word\rangle~pairs~in~corpus})}{C(w_i)C(w_j)}$$
</div>

<p>在一个大型维基百科片段中，PMI 分数最高和最低的三组二元组：</p>
<table>
<thead>
<tr>
<th>单词 1</th>
<th>单词 2</th>
<th>PMI</th>
</tr>
</thead>
<tbody><tr>
<td>puerto</td>
<td>rico</td>
<td>10.03</td>
</tr>
<tr>
<td>hong</td>
<td>kong</td>
<td>9.72</td>
</tr>
<tr>
<td>los</td>
<td>angeles</td>
<td>9.56</td>
</tr>
<tr>
<td>$\cdots$</td>
<td>$\cdots$</td>
<td>$\cdots$</td>
</tr>
<tr>
<td>to</td>
<td>and</td>
<td>-3.08</td>
</tr>
<tr>
<td>to</td>
<td>in</td>
<td>-3.12</td>
</tr>
<tr>
<td>of</td>
<td>and</td>
<td>-3.70</td>
</tr>
</tbody></table>
<h1 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h1><p><strong>GloVe</strong> [Global Vectors] 是另一种从非常大的语料库中学习静态词嵌入的算法。它<em>不是</em>一种神经方法，但在这里讨论是因为它在 Word2vec 之后（一年）发表，作为对其的反应，并且是其最重要的替代方案之一。</p>
<p>与 LSA 方法类似，GloVe 明确基于固定大小上下文窗口中词共现的矩阵的低秩分解，但矩阵元素实际上是词共现的<em>对数</em>。</p>
<p>关注共现的对数是基于以下观察的动机：共现概率的<em>比率</em>在语义上非常有信息量：</p>
<p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/glove.jpg" alt="glove"></p>
<p>该表显示了比率在区分与词对<em>冰</em>、<em>蒸汽</em>相关的词（即<em>固体</em>和<em>气体</em>）与噪声词方面做得很好。</p>
<p>直接分解共现对数概率矩阵需要对于任何 $w_i$, $w_j$ 词对满足</p>
<div>
$$
E_w(w_i)\cdot E_c(w_j)\approx \log (P(w_j~|~ w_i)) \approx \log (C(w_i, w_j)) - \log (C(w_i))
$$
</div>

<p>其中 $E_w(\cdot)$ 词嵌入和 $E_c(\cdot)$ 上下文嵌入满足这个要求，$\log(P(w_k \space | \space w_i)&#x2F;P(w_k \space | \space w_j))$ 对数概率比可以简单地表示为 $(E_w(w_i) - E_w(w_j))\cdot E_c(w_k)$，即语义上信息丰富的共现关系对应于嵌入之间的简单几何关系。</p>
<p>GloVe 不尝试最小化 $E_w(w_i) \cdot E_c(w_j) + \log (C(w_i)) - \log (C(w_i, w_j))$ 的差异对于  $w_1,w_2\in V$，而是最小化密切相关的</p>
<p>$$\sum\limits_{i, j&#x3D;1}^{|V|} f(C(w_i,w_j)) (E_w(w_i)\cdot E_c({w}_j) + b_w(w_i) +<br>  {b_c}(w_j) - \text{log} C(w_i, w_j))^2$$</p>
<p>目标。差异在于</p>
<ul>
<li>$f(\cdot)$ 加权函数对稀有共现进行降权，</li>
<li>为每个词学习的 $b_w$ 和 $b_c$ 偏差，提供了 $\log(C(w_i))$ 的对称替代。</li>
</ul>
<h2 id="GloVe-训练"><a href="#GloVe-训练" class="headerlink" title="GloVe 训练"></a>GloVe 训练</h2><p>与通过滑动上下文窗口训练的 Word2vec 不同，GloVe 的训练分为两个步骤：</p>
<ol>
<li><p>组装全局共现计数矩阵</p>
</li>
<li><p>通过随机梯度下降（SGD）优化上述目标中的 $E_w, E_c, b_w, b_c$ 参数，随机采样共现矩阵的元素</p>
</li>
</ol>
<p>与 Word2vec 相比，GloVe 由于处理共现矩阵（尽管是稀疏的）可能需要更大的内存，但这可以通过在之后对非零矩阵元素进行优化来补偿，其数量通常在语料库长度上是次线性的。</p>
<h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><h2 id="评估类型"><a href="#评估类型" class="headerlink" title="评估类型"></a>评估类型</h2><p>如何衡量词嵌入的质量？作为学习到的表示，词向量可以通过以下方式进行评估：</p>
<ul>
<li><p><strong>内在地</strong>，intrinsically 根据它们与人类对词语语义和形态特征的判断的对应程度</p>
</li>
<li><p><strong>外在地</strong>，extrinsically 根据它们在下游 NLP 任务解决方案中的有用程度</p>
</li>
</ul>
<p>从内在的角度来看，使用适当调整参数并在大型高质量语料库上训练的 Word2vec 可以生成几何特性与人类相似性判断惊人接近的嵌入。</p>
<h2 id="内在评估"><a href="#内在评估" class="headerlink" title="内在评估"></a>内在评估</h2><p>评估词嵌入质量的两种最常用的内在方法是测试它们在两个词汇语义任务中与人类判断的相关性：</p>
<ol>
<li><p><strong>词相似度</strong> Word similarity</p>
</li>
<li><p><strong>类比</strong> Analogy</p>
</li>
</ol>
<h3 id="相似度"><a href="#相似度" class="headerlink" title="相似度"></a>相似度</h3><p>相似的词应该有相似的向量。</p>
<ul>
<li><p>语义：dog - hound</p>
</li>
<li><p>语法：dog<strong>s</strong> - pear<strong>s</strong></p>
</li>
</ul>
<p>两个词的相似度通过它们表示的<em>余弦相似度</em>来衡量：$\frac{E(w_1)\cdot E(w_2)}{|E(w_1)|\times |E(w_2)|}$。</p>
<p>注意：归一化很重要，因为向量的长度大致与词频的对数成正比。</p>
<p>相似度可以通过使用降维技术（例如 t-SNE 或 UMAP）进行可视化，例如：</p>
<p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/w2v_tsne.jpg" alt="w2v_tsne"></p>
<h3 id="类比"><a href="#类比" class="headerlink" title="类比"></a>类比</h3><p>Analogy 任务测试词之间的 <strong>关系</strong>，例如 $king:queen$ 和 $man:woman$，它们在向量空间中的几何关系是否相似。</p>
<p>这些关系对应于向量的<em>差异</em>，即 $E(king)-E(queen)\approx E(man)-E(woman)$</p>
<p>或者，以稍微不同的形式，嵌入最接近 $E(king)-E(queen) + E(woman)$ 的词是否是 $man$。</p>
<p>语义和句法类比的示例：</p>
<p><img src="/AI/NLP/NLP-StaticNeuralEmbeddings/analogy.jpg" alt="analogy"></p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>也有一些专门用于内在评估的数据集，例如：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://alfonseca.org/eng/research/wordsim353.html">WordSim-353</a> 数据集包含 353 对英语单词及其语义相似度分数，范围从 0.0 到 10.0。（注意：原始数据集混淆了<em>相似性</em>和<em>相关性</em>；链接版本大多修正了这一点。）</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://fh295.github.io/simlex.html">SimLex-999</a> 取代了 WordSim-353，包含 999 对单词及其相似度分数，使用相同的评分尺度。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://vecto.space/projects/BATS/">BATS</a>（The Bigger Analogy Test Set）包含 98000 个类比问题，用于测试单词类比与向量偏移之间的对应关系。</p>
</li>
</ul>
<h2 id="外在评估"><a href="#外在评估" class="headerlink" title="外在评估"></a>外在评估</h2><p>Extrinsic 评估可以使用任何 NLP 任务进行，但通常使用标准的序列标注任务，例如命名实体识别。</p>
<p>可以通过在嵌入式架构中切换不同的嵌入来评估它们，同时保持其他部分不变。</p>
<p>在使用嵌入时，有一个重要的区别是直接使用嵌入（“冻结”）而不改变它们，还是对它们进行 <strong>微调</strong>，即在任务数据集上与其他参数一起训练它们。</p>
<h2 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h2><p>在某些共现矩阵上，Word2vec 变体、GloVe 和传统 SVD 之间的性能差异不大。最重要的是，他们发现</p>
<ul>
<li><p>超参数调优对性能的影响大于算法的选择</p>
</li>
<li><p>SGNS 被证明是一个非常强的基线，在任何情况下都没有“显著表现不佳”</p>
</li>
<li><p>两个学习到的嵌入（目标和上下文）的<em>和</em>通常比单独使用其中一个表现显著更好</p>
</li>
</ul>
<h1 id="利用内部词结构"><a href="#利用内部词结构" class="headerlink" title="利用内部词结构"></a>利用内部词结构</h1><p>Utilizing internal word structure</p>
<h2 id="黑箱问题"><a href="#黑箱问题" class="headerlink" title="黑箱问题"></a>黑箱问题</h2><p>我们讨论的词嵌入完全基于分布，词的<em>内部结构</em>不起作用。因此，</p>
<ul>
<li>词汇表外的词，和</li>
<li>在训练语料库中罕见的词</li>
</ul>
<p>没有足够的嵌入，即使它们的 内部形态&#x2F;字符结构（internal<br>morphological&#x2F;character structure） 可以提供关于其语义和句法属性的丰富信息。</p>
<p>除了使用需要形态分析器的<em>词素</em>（morpheme）嵌入外，还出现了一些自监督解决方案。</p>
<h2 id="fastText"><a href="#fastText" class="headerlink" title="fastText"></a>fastText</h2><p>fastText 算法基于 SGNS，但将 $n$-grams ($3\leq n \leq 6$) 添加到词汇表中，并将目标词建模为其所有组成部分嵌入的总和。</p>
<p>例如，对于单词 <em>where</em> 和 $n&#x3D;3$，其组成部分是 <code>&lt;wh</code>、<code>whe</code>、<code>her</code>、<code>ere</code>、<code>re&gt;</code>，加上整个单词 <code>&lt;where&gt;</code>。</p>
<p>SGNS 架构被修改为</p>
<p>$$\sigma(\sum_{w\in G(w_t)}E_t(w)\cdot E_c(w_c))$$</p>
<p>其中 $G(w_t)$ 是 $w_t$ 的所有组成部分的集合。</p>
<p>在相似性任务中，fastText 向量通常比原始 Word2vec 表现更好，尤其是在形态丰富的语言中。</p>
<p>一个额外的重要优势是，使用 fastText 可以通过将其组成 $n$-grams 的嵌入相加来生成未见词的有信息嵌入。</p>
<h2 id="子词嵌入"><a href="#子词嵌入" class="headerlink" title="子词嵌入"></a>子词嵌入</h2><p>解决黑箱问题的一个更激进的解决方案是切换到子词分词（例如，使用 BPE）并使用已建立的算法仅为词汇表中的子词生成嵌入。</p>
<p>例如，<a target="_blank" rel="noopener" href="https://github.com/bheinzerling/bpemb">PBEmb</a> 使用 GloVe 为 BPE 分词生成的子词生成嵌入。类似于 fastText，可以通过组合组成子词的嵌入（例如，取平均值）来生成 OOV 词的嵌入。虽然表现相似，但这种类型的解决方案所需的词汇表明显小于 fastText。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>NLP-StaticNeuralEmbeddings</p><p><a href="https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/">https://aloen.to/AI/NLP/NLP-StaticNeuralEmbeddings/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Aloento</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-10-08</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-11-08</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/AI/NLP/NLP-RNNs/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NLP-RNNs</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/AI/NLP/NLP-LexicalSemantics/"><span class="level-item">NLP-LexicalSemantics</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/Aloento.png" alt="Aloento"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Aloento</p><p class="is-size-6 is-block">Reindeer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Foot of Sacred Mountain</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">36</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">34</p></a></div></div></nav></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/TM/"><span class="level-start"><span class="level-item">TM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Cloud/"><span class="level-start"><span class="level-item">Cloud</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Cloud/OpenStack/"><span class="level-start"><span class="level-item">OpenStack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Data-Science/"><span class="level-start"><span class="level-item">Data Science</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/MSSQL/"><span class="level-start"><span class="level-item">MSSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Theory/"><span class="level-start"><span class="level-item">Theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math/Logic/"><span class="level-start"><span class="level-item">Logic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/Matlab/"><span class="level-start"><span class="level-item">Matlab</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Memo/"><span class="level-start"><span class="level-item">Memo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/"><span class="level-start"><span class="level-item">Program</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Program/C/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Program/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Program/WebCodecs/"><span class="level-start"><span class="level-item">WebCodecs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/NET/"><span class="tag">.NET</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C#</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS/"><span class="tag">JS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LINQ/"><span class="tag">LINQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenStack/"><span class="tag">OpenStack</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQLServer/"><span class="tag">SQLServer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WebCodecs/"><span class="tag">WebCodecs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B9%A0%E9%A2%98/"><span class="tag">习题</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91/"><span class="tag">云</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%88%E7%89%99%E5%88%A9/"><span class="tag">匈牙利</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%81%B5%E6%9C%BA/"><span class="tag">图灵机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%BB%E7%95%A5/"><span class="tag">攻略</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95/"><span class="tag">数值方法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"><span class="tag">数据科学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%95%99%E5%AD%A6/"><span class="tag">留学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">25</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%BB%E8%AF%91/"><span class="tag">翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%80%83%E8%AF%95/"><span class="tag">考试</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%BB%E8%BE%91/"><span class="tag">逻辑</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tag">面试</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"><span class="tag">音视频</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://Q-Audio.org" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Q-Audio</span></span><span class="level-right"><span class="level-item tag">q-audio.org</span></span></a></li><li><a class="level is-mobile" href="https://Musi.Land" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">MusiLand</span></span><span class="level-right"><span class="level-item tag">musi.land</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#词向量和神经网络"><span class="level-left"><span class="level-item">1</span><span class="level-item">词向量和神经网络</span></span></a></li><li><a class="level is-mobile" href="#Word2vec"><span class="level-left"><span class="level-item">2</span><span class="level-item">Word2vec</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#区别特征"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">区别特征</span></span></a></li><li><a class="level is-mobile" href="#Skipgrams"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Skipgrams</span></span></a></li><li><a class="level is-mobile" href="#Word2vec-任务"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Word2vec 任务</span></span></a></li><li><a class="level is-mobile" href="#架构"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">架构</span></span></a></li><li><a class="level is-mobile" href="#数据点生成和采样"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">数据点生成和采样</span></span></a></li><li><a class="level is-mobile" href="#避免-full-softmax"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">避免 full softmax</span></span></a></li><li><a class="level is-mobile" href="#Hierarchical-softmax"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">Hierarchical softmax</span></span></a></li><li><a class="level is-mobile" href="#负采样"><span class="level-left"><span class="level-item">2.8</span><span class="level-item">负采样</span></span></a></li><li><a class="level is-mobile" href="#Word2vec-作为矩阵分解"><span class="level-left"><span class="level-item">2.9</span><span class="level-item">Word2vec 作为矩阵分解</span></span></a></li><li><a class="level is-mobile" href="#Pointwise-Mutual-Information"><span class="level-left"><span class="level-item">2.10</span><span class="level-item">Pointwise Mutual Information</span></span></a></li></ul></li><li><a class="level is-mobile" href="#GloVe"><span class="level-left"><span class="level-item">3</span><span class="level-item">GloVe</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#GloVe-训练"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">GloVe 训练</span></span></a></li></ul></li><li><a class="level is-mobile" href="#评估"><span class="level-left"><span class="level-item">4</span><span class="level-item">评估</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#评估类型"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">评估类型</span></span></a></li><li><a class="level is-mobile" href="#内在评估"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">内在评估</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#相似度"><span class="level-left"><span class="level-item">4.2.1</span><span class="level-item">相似度</span></span></a></li><li><a class="level is-mobile" href="#类比"><span class="level-left"><span class="level-item">4.2.2</span><span class="level-item">类比</span></span></a></li><li><a class="level is-mobile" href="#数据集"><span class="level-left"><span class="level-item">4.2.3</span><span class="level-item">数据集</span></span></a></li></ul></li><li><a class="level is-mobile" href="#外在评估"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">外在评估</span></span></a></li><li><a class="level is-mobile" href="#评估结果"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">评估结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#利用内部词结构"><span class="level-left"><span class="level-item">5</span><span class="level-item">利用内部词结构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#黑箱问题"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">黑箱问题</span></span></a></li><li><a class="level is-mobile" href="#fastText"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">fastText</span></span></a></li><li><a class="level is-mobile" href="#子词嵌入"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">子词嵌入</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-08T10:19:28.000Z">2024-11-08</time></p><p class="title"><a href="/AI/NLP/NLP-Inference/">NLP-Inference</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-07T05:30:14.000Z">2024-11-07</time></p><p class="title"><a href="/AI/NLP/NLP-DialogSystems/">NLP-DialogSystems</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-06T10:18:54.000Z">2024-11-06</time></p><p class="title"><a href="/AI/NLP/NLP-Transformers/">NLP-Transformers</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-11T12:41:56.000Z">2024-10-11</time></p><p class="title"><a href="/AI/NLP/NLP-PreExamA/">NLP-PreExamA</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-10T13:07:12.000Z">2024-10-10</time></p><p class="title"><a href="/AI/NLP/NLP-Seq2Seq/">NLP-Seq2Seq</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/NLP/">NLP</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><span>&copy; 2024 Aloento</span><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Q-Audio" href="https://Q-Audio.org"><i class="fas fa-compact-disc"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="MusiLand" href="https://Musi.Land/"><i class="fab fa-dashcube"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Aloento"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>