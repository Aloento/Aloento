---
title: NLP-DependencyParsing
toc: true
categories:
  - [AI, NLP]
tags: [笔记, AI, NLP]
date: 2024-10-06 17:20:27
---

依赖关系解析

<!-- more -->

# 依存解析任务

## 句法解析

（复习）Syntactic theories 旨在描述

> “支配单词如何组合成短语、形成良构单词序列的规则或原则。”

在这种情况下，最重要的“良构序列”是*句子*：给定语言的句法理论的核心目标是找到 characterize/delineate 该语言良构句子的结构规则或原则。

如果一个句子具有满足所讨论理论的句法约束的*结构描述*或*句法解析*，那么它就是良构的。句法上的良构性并不保证连贯性或有意义。引用乔姆斯基的著名例子：

> Colorless green ideas sleep furiously.

在句法上是良构的但无意义，而

> Furiously sleep ideas green colorless.

甚至不是良构的。

## 依存语法

（复习）Dependency grammars 将单词之间的**依存关系**视为基本关系。

具体标准因理论而异，但通常在一个句子中，如果一个 $d$ 单词依赖于一个 $h$ 单词（等价地，$h$ 支配 $d$），则

- $d$ 修饰 $h$ 的意义，使其更具体，例如 *eats* $\Rightarrow$ *eats bread*, *eats slowly* 等

- 并且它们之间存在不对称的可省略关系：可以从句子中省略 $d$ 而保留 $h$，反之则不行

依存语法对一个良构句子中的依存关系施加了重要的全局约束，例如，

- 恰好有一个独立的单词（句子的根）。

- 所有其他单词直接依赖于一个单词。

由于这些约束的结果，句子的直接依存图是一个树。

大多数依存语法使用*typed direct dependencies*：存在有限的直接依存类型列表，并对它们何时可以成立施加特定约束。

## 投射性

依存解析树的一个重要（但并非总是满足）要求是*projectivity*：

> 如果一个 $w$ 单词直接依赖于 $h$，并且一个 $w'$ 单词在句子的词序中位于它们之间，那么这个 $w'$ 的支配词要么是 $w$，要么是 $h$，或者是位于它们之间的另一个单词。

更不正式地说，投射性条件表明依存关系是*嵌套的*，单词之间不能有*交叉*依存关系。

![projectivity](projectivity.jpg)

## 依存语法的优势

依存语法已成为 NLP 中使用的主要句法理论，因为

- 依存树在许多方面比短语结构解析树更简单的结构（例如，每个单词只有一个节点）；

- 依存图提供的句子谓词-论元分析是事件或框架导向语义分析的一个很好的起点。

[*Universal Dependencies (UD)*](https://universaldependencies.org/) 框架已被创建，以促进不同语言之间的一致 annotation。

## 语义表示的可用性

比较事件语义方面

![event-semantics](1.jpg)
![event-semantics](2.jpg)
![event-semantics](3.jpg)
![event-semantics](4.jpg)

## 依存解析

给定一个句法理论（syntactic theory），解析任务是为输入句子分配满足该理论 constraints/conditions 的句法结构。对于依存语法，这意味着分配一个*依存结构*：

- 识别句子中单词之间的直接依存关系

- 以这样的方式使它们共同构成一个满足所有理论约束的*依存树*

在现代 NLP 实践中，解析任务所依据的依存语法通常是隐式指定的，使用所谓的**树库**，即由带有解析树注释的句子组成的数据集。

这使得解析成为一个**结构化的监督学习任务**：给定一个由大量 $\langle \mathrm{sentence}, \mathrm{parse} \space \mathrm{tree} \rangle$ 对组成的训练集，学习预测未见句子的解析树。

## 性能指标

对于依存语法解析器，最常用的评估指标是

- **UAS**：Unlabeled Attachment Score（无标签依存准确率）正确依附于正确支配词的单词百分比

- **LAS**：Labeled Attachment Score（有标签依存准确率）正确依附于正确支配词并具有正确依存标签的单词百分比

## 解析算法

像大多数序列标注方法一样，依存解析算法使用将预测任务分解为结构元素的单个决策的策略。在这种情况下，

- 单个决策是关于单词之间的个体依存关系

- 主要问题是确保这些单个决策能形成一个连贯的依存树

依存解析器通常使用

- **transition-based**，或

- **graph-based**的方法

# 基于转换的解析

该算法基于一个解析过程的形式模型，该模型从左到右移动要解析的句子，并在每一步选择以下操作之一：

- 将当前单词分配为某个先前看到的单词的中心词

- 将某个先前看到的单词分配为当前单词的中心词

- 或者推迟对当前单词的任何处理，将其添加到存储中以供以后处理

该过程的形式模型由以下组件组成：

- 一个**缓冲区**，其中包含未处理的输入标记

- 一个**堆栈**，包含当前操作的标记并存储推迟的元素

- 一个**依存图**，用于为输入句子构建

## 模型配置

在过程的每一步，模型处于某种**配置**中：

![transition_config](transition_config.jpg)

## 初始配置

解析过程从特殊的初始配置开始，其中

- 缓冲区包含输入的所有单词

- 堆栈包含依存图的单个根节点

- 并且依存图是空的（不包含任何依存边）

## 解析过程

在每一步，都会执行一个允许的配置操作（配置转换）。允许的操作有所不同；在所谓的 **arc standard** 方法中使用了一组非常简单的操作：

- **带标签 $l$ 的左弧**：将边 $s_2\xleftarrow{l} s_1$ 添加到图中并移除 $s_2$（$s_2$ 不能是根元素）

- **带标签 $l$ 的右弧**：将边 $s_2\xrightarrow{l} s_1$ 添加到图中并移除 $s_1$（$s_1$ 不能是根元素）

- **移位**：从缓冲区中移除第一个单词 $w_1$ 并将其放在堆栈顶部

当达到一个无法执行任何操作的配置时，过程结束。

该过程保证在有限步数后结束，在此配置中，缓冲区为空，并且创建的依存图是整个输入的良构依存树：

- 它会结束，因为在每一步中我们都会减少“依存图的 collective token distance”

  $2 \cdot \#(\mathrm{缓冲区中的tokens}) + \#(\mathrm{堆栈中的tokens})$

- 缓冲区必须为空，因为否则移位操作将可用，并且堆栈只能包含根元素，原因类似

- 每个输入标记在图中恰好有一个中心词

- 图中不能有*circle*

![An example parser run](transition_run.jpg)
