---
title: ITDS Final
toc: true
categories:
  - [Data Science]
tags: [è€ƒè¯•, æ•°æ®ç§‘å­¦]
date: 2025-05-05 14:13:32
---

~~èµ¶ç´§æ¯•ä¸šå§~~

<!-- more -->

# 2024-12-10

## Missing Values

Explain how would you pre-process the data if you would like to use linear classification/regression methods and the data would contain only categorical/nominal attributes. What could we do with missing values in this case?

<details>

è§£é‡Šå¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨çº¿æ€§åˆ†ç±»/å›å½’æ–¹æ³•ï¼Œå¹¶ä¸”æ•°æ®ä»…åŒ…å«åˆ†ç±»/åä¹‰å±æ€§ï¼Œæ‚¨å°†å¦‚ä½•é¢„å¤„ç†æ•°æ®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Ÿ

Class ç”¨ One-Hotï¼Œæœ‰åºç±»åˆ«è¿˜èƒ½ç”¨ Label Encodingã€‚
ç¼ºå¤±å€¼å¯ä»¥ç”¨ä¼—æ•°ï¼ˆMode Imputationï¼‰å¡«å……ï¼Œæˆ–è€…ç”¨æ¨¡å‹ï¼ˆå¦‚ KNNï¼‰å¡«å……ã€‚

</details>

## Evaluation

Explain how internal and external evaluation of clusters work.

<details>

è§£é‡Šèšç±»çš„å†…éƒ¨è¯„ä¼°å’Œå¤–éƒ¨è¯„ä¼°æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

å†…éƒ¨ï¼šä¸ä¾èµ–çœŸå®æ ‡ç­¾ï¼Œç°‡å†…ç›¸ä¼¼åº¦æ˜¯å¦é«˜ã€ç°‡é—´å·®å¼‚æ˜¯å¦å¤§ï¼Œå¦‚ Silhouette Score
å¤–éƒ¨ï¼šä¾èµ–å·²æœ‰çš„çœŸå®æ ‡ç­¾ï¼Œä¸èšç±»ç»“æœè¿›è¡Œæ¯”è¾ƒ

</details>

## Regularized LR

Write down the objective function for regularized linear regression. Explain, under which values (high or small) of the regularization hyper-parameter, the resulting model will overfit or underfit.

<details>

å†™å‡ºæ­£åˆ™åŒ–çº¿æ€§å›å½’çš„ç›®æ ‡å‡½æ•°ã€‚è§£é‡Šåœ¨æ­£åˆ™åŒ–è¶…å‚æ•°çš„é«˜å€¼æˆ–ä½å€¼ä¸‹ï¼Œæ¨¡å‹ä¼šè¿‡æ‹Ÿåˆè¿˜æ˜¯æ¬ æ‹Ÿåˆã€‚

Ridge: $\sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p}\beta_j^2$

$\lambda$ å¤§ï¼šç®€å•ï¼Œæ¬ æ‹Ÿåˆ
$\lambda$ å°ï¼šå¤æ‚ï¼Œè¿‡æ‹Ÿåˆ

</details>

## Error

What is the relation between the prediction error on the test set and the model complexity?

<details>

æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹è¯¯å·®ä¸æ¨¡å‹å¤æ‚åº¦ä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ

U å½¢å…³ç³»ï¼šæ¨¡å‹å¤ªç®€å•æˆ–å¤ªå¤æ‚ï¼Œè¯¯å·®éƒ½é«˜ã€‚æœ€ä½³å¤æ‚åº¦åœ¨ä¸­é—´ã€‚

</details>

## Binary

What is a possible way to classify color images of animals to three different classes using binary classification methods? How would you represent the data? How would you do cross-validation in this case (i.e. how would you select the folds)?

<details>

ä½¿ç”¨äºŒå…ƒåˆ†ç±»æ–¹æ³•å°†åŠ¨ç‰©çš„å½©è‰²å›¾åƒåˆ†ç±»ä¸ºä¸‰ä¸ªä¸åŒç±»åˆ«çš„ä¸€ç§å¯èƒ½æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨å°†å¦‚ä½•è¡¨ç¤ºæ•°æ®ï¼Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å°†å¦‚ä½•è¿›è¡Œäº¤å‰éªŒè¯ï¼ˆå³ï¼Œæ‚¨å°†å¦‚ä½•é€‰æ‹©æŠ˜å ï¼‰ï¼Ÿ

One-vs-Restï¼Œå°†ä¸‰ç±»é—®é¢˜æ‹†åˆ†ä¸ºä¸‰ä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼Œæ¯ä¸ªåˆ†ç±»å™¨è´Ÿè´£è¯†åˆ«æŸä¸€ç±»åˆ«ã€‚
è½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾ï¼Œå¦‚ CNNã€‚
ä½¿ç”¨ Stratified k-fold CVï¼Œç¡®ä¿æ¯ä¸ªç±»çš„æ¯”ä¾‹ç›¸åŒã€‚

</details>

# 2024-12-27

## Metric

Verify if $\mathbf{d(x,y)} = \max(|x - y|, 1)$ a distance measure for two binary strings $x$ and $y$ of equal length satisfies the properties of a metric.

<details>

éªŒè¯ $\mathbf{d(x,y)} = \max(|x - y|, 1)$ æ˜¯å¦æ»¡è¶³ä½œä¸ºä¸¤ä¸ªç­‰é•¿äºŒè¿›åˆ¶å­—ç¬¦ä¸² $x$ å’Œ $y$ çš„è·ç¦»åº¦é‡çš„æ€§è´¨ã€‚

1. éè´Ÿï¼Œå› ä¸ºç»å¯¹å€¼å’Œ max éƒ½æ˜¯éè´Ÿçš„
2. å¯¹ç§°ï¼Œå› ä¸º $|x - y| = |y - x|$
3. ç­‰ä»·ï¼Œä¸æ»¡è¶³ï¼Œå› ä¸º $d(x,x) = 1$ï¼Œè€Œä¸æ˜¯ 0

æ‰€ä»¥ä¸æ»¡è¶³åº¦é‡çš„æ€§è´¨ã€‚

</details>

## Linkage

Provide a scenario or a dataset where complete linkage clustering would be less effective and justify your reasoning.

<details>

æä¾›ä¸€ä¸ª complete linkage èšç±»æ•ˆæœè¾ƒå·®çš„åœºæ™¯æˆ–æ•°æ®é›†ï¼Œå¹¶è¯´æ˜æ‚¨çš„ç†ç”±ã€‚

å…·æœ‰ä¸åŒå¯†åº¦æˆ–éçƒçŠ¶ç°‡çš„æ•°æ®é›†ã€‚
å› ä¸º complete äº§ç”Ÿç´§å‡‘ï¼ŒçƒçŠ¶çš„ç°‡ã€‚

</details>

## Equation

Given the following equation: $\sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p}\beta_j^2$, what do the components of this equation represent? Discuss the impact of using very small and very large values of $\lambda$.

<details>

ç»™å®šä»¥ä¸‹æ–¹ç¨‹ï¼š$ \sum*{i=1}^{n}(y_i - \hat{y}\_i)^2 + \lambda \sum*{j=1}^{p}\beta_j^2 $ï¼Œè¯¥æ–¹ç¨‹çš„å„éƒ¨åˆ†ä»£è¡¨ä»€ä¹ˆï¼Ÿè®¨è®ºä½¿ç”¨éå¸¸å°å’Œéå¸¸å¤§çš„ $\lambda$ å€¼çš„å½±å“ã€‚

1. ç¬¬ä¸€é¡¹ï¼šè®­ç»ƒè¯¯å·®ï¼Œåœ¨è®­ç»ƒé›†ä¸Šçš„æ‹Ÿåˆç¨‹åº¦
2. L2 æ­£åˆ™åŒ–é¡¹ï¼Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦
3. $\lambda$ å¤§ï¼šæ¨¡å‹ç®€å•ï¼Œæ¬ æ‹Ÿåˆ
4. $\lambda$ å°ï¼šæ¨¡å‹å¤æ‚ï¼Œè¿‡æ‹Ÿåˆ

</details>

## Multi-Class

How can logistic regression be modified to perform multi-class classification?

<details>

å¦‚ä½•ä¿®æ”¹é€»è¾‘å›å½’ä»¥æ‰§è¡Œå¤šç±»åˆ†ç±»ï¼Ÿ

One-vs-Restï¼šæ¯ä¸ªç±»åˆ«è®­ç»ƒä¸€ä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼Œé¢„æµ‹â€œè¯¥ç±» vs å…¶ä»–â€
Softmax å›å½’ï¼šå°†æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡å½’ä¸€åŒ–ä¸º 1

</details>

## k-Fold

Explain the concept of k-fold cross-validation and describe the steps involved in performing it.

<details>

è§£é‡Š k æŠ˜äº¤å‰éªŒè¯çš„æ¦‚å¿µï¼Œå¹¶æè¿°æ‰§è¡Œå®ƒæ‰€æ¶‰åŠçš„æ­¥éª¤ã€‚

ä¸€ç§æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œç”¨äºæ›´å¯é åœ°ä¼°è®¡æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„è¡¨ç°ã€‚

1. å°†æ•°æ®é›†å¹³å‡åˆ†æˆ k ä¸ªå­é›†
2. é€‰æ‹©ä¸€ä¸ªå­é›†ä½œä¸ºéªŒè¯é›†ï¼Œå…¶ä»– k-1 ä¸ªå­é›†ä½œä¸ºè®­ç»ƒé›†
3. è®­ç»ƒæ¨¡å‹å¹¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ€§èƒ½
4. é‡å¤ k æ¬¡ï¼Œè®¡ç®—å¹³å‡å€¼

</details>

# 2025-5-13

1. In supervised learning, what is assumed about the relationship between input and output?

   - There is no relationship.
   - Output is random and unrelated to input.
   - The input is a function of the output.
   - There is a true functional relationship $f : \mathcal{X} \rightarrow \mathcal{Y}$.

<details>

4. è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å­˜åœ¨ä¸€ä¸ªå›ºå®šä½†æœªçŸ¥çš„å‡½æ•°å…³ç³»

</details>

2. What is a primary risk of setting $K = 1$ in KNN?

   - Underfitting.
   - Slow inference.
   - High bias.
   - High variance.

<details>

4. 1 æ—¶ï¼ŒKNN ä»…æ ¹æ®æœ€è¿‘çš„ä¸€ä¸ªé‚»å±…åšå‡ºé¢„æµ‹ï¼Œè¿‡æ‹Ÿåˆ â†’ æ³›åŒ–å·® â†’ é«˜æ–¹å·®

</details>

3. In KNN, how the proximity in continuous feature spaces is computed?

   - $L_1$ norm.
   - Hamming distance.
   - $L_2$ norm.
   - Cosine distance.

<details>

3. KNN é€šå¸¸ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆ$L_2$ èŒƒæ•°ï¼‰æ¥è®¡ç®—è¿ç»­ç‰¹å¾ç©ºé—´ä¸­çš„é‚»è¿‘åº¦ã€‚

</details>

4. How does increasing the value of K in KNN typically affect model behavior?

   - It reduces both bias and variance.
   - It increases variance and decreases bias.
   - It decreases variance and increases bias.
   - It has no effect on model generalization.

<details>

3. å¢å¤§ Kï¼Œè€ƒè™‘æ›´å¤šé‚»å±…ï¼Œå¹³æ»‘ç¨³å®šï¼Œå‡å°‘æ–¹å·®ã€‚æ¨¡å‹å¯¹å±€éƒ¨ä¸æ•æ„Ÿï¼Œå¢åŠ åå·®ã€‚

</details>

5. Which of the following characterizes the fundamental distinction between classification and regression?

   - Classification models learn a mapping to a probability distribution over discrete categories, whereas regression models learn a mapping to a continuous-valued function.
   - Both tasks model continuous outputs but differ in their feature extraction techniques.
   - Classification involves fitting continuous target variables with discrete output models, while regression discretizes continuous inputs.
   - Regression aims to partition the input space into finite regions, while classification fits a continuous response surface.

<details>

1. åˆ†ç±»æ˜¯é¢„æµ‹ç±»åˆ«ï¼Œå›å½’æ˜¯é¢„æµ‹è¿ç»­æ•°å€¼

</details>

6. $p(y = C \mid x) = \frac{1}{1 + \sum_{c=1}^{C-1} \exp(\beta_c^T x)}$
   The equation represents:

   - The probability of class C in a softmax function used for multi-class classification.
   - The probability of class C in a one-vs-rest logistic regression model.
   - The probability of class C in a multinomial logistic regression model with class C as the reference class.
   - The posterior probability of the most likely class in a Naive Bayes classifier.

<details>

3. è¯¥å…¬å¼è¡¨ç¤ºï¼šç»™å®šè¾“å…¥ ğ‘¥ï¼Œå±äºå‚è€ƒç±»åˆ« C çš„æ¦‚ç‡ã€‚å…¶ä»–ç±»ç”¨ $\beta_c^T x$ è¡¨ç¤ºå¯¹æ¯”è¯¥å‚è€ƒç±»çš„ç›¸å¯¹å¯¹æ•°å‡ ç‡ã€‚

</details>

7. In logistic regression, the log-odds are modeled as:

   - $p = x / \beta$
   - $y = \beta_0 + \beta_1 x$
   - $\log(\text{odds}) = \beta_0 + \beta_1 x$
   - odds = $x^2$

<details>

3. åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæˆ‘ä»¬å»ºæ¨¡çš„æ˜¯äº‹ä»¶å‘ç”Ÿçš„å¯¹æ•°å‡ ç‡

</details>

8. In Weighted KNN, how are the votes from neighbors typically weighted?

   - Neighbors closer to the query point contribute more weight.
   - Each neighbor contributes equally, regardless of distance.
   - Weights are assigned randomly to each neighbor.
   - Only the single closest neighbor contributes to the prediction.

<details>

1. ç¦»å¾—è¿‘çš„é‚»å±…å½±å“æ›´å¤§

</details>

9. What type of model is KNN considered?

   - Semi-parametric.
   - Parametric.
   - Non-parametric.
   - Deterministic.

<details>

3. æ²¡æœ‰å›ºå®šæ•°é‡çš„å‚æ•°

</details>

10. Which of the following is a benefit of standardizing features in KNN?

    - Ensures distance metrics are meaningful.
    - Reduces variance.
    - Reduces overfitting.
    - Improves interpretability.

<details>

1. KNN ä½¿ç”¨è·ç¦»æ¥åˆ¤æ–­é‚»å±…ï¼Œæ•°å€¼å¤§çš„ç‰¹å¾ä¼šä¸»å¯¼è·ç¦»è®¡ç®—

</details>

11. What does the sigmoid function return values between?

    - $[0, 1]$
    - $[-1, 1]$
    - $[0, \infty)$
    - $(-\infty, \infty)$

<details>

1. Sigmoid å‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯ $[0, 1]$ï¼Œé€‚åˆäºŒåˆ†ç±»é—®é¢˜ã€‚

</details>

12. The output of logistic regression is interpreted as:

    - Distance from hyperplane.
    - Number of features.
    - Probability of belonging to class 1.
    - Logarithm of class frequencies.

<details>

3. sigmoid å‡½æ•°çš„è¾“å‡ºå±äºç±»åˆ« 1 çš„æ¦‚ç‡ã€‚

</details>

13. What is a potential drawback of LOOCV (Leave-One-Out Cross-Validation)?

    - High variance.
    - Overfitting.
    - High computation cost.
    - Uses too little data.

<details>

3. LOOCV æ˜¯å°†æ¯ä¸ªæ ·æœ¬å•ç‹¬ä½œä¸ºéªŒè¯é›†ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒé›†ã€‚ç¼ºç‚¹æ˜¯è®¡ç®—æˆæœ¬é«˜

</details>

14. In k-fold cross-validation, what happens in each iteration?

    - Train on $k-1$ folds, validate on 1 fold.
    - Train on one fold, test on the rest.
    - Train on all data, test on one fold.
    - Train on $k$ folds, validate on separate test data.

<details>

1. æ¯æ¬¡è¿­ä»£éƒ½åœ¨ kâˆ’1 ä¸ªå­é›†ä¸Šè®­ç»ƒï¼Œåœ¨å‰©ä¸‹ 1 ä¸ªå­é›†ä¸ŠéªŒè¯

</details>

15. What is the Bayes Error Rate?

    - Maximum possible error.
    - Theoretical minimum error.
    - Error of the Bayes classifier on training data.
    - Error when using nearest neighbors.

<details>

2. ç†è®ºæœ€å°é”™è¯¯ç‡

</details>

16. What does the ROC AUC score measure in a classification model?

    - The proportion of correctly predicted labels for each class.
    - The trade-off between true positive rate and false positive rate across all thresholds.
    - The accuracy of the model at a specific threshold.

<details>

2. ROC AUC è¡¡é‡æ¨¡å‹åœ¨æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»é˜ˆå€¼ä¸‹ï¼ŒçœŸæ­£ç‡ï¼ˆTPRï¼‰ä¸å‡æ­£ç‡ï¼ˆFPRï¼‰ä¹‹é—´çš„æƒè¡¡è¡¨ç°ã€‚AUC å€¼è¶Šé«˜ï¼Œè¯´æ˜æ¨¡å‹åœ¨åŒºåˆ†æ­£è´Ÿæ ·æœ¬ä¸Šçš„èƒ½åŠ›è¶Šå¼ºã€‚

</details>

17. What is the main goal of cross-validation?

    - Reduce training time.
    - Reduce the number of parameters.
    - Estimate model performance on unseen data.
    - Maximize feature usage.

<details>

3. é€šè¿‡å¤šæ¬¡åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„è¡¨ç°

</details>

18. Which task is best framed as a classification problem?

    - Forecasting daily closing prices of a stock.
    - Mapping images of digits to numerical labels.
    - Predicting average monthly rainfall in mm.
    - Estimating a carâ€™s resale value based on mileage.

<details>

2. å°†å›¾åƒåˆ†ä¸ºç¦»æ•£çš„ç±»åˆ«

</details>

19. Why might the F1-score be misleading on an imbalanced dataset?
    - It only considers the majority class.
    - It is undefined when recall is 1.
    - It assumes equal importance of precision and recall.
    - It does not account for true negatives.

<details>

3. å®ƒå¹³å‡è€ƒè™‘äº† Precision å’Œ Recallï¼Œæ— æ³•ä½“ç°å®é™…ä»»åŠ¡ä¸­çš„åé‡éœ€æ±‚ã€‚

</details>
