---
title: NLP-PreExamC
toc: true
categories:
  - [AI, NLP]
tags: [笔记, AI, NLP]
date: 2024-12-15 16:01:40
---

~~TDK 演讲忙的我似乎拼好饭中毒~~

<!-- more -->

# C1 自监督学习理论与仅文本对比模型

通过未标注的数据进行学习，给数据打标签，学习其特征

## 基于能量的建模

假设数据分布能由一个能力函数表示，能量越低，数据越真实

目标是通过优化能量函数，使模型能分辨真实数据与生成的负样本

## 对比学习

1. 生成正负样本对
   正：原始数据和它的变换，比如旋转、裁剪、翻转
   负：原始数据和其他随机数据，比如猫和狗

2. 距离函数
   用来衡量两个样本之间的相似度，比如欧式距离、Cosine Similarity

3. 拟合
   通过最小化正样本距离和最大化负样本距离，来拟合模型

对比学习就是“找相似”和“区分不同”的过程，让模型学会在没有明确标签的情况下提取有意义的特征

## 基于距离的损失函数

- Pair Loss
  相似样本距离更小，不相似的距离会大于某个阈值

- Triplet Loss
  三元组：Anchor、Positive、Negative  
  锚点和正样本要尽量靠近  
  锚点和负样本之间至少要有一个 安全距离

## NCE

Noise Contrastive Estimation 将概率估计问题转化为一个分类问题

模型的任务是区分哪些是真实数据，哪些是噪声数据

## InfoNCE

损失函数，让相似的样本靠近，不相似的样本远离

## 负采样示例

正样本：一张猫的图片和猫的裁剪版。  
负样本：一张猫的图片和狗的裁剪版。

## 标签监督的对比学习

将监督学习引入对比学习，损失函数通常基于扩展的 InfoNCE

## 对比学习中的不变性与协变性特征

Invariance：对于输入的变换，如旋转缩放，输出保持不变

Covariance：捕捉输入数据中有意义的变化，比如几何关系，输出也会变化

## 仅文本模型中的对比学习

Word2Vec 中，将 Skip-gram 看作是一个使用多个编码器来生成词嵌入的自监督学习任务

我们可以将上下文词和中心词分别看作是由不同的编码器生成的嵌入表示

BERT 下一句预测 也是一个对比学习任务

# C2 多模态对比学习与解码方法

## CLIP

收集 图像/文本 对，然后用 (ResNet/ViT) / Transformer 嵌入

随后通过对比学习，如InfoNCE，训练模型

## 多模态系统中涌现的模态连接

不同模态（如图像、文本、音频等）之间的关联和相互作用

- 通过训练，使得不同模态的数据在同一个向量空间中表示
- 通过对齐机制，使得不同模态的数据能够相互对应
- 跨模态注意力

## 迭代解码

iterative 在生成过程中，中间文本输出被迭代地编码到联合 CLIP 空间，然后用于下一次生成

不准确（无指导），效率低

## 前缀解码

prefix decoder 使用 seq2seq，结合 CLIP 和 LM （GPT），需要一个映射网络来对齐

## 零样本解码

zero-shot 使用 仅文本前缀微调解码器，且替换 CLIP 空间映射

## 对比描述生成器

Contrastive Captioner 使用预训练编码器，并训练解码器

使用图像编码，和文本编码，通过对比学习生成描述

# C3 视觉标记化与变分自编码器

将图像数据转换为离散标记（tokens）的技术

## Patching

将图像分割成较小块（patches）可以更容易地处理和分析图像数据

- 对每个小块进行独立分类
- 学习图像的局部特征

## 连续切片嵌入方法

- 将高维数据沿不同方向进行切片，生成一系列低维切片
- 对每个切片进行特征提取
- 将特征嵌入到一个低维空间中
- 调整嵌入，使其更适合特定任务

## 变分定理（含义、相关损失函数、与 MLE 的关系）

Variational Theorem 是用一个简单的分布来近似一个复杂的分布

使用 evidence lower bound 作为损失函数

通过最大化 ELBO 来近似最大化对数边际似然，从而实现参数估计

## 变分自编码器

Variational Autoencoder 是一种生成模型，通过学习数据的潜在表示来生成新的数据

它首先将输入数据编码为潜在空间中的分布，然后从该分布中采样，最后解码为原始数据

它的损失函数是由 Reconstruction Error 和 KL Divergence 组成的

## dVAE

Discrete VAE 的潜在表示是离散的

## VQ-VAE

Vector Quantized VAE 同样使用离散的潜在表示

将连续的潜在空间离散化，通过 矢量量化 将潜在表示映射到一个固定的离散 codebook 中

# C4 视觉变压器与视觉-语言模型

## 编码器式视觉变压器（ViT）

- patches，变成向量
- position encoding
- linear embedding，将每个小块映射到一个高维空间
- transformer encoder，处理序列，捕捉不同的依赖关系和特征
- classification head，用于分类

它能够很好地捕捉图像中不同部分之间的全局关系

## 使用不同输入分辨率的 ViT

使用 SWIN，基于 Shifted Window 的 Transformer，能够使用多种分辨率级别处理任意大小的图像

将输入图像逐层处理。每一层的特征图尺寸逐渐减小，通道数逐渐增加

## 切片合并

将特征图的多个小块（patches）合并成一个更大的块，从而减少特征图的分辨率并增加通道数

合并操作通常通过拼接或平均池化等方法实现，随后进行线性变化，映射到更高维的空间

## 窗口化注意力

通过在局部窗口内计算自注意力，显著降低了计算复杂度

在相邻层之间引入了窗口平移操作，使得模型能够更好地捕捉图像中的长距离依赖关系

## 完整堆栈的视觉-语言模型（如 TrOCR）

TrOCR 使用 vision transformer 作为编码器，text transformer 作为解码器，执行 OCR 任务

## 编码器-前缀-解码器模型（如 LLaVa）

结合了视觉和语言处理能力，能够从图像中提取信息并生成相应的文本描述

使用 视觉编码器（ViT） 输出的 特征向量 生成一个前缀序列

语言解码器 将前缀序列和文本提示（如问题或上下文）结合起来，生成相应的文本输出

## 具有模态专家的视觉-语言模型

引入专门处理不同模态（如图像和文本）的专家模块，比如 GPT，来提高模型的性能和灵活性

# C5 文本到图像方法

## T2I GANs

Text-to-Image Generative Adversarial Networks

生成器试图生成逼真的图像，而判别器试图区分这些图像是真实的还是生成的。

它还会检查生成的图像是否与输入的文本描述一致。

## T2I VAEs

DALL-E 是基于 transformer 的自回归模型

首先使用 ResNet 风格的 dVAE， ELBO 训练。然后用 transformer 解码器生成图像。

## 扩散的目标

Diffusion 通过逐步添加和去除噪声来生成图像

## DDPM（图模型、ELBO、简化损失、不足、插值）

Denoising Diffusion Probabilistic Models

正向扩散 从噪声开始，逐渐生成图像

反向扩散 从图像开始，逐渐生成噪声

ELBO（evidence lower bound ），旨在最大化数据的对数似然

简化的损失函数，直接衡量每一步去噪的误差

由于需要逐步去噪，生成图像的过程计算成本较高

插值是指在两个图像之间生成过渡图像，实现平滑的图像变换

## DDIM（图模型、与 DDPM 的关系、x0 预测的作用、简化损失、加速生成）

Denoising Diffusion Implicit Models

DDIM 和 DDPM 都基于扩散过程和去噪过程来生成图像。

DDIM 使用 non-Markovian chain 的方式，每一步的去噪过程不再依赖于前一步的结果

DDIM 采用确定性采样方法，而不是随机采样。这使得生成过程更加稳定和可控

在每一步去噪过程中，通过直接预测原始图像 x0 来指导每一步的去噪操作

# C6 潜在扩散模型的应用与扩展

## 分类器引导

## 无分类器引导

## 潜在扩散模型（编码到潜在空间、扩散过程、条件化方法、从潜在空间解码）

## 多阶段网络

## 条件上采样

## 修补

## 适应方法（文本逆转、适配器、ControlNets、控制适配器、潜在一致性建模）

# C7 视觉-语言-行动模型

## 视觉-语言导航

## 视觉-语言-行动模型

## VLA 模型与 VL 模型的关联

## VLN 和 VLA 任务所需的数据集

# C8 语音转文本处理

## STT 任务定义

## 语音信号处理（采样、傅里叶变换、梅尔频谱）

## 声学建模

## 语言模型与声学模型的结合

## 连接时序分类
